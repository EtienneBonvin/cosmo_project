{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating data using deep learning\n",
    "\n",
    "Note that for this approach we based ourselves on the Standford lecture notes on convolutional neural networks for visual recognition.\n",
    "\n",
    "This lecture is open source and can be found on http://cs231n.github.io/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Clean up the memory\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "\n",
    "import crowd\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "SESSION_FOLDER = \"session/\"\n",
    "\n",
    "TRAIN_SET_PERC = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, real, loop = True):\n",
    "    '''\n",
    "    Computes RMSE between predictions and real values\n",
    "    :param : float[]\n",
    "    :param : float[]\n",
    "    :return : float\n",
    "    '''\n",
    "    if len(pred) != len(real):\n",
    "        print(\"RMSE Error : Predictions and real values arrays do not have the same length, aborting.\")\n",
    "        return None\n",
    "    \n",
    "    if loop:\n",
    "        mse = 0\n",
    "        for i in range(len(pred)):\n",
    "            mse += (pred[i] - real[i])**2\n",
    "        return math.sqrt(mse/len(pred))\n",
    "    else:\n",
    "        # The creation of the array may produce memory error\n",
    "        err = pred - real\n",
    "        mse = err.T @ err\n",
    "        return math.sqrt(2 * mse / len(pred))\n",
    "    \n",
    "    \n",
    "def basic_error(pred, real):\n",
    "    '''\n",
    "    Compute basic error. Used to notify bias.\n",
    "    :param : float[]\n",
    "    :param : float[]\n",
    "    :return : float\n",
    "    '''\n",
    "    err = 0\n",
    "    for i in range(len(pred)):\n",
    "        err += (pred[i][0][0] - real[i])\n",
    "    return err\n",
    "    \n",
    "    \n",
    "def build_poly(X, degree):\n",
    "    poly = np.ones((len(X), 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        poly = np.c_[poly, np.power(X, deg)]\n",
    "    return poly[:, 1:]\n",
    "\n",
    "def garbage_collection():\n",
    "    '''\n",
    "    Calls garbage collection to clean unused memory\n",
    "    '''\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    '''\n",
    "    Plots the history of the training error\n",
    "    Usefull \n",
    "    '''\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use non normalized feature matrix\n",
    "# For now best results are given with this one\n",
    "#X = np.load(DATA_FOLDER + \"feature_mat_radial_compression.npy\")\n",
    "\n",
    "# Use normalized feature matrix\n",
    "################################################################################################\n",
    "# Careful                                                                                      #\n",
    "# Normally, normalisation should be done one each train/val/test matrices. It is not done here #\n",
    "################################################################################################\n",
    "X = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test set\n",
    "\n",
    "train_set_size = int(len(X) * TRAIN_SET_PERC)\n",
    "X_train = X[: train_set_size]\n",
    "X_test = X[train_set_size:]\n",
    "y_train = y[: train_set_size]\n",
    "y_test = y[train_set_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (30049, 15961)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \" + str(X.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single neural network model approach\n",
    "\n",
    "First we will do a single model approach, the goal is to see quickly how we can build a model using neural networks and how well it does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Number of layers and neurons doesn't really matter, we need as much as possible.\n",
    "    # We well take care of overfitting with regularizers.\n",
    "    # We chose relu activation (relative usual choice when working on regression)\n",
    "    # We add L2 regularizers on hidden layers to avoid overfitting the data. Threshold should be tuned.\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 16.2263 - mean_absolute_error: 2.3938 - val_loss: 6.2262 - val_mean_absolute_error: 1.8358\n",
      "Epoch 2/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 3.2662 - mean_absolute_error: 1.3039 - val_loss: 4.0006 - val_mean_absolute_error: 1.4015\n",
      "Epoch 3/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 1.8035 - mean_absolute_error: 0.9428 - val_loss: 4.2133 - val_mean_absolute_error: 1.4561\n",
      "Epoch 4/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 1.7472 - mean_absolute_error: 0.9308 - val_loss: 3.5445 - val_mean_absolute_error: 1.3147\n",
      "Epoch 5/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 1.4083 - mean_absolute_error: 0.8200 - val_loss: 3.1718 - val_mean_absolute_error: 1.2550\n",
      "Epoch 6/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.9822 - mean_absolute_error: 0.6464 - val_loss: 2.8547 - val_mean_absolute_error: 1.2234\n",
      "Epoch 7/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.7532 - mean_absolute_error: 0.5284 - val_loss: 1.6163 - val_mean_absolute_error: 0.8387\n",
      "Epoch 8/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.6380 - mean_absolute_error: 0.4690 - val_loss: 1.7268 - val_mean_absolute_error: 0.9506\n",
      "Epoch 9/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.6413 - mean_absolute_error: 0.4633 - val_loss: 1.3230 - val_mean_absolute_error: 0.7415\n",
      "Epoch 10/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 1.0058 - mean_absolute_error: 0.5477 - val_loss: 1.2332 - val_mean_absolute_error: 0.7133\n",
      "Epoch 11/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.5902 - mean_absolute_error: 0.4079 - val_loss: 1.1017 - val_mean_absolute_error: 0.6778\n",
      "Epoch 12/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.6531 - mean_absolute_error: 0.4508 - val_loss: 0.9402 - val_mean_absolute_error: 0.5992\n",
      "Epoch 13/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.5837 - mean_absolute_error: 0.3987 - val_loss: 1.1087 - val_mean_absolute_error: 0.6789\n",
      "Epoch 14/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.6055 - mean_absolute_error: 0.4121 - val_loss: 1.1925 - val_mean_absolute_error: 0.6696\n",
      "Epoch 15/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.6412 - mean_absolute_error: 0.4260 - val_loss: 0.9671 - val_mean_absolute_error: 0.5941\n",
      "Epoch 16/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.5682 - mean_absolute_error: 0.3909 - val_loss: 0.9031 - val_mean_absolute_error: 0.5809\n",
      "Epoch 17/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.5491 - mean_absolute_error: 0.3745 - val_loss: 0.8629 - val_mean_absolute_error: 0.5548\n",
      "Epoch 18/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.6261 - mean_absolute_error: 0.3981 - val_loss: 0.8705 - val_mean_absolute_error: 0.5569\n",
      "Epoch 19/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.5072 - mean_absolute_error: 0.3575 - val_loss: 0.8613 - val_mean_absolute_error: 0.5617\n",
      "Epoch 20/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.5018 - mean_absolute_error: 0.3553 - val_loss: 0.7478 - val_mean_absolute_error: 0.5213\n",
      "Epoch 21/200\n",
      "24339/24339 [==============================] - 38s 2ms/step - loss: 0.4505 - mean_absolute_error: 0.3590 - val_loss: 0.7303 - val_mean_absolute_error: 0.5263\n",
      "Epoch 22/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.4143 - mean_absolute_error: 0.3378 - val_loss: 0.8341 - val_mean_absolute_error: 0.5996\n",
      "Epoch 23/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.3978 - mean_absolute_error: 0.3332 - val_loss: 0.6541 - val_mean_absolute_error: 0.5093\n",
      "Epoch 24/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.3751 - mean_absolute_error: 0.3251 - val_loss: 0.7203 - val_mean_absolute_error: 0.5365\n",
      "Epoch 25/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.4049 - mean_absolute_error: 0.3355 - val_loss: 0.8044 - val_mean_absolute_error: 0.5754\n",
      "Epoch 26/200\n",
      "24339/24339 [==============================] - 37s 2ms/step - loss: 0.3539 - mean_absolute_error: 0.3089 - val_loss: 0.6578 - val_mean_absolute_error: 0.5158\n",
      "Epoch 27/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.3337 - mean_absolute_error: 0.3106 - val_loss: 0.7845 - val_mean_absolute_error: 0.5752\n",
      "Epoch 28/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.3393 - mean_absolute_error: 0.3081 - val_loss: 0.6603 - val_mean_absolute_error: 0.5195\n",
      "Epoch 29/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.3245 - mean_absolute_error: 0.3094 - val_loss: 0.7355 - val_mean_absolute_error: 0.5460\n",
      "Epoch 30/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.3205 - mean_absolute_error: 0.2984 - val_loss: 0.6860 - val_mean_absolute_error: 0.5557\n",
      "Epoch 31/200\n",
      "24339/24339 [==============================] - 40s 2ms/step - loss: 0.3256 - mean_absolute_error: 0.3047 - val_loss: 0.6606 - val_mean_absolute_error: 0.5174\n",
      "Epoch 32/200\n",
      "24339/24339 [==============================] - 37s 2ms/step - loss: 0.2948 - mean_absolute_error: 0.2879 - val_loss: 0.6690 - val_mean_absolute_error: 0.5211\n",
      "Epoch 33/200\n",
      "24339/24339 [==============================] - 39s 2ms/step - loss: 0.2970 - mean_absolute_error: 0.2843 - val_loss: 0.6379 - val_mean_absolute_error: 0.5156\n",
      "Epoch 34/200\n",
      "24339/24339 [==============================] - 40s 2ms/step - loss: 0.2931 - mean_absolute_error: 0.2907 - val_loss: 0.6759 - val_mean_absolute_error: 0.5334\n",
      "Epoch 35/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2864 - mean_absolute_error: 0.2872 - val_loss: 0.8213 - val_mean_absolute_error: 0.5945\n",
      "Epoch 36/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.3080 - mean_absolute_error: 0.2903 - val_loss: 0.6526 - val_mean_absolute_error: 0.5189\n",
      "Epoch 37/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2936 - mean_absolute_error: 0.2863 - val_loss: 0.7532 - val_mean_absolute_error: 0.5499\n",
      "Epoch 38/200\n",
      "24339/24339 [==============================] - 29s 1ms/step - loss: 0.2953 - mean_absolute_error: 0.2876 - val_loss: 0.6534 - val_mean_absolute_error: 0.5130\n",
      "Epoch 39/200\n",
      "24339/24339 [==============================] - 36s 1ms/step - loss: 0.3182 - mean_absolute_error: 0.2898 - val_loss: 0.6356 - val_mean_absolute_error: 0.5121\n",
      "Epoch 40/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2631 - mean_absolute_error: 0.2730 - val_loss: 0.6493 - val_mean_absolute_error: 0.5156\n",
      "Epoch 41/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.3078 - mean_absolute_error: 0.2886 - val_loss: 0.7755 - val_mean_absolute_error: 0.5807\n",
      "Epoch 42/200\n",
      "24339/24339 [==============================] - 37s 2ms/step - loss: 0.2728 - mean_absolute_error: 0.2687 - val_loss: 0.6954 - val_mean_absolute_error: 0.5628\n",
      "Epoch 43/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2728 - mean_absolute_error: 0.2744 - val_loss: 0.6116 - val_mean_absolute_error: 0.5099\n",
      "Epoch 44/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2520 - mean_absolute_error: 0.2633 - val_loss: 0.6216 - val_mean_absolute_error: 0.5055\n",
      "Epoch 45/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2637 - mean_absolute_error: 0.2696 - val_loss: 0.7737 - val_mean_absolute_error: 0.6197\n",
      "Epoch 46/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2471 - mean_absolute_error: 0.2690 - val_loss: 0.6230 - val_mean_absolute_error: 0.5164\n",
      "Epoch 47/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.3048 - mean_absolute_error: 0.2866 - val_loss: 0.6951 - val_mean_absolute_error: 0.5434\n",
      "Epoch 48/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.2303 - mean_absolute_error: 0.2493 - val_loss: 0.6046 - val_mean_absolute_error: 0.5190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2332 - mean_absolute_error: 0.2662 - val_loss: 0.6181 - val_mean_absolute_error: 0.5156\n",
      "Epoch 50/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.2462 - mean_absolute_error: 0.2666 - val_loss: 0.5834 - val_mean_absolute_error: 0.4958\n",
      "Epoch 51/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2626 - mean_absolute_error: 0.2700 - val_loss: 0.6383 - val_mean_absolute_error: 0.5298\n",
      "Epoch 52/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2387 - mean_absolute_error: 0.2609 - val_loss: 0.6260 - val_mean_absolute_error: 0.5193\n",
      "Epoch 53/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2534 - mean_absolute_error: 0.2679 - val_loss: 0.7373 - val_mean_absolute_error: 0.5672\n",
      "Epoch 54/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2392 - mean_absolute_error: 0.2541 - val_loss: 0.6180 - val_mean_absolute_error: 0.5061\n",
      "Epoch 55/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.2167 - mean_absolute_error: 0.2547 - val_loss: 0.6057 - val_mean_absolute_error: 0.5170\n",
      "Epoch 56/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.2207 - mean_absolute_error: 0.2554 - val_loss: 0.6085 - val_mean_absolute_error: 0.5143\n",
      "Epoch 57/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2359 - mean_absolute_error: 0.2661 - val_loss: 0.6436 - val_mean_absolute_error: 0.5293\n",
      "Epoch 58/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2169 - mean_absolute_error: 0.2506 - val_loss: 0.6402 - val_mean_absolute_error: 0.5248\n",
      "Epoch 59/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2213 - mean_absolute_error: 0.2618 - val_loss: 0.5848 - val_mean_absolute_error: 0.5069\n",
      "Epoch 60/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2135 - mean_absolute_error: 0.2528 - val_loss: 0.6369 - val_mean_absolute_error: 0.5199\n",
      "Epoch 61/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.2195 - mean_absolute_error: 0.2571 - val_loss: 0.6041 - val_mean_absolute_error: 0.5037\n",
      "Epoch 62/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2193 - mean_absolute_error: 0.2581 - val_loss: 0.6079 - val_mean_absolute_error: 0.5177\n",
      "Epoch 63/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2122 - mean_absolute_error: 0.2563 - val_loss: 0.5820 - val_mean_absolute_error: 0.5088\n",
      "Epoch 64/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2347 - mean_absolute_error: 0.2615 - val_loss: 0.6006 - val_mean_absolute_error: 0.5042\n",
      "Epoch 65/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2219 - mean_absolute_error: 0.2554 - val_loss: 0.5831 - val_mean_absolute_error: 0.5043\n",
      "Epoch 66/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1959 - mean_absolute_error: 0.2435 - val_loss: 0.5681 - val_mean_absolute_error: 0.5126\n",
      "Epoch 67/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.1909 - mean_absolute_error: 0.2416 - val_loss: 0.6328 - val_mean_absolute_error: 0.5310\n",
      "Epoch 68/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2136 - mean_absolute_error: 0.2573 - val_loss: 0.5824 - val_mean_absolute_error: 0.5037\n",
      "Epoch 69/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2052 - mean_absolute_error: 0.2529 - val_loss: 0.5619 - val_mean_absolute_error: 0.5012\n",
      "Epoch 70/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2023 - mean_absolute_error: 0.2523 - val_loss: 0.5683 - val_mean_absolute_error: 0.4953\n",
      "Epoch 71/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1965 - mean_absolute_error: 0.2471 - val_loss: 0.5831 - val_mean_absolute_error: 0.5194\n",
      "Epoch 72/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2034 - mean_absolute_error: 0.2531 - val_loss: 0.6741 - val_mean_absolute_error: 0.5551\n",
      "Epoch 73/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1982 - mean_absolute_error: 0.2460 - val_loss: 0.6421 - val_mean_absolute_error: 0.5437\n",
      "Epoch 74/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1968 - mean_absolute_error: 0.2460 - val_loss: 0.5914 - val_mean_absolute_error: 0.5165\n",
      "Epoch 75/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1990 - mean_absolute_error: 0.2498 - val_loss: 0.5744 - val_mean_absolute_error: 0.5016\n",
      "Epoch 76/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1803 - mean_absolute_error: 0.2357 - val_loss: 0.5592 - val_mean_absolute_error: 0.4956\n",
      "Epoch 77/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1927 - mean_absolute_error: 0.2504 - val_loss: 0.5857 - val_mean_absolute_error: 0.5103\n",
      "Epoch 78/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1916 - mean_absolute_error: 0.2483 - val_loss: 0.5946 - val_mean_absolute_error: 0.5198\n",
      "Epoch 79/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1980 - mean_absolute_error: 0.2526 - val_loss: 0.6112 - val_mean_absolute_error: 0.5236\n",
      "Epoch 80/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2006 - mean_absolute_error: 0.2514 - val_loss: 0.5573 - val_mean_absolute_error: 0.4972\n",
      "Epoch 81/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1844 - mean_absolute_error: 0.2380 - val_loss: 0.5463 - val_mean_absolute_error: 0.4918\n",
      "Epoch 82/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1821 - mean_absolute_error: 0.2413 - val_loss: 0.5964 - val_mean_absolute_error: 0.5232\n",
      "Epoch 83/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1865 - mean_absolute_error: 0.2433 - val_loss: 0.5576 - val_mean_absolute_error: 0.4971\n",
      "Epoch 84/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1820 - mean_absolute_error: 0.2384 - val_loss: 0.5561 - val_mean_absolute_error: 0.5038\n",
      "Epoch 85/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1853 - mean_absolute_error: 0.2459 - val_loss: 0.6114 - val_mean_absolute_error: 0.5239\n",
      "Epoch 86/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1956 - mean_absolute_error: 0.2508 - val_loss: 0.5809 - val_mean_absolute_error: 0.5108\n",
      "Epoch 87/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1939 - mean_absolute_error: 0.2511 - val_loss: 0.5912 - val_mean_absolute_error: 0.5154\n",
      "Epoch 88/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1784 - mean_absolute_error: 0.2376 - val_loss: 0.5700 - val_mean_absolute_error: 0.5078\n",
      "Epoch 89/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1898 - mean_absolute_error: 0.2457 - val_loss: 0.5670 - val_mean_absolute_error: 0.5093\n",
      "Epoch 90/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1803 - mean_absolute_error: 0.2396 - val_loss: 0.5564 - val_mean_absolute_error: 0.5028\n",
      "Epoch 91/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1761 - mean_absolute_error: 0.2375 - val_loss: 0.5721 - val_mean_absolute_error: 0.5104\n",
      "Epoch 92/200\n",
      "24339/24339 [==============================] - 36s 1ms/step - loss: 0.1812 - mean_absolute_error: 0.2425 - val_loss: 0.5921 - val_mean_absolute_error: 0.5146\n",
      "Epoch 93/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2036 - mean_absolute_error: 0.2597 - val_loss: 0.5486 - val_mean_absolute_error: 0.4927\n",
      "Epoch 94/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1754 - mean_absolute_error: 0.2297 - val_loss: 0.5646 - val_mean_absolute_error: 0.4966\n",
      "Epoch 95/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1738 - mean_absolute_error: 0.2328 - val_loss: 0.5893 - val_mean_absolute_error: 0.5087\n",
      "Epoch 96/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1862 - mean_absolute_error: 0.2442 - val_loss: 0.6873 - val_mean_absolute_error: 0.5700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1789 - mean_absolute_error: 0.2405 - val_loss: 0.6396 - val_mean_absolute_error: 0.5494\n",
      "Epoch 98/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1754 - mean_absolute_error: 0.2384 - val_loss: 0.5826 - val_mean_absolute_error: 0.5109\n",
      "Epoch 99/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1846 - mean_absolute_error: 0.2464 - val_loss: 0.6068 - val_mean_absolute_error: 0.5251\n",
      "Epoch 100/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1732 - mean_absolute_error: 0.2346 - val_loss: 0.5752 - val_mean_absolute_error: 0.4983\n",
      "Epoch 101/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1945 - mean_absolute_error: 0.2554 - val_loss: 0.5877 - val_mean_absolute_error: 0.5083\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  4086272   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  257       \n",
      "=================================================================\n",
      "Total params: 4,547,073\n",
      "Trainable params: 4,547,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We train the model on our data\n",
    "# Number of epochs the network should run through\n",
    "EPOCHS = 200\n",
    "# Size of the batch for optimization\n",
    "BATCH_SIZE = 32\n",
    "# Set up validation split\n",
    "VALIDATION_SPLIT = 0.1\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "# This will avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6604633181447641"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_test, batch_size=32)\n",
    "rmse(result, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "For the following model :\n",
    "    - 4 hidden layers of 64 neurons - relu activation.\n",
    "    - A result layer of 1 neuron - relu activation.\n",
    "    - Early stopping callback\n",
    "    - Test split of 0.2\n",
    "    - Using AdamOptimizer gives best results.\n",
    "    - No cross validation.\n",
    "    \n",
    "Network size :\n",
    "- $4*64 + 1 = 257$ neurons (biases)\n",
    "- $30049*64 + 64*64 + 64*64 + 64 = 1931392$ weights\n",
    "- Total of $1931649$ learnable parameters (almost 2 millions)\n",
    "\n",
    "With the above, we reached a RMSE of 0.5. But this is without separating the data into train and test set. This can lead to overfitting. Now we need to ensure that we are not overfitting.\n",
    "\n",
    "For this we will test 2 solutions :\n",
    "\n",
    "### Change our implementation to add regulizer that will avoid this overfitting\n",
    "\n",
    "### Cross validation over multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi neural network approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 3004)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized_red.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")\n",
    "X_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(X_red) * TRAIN_SET_PERC)\n",
    "\n",
    "# Select random rows of the matrix for train / test set\n",
    "# Random seed for reproducibility \n",
    "np.random.seed(100)\n",
    "train_idx = np.random.choice(len(X_red), size=train_set_size, replace = False)\n",
    "test_idx = [i for i in range(len(X_red)) if i not in train_idx]\n",
    "X_train_red = X_red[train_idx, :]\n",
    "X_test_red = X_red[test_idx, :]\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_red: (30049, 3004)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_red: \" + str(X_red.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No directory with name session/DNN_Crowd_8_128_relu_0.01_0.001_mse\n"
     ]
    }
   ],
   "source": [
    "crowd01 = crowd.Crowd(X_train_red, y_train, \"DNN_Crowd\")\n",
    "crowd01.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 30.5333 - mean_absolute_error: 2.9565\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 6s 314us/step - loss: 30.4944 - mean_absolute_error: 2.9535 - val_loss: 17.4383 - val_mean_absolute_error: 2.5045\n",
      "Epoch 2/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 12.0771 - mean_absolute_error: 1.5979\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 12.0425 - mean_absolute_error: 1.5925 - val_loss: 9.3693 - val_mean_absolute_error: 1.2459\n",
      "Epoch 3/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 7.3729 - mean_absolute_error: 0.8543\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 7.3576 - mean_absolute_error: 0.8529 - val_loss: 6.6759 - val_mean_absolute_error: 0.8854\n",
      "Epoch 4/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 5.3530 - mean_absolute_error: 0.5650\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 5.3483 - mean_absolute_error: 0.5646 - val_loss: 5.0313 - val_mean_absolute_error: 0.6307\n",
      "Epoch 5/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 4.3251 - mean_absolute_error: 0.5476\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 4.3207 - mean_absolute_error: 0.5484 - val_loss: 4.1152 - val_mean_absolute_error: 0.6205\n",
      "Epoch 6/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 3.5791 - mean_absolute_error: 0.5775\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 3.5760 - mean_absolute_error: 0.5783 - val_loss: 3.3470 - val_mean_absolute_error: 0.6041\n",
      "Epoch 7/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 2.8561 - mean_absolute_error: 0.5346\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 2.8530 - mean_absolute_error: 0.5351 - val_loss: 2.6901 - val_mean_absolute_error: 0.5705\n",
      "Epoch 8/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 2.3954 - mean_absolute_error: 0.5406\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 2.3943 - mean_absolute_error: 0.5405 - val_loss: 2.3943 - val_mean_absolute_error: 0.5842\n",
      "Epoch 9/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 2.1254 - mean_absolute_error: 0.5487\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 2.1246 - mean_absolute_error: 0.5485 - val_loss: 2.1288 - val_mean_absolute_error: 0.6371\n",
      "Epoch 10/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.7905 - mean_absolute_error: 0.5320\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 1.7898 - mean_absolute_error: 0.5317 - val_loss: 1.8579 - val_mean_absolute_error: 0.6189\n",
      "Epoch 11/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.5336 - mean_absolute_error: 0.5179\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 1.5318 - mean_absolute_error: 0.5174 - val_loss: 1.4978 - val_mean_absolute_error: 0.5161\n",
      "Epoch 12/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.4269 - mean_absolute_error: 0.5358\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 1.4262 - mean_absolute_error: 0.5356 - val_loss: 1.3920 - val_mean_absolute_error: 0.5250\n",
      "Epoch 13/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 1.2767 - mean_absolute_error: 0.5165\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 1.2769 - mean_absolute_error: 0.5169 - val_loss: 1.3184 - val_mean_absolute_error: 0.5325\n",
      "Epoch 14/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.2457 - mean_absolute_error: 0.5325\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 1.2453 - mean_absolute_error: 0.5323 - val_loss: 1.2362 - val_mean_absolute_error: 0.5110\n",
      "Epoch 15/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.1642 - mean_absolute_error: 0.5243\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 1.1652 - mean_absolute_error: 0.5248 - val_loss: 1.5939 - val_mean_absolute_error: 0.7763\n",
      "Epoch 16/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 1.0536 - mean_absolute_error: 0.4858\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 1.0543 - mean_absolute_error: 0.4856 - val_loss: 1.1606 - val_mean_absolute_error: 0.5321\n",
      "Epoch 17/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 1.0193 - mean_absolute_error: 0.4828\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 1.0186 - mean_absolute_error: 0.4823 - val_loss: 1.0722 - val_mean_absolute_error: 0.4996\n",
      "Epoch 18/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.9848 - mean_absolute_error: 0.4817\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.9859 - mean_absolute_error: 0.4824 - val_loss: 1.2596 - val_mean_absolute_error: 0.6285\n",
      "Epoch 19/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.9369 - mean_absolute_error: 0.4710\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.9371 - mean_absolute_error: 0.4709 - val_loss: 1.2395 - val_mean_absolute_error: 0.6633\n",
      "Epoch 20/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.8895 - mean_absolute_error: 0.4617\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.8895 - mean_absolute_error: 0.4617 - val_loss: 0.9713 - val_mean_absolute_error: 0.4967\n",
      "Epoch 21/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.8187 - mean_absolute_error: 0.4398\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.8189 - mean_absolute_error: 0.4400 - val_loss: 1.1555 - val_mean_absolute_error: 0.6511\n",
      "Epoch 22/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.8493 - mean_absolute_error: 0.4583\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.8501 - mean_absolute_error: 0.4586 - val_loss: 0.8828 - val_mean_absolute_error: 0.4509\n",
      "Epoch 23/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.7836 - mean_absolute_error: 0.4363\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.7833 - mean_absolute_error: 0.4360 - val_loss: 0.8878 - val_mean_absolute_error: 0.4812\n",
      "Epoch 24/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7774 - mean_absolute_error: 0.4317\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.7780 - mean_absolute_error: 0.4324 - val_loss: 1.2175 - val_mean_absolute_error: 0.7013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7345 - mean_absolute_error: 0.4307\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.7360 - mean_absolute_error: 0.4313 - val_loss: 1.0370 - val_mean_absolute_error: 0.5749\n",
      "Epoch 26/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.7434 - mean_absolute_error: 0.4241\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.7434 - mean_absolute_error: 0.4241 - val_loss: 0.8503 - val_mean_absolute_error: 0.4718\n",
      "Epoch 27/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.7319 - mean_absolute_error: 0.4322\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.7316 - mean_absolute_error: 0.4320 - val_loss: 0.8047 - val_mean_absolute_error: 0.4461\n",
      "Epoch 28/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6561 - mean_absolute_error: 0.4113\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.6569 - mean_absolute_error: 0.4117 - val_loss: 0.7187 - val_mean_absolute_error: 0.4376\n",
      "Epoch 29/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6844 - mean_absolute_error: 0.4357\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.6855 - mean_absolute_error: 0.4360 - val_loss: 0.7853 - val_mean_absolute_error: 0.4579\n",
      "Epoch 30/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.6706 - mean_absolute_error: 0.4218\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.6707 - mean_absolute_error: 0.4220 - val_loss: 0.7571 - val_mean_absolute_error: 0.4615\n",
      "Epoch 31/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6457 - mean_absolute_error: 0.4094\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.6454 - mean_absolute_error: 0.4092 - val_loss: 0.6983 - val_mean_absolute_error: 0.4370\n",
      "Epoch 32/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6434 - mean_absolute_error: 0.4175\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.6446 - mean_absolute_error: 0.4182 - val_loss: 0.7489 - val_mean_absolute_error: 0.4453\n",
      "Epoch 33/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6246 - mean_absolute_error: 0.4077\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.6247 - mean_absolute_error: 0.4078 - val_loss: 0.7723 - val_mean_absolute_error: 0.5005\n",
      "Epoch 34/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6234 - mean_absolute_error: 0.4140\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.6233 - mean_absolute_error: 0.4139 - val_loss: 0.7527 - val_mean_absolute_error: 0.4661\n",
      "Epoch 35/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6073 - mean_absolute_error: 0.4038\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.6067 - mean_absolute_error: 0.4034 - val_loss: 0.7020 - val_mean_absolute_error: 0.4474\n",
      "Epoch 36/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6025 - mean_absolute_error: 0.4127\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.6019 - mean_absolute_error: 0.4123 - val_loss: 0.7007 - val_mean_absolute_error: 0.4558\n",
      "Epoch 37/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6153 - mean_absolute_error: 0.4129\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.6153 - mean_absolute_error: 0.4130 - val_loss: 0.7009 - val_mean_absolute_error: 0.4458\n",
      "Epoch 38/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6017 - mean_absolute_error: 0.4103\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.6016 - mean_absolute_error: 0.4104 - val_loss: 0.7212 - val_mean_absolute_error: 0.4809\n",
      "Epoch 39/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6009 - mean_absolute_error: 0.4099\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.6008 - mean_absolute_error: 0.4097 - val_loss: 0.6818 - val_mean_absolute_error: 0.4280\n",
      "Epoch 40/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5726 - mean_absolute_error: 0.3977\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5730 - mean_absolute_error: 0.3980 - val_loss: 0.6708 - val_mean_absolute_error: 0.4443\n",
      "Epoch 41/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.5913 - mean_absolute_error: 0.4066\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5915 - mean_absolute_error: 0.4066 - val_loss: 0.6772 - val_mean_absolute_error: 0.4192\n",
      "Epoch 42/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5642 - mean_absolute_error: 0.3890\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 0.5642 - mean_absolute_error: 0.3890 - val_loss: 0.6458 - val_mean_absolute_error: 0.4286\n",
      "Epoch 43/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5620 - mean_absolute_error: 0.3947\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5621 - mean_absolute_error: 0.3947 - val_loss: 0.6630 - val_mean_absolute_error: 0.4334\n",
      "Epoch 44/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5834 - mean_absolute_error: 0.4097\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5842 - mean_absolute_error: 0.4100 - val_loss: 0.6793 - val_mean_absolute_error: 0.4414\n",
      "Epoch 45/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5701 - mean_absolute_error: 0.3988\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5698 - mean_absolute_error: 0.3986 - val_loss: 0.7090 - val_mean_absolute_error: 0.4862\n",
      "Epoch 46/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5567 - mean_absolute_error: 0.3940\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5566 - mean_absolute_error: 0.3940 - val_loss: 0.6786 - val_mean_absolute_error: 0.4433\n",
      "Epoch 47/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5625 - mean_absolute_error: 0.3992\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5636 - mean_absolute_error: 0.4002 - val_loss: 0.8410 - val_mean_absolute_error: 0.5860\n",
      "Epoch 48/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5568 - mean_absolute_error: 0.3967\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5569 - mean_absolute_error: 0.3968 - val_loss: 0.6250 - val_mean_absolute_error: 0.4273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5678 - mean_absolute_error: 0.4034\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5676 - mean_absolute_error: 0.4033 - val_loss: 0.6796 - val_mean_absolute_error: 0.4398\n",
      "Epoch 50/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5679 - mean_absolute_error: 0.3977\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5681 - mean_absolute_error: 0.3980 - val_loss: 0.6230 - val_mean_absolute_error: 0.4270\n",
      "Epoch 51/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5502 - mean_absolute_error: 0.3939\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5512 - mean_absolute_error: 0.3944 - val_loss: 0.6670 - val_mean_absolute_error: 0.4651\n",
      "Epoch 52/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5482 - mean_absolute_error: 0.3945\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5490 - mean_absolute_error: 0.3948 - val_loss: 0.6900 - val_mean_absolute_error: 0.4740\n",
      "Epoch 53/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5901 - mean_absolute_error: 0.4123\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5900 - mean_absolute_error: 0.4120 - val_loss: 0.7321 - val_mean_absolute_error: 0.4939\n",
      "Epoch 54/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.5683 - mean_absolute_error: 0.4022\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.5681 - mean_absolute_error: 0.4022 - val_loss: 0.6666 - val_mean_absolute_error: 0.4618\n",
      "Epoch 55/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5320 - mean_absolute_error: 0.3853\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5324 - mean_absolute_error: 0.3856 - val_loss: 0.7799 - val_mean_absolute_error: 0.5167\n",
      "Epoch 56/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5495 - mean_absolute_error: 0.3955\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5499 - mean_absolute_error: 0.3959 - val_loss: 0.6562 - val_mean_absolute_error: 0.4453\n",
      "Epoch 57/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5597 - mean_absolute_error: 0.3961\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.5595 - mean_absolute_error: 0.3960 - val_loss: 0.6645 - val_mean_absolute_error: 0.4508\n",
      "Epoch 58/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5275 - mean_absolute_error: 0.3797\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5276 - mean_absolute_error: 0.3797 - val_loss: 0.6420 - val_mean_absolute_error: 0.4448\n",
      "Epoch 59/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5473 - mean_absolute_error: 0.3925\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5470 - mean_absolute_error: 0.3923 - val_loss: 0.6188 - val_mean_absolute_error: 0.4217\n",
      "Epoch 60/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5366 - mean_absolute_error: 0.3844\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5370 - mean_absolute_error: 0.3847 - val_loss: 0.6060 - val_mean_absolute_error: 0.4218\n",
      "Epoch 61/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5440 - mean_absolute_error: 0.3901\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.5444 - mean_absolute_error: 0.3904 - val_loss: 0.6362 - val_mean_absolute_error: 0.4499\n",
      "Epoch 62/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5253 - mean_absolute_error: 0.3813\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5252 - mean_absolute_error: 0.3814 - val_loss: 0.6243 - val_mean_absolute_error: 0.4247\n",
      "Epoch 63/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5617 - mean_absolute_error: 0.4063\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 0.5616 - mean_absolute_error: 0.4063 - val_loss: 0.6761 - val_mean_absolute_error: 0.4652\n",
      "Epoch 64/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5430 - mean_absolute_error: 0.3910\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5427 - mean_absolute_error: 0.3910 - val_loss: 0.6298 - val_mean_absolute_error: 0.4265\n",
      "Epoch 65/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5311 - mean_absolute_error: 0.3836\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5319 - mean_absolute_error: 0.3842 - val_loss: 0.7690 - val_mean_absolute_error: 0.5412\n",
      "Epoch 66/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5430 - mean_absolute_error: 0.3960\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5427 - mean_absolute_error: 0.3961 - val_loss: 0.6190 - val_mean_absolute_error: 0.4285\n",
      "Epoch 67/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5199 - mean_absolute_error: 0.3795\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5196 - mean_absolute_error: 0.3793 - val_loss: 0.6425 - val_mean_absolute_error: 0.4262\n",
      "Epoch 68/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5529 - mean_absolute_error: 0.4012\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5530 - mean_absolute_error: 0.4011 - val_loss: 0.6428 - val_mean_absolute_error: 0.4358\n",
      "Epoch 69/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5162 - mean_absolute_error: 0.3761\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5167 - mean_absolute_error: 0.3763 - val_loss: 0.6367 - val_mean_absolute_error: 0.4401\n",
      "Epoch 70/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.5245 - mean_absolute_error: 0.3844\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5247 - mean_absolute_error: 0.3846 - val_loss: 0.6060 - val_mean_absolute_error: 0.4102\n",
      "Epoch 71/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5218 - mean_absolute_error: 0.3871\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5228 - mean_absolute_error: 0.3877 - val_loss: 0.7292 - val_mean_absolute_error: 0.4920\n",
      "Epoch 72/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5470 - mean_absolute_error: 0.3964\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5469 - mean_absolute_error: 0.3965 - val_loss: 0.6823 - val_mean_absolute_error: 0.4858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5533 - mean_absolute_error: 0.3985\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5534 - mean_absolute_error: 0.3986 - val_loss: 0.6348 - val_mean_absolute_error: 0.4308\n",
      "Epoch 74/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5147 - mean_absolute_error: 0.3759\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5145 - mean_absolute_error: 0.3759 - val_loss: 0.6006 - val_mean_absolute_error: 0.4209\n",
      "Epoch 75/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5079 - mean_absolute_error: 0.3773\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5085 - mean_absolute_error: 0.3778 - val_loss: 0.6328 - val_mean_absolute_error: 0.4462\n",
      "Epoch 76/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5256 - mean_absolute_error: 0.3869\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5259 - mean_absolute_error: 0.3869 - val_loss: 0.6298 - val_mean_absolute_error: 0.4444\n",
      "Epoch 77/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5474 - mean_absolute_error: 0.3988\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5481 - mean_absolute_error: 0.3989 - val_loss: 0.6257 - val_mean_absolute_error: 0.4240\n",
      "Epoch 78/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5233 - mean_absolute_error: 0.3829\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5251 - mean_absolute_error: 0.3840 - val_loss: 0.6010 - val_mean_absolute_error: 0.4221\n",
      "Epoch 79/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5019 - mean_absolute_error: 0.3724\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5019 - mean_absolute_error: 0.3722 - val_loss: 0.6141 - val_mean_absolute_error: 0.4332\n",
      "Epoch 80/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5275 - mean_absolute_error: 0.3902\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5275 - mean_absolute_error: 0.3900 - val_loss: 0.6269 - val_mean_absolute_error: 0.4377\n",
      "Epoch 81/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5236 - mean_absolute_error: 0.3833\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5245 - mean_absolute_error: 0.3838 - val_loss: 0.6193 - val_mean_absolute_error: 0.4231\n",
      "Epoch 82/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5094 - mean_absolute_error: 0.3785\n",
      "Epoch 00082: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5095 - mean_absolute_error: 0.3786 - val_loss: 0.6356 - val_mean_absolute_error: 0.4325\n",
      "Epoch 83/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5182 - mean_absolute_error: 0.3835\n",
      "Epoch 00083: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5182 - mean_absolute_error: 0.3837 - val_loss: 0.6333 - val_mean_absolute_error: 0.4471\n",
      "Epoch 84/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5220 - mean_absolute_error: 0.3868\n",
      "Epoch 00084: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5222 - mean_absolute_error: 0.3869 - val_loss: 0.6127 - val_mean_absolute_error: 0.4281\n",
      "Epoch 85/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5338 - mean_absolute_error: 0.3935\n",
      "Epoch 00085: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 192us/step - loss: 0.5335 - mean_absolute_error: 0.3931 - val_loss: 0.6028 - val_mean_absolute_error: 0.4233\n",
      "Epoch 86/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5116 - mean_absolute_error: 0.3825\n",
      "Epoch 00086: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5117 - mean_absolute_error: 0.3827 - val_loss: 0.6123 - val_mean_absolute_error: 0.4267\n",
      "Epoch 87/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4993 - mean_absolute_error: 0.3732\n",
      "Epoch 00087: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.4988 - mean_absolute_error: 0.3728 - val_loss: 0.6399 - val_mean_absolute_error: 0.4546\n",
      "Epoch 88/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5194 - mean_absolute_error: 0.3864\n",
      "Epoch 00088: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5194 - mean_absolute_error: 0.3864 - val_loss: 0.8590 - val_mean_absolute_error: 0.6102\n",
      "Epoch 89/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5315 - mean_absolute_error: 0.3943\n",
      "Epoch 00089: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5321 - mean_absolute_error: 0.3946 - val_loss: 0.7965 - val_mean_absolute_error: 0.5620\n",
      "Epoch 90/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5361 - mean_absolute_error: 0.3941\n",
      "Epoch 00090: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5360 - mean_absolute_error: 0.3940 - val_loss: 0.6163 - val_mean_absolute_error: 0.4239\n",
      "Epoch 91/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5093 - mean_absolute_error: 0.3771\n",
      "Epoch 00091: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5093 - mean_absolute_error: 0.3771 - val_loss: 0.6349 - val_mean_absolute_error: 0.4401\n",
      "Epoch 92/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5122 - mean_absolute_error: 0.3816\n",
      "Epoch 00092: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5122 - mean_absolute_error: 0.3816 - val_loss: 0.6135 - val_mean_absolute_error: 0.4256\n",
      "Epoch 93/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.4942 - mean_absolute_error: 0.3688\n",
      "Epoch 00093: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.4945 - mean_absolute_error: 0.3691 - val_loss: 0.6253 - val_mean_absolute_error: 0.4469\n",
      "Epoch 94/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5170 - mean_absolute_error: 0.3846\n",
      "Epoch 00094: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 0.5171 - mean_absolute_error: 0.3846 - val_loss: 0.5984 - val_mean_absolute_error: 0.4265\n",
      "Epoch 95/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5187 - mean_absolute_error: 0.3863\n",
      "Epoch 00095: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5191 - mean_absolute_error: 0.3866 - val_loss: 0.6029 - val_mean_absolute_error: 0.4183\n",
      "Epoch 96/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5096 - mean_absolute_error: 0.3768\n",
      "Epoch 00096: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5099 - mean_absolute_error: 0.3769 - val_loss: 0.5969 - val_mean_absolute_error: 0.4252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5014 - mean_absolute_error: 0.3747\n",
      "Epoch 00097: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5022 - mean_absolute_error: 0.3751 - val_loss: 0.6288 - val_mean_absolute_error: 0.4312\n",
      "Epoch 98/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5269 - mean_absolute_error: 0.3902\n",
      "Epoch 00098: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5268 - mean_absolute_error: 0.3901 - val_loss: 0.6086 - val_mean_absolute_error: 0.4307\n",
      "Epoch 99/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5073 - mean_absolute_error: 0.3775\n",
      "Epoch 00099: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5072 - mean_absolute_error: 0.3775 - val_loss: 0.6755 - val_mean_absolute_error: 0.4888\n",
      "Epoch 100/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5171 - mean_absolute_error: 0.3805\n",
      "Epoch 00100: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5165 - mean_absolute_error: 0.3801 - val_loss: 0.7088 - val_mean_absolute_error: 0.5103\n",
      "Epoch 101/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5194 - mean_absolute_error: 0.3858\n",
      "Epoch 00101: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 0.5193 - mean_absolute_error: 0.3859 - val_loss: 0.6176 - val_mean_absolute_error: 0.4276\n",
      "Epoch 102/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4928 - mean_absolute_error: 0.3676\n",
      "Epoch 00102: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.4940 - mean_absolute_error: 0.3684 - val_loss: 0.6463 - val_mean_absolute_error: 0.4558\n",
      "Epoch 103/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5129 - mean_absolute_error: 0.3840\n",
      "Epoch 00103: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5128 - mean_absolute_error: 0.3838 - val_loss: 0.6131 - val_mean_absolute_error: 0.4513\n",
      "Epoch 104/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5094 - mean_absolute_error: 0.3763\n",
      "Epoch 00104: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.5093 - mean_absolute_error: 0.3764 - val_loss: 0.6389 - val_mean_absolute_error: 0.4493\n",
      "Epoch 105/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.4992 - mean_absolute_error: 0.3733\n",
      "Epoch 00105: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.4989 - mean_absolute_error: 0.3732 - val_loss: 0.5744 - val_mean_absolute_error: 0.4084\n",
      "Epoch 106/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.4998 - mean_absolute_error: 0.3784\n",
      "Epoch 00106: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5012 - mean_absolute_error: 0.3792 - val_loss: 0.6280 - val_mean_absolute_error: 0.4466\n",
      "Epoch 107/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5098 - mean_absolute_error: 0.3793\n",
      "Epoch 00107: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5095 - mean_absolute_error: 0.3794 - val_loss: 0.6783 - val_mean_absolute_error: 0.4816\n",
      "Epoch 108/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5247 - mean_absolute_error: 0.3837\n",
      "Epoch 00108: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5260 - mean_absolute_error: 0.3843 - val_loss: 0.5870 - val_mean_absolute_error: 0.4111\n",
      "Epoch 109/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5108 - mean_absolute_error: 0.3790\n",
      "Epoch 00109: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.5108 - mean_absolute_error: 0.3790 - val_loss: 0.5785 - val_mean_absolute_error: 0.4112\n",
      "Epoch 110/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5099 - mean_absolute_error: 0.3804\n",
      "Epoch 00110: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5102 - mean_absolute_error: 0.3807 - val_loss: 0.6913 - val_mean_absolute_error: 0.5058\n",
      "Epoch 111/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.4886 - mean_absolute_error: 0.3662\n",
      "Epoch 00111: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.4886 - mean_absolute_error: 0.3661 - val_loss: 0.6301 - val_mean_absolute_error: 0.4334\n",
      "Epoch 112/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5216 - mean_absolute_error: 0.3902\n",
      "Epoch 00112: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5226 - mean_absolute_error: 0.3907 - val_loss: 0.6050 - val_mean_absolute_error: 0.4249\n",
      "Epoch 113/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5065 - mean_absolute_error: 0.3750\n",
      "Epoch 00113: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5066 - mean_absolute_error: 0.3752 - val_loss: 0.7080 - val_mean_absolute_error: 0.5087\n",
      "Epoch 114/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5153 - mean_absolute_error: 0.3889\n",
      "Epoch 00114: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5154 - mean_absolute_error: 0.3890 - val_loss: 0.5938 - val_mean_absolute_error: 0.4289\n",
      "Epoch 115/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5000 - mean_absolute_error: 0.3753\n",
      "Epoch 00115: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5001 - mean_absolute_error: 0.3753 - val_loss: 0.6462 - val_mean_absolute_error: 0.4569\n",
      "Epoch 116/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5025 - mean_absolute_error: 0.3743\n",
      "Epoch 00116: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 193us/step - loss: 0.5031 - mean_absolute_error: 0.3745 - val_loss: 0.5879 - val_mean_absolute_error: 0.4183\n",
      "Epoch 117/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4993 - mean_absolute_error: 0.3739\n",
      "Epoch 00117: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.4995 - mean_absolute_error: 0.3743 - val_loss: 0.6588 - val_mean_absolute_error: 0.4768\n",
      "Epoch 118/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5056 - mean_absolute_error: 0.3772\n",
      "Epoch 00118: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 197us/step - loss: 0.5066 - mean_absolute_error: 0.3777 - val_loss: 0.6237 - val_mean_absolute_error: 0.4296\n",
      "Epoch 119/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5059 - mean_absolute_error: 0.3756\n",
      "Epoch 00119: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 195us/step - loss: 0.5060 - mean_absolute_error: 0.3754 - val_loss: 0.6379 - val_mean_absolute_error: 0.4432\n",
      "Epoch 120/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.4982 - mean_absolute_error: 0.3767\n",
      "Epoch 00120: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 0.4983 - mean_absolute_error: 0.3769 - val_loss: 0.6382 - val_mean_absolute_error: 0.4415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5089 - mean_absolute_error: 0.3789\n",
      "Epoch 00121: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 198us/step - loss: 0.5089 - mean_absolute_error: 0.3791 - val_loss: 0.6240 - val_mean_absolute_error: 0.4399\n",
      "Epoch 122/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.4954 - mean_absolute_error: 0.3705\n",
      "Epoch 00122: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 194us/step - loss: 0.4964 - mean_absolute_error: 0.3716 - val_loss: 0.7466 - val_mean_absolute_error: 0.5354\n",
      "Epoch 123/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5029 - mean_absolute_error: 0.3784\n",
      "Epoch 00123: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.5032 - mean_absolute_error: 0.3788 - val_loss: 0.6487 - val_mean_absolute_error: 0.4753\n",
      "Epoch 124/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.4931 - mean_absolute_error: 0.3682\n",
      "Epoch 00124: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.4936 - mean_absolute_error: 0.3685 - val_loss: 0.5979 - val_mean_absolute_error: 0.4232\n",
      "Epoch 125/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.4891 - mean_absolute_error: 0.3678\n",
      "Epoch 00125: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/8\n",
      "20282/20282 [==============================] - 4s 196us/step - loss: 0.4891 - mean_absolute_error: 0.3677 - val_loss: 0.5887 - val_mean_absolute_error: 0.4195\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 31.2920 - mean_absolute_error: 2.9739\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 6s 301us/step - loss: 31.0883 - mean_absolute_error: 2.9612 - val_loss: 14.9542 - val_mean_absolute_error: 1.8534\n",
      "Epoch 2/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 11.8970 - mean_absolute_error: 1.5061\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 11.8815 - mean_absolute_error: 1.5035 - val_loss: 8.9688 - val_mean_absolute_error: 1.0490\n",
      "Epoch 3/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 7.4125 - mean_absolute_error: 0.7969\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 7.4106 - mean_absolute_error: 0.7966 - val_loss: 6.4915 - val_mean_absolute_error: 0.7274\n",
      "Epoch 4/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 5.4844 - mean_absolute_error: 0.5472\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 5.4817 - mean_absolute_error: 0.5471 - val_loss: 5.1207 - val_mean_absolute_error: 0.6215\n",
      "Epoch 5/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 4.4044 - mean_absolute_error: 0.5395\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 4.4016 - mean_absolute_error: 0.5393 - val_loss: 4.3976 - val_mean_absolute_error: 0.7328\n",
      "Epoch 6/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 3.6803 - mean_absolute_error: 0.5897\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 3.6782 - mean_absolute_error: 0.5892 - val_loss: 3.3500 - val_mean_absolute_error: 0.5906\n",
      "Epoch 7/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 2.8465 - mean_absolute_error: 0.5105\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 2.8448 - mean_absolute_error: 0.5105 - val_loss: 2.8025 - val_mean_absolute_error: 0.6274\n",
      "Epoch 8/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 2.2925 - mean_absolute_error: 0.4951\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 2.2921 - mean_absolute_error: 0.4961 - val_loss: 2.2377 - val_mean_absolute_error: 0.5634\n",
      "Epoch 9/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.9398 - mean_absolute_error: 0.5208\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 1.9402 - mean_absolute_error: 0.5219 - val_loss: 1.8969 - val_mean_absolute_error: 0.5771\n",
      "Epoch 10/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.6321 - mean_absolute_error: 0.5110\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 1.6297 - mean_absolute_error: 0.5105 - val_loss: 1.5658 - val_mean_absolute_error: 0.5202\n",
      "Epoch 11/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.4270 - mean_absolute_error: 0.5074\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 1.4271 - mean_absolute_error: 0.5076 - val_loss: 1.5158 - val_mean_absolute_error: 0.5621\n",
      "Epoch 12/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 1.3408 - mean_absolute_error: 0.5225\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 1.3417 - mean_absolute_error: 0.5230 - val_loss: 1.5809 - val_mean_absolute_error: 0.6615\n",
      "Epoch 13/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.2387 - mean_absolute_error: 0.5140\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 1.2380 - mean_absolute_error: 0.5136 - val_loss: 1.2898 - val_mean_absolute_error: 0.5359\n",
      "Epoch 14/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 1.2532 - mean_absolute_error: 0.5449\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 1.2527 - mean_absolute_error: 0.5449 - val_loss: 1.2314 - val_mean_absolute_error: 0.5256\n",
      "Epoch 15/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 1.1184 - mean_absolute_error: 0.5095\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 1.1190 - mean_absolute_error: 0.5099 - val_loss: 1.1068 - val_mean_absolute_error: 0.4995\n",
      "Epoch 16/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 1.0953 - mean_absolute_error: 0.5040\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 1.0979 - mean_absolute_error: 0.5055 - val_loss: 1.3581 - val_mean_absolute_error: 0.6139\n",
      "Epoch 17/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.0022 - mean_absolute_error: 0.4821\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 1.0022 - mean_absolute_error: 0.4821 - val_loss: 1.0574 - val_mean_absolute_error: 0.4961\n",
      "Epoch 18/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.9704 - mean_absolute_error: 0.4742\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.9700 - mean_absolute_error: 0.4740 - val_loss: 1.0866 - val_mean_absolute_error: 0.5240\n",
      "Epoch 19/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.9455 - mean_absolute_error: 0.4633\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.9451 - mean_absolute_error: 0.4634 - val_loss: 0.9949 - val_mean_absolute_error: 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.8918 - mean_absolute_error: 0.4625\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.8920 - mean_absolute_error: 0.4626 - val_loss: 0.9949 - val_mean_absolute_error: 0.5008\n",
      "Epoch 21/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.8422 - mean_absolute_error: 0.4481\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.8422 - mean_absolute_error: 0.4480 - val_loss: 0.8896 - val_mean_absolute_error: 0.4564\n",
      "Epoch 22/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.8117 - mean_absolute_error: 0.4394\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.8122 - mean_absolute_error: 0.4396 - val_loss: 0.9116 - val_mean_absolute_error: 0.4744\n",
      "Epoch 23/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.8223 - mean_absolute_error: 0.4485\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.8219 - mean_absolute_error: 0.4481 - val_loss: 0.8910 - val_mean_absolute_error: 0.4674\n",
      "Epoch 24/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.7848 - mean_absolute_error: 0.4387\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.7868 - mean_absolute_error: 0.4403 - val_loss: 1.2000 - val_mean_absolute_error: 0.7181\n",
      "Epoch 25/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.7795 - mean_absolute_error: 0.4375\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.7799 - mean_absolute_error: 0.4378 - val_loss: 0.8850 - val_mean_absolute_error: 0.4802\n",
      "Epoch 26/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6926 - mean_absolute_error: 0.4173\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.6932 - mean_absolute_error: 0.4177 - val_loss: 0.7894 - val_mean_absolute_error: 0.4594\n",
      "Epoch 27/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6862 - mean_absolute_error: 0.4213\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.6861 - mean_absolute_error: 0.4212 - val_loss: 0.7984 - val_mean_absolute_error: 0.4705\n",
      "Epoch 28/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6709 - mean_absolute_error: 0.4192\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.6715 - mean_absolute_error: 0.4196 - val_loss: 0.8431 - val_mean_absolute_error: 0.5167\n",
      "Epoch 29/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6460 - mean_absolute_error: 0.4126\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.6469 - mean_absolute_error: 0.4130 - val_loss: 0.7571 - val_mean_absolute_error: 0.4596\n",
      "Epoch 30/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.6639 - mean_absolute_error: 0.4295\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.6652 - mean_absolute_error: 0.4301 - val_loss: 0.7623 - val_mean_absolute_error: 0.4687\n",
      "Epoch 31/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6278 - mean_absolute_error: 0.4083\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.6282 - mean_absolute_error: 0.4086 - val_loss: 0.7286 - val_mean_absolute_error: 0.4790\n",
      "Epoch 32/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6242 - mean_absolute_error: 0.4144\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.6251 - mean_absolute_error: 0.4150 - val_loss: 0.8856 - val_mean_absolute_error: 0.5698\n",
      "Epoch 33/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6743 - mean_absolute_error: 0.4349\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.6732 - mean_absolute_error: 0.4342 - val_loss: 0.7818 - val_mean_absolute_error: 0.4974\n",
      "Epoch 34/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6026 - mean_absolute_error: 0.4061\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.6025 - mean_absolute_error: 0.4061 - val_loss: 0.6884 - val_mean_absolute_error: 0.4455\n",
      "Epoch 35/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5748 - mean_absolute_error: 0.3924\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5748 - mean_absolute_error: 0.3923 - val_loss: 0.8422 - val_mean_absolute_error: 0.5608\n",
      "Epoch 36/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6102 - mean_absolute_error: 0.4133\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.6104 - mean_absolute_error: 0.4134 - val_loss: 0.7167 - val_mean_absolute_error: 0.4448\n",
      "Epoch 37/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6064 - mean_absolute_error: 0.4116\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.6071 - mean_absolute_error: 0.4122 - val_loss: 0.7179 - val_mean_absolute_error: 0.4566\n",
      "Epoch 38/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5937 - mean_absolute_error: 0.4068\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5937 - mean_absolute_error: 0.4068 - val_loss: 0.8448 - val_mean_absolute_error: 0.5658\n",
      "Epoch 39/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5552 - mean_absolute_error: 0.3900\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5558 - mean_absolute_error: 0.3904 - val_loss: 0.6767 - val_mean_absolute_error: 0.4458\n",
      "Epoch 40/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5590 - mean_absolute_error: 0.3927\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 212us/step - loss: 0.5590 - mean_absolute_error: 0.3926 - val_loss: 0.6513 - val_mean_absolute_error: 0.4253\n",
      "Epoch 41/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5824 - mean_absolute_error: 0.4092\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 0.5830 - mean_absolute_error: 0.4093 - val_loss: 0.7014 - val_mean_absolute_error: 0.4544\n",
      "Epoch 42/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5930 - mean_absolute_error: 0.4183\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5932 - mean_absolute_error: 0.4185 - val_loss: 0.7514 - val_mean_absolute_error: 0.5127\n",
      "Epoch 43/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5464 - mean_absolute_error: 0.3893\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5466 - mean_absolute_error: 0.3894 - val_loss: 0.6374 - val_mean_absolute_error: 0.4321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5662 - mean_absolute_error: 0.4056\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5663 - mean_absolute_error: 0.4059 - val_loss: 0.7229 - val_mean_absolute_error: 0.4915\n",
      "Epoch 45/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5514 - mean_absolute_error: 0.3932\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5517 - mean_absolute_error: 0.3933 - val_loss: 0.7170 - val_mean_absolute_error: 0.4824\n",
      "Epoch 46/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5647 - mean_absolute_error: 0.4052\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5650 - mean_absolute_error: 0.4055 - val_loss: 0.7270 - val_mean_absolute_error: 0.4844\n",
      "Epoch 47/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5513 - mean_absolute_error: 0.3958\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5515 - mean_absolute_error: 0.3959 - val_loss: 0.8115 - val_mean_absolute_error: 0.5617\n",
      "Epoch 48/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.5447 - mean_absolute_error: 0.3950\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5444 - mean_absolute_error: 0.3948 - val_loss: 0.6953 - val_mean_absolute_error: 0.4601\n",
      "Epoch 49/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5607 - mean_absolute_error: 0.4017\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5617 - mean_absolute_error: 0.4023 - val_loss: 0.7895 - val_mean_absolute_error: 0.5375\n",
      "Epoch 50/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5405 - mean_absolute_error: 0.3907\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5406 - mean_absolute_error: 0.3909 - val_loss: 0.7038 - val_mean_absolute_error: 0.4931\n",
      "Epoch 51/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5232 - mean_absolute_error: 0.3822\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5230 - mean_absolute_error: 0.3820 - val_loss: 0.6354 - val_mean_absolute_error: 0.4389\n",
      "Epoch 52/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5425 - mean_absolute_error: 0.3993\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5427 - mean_absolute_error: 0.3992 - val_loss: 0.6518 - val_mean_absolute_error: 0.4595\n",
      "Epoch 53/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5511 - mean_absolute_error: 0.3993\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5512 - mean_absolute_error: 0.3994 - val_loss: 0.6541 - val_mean_absolute_error: 0.4370\n",
      "Epoch 54/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5408 - mean_absolute_error: 0.3942\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5405 - mean_absolute_error: 0.3940 - val_loss: 0.6591 - val_mean_absolute_error: 0.4540\n",
      "Epoch 55/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5403 - mean_absolute_error: 0.3956\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5409 - mean_absolute_error: 0.3960 - val_loss: 0.6515 - val_mean_absolute_error: 0.4356\n",
      "Epoch 56/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5404 - mean_absolute_error: 0.3952\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5411 - mean_absolute_error: 0.3957 - val_loss: 0.7042 - val_mean_absolute_error: 0.4814\n",
      "Epoch 57/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5245 - mean_absolute_error: 0.3905\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5244 - mean_absolute_error: 0.3905 - val_loss: 0.7327 - val_mean_absolute_error: 0.5205\n",
      "Epoch 58/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5229 - mean_absolute_error: 0.3874\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5229 - mean_absolute_error: 0.3875 - val_loss: 0.6581 - val_mean_absolute_error: 0.4323\n",
      "Epoch 59/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5183 - mean_absolute_error: 0.3815\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5184 - mean_absolute_error: 0.3817 - val_loss: 0.6718 - val_mean_absolute_error: 0.4739\n",
      "Epoch 60/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5243 - mean_absolute_error: 0.3886\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.5242 - mean_absolute_error: 0.3886 - val_loss: 0.6721 - val_mean_absolute_error: 0.4593\n",
      "Epoch 61/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5303 - mean_absolute_error: 0.3902\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5309 - mean_absolute_error: 0.3904 - val_loss: 0.6433 - val_mean_absolute_error: 0.4392\n",
      "Epoch 62/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5161 - mean_absolute_error: 0.3772\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5172 - mean_absolute_error: 0.3781 - val_loss: 0.6310 - val_mean_absolute_error: 0.4388\n",
      "Epoch 63/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5679 - mean_absolute_error: 0.4055\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5678 - mean_absolute_error: 0.4054 - val_loss: 0.6360 - val_mean_absolute_error: 0.4353\n",
      "Epoch 64/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5345 - mean_absolute_error: 0.3971\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.5344 - mean_absolute_error: 0.3972 - val_loss: 0.6801 - val_mean_absolute_error: 0.4604\n",
      "Epoch 65/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5259 - mean_absolute_error: 0.3897\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5257 - mean_absolute_error: 0.3895 - val_loss: 0.6363 - val_mean_absolute_error: 0.4424\n",
      "Epoch 66/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5035 - mean_absolute_error: 0.3775\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5041 - mean_absolute_error: 0.3781 - val_loss: 0.6348 - val_mean_absolute_error: 0.4544\n",
      "Epoch 67/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5093 - mean_absolute_error: 0.3811\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5099 - mean_absolute_error: 0.3817 - val_loss: 0.7603 - val_mean_absolute_error: 0.5281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5338 - mean_absolute_error: 0.3952\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5342 - mean_absolute_error: 0.3955 - val_loss: 0.7581 - val_mean_absolute_error: 0.5252\n",
      "Epoch 69/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5216 - mean_absolute_error: 0.3848\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5214 - mean_absolute_error: 0.3848 - val_loss: 0.6438 - val_mean_absolute_error: 0.4686\n",
      "Epoch 70/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5194 - mean_absolute_error: 0.3850\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.5193 - mean_absolute_error: 0.3851 - val_loss: 0.6376 - val_mean_absolute_error: 0.4267\n",
      "Epoch 71/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5158 - mean_absolute_error: 0.3852\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5162 - mean_absolute_error: 0.3855 - val_loss: 0.6949 - val_mean_absolute_error: 0.4647\n",
      "Epoch 72/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5214 - mean_absolute_error: 0.3907\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5215 - mean_absolute_error: 0.3907 - val_loss: 0.6270 - val_mean_absolute_error: 0.4375\n",
      "Epoch 73/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5108 - mean_absolute_error: 0.3832\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5110 - mean_absolute_error: 0.3832 - val_loss: 0.6219 - val_mean_absolute_error: 0.4231\n",
      "Epoch 74/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5022 - mean_absolute_error: 0.3782\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5040 - mean_absolute_error: 0.3794 - val_loss: 0.6354 - val_mean_absolute_error: 0.4470\n",
      "Epoch 75/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5069 - mean_absolute_error: 0.3800\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5071 - mean_absolute_error: 0.3801 - val_loss: 0.5975 - val_mean_absolute_error: 0.4257\n",
      "Epoch 76/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5209 - mean_absolute_error: 0.3911\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5205 - mean_absolute_error: 0.3907 - val_loss: 0.6127 - val_mean_absolute_error: 0.4248\n",
      "Epoch 77/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5079 - mean_absolute_error: 0.3822\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 199us/step - loss: 0.5079 - mean_absolute_error: 0.3823 - val_loss: 0.6499 - val_mean_absolute_error: 0.4563\n",
      "Epoch 78/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5110 - mean_absolute_error: 0.3878\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5109 - mean_absolute_error: 0.3876 - val_loss: 0.6035 - val_mean_absolute_error: 0.4283\n",
      "Epoch 79/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5063 - mean_absolute_error: 0.3830\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 200us/step - loss: 0.5063 - mean_absolute_error: 0.3830 - val_loss: 0.6271 - val_mean_absolute_error: 0.4287\n",
      "Epoch 80/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5017 - mean_absolute_error: 0.3791\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.5023 - mean_absolute_error: 0.3792 - val_loss: 0.6144 - val_mean_absolute_error: 0.4396\n",
      "Epoch 81/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4995 - mean_absolute_error: 0.3792\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.4999 - mean_absolute_error: 0.3795 - val_loss: 0.6152 - val_mean_absolute_error: 0.4313\n",
      "Epoch 82/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5131 - mean_absolute_error: 0.3882\n",
      "Epoch 00082: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 0.5132 - mean_absolute_error: 0.3884 - val_loss: 0.6087 - val_mean_absolute_error: 0.4316\n",
      "Epoch 83/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5113 - mean_absolute_error: 0.3873\n",
      "Epoch 00083: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5112 - mean_absolute_error: 0.3872 - val_loss: 0.6140 - val_mean_absolute_error: 0.4202\n",
      "Epoch 84/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4882 - mean_absolute_error: 0.3723\n",
      "Epoch 00084: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.4879 - mean_absolute_error: 0.3723 - val_loss: 0.6094 - val_mean_absolute_error: 0.4273\n",
      "Epoch 85/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5228 - mean_absolute_error: 0.3944\n",
      "Epoch 00085: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5225 - mean_absolute_error: 0.3942 - val_loss: 0.6460 - val_mean_absolute_error: 0.4600\n",
      "Epoch 86/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5294 - mean_absolute_error: 0.3952\n",
      "Epoch 00086: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5295 - mean_absolute_error: 0.3955 - val_loss: 0.6491 - val_mean_absolute_error: 0.4670\n",
      "Epoch 87/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5002 - mean_absolute_error: 0.3800\n",
      "Epoch 00087: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5004 - mean_absolute_error: 0.3802 - val_loss: 0.6657 - val_mean_absolute_error: 0.4708\n",
      "Epoch 88/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4940 - mean_absolute_error: 0.3763\n",
      "Epoch 00088: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.4954 - mean_absolute_error: 0.3771 - val_loss: 0.6413 - val_mean_absolute_error: 0.4361\n",
      "Epoch 89/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5290 - mean_absolute_error: 0.3955\n",
      "Epoch 00089: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.5299 - mean_absolute_error: 0.3961 - val_loss: 0.6282 - val_mean_absolute_error: 0.4275\n",
      "Epoch 90/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5007 - mean_absolute_error: 0.3771\n",
      "Epoch 00090: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5007 - mean_absolute_error: 0.3771 - val_loss: 0.6090 - val_mean_absolute_error: 0.4182\n",
      "Epoch 91/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.4920 - mean_absolute_error: 0.3763\n",
      "Epoch 00091: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 212us/step - loss: 0.4926 - mean_absolute_error: 0.3768 - val_loss: 0.6502 - val_mean_absolute_error: 0.4556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5167 - mean_absolute_error: 0.3910\n",
      "Epoch 00092: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5169 - mean_absolute_error: 0.3909 - val_loss: 0.5909 - val_mean_absolute_error: 0.4167\n",
      "Epoch 93/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5086 - mean_absolute_error: 0.3826\n",
      "Epoch 00093: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 213us/step - loss: 0.5088 - mean_absolute_error: 0.3828 - val_loss: 0.6082 - val_mean_absolute_error: 0.4240\n",
      "Epoch 94/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.4915 - mean_absolute_error: 0.3761\n",
      "Epoch 00094: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 211us/step - loss: 0.4928 - mean_absolute_error: 0.3766 - val_loss: 0.5959 - val_mean_absolute_error: 0.4231\n",
      "Epoch 95/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5214 - mean_absolute_error: 0.3896\n",
      "Epoch 00095: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5218 - mean_absolute_error: 0.3900 - val_loss: 0.7071 - val_mean_absolute_error: 0.4958\n",
      "Epoch 96/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.4874 - mean_absolute_error: 0.3679\n",
      "Epoch 00096: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.4876 - mean_absolute_error: 0.3682 - val_loss: 0.6058 - val_mean_absolute_error: 0.4393\n",
      "Epoch 97/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5042 - mean_absolute_error: 0.3862\n",
      "Epoch 00097: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5048 - mean_absolute_error: 0.3865 - val_loss: 0.6580 - val_mean_absolute_error: 0.4552\n",
      "Epoch 98/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.5059 - mean_absolute_error: 0.3844\n",
      "Epoch 00098: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5056 - mean_absolute_error: 0.3840 - val_loss: 0.6252 - val_mean_absolute_error: 0.4329\n",
      "Epoch 99/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4995 - mean_absolute_error: 0.3806\n",
      "Epoch 00099: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.5008 - mean_absolute_error: 0.3816 - val_loss: 0.6057 - val_mean_absolute_error: 0.4252\n",
      "Epoch 100/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4941 - mean_absolute_error: 0.3779\n",
      "Epoch 00100: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.4942 - mean_absolute_error: 0.3780 - val_loss: 0.6251 - val_mean_absolute_error: 0.4320\n",
      "Epoch 101/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4857 - mean_absolute_error: 0.3733\n",
      "Epoch 00101: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.4862 - mean_absolute_error: 0.3738 - val_loss: 0.6250 - val_mean_absolute_error: 0.4501\n",
      "Epoch 102/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5082 - mean_absolute_error: 0.3882\n",
      "Epoch 00102: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5084 - mean_absolute_error: 0.3884 - val_loss: 0.6711 - val_mean_absolute_error: 0.4653\n",
      "Epoch 103/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5090 - mean_absolute_error: 0.3844\n",
      "Epoch 00103: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.5091 - mean_absolute_error: 0.3845 - val_loss: 0.6403 - val_mean_absolute_error: 0.4539\n",
      "Epoch 104/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.4983 - mean_absolute_error: 0.3807\n",
      "Epoch 00104: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 204us/step - loss: 0.4983 - mean_absolute_error: 0.3807 - val_loss: 0.6046 - val_mean_absolute_error: 0.4276\n",
      "Epoch 105/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4961 - mean_absolute_error: 0.3798\n",
      "Epoch 00105: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.4966 - mean_absolute_error: 0.3801 - val_loss: 0.6168 - val_mean_absolute_error: 0.4335\n",
      "Epoch 106/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5058 - mean_absolute_error: 0.3870\n",
      "Epoch 00106: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5058 - mean_absolute_error: 0.3871 - val_loss: 0.6016 - val_mean_absolute_error: 0.4184\n",
      "Epoch 107/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4852 - mean_absolute_error: 0.3704\n",
      "Epoch 00107: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.4855 - mean_absolute_error: 0.3708 - val_loss: 0.6258 - val_mean_absolute_error: 0.4361\n",
      "Epoch 108/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5003 - mean_absolute_error: 0.3842\n",
      "Epoch 00108: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.5002 - mean_absolute_error: 0.3842 - val_loss: 0.6482 - val_mean_absolute_error: 0.4545\n",
      "Epoch 109/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.4860 - mean_absolute_error: 0.3741\n",
      "Epoch 00109: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.4863 - mean_absolute_error: 0.3744 - val_loss: 0.6133 - val_mean_absolute_error: 0.4257\n",
      "Epoch 110/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5014 - mean_absolute_error: 0.3845\n",
      "Epoch 00110: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 203us/step - loss: 0.5013 - mean_absolute_error: 0.3845 - val_loss: 0.6042 - val_mean_absolute_error: 0.4275\n",
      "Epoch 111/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4953 - mean_absolute_error: 0.3780\n",
      "Epoch 00111: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 201us/step - loss: 0.4956 - mean_absolute_error: 0.3782 - val_loss: 0.5960 - val_mean_absolute_error: 0.4176\n",
      "Epoch 112/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4964 - mean_absolute_error: 0.3778\n",
      "Epoch 00112: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/9\n",
      "20282/20282 [==============================] - 4s 202us/step - loss: 0.4971 - mean_absolute_error: 0.3781 - val_loss: 0.5957 - val_mean_absolute_error: 0.4144\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 34.7889 - mean_absolute_error: 3.1307\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 6s 318us/step - loss: 34.5627 - mean_absolute_error: 3.1176 - val_loss: 13.6965 - val_mean_absolute_error: 1.8526\n",
      "Epoch 2/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 11.3814 - mean_absolute_error: 1.5461\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 11.3365 - mean_absolute_error: 1.5390 - val_loss: 7.9390 - val_mean_absolute_error: 1.0371\n",
      "Epoch 3/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 6.5308 - mean_absolute_error: 0.7669\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 211us/step - loss: 6.5294 - mean_absolute_error: 0.7667 - val_loss: 5.6867 - val_mean_absolute_error: 0.6599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 4.8158 - mean_absolute_error: 0.5074\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 4.8136 - mean_absolute_error: 0.5074 - val_loss: 4.6076 - val_mean_absolute_error: 0.6509\n",
      "Epoch 5/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 3.9173 - mean_absolute_error: 0.5161\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 211us/step - loss: 3.9125 - mean_absolute_error: 0.5157 - val_loss: 3.8339 - val_mean_absolute_error: 0.6372\n",
      "Epoch 6/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 3.2217 - mean_absolute_error: 0.5190\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 3.2175 - mean_absolute_error: 0.5186 - val_loss: 3.0063 - val_mean_absolute_error: 0.5750\n",
      "Epoch 7/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 2.5835 - mean_absolute_error: 0.4997\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 2.5829 - mean_absolute_error: 0.5000 - val_loss: 2.4457 - val_mean_absolute_error: 0.5260\n",
      "Epoch 8/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 2.2138 - mean_absolute_error: 0.5346\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 2.2118 - mean_absolute_error: 0.5341 - val_loss: 2.0527 - val_mean_absolute_error: 0.5289\n",
      "Epoch 9/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.8364 - mean_absolute_error: 0.5081\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.8362 - mean_absolute_error: 0.5082 - val_loss: 1.7397 - val_mean_absolute_error: 0.5065\n",
      "Epoch 10/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.5754 - mean_absolute_error: 0.4975\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.5742 - mean_absolute_error: 0.4975 - val_loss: 1.7103 - val_mean_absolute_error: 0.5937\n",
      "Epoch 11/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.4475 - mean_absolute_error: 0.5242\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.4476 - mean_absolute_error: 0.5243 - val_loss: 1.4104 - val_mean_absolute_error: 0.5042\n",
      "Epoch 12/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 1.3346 - mean_absolute_error: 0.5227\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 1.3375 - mean_absolute_error: 0.5234 - val_loss: 1.3838 - val_mean_absolute_error: 0.5466\n",
      "Epoch 13/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.2455 - mean_absolute_error: 0.5087\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.2459 - mean_absolute_error: 0.5085 - val_loss: 1.3095 - val_mean_absolute_error: 0.5259\n",
      "Epoch 14/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.1900 - mean_absolute_error: 0.5139\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.1898 - mean_absolute_error: 0.5138 - val_loss: 1.2042 - val_mean_absolute_error: 0.5109\n",
      "Epoch 15/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.1472 - mean_absolute_error: 0.5063\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 1.1454 - mean_absolute_error: 0.5052 - val_loss: 1.2110 - val_mean_absolute_error: 0.5288\n",
      "Epoch 16/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.0735 - mean_absolute_error: 0.4974\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.0737 - mean_absolute_error: 0.4977 - val_loss: 1.2221 - val_mean_absolute_error: 0.5782\n",
      "Epoch 17/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.0850 - mean_absolute_error: 0.5115\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.0843 - mean_absolute_error: 0.5112 - val_loss: 1.0717 - val_mean_absolute_error: 0.5045\n",
      "Epoch 18/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 1.0095 - mean_absolute_error: 0.4839\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 1.0099 - mean_absolute_error: 0.4841 - val_loss: 1.0469 - val_mean_absolute_error: 0.5024\n",
      "Epoch 19/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.9546 - mean_absolute_error: 0.4723\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 0.9559 - mean_absolute_error: 0.4728 - val_loss: 1.0823 - val_mean_absolute_error: 0.4845\n",
      "Epoch 20/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.9073 - mean_absolute_error: 0.4531\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.9072 - mean_absolute_error: 0.4532 - val_loss: 0.9836 - val_mean_absolute_error: 0.4804\n",
      "Epoch 21/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.8555 - mean_absolute_error: 0.4562\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.8555 - mean_absolute_error: 0.4561 - val_loss: 0.9745 - val_mean_absolute_error: 0.4952\n",
      "Epoch 22/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.8973 - mean_absolute_error: 0.4602\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 0.8983 - mean_absolute_error: 0.4609 - val_loss: 0.9409 - val_mean_absolute_error: 0.4759\n",
      "Epoch 23/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.8331 - mean_absolute_error: 0.4403\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.8334 - mean_absolute_error: 0.4406 - val_loss: 0.9743 - val_mean_absolute_error: 0.5268\n",
      "Epoch 24/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.8087 - mean_absolute_error: 0.4502\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 211us/step - loss: 0.8097 - mean_absolute_error: 0.4508 - val_loss: 0.9512 - val_mean_absolute_error: 0.5198\n",
      "Epoch 25/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.7278 - mean_absolute_error: 0.4249\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.7280 - mean_absolute_error: 0.4247 - val_loss: 0.8634 - val_mean_absolute_error: 0.4746\n",
      "Epoch 26/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.7514 - mean_absolute_error: 0.4355\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.7509 - mean_absolute_error: 0.4353 - val_loss: 0.8146 - val_mean_absolute_error: 0.4499\n",
      "Epoch 27/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7462 - mean_absolute_error: 0.4402\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.7472 - mean_absolute_error: 0.4402 - val_loss: 0.9334 - val_mean_absolute_error: 0.5044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.7159 - mean_absolute_error: 0.4245\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.7153 - mean_absolute_error: 0.4243 - val_loss: 0.8442 - val_mean_absolute_error: 0.5143\n",
      "Epoch 29/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.7031 - mean_absolute_error: 0.4272\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.7054 - mean_absolute_error: 0.4288 - val_loss: 1.7064 - val_mean_absolute_error: 1.0008\n",
      "Epoch 30/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.6953 - mean_absolute_error: 0.4315\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 0.6949 - mean_absolute_error: 0.4314 - val_loss: 0.8305 - val_mean_absolute_error: 0.5106\n",
      "Epoch 31/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6546 - mean_absolute_error: 0.4088\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 0.6546 - mean_absolute_error: 0.4088 - val_loss: 0.7762 - val_mean_absolute_error: 0.4596\n",
      "Epoch 32/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.6483 - mean_absolute_error: 0.4094\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.6482 - mean_absolute_error: 0.4093 - val_loss: 0.7077 - val_mean_absolute_error: 0.4420\n",
      "Epoch 33/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6614 - mean_absolute_error: 0.4264\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.6615 - mean_absolute_error: 0.4265 - val_loss: 0.6969 - val_mean_absolute_error: 0.4300\n",
      "Epoch 34/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6261 - mean_absolute_error: 0.4111\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.6268 - mean_absolute_error: 0.4116 - val_loss: 0.7894 - val_mean_absolute_error: 0.5230\n",
      "Epoch 35/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6056 - mean_absolute_error: 0.4124\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.6060 - mean_absolute_error: 0.4126 - val_loss: 0.6985 - val_mean_absolute_error: 0.4415\n",
      "Epoch 36/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6203 - mean_absolute_error: 0.4185\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.6207 - mean_absolute_error: 0.4189 - val_loss: 0.7569 - val_mean_absolute_error: 0.4981\n",
      "Epoch 37/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6013 - mean_absolute_error: 0.4032\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.6016 - mean_absolute_error: 0.4035 - val_loss: 0.7149 - val_mean_absolute_error: 0.4456\n",
      "Epoch 38/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6266 - mean_absolute_error: 0.4269\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 212us/step - loss: 0.6266 - mean_absolute_error: 0.4268 - val_loss: 0.6895 - val_mean_absolute_error: 0.4481\n",
      "Epoch 39/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.6088 - mean_absolute_error: 0.4103\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.6103 - mean_absolute_error: 0.4114 - val_loss: 0.7265 - val_mean_absolute_error: 0.4716\n",
      "Epoch 40/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6121 - mean_absolute_error: 0.4148\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.6127 - mean_absolute_error: 0.4151 - val_loss: 0.8544 - val_mean_absolute_error: 0.5655\n",
      "Epoch 41/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5934 - mean_absolute_error: 0.4134\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 211us/step - loss: 0.5952 - mean_absolute_error: 0.4145 - val_loss: 0.7121 - val_mean_absolute_error: 0.4631\n",
      "Epoch 42/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6007 - mean_absolute_error: 0.4114\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.6004 - mean_absolute_error: 0.4113 - val_loss: 0.6854 - val_mean_absolute_error: 0.4502\n",
      "Epoch 43/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5796 - mean_absolute_error: 0.4026\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5796 - mean_absolute_error: 0.4026 - val_loss: 0.7405 - val_mean_absolute_error: 0.5076\n",
      "Epoch 44/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5844 - mean_absolute_error: 0.4101\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5847 - mean_absolute_error: 0.4104 - val_loss: 0.7306 - val_mean_absolute_error: 0.4793\n",
      "Epoch 45/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5937 - mean_absolute_error: 0.4071\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5939 - mean_absolute_error: 0.4073 - val_loss: 0.7001 - val_mean_absolute_error: 0.4589\n",
      "Epoch 46/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5920 - mean_absolute_error: 0.4123\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5919 - mean_absolute_error: 0.4122 - val_loss: 0.7073 - val_mean_absolute_error: 0.4526\n",
      "Epoch 47/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5754 - mean_absolute_error: 0.3999\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5761 - mean_absolute_error: 0.4003 - val_loss: 0.6505 - val_mean_absolute_error: 0.4216\n",
      "Epoch 48/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5610 - mean_absolute_error: 0.3977\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5618 - mean_absolute_error: 0.3982 - val_loss: 0.6941 - val_mean_absolute_error: 0.4618\n",
      "Epoch 49/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5742 - mean_absolute_error: 0.4063\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5741 - mean_absolute_error: 0.4063 - val_loss: 0.6792 - val_mean_absolute_error: 0.4478\n",
      "Epoch 50/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5783 - mean_absolute_error: 0.4073\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5782 - mean_absolute_error: 0.4073 - val_loss: 0.7704 - val_mean_absolute_error: 0.5237\n",
      "Epoch 51/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5634 - mean_absolute_error: 0.4016\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5641 - mean_absolute_error: 0.4016 - val_loss: 0.7267 - val_mean_absolute_error: 0.4669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5686 - mean_absolute_error: 0.3981\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5687 - mean_absolute_error: 0.3982 - val_loss: 0.7249 - val_mean_absolute_error: 0.4864\n",
      "Epoch 53/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5611 - mean_absolute_error: 0.4002\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5607 - mean_absolute_error: 0.3999 - val_loss: 0.6734 - val_mean_absolute_error: 0.4574\n",
      "Epoch 54/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5432 - mean_absolute_error: 0.3923\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5438 - mean_absolute_error: 0.3928 - val_loss: 0.7564 - val_mean_absolute_error: 0.5177\n",
      "Epoch 55/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5638 - mean_absolute_error: 0.4048\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5637 - mean_absolute_error: 0.4048 - val_loss: 0.7319 - val_mean_absolute_error: 0.4780\n",
      "Epoch 56/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5637 - mean_absolute_error: 0.4014\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5631 - mean_absolute_error: 0.4009 - val_loss: 0.6697 - val_mean_absolute_error: 0.4334\n",
      "Epoch 57/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5834 - mean_absolute_error: 0.4172\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5835 - mean_absolute_error: 0.4172 - val_loss: 0.6784 - val_mean_absolute_error: 0.4587\n",
      "Epoch 58/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5272 - mean_absolute_error: 0.3789\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5272 - mean_absolute_error: 0.3789 - val_loss: 0.6252 - val_mean_absolute_error: 0.4337\n",
      "Epoch 59/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5455 - mean_absolute_error: 0.4003\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5454 - mean_absolute_error: 0.4002 - val_loss: 0.7569 - val_mean_absolute_error: 0.5327\n",
      "Epoch 60/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5367 - mean_absolute_error: 0.3899\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 0.5363 - mean_absolute_error: 0.3898 - val_loss: 0.6591 - val_mean_absolute_error: 0.4621\n",
      "Epoch 61/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5355 - mean_absolute_error: 0.3906\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5356 - mean_absolute_error: 0.3908 - val_loss: 0.6827 - val_mean_absolute_error: 0.4795\n",
      "Epoch 62/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5728 - mean_absolute_error: 0.4095\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5732 - mean_absolute_error: 0.4097 - val_loss: 0.8362 - val_mean_absolute_error: 0.5763\n",
      "Epoch 63/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5528 - mean_absolute_error: 0.3996\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5523 - mean_absolute_error: 0.3992 - val_loss: 0.6814 - val_mean_absolute_error: 0.4694\n",
      "Epoch 64/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5256 - mean_absolute_error: 0.3853\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5255 - mean_absolute_error: 0.3855 - val_loss: 0.6516 - val_mean_absolute_error: 0.4471\n",
      "Epoch 65/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5540 - mean_absolute_error: 0.4087\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5540 - mean_absolute_error: 0.4086 - val_loss: 0.6367 - val_mean_absolute_error: 0.4316\n",
      "Epoch 66/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5350 - mean_absolute_error: 0.3910\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5349 - mean_absolute_error: 0.3910 - val_loss: 0.6627 - val_mean_absolute_error: 0.4522\n",
      "Epoch 67/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5427 - mean_absolute_error: 0.3951\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5433 - mean_absolute_error: 0.3953 - val_loss: 0.7952 - val_mean_absolute_error: 0.5469\n",
      "Epoch 68/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5559 - mean_absolute_error: 0.4054\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5560 - mean_absolute_error: 0.4055 - val_loss: 0.6428 - val_mean_absolute_error: 0.4409\n",
      "Epoch 69/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5370 - mean_absolute_error: 0.3933\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 214us/step - loss: 0.5367 - mean_absolute_error: 0.3932 - val_loss: 0.6504 - val_mean_absolute_error: 0.4513\n",
      "Epoch 70/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5288 - mean_absolute_error: 0.3876\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 5s 237us/step - loss: 0.5286 - mean_absolute_error: 0.3875 - val_loss: 0.6907 - val_mean_absolute_error: 0.4845\n",
      "Epoch 71/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.5315 - mean_absolute_error: 0.3923\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5309 - mean_absolute_error: 0.3920 - val_loss: 0.6320 - val_mean_absolute_error: 0.4289\n",
      "Epoch 72/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5409 - mean_absolute_error: 0.3955\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5409 - mean_absolute_error: 0.3955 - val_loss: 0.6977 - val_mean_absolute_error: 0.4785\n",
      "Epoch 73/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5307 - mean_absolute_error: 0.3878\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 211us/step - loss: 0.5311 - mean_absolute_error: 0.3881 - val_loss: 0.6595 - val_mean_absolute_error: 0.4530\n",
      "Epoch 74/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5251 - mean_absolute_error: 0.3839\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 211us/step - loss: 0.5252 - mean_absolute_error: 0.3839 - val_loss: 0.6196 - val_mean_absolute_error: 0.4279\n",
      "Epoch 75/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5249 - mean_absolute_error: 0.3857\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5251 - mean_absolute_error: 0.3857 - val_loss: 0.6229 - val_mean_absolute_error: 0.4255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5360 - mean_absolute_error: 0.3979\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5364 - mean_absolute_error: 0.3979 - val_loss: 0.6371 - val_mean_absolute_error: 0.4381\n",
      "Epoch 77/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5317 - mean_absolute_error: 0.3932\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5328 - mean_absolute_error: 0.3939 - val_loss: 0.6233 - val_mean_absolute_error: 0.4333\n",
      "Epoch 78/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5322 - mean_absolute_error: 0.3922\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5325 - mean_absolute_error: 0.3926 - val_loss: 0.7358 - val_mean_absolute_error: 0.5327\n",
      "Epoch 79/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5149 - mean_absolute_error: 0.3788\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5146 - mean_absolute_error: 0.3787 - val_loss: 0.5999 - val_mean_absolute_error: 0.4219\n",
      "Epoch 80/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5171 - mean_absolute_error: 0.3842\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5170 - mean_absolute_error: 0.3841 - val_loss: 0.7457 - val_mean_absolute_error: 0.5369\n",
      "Epoch 81/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5234 - mean_absolute_error: 0.3877\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.5240 - mean_absolute_error: 0.3882 - val_loss: 0.6556 - val_mean_absolute_error: 0.4509\n",
      "Epoch 82/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5451 - mean_absolute_error: 0.3973\n",
      "Epoch 00082: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5444 - mean_absolute_error: 0.3968 - val_loss: 0.6766 - val_mean_absolute_error: 0.4611\n",
      "Epoch 83/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5361 - mean_absolute_error: 0.3894\n",
      "Epoch 00083: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5363 - mean_absolute_error: 0.3897 - val_loss: 0.6396 - val_mean_absolute_error: 0.4435\n",
      "Epoch 84/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5281 - mean_absolute_error: 0.3869\n",
      "Epoch 00084: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.5280 - mean_absolute_error: 0.3869 - val_loss: 0.6151 - val_mean_absolute_error: 0.4172\n",
      "Epoch 85/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5129 - mean_absolute_error: 0.3812\n",
      "Epoch 00085: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5131 - mean_absolute_error: 0.3815 - val_loss: 0.7077 - val_mean_absolute_error: 0.4859\n",
      "Epoch 86/200\n",
      "20000/20282 [============================>.] - ETA: 0s - loss: 0.5343 - mean_absolute_error: 0.3911\n",
      "Epoch 00086: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5341 - mean_absolute_error: 0.3911 - val_loss: 0.6271 - val_mean_absolute_error: 0.4315\n",
      "Epoch 87/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5272 - mean_absolute_error: 0.3903\n",
      "Epoch 00087: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5270 - mean_absolute_error: 0.3902 - val_loss: 0.7237 - val_mean_absolute_error: 0.5307\n",
      "Epoch 88/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5049 - mean_absolute_error: 0.3811\n",
      "Epoch 00088: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5054 - mean_absolute_error: 0.3811 - val_loss: 1.0765 - val_mean_absolute_error: 0.7603\n",
      "Epoch 89/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5233 - mean_absolute_error: 0.3881\n",
      "Epoch 00089: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5231 - mean_absolute_error: 0.3878 - val_loss: 0.6879 - val_mean_absolute_error: 0.4716\n",
      "Epoch 90/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5147 - mean_absolute_error: 0.3846\n",
      "Epoch 00090: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5157 - mean_absolute_error: 0.3853 - val_loss: 0.6425 - val_mean_absolute_error: 0.4468\n",
      "Epoch 91/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5297 - mean_absolute_error: 0.3918\n",
      "Epoch 00091: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 205us/step - loss: 0.5291 - mean_absolute_error: 0.3913 - val_loss: 0.6128 - val_mean_absolute_error: 0.4171\n",
      "Epoch 92/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5655 - mean_absolute_error: 0.4088\n",
      "Epoch 00092: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 208us/step - loss: 0.5655 - mean_absolute_error: 0.4090 - val_loss: 0.6328 - val_mean_absolute_error: 0.4327\n",
      "Epoch 93/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5132 - mean_absolute_error: 0.3731\n",
      "Epoch 00093: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5129 - mean_absolute_error: 0.3730 - val_loss: 0.6315 - val_mean_absolute_error: 0.4288\n",
      "Epoch 94/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5105 - mean_absolute_error: 0.3801\n",
      "Epoch 00094: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5117 - mean_absolute_error: 0.3810 - val_loss: 0.6498 - val_mean_absolute_error: 0.4558\n",
      "Epoch 95/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5243 - mean_absolute_error: 0.3904\n",
      "Epoch 00095: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 206us/step - loss: 0.5255 - mean_absolute_error: 0.3909 - val_loss: 0.6504 - val_mean_absolute_error: 0.4587\n",
      "Epoch 96/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5120 - mean_absolute_error: 0.3768\n",
      "Epoch 00096: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 209us/step - loss: 0.5117 - mean_absolute_error: 0.3767 - val_loss: 0.6377 - val_mean_absolute_error: 0.4548\n",
      "Epoch 97/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5403 - mean_absolute_error: 0.3932\n",
      "Epoch 00097: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5408 - mean_absolute_error: 0.3937 - val_loss: 0.6343 - val_mean_absolute_error: 0.4303\n",
      "Epoch 98/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5239 - mean_absolute_error: 0.3849\n",
      "Epoch 00098: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 210us/step - loss: 0.5238 - mean_absolute_error: 0.3848 - val_loss: 0.6840 - val_mean_absolute_error: 0.4837\n",
      "Epoch 99/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5061 - mean_absolute_error: 0.3750\n",
      "Epoch 00099: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/10\n",
      "20282/20282 [==============================] - 4s 207us/step - loss: 0.5059 - mean_absolute_error: 0.3749 - val_loss: 0.6303 - val_mean_absolute_error: 0.4352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 30.6804 - mean_absolute_error: 2.9762\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 7s 337us/step - loss: 30.6621 - mean_absolute_error: 2.9750 - val_loss: 14.0431 - val_mean_absolute_error: 1.8957\n",
      "Epoch 2/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 11.6620 - mean_absolute_error: 1.5352\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 11.6587 - mean_absolute_error: 1.5349 - val_loss: 8.4707 - val_mean_absolute_error: 1.0381\n",
      "Epoch 3/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 7.0426 - mean_absolute_error: 0.8110\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 7.0290 - mean_absolute_error: 0.8089 - val_loss: 6.1520 - val_mean_absolute_error: 0.7251\n",
      "Epoch 4/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 5.1001 - mean_absolute_error: 0.5247\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 5.0928 - mean_absolute_error: 0.5244 - val_loss: 4.7930 - val_mean_absolute_error: 0.5983\n",
      "Epoch 5/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 4.1187 - mean_absolute_error: 0.5355\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 4.1180 - mean_absolute_error: 0.5354 - val_loss: 4.0363 - val_mean_absolute_error: 0.6776\n",
      "Epoch 6/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 3.3998 - mean_absolute_error: 0.5604\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 3.3970 - mean_absolute_error: 0.5601 - val_loss: 3.1487 - val_mean_absolute_error: 0.5671\n",
      "Epoch 7/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 2.7529 - mean_absolute_error: 0.5297\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 2.7523 - mean_absolute_error: 0.5297 - val_loss: 2.6935 - val_mean_absolute_error: 0.6188\n",
      "Epoch 8/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 2.4036 - mean_absolute_error: 0.5453\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 2.4051 - mean_absolute_error: 0.5466 - val_loss: 2.5328 - val_mean_absolute_error: 0.7104\n",
      "Epoch 9/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 2.1803 - mean_absolute_error: 0.5704\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 2.1807 - mean_absolute_error: 0.5705 - val_loss: 2.1313 - val_mean_absolute_error: 0.5723\n",
      "Epoch 10/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.9989 - mean_absolute_error: 0.5627\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 1.9976 - mean_absolute_error: 0.5623 - val_loss: 2.0712 - val_mean_absolute_error: 0.6145\n",
      "Epoch 11/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.7682 - mean_absolute_error: 0.5318\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 1.7677 - mean_absolute_error: 0.5318 - val_loss: 1.7853 - val_mean_absolute_error: 0.5651\n",
      "Epoch 12/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.6105 - mean_absolute_error: 0.5334\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 1.6103 - mean_absolute_error: 0.5333 - val_loss: 1.7605 - val_mean_absolute_error: 0.5727\n",
      "Epoch 13/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.5309 - mean_absolute_error: 0.5360\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 1.5305 - mean_absolute_error: 0.5360 - val_loss: 1.4888 - val_mean_absolute_error: 0.5312\n",
      "Epoch 14/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.3319 - mean_absolute_error: 0.5090\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 1.3304 - mean_absolute_error: 0.5087 - val_loss: 1.2767 - val_mean_absolute_error: 0.5034\n",
      "Epoch 15/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.2246 - mean_absolute_error: 0.5052\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 1.2257 - mean_absolute_error: 0.5057 - val_loss: 1.2625 - val_mean_absolute_error: 0.5147\n",
      "Epoch 16/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.1056 - mean_absolute_error: 0.4889\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 1.1049 - mean_absolute_error: 0.4891 - val_loss: 1.1380 - val_mean_absolute_error: 0.5126\n",
      "Epoch 17/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.0470 - mean_absolute_error: 0.4862\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 1.0469 - mean_absolute_error: 0.4862 - val_loss: 1.0941 - val_mean_absolute_error: 0.5295\n",
      "Epoch 18/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.0046 - mean_absolute_error: 0.4794\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 1.0041 - mean_absolute_error: 0.4788 - val_loss: 1.0619 - val_mean_absolute_error: 0.4878\n",
      "Epoch 19/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.9540 - mean_absolute_error: 0.4724\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.9535 - mean_absolute_error: 0.4722 - val_loss: 1.0271 - val_mean_absolute_error: 0.5105\n",
      "Epoch 20/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.9211 - mean_absolute_error: 0.4680\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 0.9215 - mean_absolute_error: 0.4682 - val_loss: 1.0735 - val_mean_absolute_error: 0.5383\n",
      "Epoch 21/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.8857 - mean_absolute_error: 0.4508\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.8861 - mean_absolute_error: 0.4508 - val_loss: 1.0159 - val_mean_absolute_error: 0.5044\n",
      "Epoch 22/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.8282 - mean_absolute_error: 0.4372\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.8293 - mean_absolute_error: 0.4379 - val_loss: 1.0872 - val_mean_absolute_error: 0.6163\n",
      "Epoch 23/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.8370 - mean_absolute_error: 0.4480\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.8367 - mean_absolute_error: 0.4478 - val_loss: 0.9164 - val_mean_absolute_error: 0.4932\n",
      "Epoch 24/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.8391 - mean_absolute_error: 0.4424\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.8390 - mean_absolute_error: 0.4422 - val_loss: 0.9145 - val_mean_absolute_error: 0.4565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.7684 - mean_absolute_error: 0.4294\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.7675 - mean_absolute_error: 0.4288 - val_loss: 0.8354 - val_mean_absolute_error: 0.4735\n",
      "Epoch 26/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.7432 - mean_absolute_error: 0.4290\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.7436 - mean_absolute_error: 0.4292 - val_loss: 0.8699 - val_mean_absolute_error: 0.4643\n",
      "Epoch 27/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7788 - mean_absolute_error: 0.4419\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 0.7804 - mean_absolute_error: 0.4429 - val_loss: 0.9103 - val_mean_absolute_error: 0.4836\n",
      "Epoch 28/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.7278 - mean_absolute_error: 0.4246\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.7277 - mean_absolute_error: 0.4245 - val_loss: 0.8508 - val_mean_absolute_error: 0.4803\n",
      "Epoch 29/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.7009 - mean_absolute_error: 0.4285\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.7013 - mean_absolute_error: 0.4286 - val_loss: 0.8101 - val_mean_absolute_error: 0.4715\n",
      "Epoch 30/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6739 - mean_absolute_error: 0.4092\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.6737 - mean_absolute_error: 0.4091 - val_loss: 0.7574 - val_mean_absolute_error: 0.4546\n",
      "Epoch 31/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6736 - mean_absolute_error: 0.4199\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.6738 - mean_absolute_error: 0.4200 - val_loss: 0.8132 - val_mean_absolute_error: 0.4505\n",
      "Epoch 32/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6759 - mean_absolute_error: 0.4237\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.6753 - mean_absolute_error: 0.4235 - val_loss: 0.7241 - val_mean_absolute_error: 0.4548\n",
      "Epoch 33/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.6122 - mean_absolute_error: 0.4098\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.6125 - mean_absolute_error: 0.4099 - val_loss: 0.7565 - val_mean_absolute_error: 0.4776\n",
      "Epoch 34/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.6201 - mean_absolute_error: 0.4061\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.6209 - mean_absolute_error: 0.4067 - val_loss: 0.7057 - val_mean_absolute_error: 0.4417\n",
      "Epoch 35/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6081 - mean_absolute_error: 0.4061\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.6080 - mean_absolute_error: 0.4057 - val_loss: 0.7008 - val_mean_absolute_error: 0.4411\n",
      "Epoch 36/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5971 - mean_absolute_error: 0.4087\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5972 - mean_absolute_error: 0.4087 - val_loss: 0.7408 - val_mean_absolute_error: 0.4614\n",
      "Epoch 37/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5953 - mean_absolute_error: 0.4059\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5952 - mean_absolute_error: 0.4058 - val_loss: 0.6400 - val_mean_absolute_error: 0.4177\n",
      "Epoch 38/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5744 - mean_absolute_error: 0.3998\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5755 - mean_absolute_error: 0.4006 - val_loss: 0.7521 - val_mean_absolute_error: 0.4945\n",
      "Epoch 39/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5938 - mean_absolute_error: 0.4057\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5942 - mean_absolute_error: 0.4057 - val_loss: 0.7036 - val_mean_absolute_error: 0.4638\n",
      "Epoch 40/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5688 - mean_absolute_error: 0.3920\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5692 - mean_absolute_error: 0.3923 - val_loss: 0.7033 - val_mean_absolute_error: 0.4465\n",
      "Epoch 41/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5616 - mean_absolute_error: 0.3956\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5620 - mean_absolute_error: 0.3957 - val_loss: 0.7587 - val_mean_absolute_error: 0.5223\n",
      "Epoch 42/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5674 - mean_absolute_error: 0.4056\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5674 - mean_absolute_error: 0.4056 - val_loss: 0.6694 - val_mean_absolute_error: 0.4393\n",
      "Epoch 43/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5526 - mean_absolute_error: 0.3864\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5531 - mean_absolute_error: 0.3866 - val_loss: 0.6930 - val_mean_absolute_error: 0.4482\n",
      "Epoch 44/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5699 - mean_absolute_error: 0.4072\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5698 - mean_absolute_error: 0.4072 - val_loss: 0.8078 - val_mean_absolute_error: 0.5753\n",
      "Epoch 45/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5470 - mean_absolute_error: 0.3884\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 5s 228us/step - loss: 0.5477 - mean_absolute_error: 0.3887 - val_loss: 0.6231 - val_mean_absolute_error: 0.4158\n",
      "Epoch 46/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5577 - mean_absolute_error: 0.3954\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5585 - mean_absolute_error: 0.3962 - val_loss: 0.6676 - val_mean_absolute_error: 0.4612\n",
      "Epoch 47/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5611 - mean_absolute_error: 0.4080\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5611 - mean_absolute_error: 0.4079 - val_loss: 0.6045 - val_mean_absolute_error: 0.4173\n",
      "Epoch 48/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5276 - mean_absolute_error: 0.3819\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5273 - mean_absolute_error: 0.3817 - val_loss: 0.6292 - val_mean_absolute_error: 0.4329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5490 - mean_absolute_error: 0.3966\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5488 - mean_absolute_error: 0.3966 - val_loss: 0.6281 - val_mean_absolute_error: 0.4222\n",
      "Epoch 50/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5299 - mean_absolute_error: 0.3851\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5297 - mean_absolute_error: 0.3850 - val_loss: 0.6483 - val_mean_absolute_error: 0.4610\n",
      "Epoch 51/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5294 - mean_absolute_error: 0.3881\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5298 - mean_absolute_error: 0.3884 - val_loss: 0.6800 - val_mean_absolute_error: 0.4585\n",
      "Epoch 52/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5275 - mean_absolute_error: 0.3934\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5278 - mean_absolute_error: 0.3938 - val_loss: 0.7338 - val_mean_absolute_error: 0.5312\n",
      "Epoch 53/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5288 - mean_absolute_error: 0.3916\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5289 - mean_absolute_error: 0.3917 - val_loss: 0.6474 - val_mean_absolute_error: 0.4499\n",
      "Epoch 54/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5178 - mean_absolute_error: 0.3794\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5181 - mean_absolute_error: 0.3797 - val_loss: 0.6780 - val_mean_absolute_error: 0.4778\n",
      "Epoch 55/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5234 - mean_absolute_error: 0.3874\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5241 - mean_absolute_error: 0.3878 - val_loss: 0.7085 - val_mean_absolute_error: 0.5066\n",
      "Epoch 56/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5378 - mean_absolute_error: 0.3968\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5380 - mean_absolute_error: 0.3970 - val_loss: 0.6627 - val_mean_absolute_error: 0.4524\n",
      "Epoch 57/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5191 - mean_absolute_error: 0.3874\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5193 - mean_absolute_error: 0.3875 - val_loss: 0.6070 - val_mean_absolute_error: 0.4270\n",
      "Epoch 58/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5120 - mean_absolute_error: 0.3824\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5125 - mean_absolute_error: 0.3828 - val_loss: 0.6341 - val_mean_absolute_error: 0.4563\n",
      "Epoch 59/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5180 - mean_absolute_error: 0.3850\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5181 - mean_absolute_error: 0.3850 - val_loss: 0.6097 - val_mean_absolute_error: 0.4301\n",
      "Epoch 60/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5162 - mean_absolute_error: 0.3827\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 0.5166 - mean_absolute_error: 0.3828 - val_loss: 0.5920 - val_mean_absolute_error: 0.4271\n",
      "Epoch 61/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5067 - mean_absolute_error: 0.3785\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5067 - mean_absolute_error: 0.3784 - val_loss: 0.5955 - val_mean_absolute_error: 0.4191\n",
      "Epoch 62/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5070 - mean_absolute_error: 0.3778\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5072 - mean_absolute_error: 0.3779 - val_loss: 0.5880 - val_mean_absolute_error: 0.4162\n",
      "Epoch 63/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5121 - mean_absolute_error: 0.3839\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5125 - mean_absolute_error: 0.3842 - val_loss: 0.6249 - val_mean_absolute_error: 0.4315\n",
      "Epoch 64/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5127 - mean_absolute_error: 0.3799\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5130 - mean_absolute_error: 0.3801 - val_loss: 0.6918 - val_mean_absolute_error: 0.5037\n",
      "Epoch 65/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5109 - mean_absolute_error: 0.3849\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5110 - mean_absolute_error: 0.3850 - val_loss: 0.6147 - val_mean_absolute_error: 0.4481\n",
      "Epoch 66/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.4996 - mean_absolute_error: 0.3788\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5007 - mean_absolute_error: 0.3795 - val_loss: 0.6321 - val_mean_absolute_error: 0.4355\n",
      "Epoch 67/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5225 - mean_absolute_error: 0.3940\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 0.5222 - mean_absolute_error: 0.3937 - val_loss: 0.6039 - val_mean_absolute_error: 0.4216\n",
      "Epoch 68/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5040 - mean_absolute_error: 0.3771\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 0.5040 - mean_absolute_error: 0.3772 - val_loss: 0.6874 - val_mean_absolute_error: 0.5124\n",
      "Epoch 69/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5113 - mean_absolute_error: 0.3857\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5118 - mean_absolute_error: 0.3860 - val_loss: 0.6342 - val_mean_absolute_error: 0.4413\n",
      "Epoch 70/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5072 - mean_absolute_error: 0.3854\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.5073 - mean_absolute_error: 0.3854 - val_loss: 0.6316 - val_mean_absolute_error: 0.4644\n",
      "Epoch 71/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4970 - mean_absolute_error: 0.3757\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.4972 - mean_absolute_error: 0.3758 - val_loss: 0.5933 - val_mean_absolute_error: 0.4280\n",
      "Epoch 72/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5100 - mean_absolute_error: 0.3874\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5098 - mean_absolute_error: 0.3874 - val_loss: 0.5937 - val_mean_absolute_error: 0.4271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5037 - mean_absolute_error: 0.3819\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5039 - mean_absolute_error: 0.3820 - val_loss: 0.6091 - val_mean_absolute_error: 0.4364\n",
      "Epoch 74/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5012 - mean_absolute_error: 0.3824\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5008 - mean_absolute_error: 0.3821 - val_loss: 0.6245 - val_mean_absolute_error: 0.4434\n",
      "Epoch 75/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5113 - mean_absolute_error: 0.3882\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5114 - mean_absolute_error: 0.3882 - val_loss: 0.6200 - val_mean_absolute_error: 0.4431\n",
      "Epoch 76/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5019 - mean_absolute_error: 0.3818\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5019 - mean_absolute_error: 0.3818 - val_loss: 0.6113 - val_mean_absolute_error: 0.4456\n",
      "Epoch 77/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5005 - mean_absolute_error: 0.3816\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5003 - mean_absolute_error: 0.3815 - val_loss: 0.6142 - val_mean_absolute_error: 0.4363\n",
      "Epoch 78/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5067 - mean_absolute_error: 0.3799\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5066 - mean_absolute_error: 0.3799 - val_loss: 0.6029 - val_mean_absolute_error: 0.4279\n",
      "Epoch 79/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5015 - mean_absolute_error: 0.3798\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 215us/step - loss: 0.5013 - mean_absolute_error: 0.3798 - val_loss: 0.6221 - val_mean_absolute_error: 0.4491\n",
      "Epoch 80/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4933 - mean_absolute_error: 0.3764\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.4933 - mean_absolute_error: 0.3764 - val_loss: 0.6415 - val_mean_absolute_error: 0.4658\n",
      "Epoch 81/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5116 - mean_absolute_error: 0.3907\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5120 - mean_absolute_error: 0.3910 - val_loss: 0.6106 - val_mean_absolute_error: 0.4362\n",
      "Epoch 82/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5115 - mean_absolute_error: 0.3864\n",
      "Epoch 00082: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/11\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5131 - mean_absolute_error: 0.3876 - val_loss: 0.6196 - val_mean_absolute_error: 0.4575\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 32.3503 - mean_absolute_error: 2.9227\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 7s 349us/step - loss: 32.1064 - mean_absolute_error: 2.9056 - val_loss: 14.6083 - val_mean_absolute_error: 1.8766\n",
      "Epoch 2/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 11.6702 - mean_absolute_error: 1.4024\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 11.6687 - mean_absolute_error: 1.4022 - val_loss: 9.5410 - val_mean_absolute_error: 1.0842\n",
      "Epoch 3/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 8.1550 - mean_absolute_error: 0.8543\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 8.1480 - mean_absolute_error: 0.8534 - val_loss: 7.3049 - val_mean_absolute_error: 0.7820\n",
      "Epoch 4/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 6.1144 - mean_absolute_error: 0.5506\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 6.1137 - mean_absolute_error: 0.5507 - val_loss: 5.7234 - val_mean_absolute_error: 0.6154\n",
      "Epoch 5/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 4.9604 - mean_absolute_error: 0.4991\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 4.9601 - mean_absolute_error: 0.4991 - val_loss: 4.8590 - val_mean_absolute_error: 0.7020\n",
      "Epoch 6/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 4.0650 - mean_absolute_error: 0.5004\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 4.0624 - mean_absolute_error: 0.5003 - val_loss: 3.7507 - val_mean_absolute_error: 0.5341\n",
      "Epoch 7/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 3.2520 - mean_absolute_error: 0.4668\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 3.2513 - mean_absolute_error: 0.4667 - val_loss: 3.0630 - val_mean_absolute_error: 0.5458\n",
      "Epoch 8/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 2.6627 - mean_absolute_error: 0.4864\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 5s 228us/step - loss: 2.6608 - mean_absolute_error: 0.4863 - val_loss: 2.4707 - val_mean_absolute_error: 0.5061\n",
      "Epoch 9/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 2.2310 - mean_absolute_error: 0.5124\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 2.2281 - mean_absolute_error: 0.5116 - val_loss: 2.0810 - val_mean_absolute_error: 0.5268\n",
      "Epoch 10/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.8545 - mean_absolute_error: 0.5127\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 1.8552 - mean_absolute_error: 0.5129 - val_loss: 1.9121 - val_mean_absolute_error: 0.5712\n",
      "Epoch 11/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.6222 - mean_absolute_error: 0.5223\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 1.6239 - mean_absolute_error: 0.5226 - val_loss: 1.6453 - val_mean_absolute_error: 0.5678\n",
      "Epoch 12/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 1.4358 - mean_absolute_error: 0.5225\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 1.4346 - mean_absolute_error: 0.5222 - val_loss: 1.4173 - val_mean_absolute_error: 0.5292\n",
      "Epoch 13/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.2855 - mean_absolute_error: 0.5059\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 1.2857 - mean_absolute_error: 0.5060 - val_loss: 1.2659 - val_mean_absolute_error: 0.5038\n",
      "Epoch 14/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 1.2027 - mean_absolute_error: 0.5173\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 1.2020 - mean_absolute_error: 0.5171 - val_loss: 1.1984 - val_mean_absolute_error: 0.5122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.1263 - mean_absolute_error: 0.5053\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 1.1275 - mean_absolute_error: 0.5059 - val_loss: 1.3808 - val_mean_absolute_error: 0.6494\n",
      "Epoch 16/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.0414 - mean_absolute_error: 0.4851\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 1.0425 - mean_absolute_error: 0.4859 - val_loss: 1.1567 - val_mean_absolute_error: 0.5458\n",
      "Epoch 17/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.0403 - mean_absolute_error: 0.4904\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 1.0406 - mean_absolute_error: 0.4905 - val_loss: 1.3359 - val_mean_absolute_error: 0.6769\n",
      "Epoch 18/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.9505 - mean_absolute_error: 0.4839\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.9505 - mean_absolute_error: 0.4840 - val_loss: 1.0073 - val_mean_absolute_error: 0.5055\n",
      "Epoch 19/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.8859 - mean_absolute_error: 0.4600\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.8857 - mean_absolute_error: 0.4599 - val_loss: 1.0384 - val_mean_absolute_error: 0.5522\n",
      "Epoch 20/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.8874 - mean_absolute_error: 0.4711\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.8875 - mean_absolute_error: 0.4712 - val_loss: 1.0607 - val_mean_absolute_error: 0.5084\n",
      "Epoch 21/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.8053 - mean_absolute_error: 0.4386\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.8055 - mean_absolute_error: 0.4387 - val_loss: 0.8860 - val_mean_absolute_error: 0.4623\n",
      "Epoch 22/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.7750 - mean_absolute_error: 0.4373\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.7748 - mean_absolute_error: 0.4372 - val_loss: 0.8562 - val_mean_absolute_error: 0.4739\n",
      "Epoch 23/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7815 - mean_absolute_error: 0.4444\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.7841 - mean_absolute_error: 0.4456 - val_loss: 1.0124 - val_mean_absolute_error: 0.5470\n",
      "Epoch 24/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.7387 - mean_absolute_error: 0.4347\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.7384 - mean_absolute_error: 0.4345 - val_loss: 0.8362 - val_mean_absolute_error: 0.4559\n",
      "Epoch 25/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7131 - mean_absolute_error: 0.4201\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.7133 - mean_absolute_error: 0.4204 - val_loss: 0.8005 - val_mean_absolute_error: 0.4746\n",
      "Epoch 26/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6950 - mean_absolute_error: 0.4245\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.6950 - mean_absolute_error: 0.4244 - val_loss: 0.8609 - val_mean_absolute_error: 0.4509\n",
      "Epoch 27/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.7153 - mean_absolute_error: 0.4251\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.7154 - mean_absolute_error: 0.4253 - val_loss: 0.8878 - val_mean_absolute_error: 0.5218\n",
      "Epoch 28/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6380 - mean_absolute_error: 0.4148\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.6394 - mean_absolute_error: 0.4156 - val_loss: 0.7550 - val_mean_absolute_error: 0.4615\n",
      "Epoch 29/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6804 - mean_absolute_error: 0.4397\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.6807 - mean_absolute_error: 0.4398 - val_loss: 0.8055 - val_mean_absolute_error: 0.4849\n",
      "Epoch 30/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6423 - mean_absolute_error: 0.4164\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.6424 - mean_absolute_error: 0.4165 - val_loss: 0.7106 - val_mean_absolute_error: 0.4498\n",
      "Epoch 31/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5979 - mean_absolute_error: 0.4019\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5978 - mean_absolute_error: 0.4019 - val_loss: 0.8269 - val_mean_absolute_error: 0.5425\n",
      "Epoch 32/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6307 - mean_absolute_error: 0.4248\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.6311 - mean_absolute_error: 0.4248 - val_loss: 0.7324 - val_mean_absolute_error: 0.4386\n",
      "Epoch 33/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.6301 - mean_absolute_error: 0.4178\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.6301 - mean_absolute_error: 0.4179 - val_loss: 0.8251 - val_mean_absolute_error: 0.5544\n",
      "Epoch 34/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6046 - mean_absolute_error: 0.4140\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.6047 - mean_absolute_error: 0.4140 - val_loss: 0.7073 - val_mean_absolute_error: 0.4516\n",
      "Epoch 35/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5930 - mean_absolute_error: 0.4106\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5929 - mean_absolute_error: 0.4105 - val_loss: 0.7557 - val_mean_absolute_error: 0.4881\n",
      "Epoch 36/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5730 - mean_absolute_error: 0.4011\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5726 - mean_absolute_error: 0.4010 - val_loss: 0.6529 - val_mean_absolute_error: 0.4340\n",
      "Epoch 37/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5833 - mean_absolute_error: 0.4146\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5864 - mean_absolute_error: 0.4165 - val_loss: 0.7821 - val_mean_absolute_error: 0.5234\n",
      "Epoch 38/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5881 - mean_absolute_error: 0.4146\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5885 - mean_absolute_error: 0.4149 - val_loss: 0.6965 - val_mean_absolute_error: 0.4703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5670 - mean_absolute_error: 0.3969\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5668 - mean_absolute_error: 0.3968 - val_loss: 0.6714 - val_mean_absolute_error: 0.4481\n",
      "Epoch 40/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5740 - mean_absolute_error: 0.4063\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5742 - mean_absolute_error: 0.4064 - val_loss: 0.6361 - val_mean_absolute_error: 0.4311\n",
      "Epoch 41/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5843 - mean_absolute_error: 0.4180\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5845 - mean_absolute_error: 0.4175 - val_loss: 0.7076 - val_mean_absolute_error: 0.4481\n",
      "Epoch 42/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5702 - mean_absolute_error: 0.4079\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5711 - mean_absolute_error: 0.4086 - val_loss: 0.6709 - val_mean_absolute_error: 0.4507\n",
      "Epoch 43/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5566 - mean_absolute_error: 0.3958\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5571 - mean_absolute_error: 0.3959 - val_loss: 0.6655 - val_mean_absolute_error: 0.4307\n",
      "Epoch 44/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5553 - mean_absolute_error: 0.4001\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5553 - mean_absolute_error: 0.4003 - val_loss: 0.6637 - val_mean_absolute_error: 0.4454\n",
      "Epoch 45/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5619 - mean_absolute_error: 0.4018\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5616 - mean_absolute_error: 0.4016 - val_loss: 0.6974 - val_mean_absolute_error: 0.4523\n",
      "Epoch 46/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5591 - mean_absolute_error: 0.3988\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5593 - mean_absolute_error: 0.3990 - val_loss: 0.7107 - val_mean_absolute_error: 0.4855\n",
      "Epoch 47/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5499 - mean_absolute_error: 0.3996\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5501 - mean_absolute_error: 0.3997 - val_loss: 0.7081 - val_mean_absolute_error: 0.4848\n",
      "Epoch 48/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5364 - mean_absolute_error: 0.3892\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5379 - mean_absolute_error: 0.3901 - val_loss: 0.7233 - val_mean_absolute_error: 0.5014\n",
      "Epoch 49/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5578 - mean_absolute_error: 0.4088\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5578 - mean_absolute_error: 0.4088 - val_loss: 0.6751 - val_mean_absolute_error: 0.4613\n",
      "Epoch 50/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5454 - mean_absolute_error: 0.4001\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5462 - mean_absolute_error: 0.4006 - val_loss: 0.6559 - val_mean_absolute_error: 0.4420\n",
      "Epoch 51/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5468 - mean_absolute_error: 0.4002\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5474 - mean_absolute_error: 0.4007 - val_loss: 0.6432 - val_mean_absolute_error: 0.4321\n",
      "Epoch 52/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5286 - mean_absolute_error: 0.3905\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5284 - mean_absolute_error: 0.3904 - val_loss: 0.6285 - val_mean_absolute_error: 0.4345\n",
      "Epoch 53/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5305 - mean_absolute_error: 0.3964\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5305 - mean_absolute_error: 0.3964 - val_loss: 0.6816 - val_mean_absolute_error: 0.4664\n",
      "Epoch 54/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5259 - mean_absolute_error: 0.3899\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5261 - mean_absolute_error: 0.3901 - val_loss: 0.6155 - val_mean_absolute_error: 0.4286\n",
      "Epoch 55/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5332 - mean_absolute_error: 0.3921\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 0.5331 - mean_absolute_error: 0.3920 - val_loss: 0.7805 - val_mean_absolute_error: 0.5441\n",
      "Epoch 56/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5412 - mean_absolute_error: 0.4008\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5417 - mean_absolute_error: 0.4012 - val_loss: 0.8439 - val_mean_absolute_error: 0.5922\n",
      "Epoch 57/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5342 - mean_absolute_error: 0.3973\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5348 - mean_absolute_error: 0.3975 - val_loss: 0.6627 - val_mean_absolute_error: 0.4666\n",
      "Epoch 58/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5164 - mean_absolute_error: 0.3855\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5172 - mean_absolute_error: 0.3863 - val_loss: 0.6568 - val_mean_absolute_error: 0.4405\n",
      "Epoch 59/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5189 - mean_absolute_error: 0.3863\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5193 - mean_absolute_error: 0.3867 - val_loss: 0.6447 - val_mean_absolute_error: 0.4481\n",
      "Epoch 60/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5283 - mean_absolute_error: 0.3938\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5287 - mean_absolute_error: 0.3940 - val_loss: 0.6284 - val_mean_absolute_error: 0.4374\n",
      "Epoch 61/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5330 - mean_absolute_error: 0.3952\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5325 - mean_absolute_error: 0.3950 - val_loss: 0.6213 - val_mean_absolute_error: 0.4352\n",
      "Epoch 62/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5266 - mean_absolute_error: 0.3955\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5282 - mean_absolute_error: 0.3960 - val_loss: 0.6767 - val_mean_absolute_error: 0.4676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5136 - mean_absolute_error: 0.3831\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5138 - mean_absolute_error: 0.3832 - val_loss: 0.6431 - val_mean_absolute_error: 0.4504\n",
      "Epoch 64/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5214 - mean_absolute_error: 0.3910\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5215 - mean_absolute_error: 0.3909 - val_loss: 0.6661 - val_mean_absolute_error: 0.4594\n",
      "Epoch 65/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5424 - mean_absolute_error: 0.4037\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5429 - mean_absolute_error: 0.4040 - val_loss: 0.6275 - val_mean_absolute_error: 0.4332\n",
      "Epoch 66/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5161 - mean_absolute_error: 0.3849\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5162 - mean_absolute_error: 0.3851 - val_loss: 0.6162 - val_mean_absolute_error: 0.4422\n",
      "Epoch 67/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4946 - mean_absolute_error: 0.3740\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.4944 - mean_absolute_error: 0.3738 - val_loss: 0.6032 - val_mean_absolute_error: 0.4250\n",
      "Epoch 68/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5156 - mean_absolute_error: 0.3889\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5156 - mean_absolute_error: 0.3889 - val_loss: 0.6309 - val_mean_absolute_error: 0.4365\n",
      "Epoch 69/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5300 - mean_absolute_error: 0.3937\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.5302 - mean_absolute_error: 0.3940 - val_loss: 0.6604 - val_mean_absolute_error: 0.4617\n",
      "Epoch 70/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5177 - mean_absolute_error: 0.3940\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5178 - mean_absolute_error: 0.3942 - val_loss: 0.5808 - val_mean_absolute_error: 0.4200\n",
      "Epoch 71/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5074 - mean_absolute_error: 0.3863\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5073 - mean_absolute_error: 0.3863 - val_loss: 0.6366 - val_mean_absolute_error: 0.4373\n",
      "Epoch 72/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5249 - mean_absolute_error: 0.4001\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5254 - mean_absolute_error: 0.4003 - val_loss: 0.6120 - val_mean_absolute_error: 0.4342\n",
      "Epoch 73/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5244 - mean_absolute_error: 0.3961\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5242 - mean_absolute_error: 0.3959 - val_loss: 0.6235 - val_mean_absolute_error: 0.4350\n",
      "Epoch 74/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4902 - mean_absolute_error: 0.3752\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.4901 - mean_absolute_error: 0.3751 - val_loss: 0.6131 - val_mean_absolute_error: 0.4356\n",
      "Epoch 75/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5176 - mean_absolute_error: 0.3913\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5179 - mean_absolute_error: 0.3916 - val_loss: 0.6678 - val_mean_absolute_error: 0.4638\n",
      "Epoch 76/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5240 - mean_absolute_error: 0.3981\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5244 - mean_absolute_error: 0.3983 - val_loss: 0.6345 - val_mean_absolute_error: 0.4530\n",
      "Epoch 77/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5028 - mean_absolute_error: 0.3820\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5032 - mean_absolute_error: 0.3821 - val_loss: 0.6112 - val_mean_absolute_error: 0.4354\n",
      "Epoch 78/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5083 - mean_absolute_error: 0.3860\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5086 - mean_absolute_error: 0.3860 - val_loss: 0.6222 - val_mean_absolute_error: 0.4353\n",
      "Epoch 79/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5026 - mean_absolute_error: 0.3840\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5025 - mean_absolute_error: 0.3840 - val_loss: 0.6329 - val_mean_absolute_error: 0.4430\n",
      "Epoch 80/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5145 - mean_absolute_error: 0.3865\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5142 - mean_absolute_error: 0.3864 - val_loss: 0.6340 - val_mean_absolute_error: 0.4469\n",
      "Epoch 81/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5068 - mean_absolute_error: 0.3861\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5068 - mean_absolute_error: 0.3861 - val_loss: 0.6402 - val_mean_absolute_error: 0.4501\n",
      "Epoch 82/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5107 - mean_absolute_error: 0.3897\n",
      "Epoch 00082: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5106 - mean_absolute_error: 0.3896 - val_loss: 0.6110 - val_mean_absolute_error: 0.4496\n",
      "Epoch 83/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5152 - mean_absolute_error: 0.3928\n",
      "Epoch 00083: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 216us/step - loss: 0.5154 - mean_absolute_error: 0.3928 - val_loss: 0.6209 - val_mean_absolute_error: 0.4362\n",
      "Epoch 84/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5071 - mean_absolute_error: 0.3841\n",
      "Epoch 00084: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 219us/step - loss: 0.5077 - mean_absolute_error: 0.3846 - val_loss: 0.6624 - val_mean_absolute_error: 0.4715\n",
      "Epoch 85/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5100 - mean_absolute_error: 0.3822\n",
      "Epoch 00085: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5098 - mean_absolute_error: 0.3821 - val_loss: 0.6298 - val_mean_absolute_error: 0.4383\n",
      "Epoch 86/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5002 - mean_absolute_error: 0.3827\n",
      "Epoch 00086: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5003 - mean_absolute_error: 0.3828 - val_loss: 0.6152 - val_mean_absolute_error: 0.4479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5099 - mean_absolute_error: 0.3857\n",
      "Epoch 00087: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 217us/step - loss: 0.5101 - mean_absolute_error: 0.3858 - val_loss: 0.6200 - val_mean_absolute_error: 0.4410\n",
      "Epoch 88/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5022 - mean_absolute_error: 0.3776\n",
      "Epoch 00088: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5022 - mean_absolute_error: 0.3777 - val_loss: 0.6253 - val_mean_absolute_error: 0.4387\n",
      "Epoch 89/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5085 - mean_absolute_error: 0.3806\n",
      "Epoch 00089: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 218us/step - loss: 0.5087 - mean_absolute_error: 0.3808 - val_loss: 0.6500 - val_mean_absolute_error: 0.4701\n",
      "Epoch 90/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5029 - mean_absolute_error: 0.3827\n",
      "Epoch 00090: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/12\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5026 - mean_absolute_error: 0.3825 - val_loss: 0.6255 - val_mean_absolute_error: 0.4530\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 48.9059 - mean_absolute_error: 3.8305\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 7s 364us/step - loss: 48.6827 - mean_absolute_error: 3.8181 - val_loss: 9.0561 - val_mean_absolute_error: 1.4594\n",
      "Epoch 2/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 6.3934 - mean_absolute_error: 0.9727\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 6.3841 - mean_absolute_error: 0.9711 - val_loss: 5.0426 - val_mean_absolute_error: 0.7789\n",
      "Epoch 3/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 4.1638 - mean_absolute_error: 0.5415\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 4.1645 - mean_absolute_error: 0.5420 - val_loss: 4.3536 - val_mean_absolute_error: 0.7919\n",
      "Epoch 4/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 3.5268 - mean_absolute_error: 0.5464\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 3.5260 - mean_absolute_error: 0.5469 - val_loss: 3.5372 - val_mean_absolute_error: 0.6761\n",
      "Epoch 5/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 3.0271 - mean_absolute_error: 0.5616\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 3.0241 - mean_absolute_error: 0.5613 - val_loss: 2.9753 - val_mean_absolute_error: 0.6524\n",
      "Epoch 6/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 2.4671 - mean_absolute_error: 0.4926\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 2.4662 - mean_absolute_error: 0.4926 - val_loss: 2.3859 - val_mean_absolute_error: 0.5390\n",
      "Epoch 7/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 2.2889 - mean_absolute_error: 0.5747\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 2.2880 - mean_absolute_error: 0.5747 - val_loss: 2.3755 - val_mean_absolute_error: 0.6577\n",
      "Epoch 8/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.9960 - mean_absolute_error: 0.5433\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 1.9965 - mean_absolute_error: 0.5438 - val_loss: 2.0633 - val_mean_absolute_error: 0.6263\n",
      "Epoch 9/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.8763 - mean_absolute_error: 0.5662\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 1.8761 - mean_absolute_error: 0.5663 - val_loss: 1.8126 - val_mean_absolute_error: 0.5588\n",
      "Epoch 10/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 1.6567 - mean_absolute_error: 0.5332\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 1.6562 - mean_absolute_error: 0.5333 - val_loss: 1.7946 - val_mean_absolute_error: 0.6252\n",
      "Epoch 11/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 1.5341 - mean_absolute_error: 0.5232\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 1.5337 - mean_absolute_error: 0.5235 - val_loss: 1.6500 - val_mean_absolute_error: 0.5946\n",
      "Epoch 12/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.5870 - mean_absolute_error: 0.5565\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 1.5898 - mean_absolute_error: 0.5575 - val_loss: 1.6620 - val_mean_absolute_error: 0.5644\n",
      "Epoch 13/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 1.4076 - mean_absolute_error: 0.5151\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 222us/step - loss: 1.4084 - mean_absolute_error: 0.5162 - val_loss: 1.5270 - val_mean_absolute_error: 0.6210\n",
      "Epoch 14/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.2774 - mean_absolute_error: 0.5118\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 1.2785 - mean_absolute_error: 0.5127 - val_loss: 1.3108 - val_mean_absolute_error: 0.5186\n",
      "Epoch 15/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 1.1712 - mean_absolute_error: 0.5039\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 1.1725 - mean_absolute_error: 0.5044 - val_loss: 1.3336 - val_mean_absolute_error: 0.5744\n",
      "Epoch 16/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 1.1490 - mean_absolute_error: 0.5242\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 1.1479 - mean_absolute_error: 0.5238 - val_loss: 1.1095 - val_mean_absolute_error: 0.4868\n",
      "Epoch 17/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.0080 - mean_absolute_error: 0.4763\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 1.0084 - mean_absolute_error: 0.4765 - val_loss: 1.1027 - val_mean_absolute_error: 0.4946\n",
      "Epoch 18/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.9777 - mean_absolute_error: 0.4742\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.9777 - mean_absolute_error: 0.4742 - val_loss: 1.0598 - val_mean_absolute_error: 0.5124\n",
      "Epoch 19/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.9360 - mean_absolute_error: 0.4737\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 232us/step - loss: 0.9363 - mean_absolute_error: 0.4740 - val_loss: 1.0647 - val_mean_absolute_error: 0.4911\n",
      "Epoch 20/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.9172 - mean_absolute_error: 0.4690\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.9171 - mean_absolute_error: 0.4687 - val_loss: 1.0098 - val_mean_absolute_error: 0.4984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.8636 - mean_absolute_error: 0.4465\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.8632 - mean_absolute_error: 0.4463 - val_loss: 1.0300 - val_mean_absolute_error: 0.5324\n",
      "Epoch 22/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.8777 - mean_absolute_error: 0.4669\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.8775 - mean_absolute_error: 0.4668 - val_loss: 1.1386 - val_mean_absolute_error: 0.5982\n",
      "Epoch 23/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.8427 - mean_absolute_error: 0.4551\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.8435 - mean_absolute_error: 0.4556 - val_loss: 1.1676 - val_mean_absolute_error: 0.6872\n",
      "Epoch 24/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7929 - mean_absolute_error: 0.4512\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.7918 - mean_absolute_error: 0.4504 - val_loss: 0.8111 - val_mean_absolute_error: 0.4368\n",
      "Epoch 25/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.7806 - mean_absolute_error: 0.4337\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.7811 - mean_absolute_error: 0.4341 - val_loss: 1.0741 - val_mean_absolute_error: 0.6183\n",
      "Epoch 26/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.7542 - mean_absolute_error: 0.4278\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 0.7551 - mean_absolute_error: 0.4282 - val_loss: 1.0653 - val_mean_absolute_error: 0.6166\n",
      "Epoch 27/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.7398 - mean_absolute_error: 0.4331\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.7418 - mean_absolute_error: 0.4340 - val_loss: 0.8837 - val_mean_absolute_error: 0.4940\n",
      "Epoch 28/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.7326 - mean_absolute_error: 0.4356\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.7324 - mean_absolute_error: 0.4356 - val_loss: 0.8118 - val_mean_absolute_error: 0.4690\n",
      "Epoch 29/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6766 - mean_absolute_error: 0.4223\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.6765 - mean_absolute_error: 0.4223 - val_loss: 0.7488 - val_mean_absolute_error: 0.4502\n",
      "Epoch 30/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.7079 - mean_absolute_error: 0.4362\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.7076 - mean_absolute_error: 0.4360 - val_loss: 0.8041 - val_mean_absolute_error: 0.4622\n",
      "Epoch 31/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6595 - mean_absolute_error: 0.4194\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.6589 - mean_absolute_error: 0.4190 - val_loss: 0.7441 - val_mean_absolute_error: 0.4578\n",
      "Epoch 32/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6257 - mean_absolute_error: 0.4118\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.6259 - mean_absolute_error: 0.4119 - val_loss: 0.7730 - val_mean_absolute_error: 0.4967\n",
      "Epoch 33/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6575 - mean_absolute_error: 0.4280\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 222us/step - loss: 0.6578 - mean_absolute_error: 0.4281 - val_loss: 0.7511 - val_mean_absolute_error: 0.4438\n",
      "Epoch 34/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6575 - mean_absolute_error: 0.4252\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.6574 - mean_absolute_error: 0.4252 - val_loss: 0.7265 - val_mean_absolute_error: 0.4474\n",
      "Epoch 35/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6077 - mean_absolute_error: 0.4022\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.6081 - mean_absolute_error: 0.4026 - val_loss: 0.8074 - val_mean_absolute_error: 0.5499\n",
      "Epoch 36/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6169 - mean_absolute_error: 0.4120\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.6169 - mean_absolute_error: 0.4120 - val_loss: 0.7212 - val_mean_absolute_error: 0.4596\n",
      "Epoch 37/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.6001 - mean_absolute_error: 0.4022\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 0.5997 - mean_absolute_error: 0.4021 - val_loss: 0.7225 - val_mean_absolute_error: 0.4563\n",
      "Epoch 38/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5957 - mean_absolute_error: 0.4074\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5960 - mean_absolute_error: 0.4075 - val_loss: 0.7626 - val_mean_absolute_error: 0.5005\n",
      "Epoch 39/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6205 - mean_absolute_error: 0.4236\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 222us/step - loss: 0.6206 - mean_absolute_error: 0.4236 - val_loss: 0.7023 - val_mean_absolute_error: 0.4489\n",
      "Epoch 40/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6182 - mean_absolute_error: 0.4225\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 0.6181 - mean_absolute_error: 0.4225 - val_loss: 0.6900 - val_mean_absolute_error: 0.4453\n",
      "Epoch 41/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5861 - mean_absolute_error: 0.3993\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5866 - mean_absolute_error: 0.3997 - val_loss: 0.7063 - val_mean_absolute_error: 0.4612\n",
      "Epoch 42/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5818 - mean_absolute_error: 0.4036\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 222us/step - loss: 0.5834 - mean_absolute_error: 0.4046 - val_loss: 0.6871 - val_mean_absolute_error: 0.4624\n",
      "Epoch 43/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5741 - mean_absolute_error: 0.4028\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5741 - mean_absolute_error: 0.4029 - val_loss: 0.6713 - val_mean_absolute_error: 0.4473\n",
      "Epoch 44/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5828 - mean_absolute_error: 0.4025\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5829 - mean_absolute_error: 0.4026 - val_loss: 0.7394 - val_mean_absolute_error: 0.5004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5944 - mean_absolute_error: 0.4134\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5946 - mean_absolute_error: 0.4136 - val_loss: 0.7250 - val_mean_absolute_error: 0.4661\n",
      "Epoch 46/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5817 - mean_absolute_error: 0.4012\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5821 - mean_absolute_error: 0.4014 - val_loss: 0.7761 - val_mean_absolute_error: 0.5199\n",
      "Epoch 47/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5549 - mean_absolute_error: 0.3900\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 0.5549 - mean_absolute_error: 0.3901 - val_loss: 0.6919 - val_mean_absolute_error: 0.4601\n",
      "Epoch 48/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5736 - mean_absolute_error: 0.4117\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.5736 - mean_absolute_error: 0.4117 - val_loss: 0.7336 - val_mean_absolute_error: 0.4934\n",
      "Epoch 49/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5815 - mean_absolute_error: 0.4132\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5814 - mean_absolute_error: 0.4131 - val_loss: 0.7022 - val_mean_absolute_error: 0.4752\n",
      "Epoch 50/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5717 - mean_absolute_error: 0.4066\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.5727 - mean_absolute_error: 0.4070 - val_loss: 0.8203 - val_mean_absolute_error: 0.5852\n",
      "Epoch 51/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5714 - mean_absolute_error: 0.4089\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 220us/step - loss: 0.5711 - mean_absolute_error: 0.4086 - val_loss: 0.6771 - val_mean_absolute_error: 0.4507\n",
      "Epoch 52/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5569 - mean_absolute_error: 0.3964\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5573 - mean_absolute_error: 0.3966 - val_loss: 0.6471 - val_mean_absolute_error: 0.4444\n",
      "Epoch 53/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5430 - mean_absolute_error: 0.3899\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5450 - mean_absolute_error: 0.3909 - val_loss: 0.6712 - val_mean_absolute_error: 0.4461\n",
      "Epoch 54/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5604 - mean_absolute_error: 0.4040\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5610 - mean_absolute_error: 0.4042 - val_loss: 0.6515 - val_mean_absolute_error: 0.4430\n",
      "Epoch 55/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5464 - mean_absolute_error: 0.3916\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 222us/step - loss: 0.5467 - mean_absolute_error: 0.3918 - val_loss: 0.7130 - val_mean_absolute_error: 0.4892\n",
      "Epoch 56/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5575 - mean_absolute_error: 0.4020\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5572 - mean_absolute_error: 0.4018 - val_loss: 0.7032 - val_mean_absolute_error: 0.4827\n",
      "Epoch 57/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5455 - mean_absolute_error: 0.3969\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 222us/step - loss: 0.5454 - mean_absolute_error: 0.3968 - val_loss: 0.6619 - val_mean_absolute_error: 0.4488\n",
      "Epoch 58/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5512 - mean_absolute_error: 0.4003\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5513 - mean_absolute_error: 0.4004 - val_loss: 0.6929 - val_mean_absolute_error: 0.4720\n",
      "Epoch 59/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5583 - mean_absolute_error: 0.3997\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5584 - mean_absolute_error: 0.3997 - val_loss: 0.7131 - val_mean_absolute_error: 0.4635\n",
      "Epoch 60/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5491 - mean_absolute_error: 0.3896\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5495 - mean_absolute_error: 0.3899 - val_loss: 0.7289 - val_mean_absolute_error: 0.5149\n",
      "Epoch 61/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5178 - mean_absolute_error: 0.3798\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 0.5182 - mean_absolute_error: 0.3802 - val_loss: 0.6112 - val_mean_absolute_error: 0.4222\n",
      "Epoch 62/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5333 - mean_absolute_error: 0.3897\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 4s 221us/step - loss: 0.5331 - mean_absolute_error: 0.3896 - val_loss: 0.6361 - val_mean_absolute_error: 0.4430\n",
      "Epoch 63/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5379 - mean_absolute_error: 0.3929\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 225us/step - loss: 0.5393 - mean_absolute_error: 0.3935 - val_loss: 0.6505 - val_mean_absolute_error: 0.4420\n",
      "Epoch 64/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5479 - mean_absolute_error: 0.3992\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 228us/step - loss: 0.5482 - mean_absolute_error: 0.3994 - val_loss: 0.7826 - val_mean_absolute_error: 0.5167\n",
      "Epoch 65/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5445 - mean_absolute_error: 0.3918\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5443 - mean_absolute_error: 0.3917 - val_loss: 0.6952 - val_mean_absolute_error: 0.4873\n",
      "Epoch 66/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5228 - mean_absolute_error: 0.3816\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5228 - mean_absolute_error: 0.3819 - val_loss: 0.6383 - val_mean_absolute_error: 0.4315\n",
      "Epoch 67/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5444 - mean_absolute_error: 0.4007\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5442 - mean_absolute_error: 0.4006 - val_loss: 0.6264 - val_mean_absolute_error: 0.4349\n",
      "Epoch 68/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5276 - mean_absolute_error: 0.3863\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5272 - mean_absolute_error: 0.3862 - val_loss: 0.6518 - val_mean_absolute_error: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5485 - mean_absolute_error: 0.3960\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.5484 - mean_absolute_error: 0.3960 - val_loss: 0.7055 - val_mean_absolute_error: 0.4759\n",
      "Epoch 70/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5327 - mean_absolute_error: 0.3873\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 232us/step - loss: 0.5326 - mean_absolute_error: 0.3872 - val_loss: 0.6168 - val_mean_absolute_error: 0.4266\n",
      "Epoch 71/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5329 - mean_absolute_error: 0.3949\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5331 - mean_absolute_error: 0.3951 - val_loss: 0.7033 - val_mean_absolute_error: 0.5049\n",
      "Epoch 72/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5254 - mean_absolute_error: 0.3905\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 226us/step - loss: 0.5256 - mean_absolute_error: 0.3905 - val_loss: 0.6785 - val_mean_absolute_error: 0.4598\n",
      "Epoch 73/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5037 - mean_absolute_error: 0.3749\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 222us/step - loss: 0.5044 - mean_absolute_error: 0.3751 - val_loss: 0.6480 - val_mean_absolute_error: 0.4519\n",
      "Epoch 74/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5240 - mean_absolute_error: 0.3845\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5250 - mean_absolute_error: 0.3852 - val_loss: 0.6495 - val_mean_absolute_error: 0.4558\n",
      "Epoch 75/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5245 - mean_absolute_error: 0.3894\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 224us/step - loss: 0.5247 - mean_absolute_error: 0.3896 - val_loss: 0.6219 - val_mean_absolute_error: 0.4364\n",
      "Epoch 76/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5341 - mean_absolute_error: 0.3973\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5337 - mean_absolute_error: 0.3972 - val_loss: 0.6320 - val_mean_absolute_error: 0.4302\n",
      "Epoch 77/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5075 - mean_absolute_error: 0.3760\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5075 - mean_absolute_error: 0.3759 - val_loss: 0.6624 - val_mean_absolute_error: 0.4569\n",
      "Epoch 78/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5258 - mean_absolute_error: 0.3879\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5259 - mean_absolute_error: 0.3880 - val_loss: 0.6550 - val_mean_absolute_error: 0.4423\n",
      "Epoch 79/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5281 - mean_absolute_error: 0.3859\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 223us/step - loss: 0.5282 - mean_absolute_error: 0.3860 - val_loss: 0.6775 - val_mean_absolute_error: 0.4664\n",
      "Epoch 80/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5145 - mean_absolute_error: 0.3840\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 236us/step - loss: 0.5151 - mean_absolute_error: 0.3843 - val_loss: 0.6162 - val_mean_absolute_error: 0.4405\n",
      "Epoch 81/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5135 - mean_absolute_error: 0.3800\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/13\n",
      "20282/20282 [==============================] - 5s 232us/step - loss: 0.5140 - mean_absolute_error: 0.3802 - val_loss: 0.7144 - val_mean_absolute_error: 0.5067\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 32.1272 - mean_absolute_error: 2.9998\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 8s 384us/step - loss: 31.9615 - mean_absolute_error: 2.9890 - val_loss: 13.7698 - val_mean_absolute_error: 1.8227\n",
      "Epoch 2/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 11.9765 - mean_absolute_error: 1.5901\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 11.9434 - mean_absolute_error: 1.5852 - val_loss: 9.2845 - val_mean_absolute_error: 1.1869\n",
      "Epoch 3/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 7.5311 - mean_absolute_error: 0.8974\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 231us/step - loss: 7.5204 - mean_absolute_error: 0.8971 - val_loss: 6.3613 - val_mean_absolute_error: 0.7382\n",
      "Epoch 4/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 5.3903 - mean_absolute_error: 0.5589\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 234us/step - loss: 5.3825 - mean_absolute_error: 0.5581 - val_loss: 4.9814 - val_mean_absolute_error: 0.5973\n",
      "Epoch 5/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 4.3240 - mean_absolute_error: 0.5283\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 4.3232 - mean_absolute_error: 0.5300 - val_loss: 4.1306 - val_mean_absolute_error: 0.6373\n",
      "Epoch 6/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 3.5415 - mean_absolute_error: 0.5359\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 238us/step - loss: 3.5370 - mean_absolute_error: 0.5357 - val_loss: 3.2599 - val_mean_absolute_error: 0.5464\n",
      "Epoch 7/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 2.8271 - mean_absolute_error: 0.5090\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 238us/step - loss: 2.8252 - mean_absolute_error: 0.5093 - val_loss: 2.9348 - val_mean_absolute_error: 0.7449\n",
      "Epoch 8/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 2.3101 - mean_absolute_error: 0.5207\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 236us/step - loss: 2.3082 - mean_absolute_error: 0.5210 - val_loss: 2.1333 - val_mean_absolute_error: 0.5148\n",
      "Epoch 9/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 1.9094 - mean_absolute_error: 0.5136\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 1.9090 - mean_absolute_error: 0.5136 - val_loss: 1.9401 - val_mean_absolute_error: 0.6059\n",
      "Epoch 10/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 1.6036 - mean_absolute_error: 0.5012\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 1.6019 - mean_absolute_error: 0.5011 - val_loss: 1.6802 - val_mean_absolute_error: 0.5883\n",
      "Epoch 11/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.4764 - mean_absolute_error: 0.5397\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 1.4761 - mean_absolute_error: 0.5396 - val_loss: 1.4857 - val_mean_absolute_error: 0.5671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 1.2766 - mean_absolute_error: 0.4961\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 1.2775 - mean_absolute_error: 0.4968 - val_loss: 1.3389 - val_mean_absolute_error: 0.5337\n",
      "Epoch 13/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.2406 - mean_absolute_error: 0.5267\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 1.2405 - mean_absolute_error: 0.5266 - val_loss: 1.2938 - val_mean_absolute_error: 0.5750\n",
      "Epoch 14/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 1.1567 - mean_absolute_error: 0.5100\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 1.1572 - mean_absolute_error: 0.5104 - val_loss: 1.2641 - val_mean_absolute_error: 0.5462\n",
      "Epoch 15/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.0993 - mean_absolute_error: 0.4970\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 1.0995 - mean_absolute_error: 0.4971 - val_loss: 1.2811 - val_mean_absolute_error: 0.5865\n",
      "Epoch 16/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.0615 - mean_absolute_error: 0.4998\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 231us/step - loss: 1.0611 - mean_absolute_error: 0.4995 - val_loss: 1.2104 - val_mean_absolute_error: 0.5582\n",
      "Epoch 17/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 1.0410 - mean_absolute_error: 0.4880\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 239us/step - loss: 1.0414 - mean_absolute_error: 0.4884 - val_loss: 1.1699 - val_mean_absolute_error: 0.5587\n",
      "Epoch 18/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.9435 - mean_absolute_error: 0.4653\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 236us/step - loss: 0.9437 - mean_absolute_error: 0.4656 - val_loss: 1.0108 - val_mean_absolute_error: 0.4964\n",
      "Epoch 19/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.9159 - mean_absolute_error: 0.4550\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 231us/step - loss: 0.9160 - mean_absolute_error: 0.4552 - val_loss: 0.9724 - val_mean_absolute_error: 0.4741\n",
      "Epoch 20/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.8804 - mean_absolute_error: 0.4574\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.8799 - mean_absolute_error: 0.4572 - val_loss: 0.9434 - val_mean_absolute_error: 0.4782\n",
      "Epoch 21/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.8769 - mean_absolute_error: 0.4647\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 240us/step - loss: 0.8777 - mean_absolute_error: 0.4652 - val_loss: 1.0751 - val_mean_absolute_error: 0.5848\n",
      "Epoch 22/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.8510 - mean_absolute_error: 0.4512\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 240us/step - loss: 0.8514 - mean_absolute_error: 0.4514 - val_loss: 1.0978 - val_mean_absolute_error: 0.5753\n",
      "Epoch 23/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.8181 - mean_absolute_error: 0.4510\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.8187 - mean_absolute_error: 0.4518 - val_loss: 0.8943 - val_mean_absolute_error: 0.4717\n",
      "Epoch 24/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.7483 - mean_absolute_error: 0.4262\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.7482 - mean_absolute_error: 0.4261 - val_loss: 0.9604 - val_mean_absolute_error: 0.5374\n",
      "Epoch 25/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7658 - mean_absolute_error: 0.4365\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.7666 - mean_absolute_error: 0.4369 - val_loss: 0.8815 - val_mean_absolute_error: 0.5044\n",
      "Epoch 26/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7052 - mean_absolute_error: 0.4262\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.7062 - mean_absolute_error: 0.4267 - val_loss: 0.8696 - val_mean_absolute_error: 0.4728\n",
      "Epoch 27/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.7246 - mean_absolute_error: 0.4308\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.7246 - mean_absolute_error: 0.4309 - val_loss: 0.7972 - val_mean_absolute_error: 0.4505\n",
      "Epoch 28/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6539 - mean_absolute_error: 0.4075\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.6546 - mean_absolute_error: 0.4081 - val_loss: 0.7347 - val_mean_absolute_error: 0.4326\n",
      "Epoch 29/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6646 - mean_absolute_error: 0.4136\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.6659 - mean_absolute_error: 0.4144 - val_loss: 1.1353 - val_mean_absolute_error: 0.7251\n",
      "Epoch 30/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6936 - mean_absolute_error: 0.4402\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 231us/step - loss: 0.6936 - mean_absolute_error: 0.4401 - val_loss: 0.8113 - val_mean_absolute_error: 0.4792\n",
      "Epoch 31/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6448 - mean_absolute_error: 0.4083\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 232us/step - loss: 0.6450 - mean_absolute_error: 0.4087 - val_loss: 0.7775 - val_mean_absolute_error: 0.4873\n",
      "Epoch 32/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6451 - mean_absolute_error: 0.4184\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.6464 - mean_absolute_error: 0.4190 - val_loss: 0.8386 - val_mean_absolute_error: 0.5297\n",
      "Epoch 33/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6586 - mean_absolute_error: 0.4278\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.6586 - mean_absolute_error: 0.4277 - val_loss: 0.7868 - val_mean_absolute_error: 0.4799\n",
      "Epoch 34/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6360 - mean_absolute_error: 0.4159\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 231us/step - loss: 0.6360 - mean_absolute_error: 0.4158 - val_loss: 0.6843 - val_mean_absolute_error: 0.4204\n",
      "Epoch 35/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5973 - mean_absolute_error: 0.3984\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5979 - mean_absolute_error: 0.3987 - val_loss: 0.6953 - val_mean_absolute_error: 0.4276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6100 - mean_absolute_error: 0.4016\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.6105 - mean_absolute_error: 0.4018 - val_loss: 0.7091 - val_mean_absolute_error: 0.4264\n",
      "Epoch 37/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.6066 - mean_absolute_error: 0.4098\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 6s 274us/step - loss: 0.6068 - mean_absolute_error: 0.4102 - val_loss: 0.8222 - val_mean_absolute_error: 0.5490\n",
      "Epoch 38/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6041 - mean_absolute_error: 0.4132\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 6s 289us/step - loss: 0.6045 - mean_absolute_error: 0.4134 - val_loss: 0.8122 - val_mean_absolute_error: 0.5413\n",
      "Epoch 39/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5891 - mean_absolute_error: 0.4027\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.5888 - mean_absolute_error: 0.4025 - val_loss: 0.6788 - val_mean_absolute_error: 0.4440\n",
      "Epoch 40/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5661 - mean_absolute_error: 0.3970\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.5660 - mean_absolute_error: 0.3969 - val_loss: 0.6937 - val_mean_absolute_error: 0.4479\n",
      "Epoch 41/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5916 - mean_absolute_error: 0.4097\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 6s 276us/step - loss: 0.5917 - mean_absolute_error: 0.4098 - val_loss: 0.7054 - val_mean_absolute_error: 0.4591\n",
      "Epoch 42/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5735 - mean_absolute_error: 0.3987\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 6s 319us/step - loss: 0.5742 - mean_absolute_error: 0.3990 - val_loss: 0.7081 - val_mean_absolute_error: 0.4592\n",
      "Epoch 43/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5837 - mean_absolute_error: 0.3995\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 6s 306us/step - loss: 0.5836 - mean_absolute_error: 0.3994 - val_loss: 0.6797 - val_mean_absolute_error: 0.4465\n",
      "Epoch 44/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5686 - mean_absolute_error: 0.3963\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 269us/step - loss: 0.5699 - mean_absolute_error: 0.3974 - val_loss: 0.6710 - val_mean_absolute_error: 0.4479\n",
      "Epoch 45/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5772 - mean_absolute_error: 0.4052\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.5775 - mean_absolute_error: 0.4056 - val_loss: 0.6667 - val_mean_absolute_error: 0.4421\n",
      "Epoch 46/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5691 - mean_absolute_error: 0.4005\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.5706 - mean_absolute_error: 0.4016 - val_loss: 0.6747 - val_mean_absolute_error: 0.4524\n",
      "Epoch 47/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5684 - mean_absolute_error: 0.3982\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 242us/step - loss: 0.5684 - mean_absolute_error: 0.3983 - val_loss: 0.6379 - val_mean_absolute_error: 0.4241\n",
      "Epoch 48/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5647 - mean_absolute_error: 0.3993\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 271us/step - loss: 0.5651 - mean_absolute_error: 0.3995 - val_loss: 0.6748 - val_mean_absolute_error: 0.4488\n",
      "Epoch 49/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5732 - mean_absolute_error: 0.4019\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5736 - mean_absolute_error: 0.4024 - val_loss: 0.6844 - val_mean_absolute_error: 0.4397\n",
      "Epoch 50/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5722 - mean_absolute_error: 0.4079\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5727 - mean_absolute_error: 0.4082 - val_loss: 0.7571 - val_mean_absolute_error: 0.5037\n",
      "Epoch 51/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5698 - mean_absolute_error: 0.3989\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5693 - mean_absolute_error: 0.3986 - val_loss: 0.6453 - val_mean_absolute_error: 0.4305\n",
      "Epoch 52/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5463 - mean_absolute_error: 0.3881\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5467 - mean_absolute_error: 0.3882 - val_loss: 0.7135 - val_mean_absolute_error: 0.4857\n",
      "Epoch 53/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5594 - mean_absolute_error: 0.3935\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.5595 - mean_absolute_error: 0.3935 - val_loss: 0.6474 - val_mean_absolute_error: 0.4466\n",
      "Epoch 54/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5431 - mean_absolute_error: 0.3903\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5436 - mean_absolute_error: 0.3906 - val_loss: 0.6730 - val_mean_absolute_error: 0.4570\n",
      "Epoch 55/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5591 - mean_absolute_error: 0.3941\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5592 - mean_absolute_error: 0.3942 - val_loss: 0.6582 - val_mean_absolute_error: 0.4417\n",
      "Epoch 56/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5622 - mean_absolute_error: 0.4003\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5617 - mean_absolute_error: 0.4000 - val_loss: 0.6525 - val_mean_absolute_error: 0.4285\n",
      "Epoch 57/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5420 - mean_absolute_error: 0.3891\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5419 - mean_absolute_error: 0.3891 - val_loss: 0.6534 - val_mean_absolute_error: 0.4438\n",
      "Epoch 58/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5418 - mean_absolute_error: 0.3880\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5417 - mean_absolute_error: 0.3880 - val_loss: 0.6508 - val_mean_absolute_error: 0.4515\n",
      "Epoch 59/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5405 - mean_absolute_error: 0.3858\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5403 - mean_absolute_error: 0.3857 - val_loss: 0.6182 - val_mean_absolute_error: 0.4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5516 - mean_absolute_error: 0.3952\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5522 - mean_absolute_error: 0.3954 - val_loss: 0.6638 - val_mean_absolute_error: 0.4394\n",
      "Epoch 61/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.5624 - mean_absolute_error: 0.3920\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.5622 - mean_absolute_error: 0.3920 - val_loss: 0.6407 - val_mean_absolute_error: 0.4422\n",
      "Epoch 62/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5566 - mean_absolute_error: 0.4013\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5565 - mean_absolute_error: 0.4013 - val_loss: 0.6225 - val_mean_absolute_error: 0.4283\n",
      "Epoch 63/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5293 - mean_absolute_error: 0.3853\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5294 - mean_absolute_error: 0.3853 - val_loss: 0.7464 - val_mean_absolute_error: 0.5172\n",
      "Epoch 64/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5515 - mean_absolute_error: 0.3950\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5523 - mean_absolute_error: 0.3953 - val_loss: 0.6471 - val_mean_absolute_error: 0.4239\n",
      "Epoch 65/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5362 - mean_absolute_error: 0.3814\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5359 - mean_absolute_error: 0.3814 - val_loss: 0.6451 - val_mean_absolute_error: 0.4603\n",
      "Epoch 66/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5388 - mean_absolute_error: 0.3931\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5389 - mean_absolute_error: 0.3932 - val_loss: 0.6648 - val_mean_absolute_error: 0.4572\n",
      "Epoch 67/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5387 - mean_absolute_error: 0.3912\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.5382 - mean_absolute_error: 0.3908 - val_loss: 0.6233 - val_mean_absolute_error: 0.4225\n",
      "Epoch 68/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5532 - mean_absolute_error: 0.3979\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5529 - mean_absolute_error: 0.3977 - val_loss: 0.6349 - val_mean_absolute_error: 0.4390\n",
      "Epoch 69/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5197 - mean_absolute_error: 0.3793\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5196 - mean_absolute_error: 0.3794 - val_loss: 0.6678 - val_mean_absolute_error: 0.4693\n",
      "Epoch 70/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5331 - mean_absolute_error: 0.3875\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.5329 - mean_absolute_error: 0.3874 - val_loss: 0.6524 - val_mean_absolute_error: 0.4312\n",
      "Epoch 71/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5319 - mean_absolute_error: 0.3857\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5319 - mean_absolute_error: 0.3857 - val_loss: 0.6417 - val_mean_absolute_error: 0.4370\n",
      "Epoch 72/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5292 - mean_absolute_error: 0.3870\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5294 - mean_absolute_error: 0.3871 - val_loss: 0.6568 - val_mean_absolute_error: 0.4513\n",
      "Epoch 73/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5549 - mean_absolute_error: 0.4066\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5551 - mean_absolute_error: 0.4066 - val_loss: 0.6453 - val_mean_absolute_error: 0.4358\n",
      "Epoch 74/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5219 - mean_absolute_error: 0.3799\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5218 - mean_absolute_error: 0.3798 - val_loss: 0.6650 - val_mean_absolute_error: 0.4810\n",
      "Epoch 75/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5419 - mean_absolute_error: 0.3939\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5419 - mean_absolute_error: 0.3940 - val_loss: 0.7400 - val_mean_absolute_error: 0.5094\n",
      "Epoch 76/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5268 - mean_absolute_error: 0.3871\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5269 - mean_absolute_error: 0.3872 - val_loss: 0.6177 - val_mean_absolute_error: 0.4273\n",
      "Epoch 77/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5288 - mean_absolute_error: 0.3885\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5290 - mean_absolute_error: 0.3885 - val_loss: 0.6250 - val_mean_absolute_error: 0.4194\n",
      "Epoch 78/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5146 - mean_absolute_error: 0.3798\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5149 - mean_absolute_error: 0.3800 - val_loss: 0.6353 - val_mean_absolute_error: 0.4365\n",
      "Epoch 79/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5251 - mean_absolute_error: 0.3843\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5251 - mean_absolute_error: 0.3842 - val_loss: 0.6372 - val_mean_absolute_error: 0.4374\n",
      "Epoch 80/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5308 - mean_absolute_error: 0.3886\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5307 - mean_absolute_error: 0.3885 - val_loss: 0.6163 - val_mean_absolute_error: 0.4303\n",
      "Epoch 81/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5256 - mean_absolute_error: 0.3903\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5261 - mean_absolute_error: 0.3905 - val_loss: 0.6869 - val_mean_absolute_error: 0.4686\n",
      "Epoch 82/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5289 - mean_absolute_error: 0.3866\n",
      "Epoch 00082: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5285 - mean_absolute_error: 0.3863 - val_loss: 0.6414 - val_mean_absolute_error: 0.4428\n",
      "Epoch 83/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5217 - mean_absolute_error: 0.3865\n",
      "Epoch 00083: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5227 - mean_absolute_error: 0.3871 - val_loss: 0.6390 - val_mean_absolute_error: 0.4402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5234 - mean_absolute_error: 0.3835\n",
      "Epoch 00084: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5235 - mean_absolute_error: 0.3836 - val_loss: 0.6238 - val_mean_absolute_error: 0.4238\n",
      "Epoch 85/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5150 - mean_absolute_error: 0.3810\n",
      "Epoch 00085: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5150 - mean_absolute_error: 0.3811 - val_loss: 0.6174 - val_mean_absolute_error: 0.4278\n",
      "Epoch 86/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5382 - mean_absolute_error: 0.3908\n",
      "Epoch 00086: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5384 - mean_absolute_error: 0.3911 - val_loss: 0.6541 - val_mean_absolute_error: 0.4573\n",
      "Epoch 87/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5239 - mean_absolute_error: 0.3816\n",
      "Epoch 00087: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5237 - mean_absolute_error: 0.3814 - val_loss: 0.6168 - val_mean_absolute_error: 0.4214\n",
      "Epoch 88/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5157 - mean_absolute_error: 0.3794\n",
      "Epoch 00088: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5163 - mean_absolute_error: 0.3799 - val_loss: 0.6122 - val_mean_absolute_error: 0.4353\n",
      "Epoch 89/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5369 - mean_absolute_error: 0.3963\n",
      "Epoch 00089: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5370 - mean_absolute_error: 0.3964 - val_loss: 0.6192 - val_mean_absolute_error: 0.4317\n",
      "Epoch 90/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.4922 - mean_absolute_error: 0.3686\n",
      "Epoch 00090: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.4921 - mean_absolute_error: 0.3686 - val_loss: 0.6693 - val_mean_absolute_error: 0.4710\n",
      "Epoch 91/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5334 - mean_absolute_error: 0.3886\n",
      "Epoch 00091: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5336 - mean_absolute_error: 0.3886 - val_loss: 0.6075 - val_mean_absolute_error: 0.4218\n",
      "Epoch 92/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5132 - mean_absolute_error: 0.3811\n",
      "Epoch 00092: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5134 - mean_absolute_error: 0.3812 - val_loss: 0.6184 - val_mean_absolute_error: 0.4268\n",
      "Epoch 93/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5033 - mean_absolute_error: 0.3733\n",
      "Epoch 00093: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5033 - mean_absolute_error: 0.3733 - val_loss: 0.6830 - val_mean_absolute_error: 0.4612\n",
      "Epoch 94/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5285 - mean_absolute_error: 0.3912\n",
      "Epoch 00094: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5285 - mean_absolute_error: 0.3912 - val_loss: 0.6319 - val_mean_absolute_error: 0.4388\n",
      "Epoch 95/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5102 - mean_absolute_error: 0.3754\n",
      "Epoch 00095: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5108 - mean_absolute_error: 0.3759 - val_loss: 0.6136 - val_mean_absolute_error: 0.4247\n",
      "Epoch 96/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5219 - mean_absolute_error: 0.3910\n",
      "Epoch 00096: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5220 - mean_absolute_error: 0.3909 - val_loss: 0.6471 - val_mean_absolute_error: 0.4457\n",
      "Epoch 97/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5144 - mean_absolute_error: 0.3812\n",
      "Epoch 00097: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5143 - mean_absolute_error: 0.3811 - val_loss: 0.6181 - val_mean_absolute_error: 0.4294\n",
      "Epoch 98/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5274 - mean_absolute_error: 0.3880\n",
      "Epoch 00098: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5271 - mean_absolute_error: 0.3879 - val_loss: 0.6781 - val_mean_absolute_error: 0.4772\n",
      "Epoch 99/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5070 - mean_absolute_error: 0.3805\n",
      "Epoch 00099: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5068 - mean_absolute_error: 0.3804 - val_loss: 0.6394 - val_mean_absolute_error: 0.4390\n",
      "Epoch 100/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5113 - mean_absolute_error: 0.3792\n",
      "Epoch 00100: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5111 - mean_absolute_error: 0.3791 - val_loss: 0.6090 - val_mean_absolute_error: 0.4184\n",
      "Epoch 101/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5079 - mean_absolute_error: 0.3781\n",
      "Epoch 00101: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5085 - mean_absolute_error: 0.3785 - val_loss: 0.6580 - val_mean_absolute_error: 0.4734\n",
      "Epoch 102/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5190 - mean_absolute_error: 0.3833\n",
      "Epoch 00102: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5205 - mean_absolute_error: 0.3842 - val_loss: 0.7248 - val_mean_absolute_error: 0.5232\n",
      "Epoch 103/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5113 - mean_absolute_error: 0.3847\n",
      "Epoch 00103: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5114 - mean_absolute_error: 0.3848 - val_loss: 0.6125 - val_mean_absolute_error: 0.4285\n",
      "Epoch 104/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5125 - mean_absolute_error: 0.3844\n",
      "Epoch 00104: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5123 - mean_absolute_error: 0.3843 - val_loss: 0.6762 - val_mean_absolute_error: 0.4683\n",
      "Epoch 105/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5236 - mean_absolute_error: 0.3872\n",
      "Epoch 00105: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5237 - mean_absolute_error: 0.3872 - val_loss: 0.6357 - val_mean_absolute_error: 0.4326\n",
      "Epoch 106/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5052 - mean_absolute_error: 0.3784\n",
      "Epoch 00106: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5052 - mean_absolute_error: 0.3784 - val_loss: 0.6205 - val_mean_absolute_error: 0.4294\n",
      "Epoch 107/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5116 - mean_absolute_error: 0.3791\n",
      "Epoch 00107: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5115 - mean_absolute_error: 0.3790 - val_loss: 0.6187 - val_mean_absolute_error: 0.4326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5055 - mean_absolute_error: 0.3798\n",
      "Epoch 00108: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5055 - mean_absolute_error: 0.3799 - val_loss: 0.6268 - val_mean_absolute_error: 0.4375\n",
      "Epoch 109/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5024 - mean_absolute_error: 0.3776\n",
      "Epoch 00109: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5036 - mean_absolute_error: 0.3782 - val_loss: 0.6314 - val_mean_absolute_error: 0.4457\n",
      "Epoch 110/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5111 - mean_absolute_error: 0.3768\n",
      "Epoch 00110: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5111 - mean_absolute_error: 0.3768 - val_loss: 0.6347 - val_mean_absolute_error: 0.4282\n",
      "Epoch 111/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5004 - mean_absolute_error: 0.3766\n",
      "Epoch 00111: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5005 - mean_absolute_error: 0.3767 - val_loss: 0.5944 - val_mean_absolute_error: 0.4297\n",
      "Epoch 112/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5081 - mean_absolute_error: 0.3767\n",
      "Epoch 00112: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5081 - mean_absolute_error: 0.3769 - val_loss: 0.6081 - val_mean_absolute_error: 0.4242\n",
      "Epoch 113/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4971 - mean_absolute_error: 0.3713\n",
      "Epoch 00113: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.4975 - mean_absolute_error: 0.3716 - val_loss: 0.6513 - val_mean_absolute_error: 0.4555\n",
      "Epoch 114/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5140 - mean_absolute_error: 0.3836\n",
      "Epoch 00114: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5136 - mean_absolute_error: 0.3832 - val_loss: 0.6253 - val_mean_absolute_error: 0.4277\n",
      "Epoch 115/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5045 - mean_absolute_error: 0.3763\n",
      "Epoch 00115: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5049 - mean_absolute_error: 0.3765 - val_loss: 0.6493 - val_mean_absolute_error: 0.4541\n",
      "Epoch 116/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4935 - mean_absolute_error: 0.3693\n",
      "Epoch 00116: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.4938 - mean_absolute_error: 0.3696 - val_loss: 0.7675 - val_mean_absolute_error: 0.5446\n",
      "Epoch 117/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5248 - mean_absolute_error: 0.3891\n",
      "Epoch 00117: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.5249 - mean_absolute_error: 0.3892 - val_loss: 0.6643 - val_mean_absolute_error: 0.4446\n",
      "Epoch 118/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5083 - mean_absolute_error: 0.3777\n",
      "Epoch 00118: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5083 - mean_absolute_error: 0.3778 - val_loss: 0.6612 - val_mean_absolute_error: 0.4590\n",
      "Epoch 119/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5030 - mean_absolute_error: 0.3747\n",
      "Epoch 00119: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.5033 - mean_absolute_error: 0.3750 - val_loss: 0.6082 - val_mean_absolute_error: 0.4231\n",
      "Epoch 120/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4980 - mean_absolute_error: 0.3717\n",
      "Epoch 00120: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.4981 - mean_absolute_error: 0.3719 - val_loss: 0.6774 - val_mean_absolute_error: 0.4924\n",
      "Epoch 121/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.4907 - mean_absolute_error: 0.3732\n",
      "Epoch 00121: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.4908 - mean_absolute_error: 0.3734 - val_loss: 0.6109 - val_mean_absolute_error: 0.4285\n",
      "Epoch 122/200\n",
      "20032/20282 [============================>.] - ETA: 0s - loss: 0.4909 - mean_absolute_error: 0.3720\n",
      "Epoch 00122: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.4908 - mean_absolute_error: 0.3722 - val_loss: 0.6123 - val_mean_absolute_error: 0.4297\n",
      "Epoch 123/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.4982 - mean_absolute_error: 0.3722\n",
      "Epoch 00123: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.4986 - mean_absolute_error: 0.3727 - val_loss: 0.6205 - val_mean_absolute_error: 0.4467\n",
      "Epoch 124/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5118 - mean_absolute_error: 0.3812\n",
      "Epoch 00124: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5118 - mean_absolute_error: 0.3814 - val_loss: 0.6227 - val_mean_absolute_error: 0.4262\n",
      "Epoch 125/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4911 - mean_absolute_error: 0.3720\n",
      "Epoch 00125: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.4909 - mean_absolute_error: 0.3718 - val_loss: 0.6443 - val_mean_absolute_error: 0.4482\n",
      "Epoch 126/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4925 - mean_absolute_error: 0.3757\n",
      "Epoch 00126: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.4927 - mean_absolute_error: 0.3757 - val_loss: 0.6181 - val_mean_absolute_error: 0.4331\n",
      "Epoch 127/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4939 - mean_absolute_error: 0.3751\n",
      "Epoch 00127: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.4939 - mean_absolute_error: 0.3751 - val_loss: 0.6359 - val_mean_absolute_error: 0.4572\n",
      "Epoch 128/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5064 - mean_absolute_error: 0.3817\n",
      "Epoch 00128: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5068 - mean_absolute_error: 0.3818 - val_loss: 0.6254 - val_mean_absolute_error: 0.4317\n",
      "Epoch 129/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.4991 - mean_absolute_error: 0.3803\n",
      "Epoch 00129: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.4995 - mean_absolute_error: 0.3807 - val_loss: 0.6304 - val_mean_absolute_error: 0.4536\n",
      "Epoch 130/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.4969 - mean_absolute_error: 0.3722\n",
      "Epoch 00130: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.4970 - mean_absolute_error: 0.3724 - val_loss: 0.6103 - val_mean_absolute_error: 0.4233\n",
      "Epoch 131/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5016 - mean_absolute_error: 0.3760\n",
      "Epoch 00131: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/14\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5022 - mean_absolute_error: 0.3763 - val_loss: 0.6062 - val_mean_absolute_error: 0.4356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 41.9507 - mean_absolute_error: 3.4798\n",
      "Epoch 00001: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 9s 439us/step - loss: 41.9134 - mean_absolute_error: 3.4778 - val_loss: 13.0249 - val_mean_absolute_error: 1.9389\n",
      "Epoch 2/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 10.5294 - mean_absolute_error: 1.5225\n",
      "Epoch 00002: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 10.5210 - mean_absolute_error: 1.5216 - val_loss: 8.1355 - val_mean_absolute_error: 1.2309\n",
      "Epoch 3/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 6.0986 - mean_absolute_error: 0.7491\n",
      "Epoch 00003: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 6.0979 - mean_absolute_error: 0.7492 - val_loss: 5.3737 - val_mean_absolute_error: 0.6924\n",
      "Epoch 4/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 4.5710 - mean_absolute_error: 0.5184\n",
      "Epoch 00004: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 4.5702 - mean_absolute_error: 0.5183 - val_loss: 4.4332 - val_mean_absolute_error: 0.6095\n",
      "Epoch 5/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 3.8172 - mean_absolute_error: 0.5185\n",
      "Epoch 00005: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 3.8167 - mean_absolute_error: 0.5185 - val_loss: 3.7379 - val_mean_absolute_error: 0.6356\n",
      "Epoch 6/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 3.2127 - mean_absolute_error: 0.5378\n",
      "Epoch 00006: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 3.2084 - mean_absolute_error: 0.5373 - val_loss: 2.9830 - val_mean_absolute_error: 0.5421\n",
      "Epoch 7/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 2.6420 - mean_absolute_error: 0.5062\n",
      "Epoch 00007: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 2.6417 - mean_absolute_error: 0.5063 - val_loss: 2.6542 - val_mean_absolute_error: 0.6234\n",
      "Epoch 8/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 2.4080 - mean_absolute_error: 0.5669\n",
      "Epoch 00008: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 2.4072 - mean_absolute_error: 0.5671 - val_loss: 2.3084 - val_mean_absolute_error: 0.5736\n",
      "Epoch 9/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 2.0806 - mean_absolute_error: 0.5420\n",
      "Epoch 00009: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 2.0773 - mean_absolute_error: 0.5411 - val_loss: 1.9982 - val_mean_absolute_error: 0.5461\n",
      "Epoch 10/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.8983 - mean_absolute_error: 0.5462\n",
      "Epoch 00010: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 1.8979 - mean_absolute_error: 0.5461 - val_loss: 2.2252 - val_mean_absolute_error: 0.7185\n",
      "Epoch 11/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.7972 - mean_absolute_error: 0.5570\n",
      "Epoch 00011: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 1.7973 - mean_absolute_error: 0.5571 - val_loss: 1.7758 - val_mean_absolute_error: 0.5590\n",
      "Epoch 12/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 1.6247 - mean_absolute_error: 0.5361\n",
      "Epoch 00012: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 1.6240 - mean_absolute_error: 0.5361 - val_loss: 1.6603 - val_mean_absolute_error: 0.5659\n",
      "Epoch 13/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 1.6534 - mean_absolute_error: 0.5619\n",
      "Epoch 00013: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 1.6535 - mean_absolute_error: 0.5620 - val_loss: 1.8146 - val_mean_absolute_error: 0.6415\n",
      "Epoch 14/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.4889 - mean_absolute_error: 0.5280\n",
      "Epoch 00014: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 1.4893 - mean_absolute_error: 0.5281 - val_loss: 1.5499 - val_mean_absolute_error: 0.5459\n",
      "Epoch 15/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 1.3955 - mean_absolute_error: 0.5161\n",
      "Epoch 00015: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 1.3955 - mean_absolute_error: 0.5163 - val_loss: 1.6044 - val_mean_absolute_error: 0.6467\n",
      "Epoch 16/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 1.3027 - mean_absolute_error: 0.5159\n",
      "Epoch 00016: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 1.3003 - mean_absolute_error: 0.5151 - val_loss: 1.2780 - val_mean_absolute_error: 0.5107\n",
      "Epoch 17/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 1.1909 - mean_absolute_error: 0.5140\n",
      "Epoch 00017: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 1.1906 - mean_absolute_error: 0.5140 - val_loss: 1.2030 - val_mean_absolute_error: 0.5023\n",
      "Epoch 18/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.1410 - mean_absolute_error: 0.5110\n",
      "Epoch 00018: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 1.1408 - mean_absolute_error: 0.5109 - val_loss: 1.2357 - val_mean_absolute_error: 0.5214\n",
      "Epoch 19/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 1.0587 - mean_absolute_error: 0.4900\n",
      "Epoch 00019: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 1.0585 - mean_absolute_error: 0.4899 - val_loss: 1.1461 - val_mean_absolute_error: 0.5245\n",
      "Epoch 20/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.9626 - mean_absolute_error: 0.4692\n",
      "Epoch 00020: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.9628 - mean_absolute_error: 0.4693 - val_loss: 1.1973 - val_mean_absolute_error: 0.5999\n",
      "Epoch 21/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.9517 - mean_absolute_error: 0.4727\n",
      "Epoch 00021: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.9515 - mean_absolute_error: 0.4726 - val_loss: 1.0461 - val_mean_absolute_error: 0.4783\n",
      "Epoch 22/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.9328 - mean_absolute_error: 0.4696\n",
      "Epoch 00022: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.9321 - mean_absolute_error: 0.4692 - val_loss: 0.9876 - val_mean_absolute_error: 0.4636\n",
      "Epoch 23/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.9100 - mean_absolute_error: 0.4568\n",
      "Epoch 00023: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.9100 - mean_absolute_error: 0.4570 - val_loss: 0.9497 - val_mean_absolute_error: 0.4960\n",
      "Epoch 24/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.8709 - mean_absolute_error: 0.4581\n",
      "Epoch 00024: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.8720 - mean_absolute_error: 0.4583 - val_loss: 1.0974 - val_mean_absolute_error: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.8700 - mean_absolute_error: 0.4485\n",
      "Epoch 00025: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.8695 - mean_absolute_error: 0.4484 - val_loss: 0.9413 - val_mean_absolute_error: 0.4911\n",
      "Epoch 26/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.7758 - mean_absolute_error: 0.4269\n",
      "Epoch 00026: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.7774 - mean_absolute_error: 0.4274 - val_loss: 0.9810 - val_mean_absolute_error: 0.4975\n",
      "Epoch 27/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.7354 - mean_absolute_error: 0.4174\n",
      "Epoch 00027: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.7354 - mean_absolute_error: 0.4173 - val_loss: 0.7950 - val_mean_absolute_error: 0.4508\n",
      "Epoch 28/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.7918 - mean_absolute_error: 0.4433\n",
      "Epoch 00028: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.7920 - mean_absolute_error: 0.4434 - val_loss: 1.0041 - val_mean_absolute_error: 0.4873\n",
      "Epoch 29/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.7655 - mean_absolute_error: 0.4286\n",
      "Epoch 00029: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.7655 - mean_absolute_error: 0.4288 - val_loss: 0.8599 - val_mean_absolute_error: 0.5099\n",
      "Epoch 30/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.7115 - mean_absolute_error: 0.4236\n",
      "Epoch 00030: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.7113 - mean_absolute_error: 0.4234 - val_loss: 0.8329 - val_mean_absolute_error: 0.4698\n",
      "Epoch 31/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.7127 - mean_absolute_error: 0.4354\n",
      "Epoch 00031: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.7127 - mean_absolute_error: 0.4354 - val_loss: 0.7670 - val_mean_absolute_error: 0.4630\n",
      "Epoch 32/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.7017 - mean_absolute_error: 0.4275\n",
      "Epoch 00032: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.7020 - mean_absolute_error: 0.4276 - val_loss: 0.8628 - val_mean_absolute_error: 0.4667\n",
      "Epoch 33/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.7089 - mean_absolute_error: 0.4274\n",
      "Epoch 00033: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.7086 - mean_absolute_error: 0.4272 - val_loss: 0.8166 - val_mean_absolute_error: 0.4661\n",
      "Epoch 34/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6347 - mean_absolute_error: 0.3997\n",
      "Epoch 00034: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.6345 - mean_absolute_error: 0.3996 - val_loss: 0.7705 - val_mean_absolute_error: 0.4713\n",
      "Epoch 35/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6628 - mean_absolute_error: 0.4171\n",
      "Epoch 00035: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.6622 - mean_absolute_error: 0.4167 - val_loss: 0.7640 - val_mean_absolute_error: 0.4556\n",
      "Epoch 36/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6260 - mean_absolute_error: 0.4045\n",
      "Epoch 00036: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.6258 - mean_absolute_error: 0.4044 - val_loss: 0.7128 - val_mean_absolute_error: 0.4404\n",
      "Epoch 37/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6237 - mean_absolute_error: 0.4132\n",
      "Epoch 00037: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.6235 - mean_absolute_error: 0.4131 - val_loss: 0.7222 - val_mean_absolute_error: 0.4514\n",
      "Epoch 38/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.6334 - mean_absolute_error: 0.4154\n",
      "Epoch 00038: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.6335 - mean_absolute_error: 0.4154 - val_loss: 0.7622 - val_mean_absolute_error: 0.4544\n",
      "Epoch 39/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.6165 - mean_absolute_error: 0.4047\n",
      "Epoch 00039: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.6170 - mean_absolute_error: 0.4051 - val_loss: 0.7247 - val_mean_absolute_error: 0.4449\n",
      "Epoch 40/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5992 - mean_absolute_error: 0.4001\n",
      "Epoch 00040: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5991 - mean_absolute_error: 0.4000 - val_loss: 0.7455 - val_mean_absolute_error: 0.4933\n",
      "Epoch 41/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.6052 - mean_absolute_error: 0.4154\n",
      "Epoch 00041: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.6054 - mean_absolute_error: 0.4155 - val_loss: 0.6976 - val_mean_absolute_error: 0.4528\n",
      "Epoch 42/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5938 - mean_absolute_error: 0.4039\n",
      "Epoch 00042: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5943 - mean_absolute_error: 0.4044 - val_loss: 0.7005 - val_mean_absolute_error: 0.4577\n",
      "Epoch 43/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5880 - mean_absolute_error: 0.4038\n",
      "Epoch 00043: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.5884 - mean_absolute_error: 0.4043 - val_loss: 0.7610 - val_mean_absolute_error: 0.4852\n",
      "Epoch 44/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.6044 - mean_absolute_error: 0.4140\n",
      "Epoch 00044: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.6040 - mean_absolute_error: 0.4138 - val_loss: 0.6971 - val_mean_absolute_error: 0.4464\n",
      "Epoch 45/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5884 - mean_absolute_error: 0.4089\n",
      "Epoch 00045: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5884 - mean_absolute_error: 0.4089 - val_loss: 0.7511 - val_mean_absolute_error: 0.4965\n",
      "Epoch 46/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5813 - mean_absolute_error: 0.4020\n",
      "Epoch 00046: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.5813 - mean_absolute_error: 0.4020 - val_loss: 0.7578 - val_mean_absolute_error: 0.5141\n",
      "Epoch 47/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5867 - mean_absolute_error: 0.4056\n",
      "Epoch 00047: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5871 - mean_absolute_error: 0.4057 - val_loss: 0.7134 - val_mean_absolute_error: 0.4554\n",
      "Epoch 48/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5626 - mean_absolute_error: 0.3876\n",
      "Epoch 00048: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5637 - mean_absolute_error: 0.3883 - val_loss: 0.7051 - val_mean_absolute_error: 0.4742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5832 - mean_absolute_error: 0.4077\n",
      "Epoch 00049: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5841 - mean_absolute_error: 0.4080 - val_loss: 0.7776 - val_mean_absolute_error: 0.5020\n",
      "Epoch 50/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5842 - mean_absolute_error: 0.4030\n",
      "Epoch 00050: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5840 - mean_absolute_error: 0.4030 - val_loss: 0.6574 - val_mean_absolute_error: 0.4325\n",
      "Epoch 51/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5554 - mean_absolute_error: 0.3923\n",
      "Epoch 00051: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5551 - mean_absolute_error: 0.3922 - val_loss: 0.6343 - val_mean_absolute_error: 0.4319\n",
      "Epoch 52/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5636 - mean_absolute_error: 0.4025\n",
      "Epoch 00052: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5641 - mean_absolute_error: 0.4029 - val_loss: 0.6509 - val_mean_absolute_error: 0.4432\n",
      "Epoch 53/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5621 - mean_absolute_error: 0.3944\n",
      "Epoch 00053: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5622 - mean_absolute_error: 0.3944 - val_loss: 0.6562 - val_mean_absolute_error: 0.4337\n",
      "Epoch 54/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5409 - mean_absolute_error: 0.3854\n",
      "Epoch 00054: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5410 - mean_absolute_error: 0.3855 - val_loss: 0.6190 - val_mean_absolute_error: 0.4196\n",
      "Epoch 55/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5643 - mean_absolute_error: 0.4026\n",
      "Epoch 00055: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5653 - mean_absolute_error: 0.4031 - val_loss: 0.7487 - val_mean_absolute_error: 0.5024\n",
      "Epoch 56/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5618 - mean_absolute_error: 0.3988\n",
      "Epoch 00056: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5618 - mean_absolute_error: 0.3988 - val_loss: 0.6558 - val_mean_absolute_error: 0.4408\n",
      "Epoch 57/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5443 - mean_absolute_error: 0.3916\n",
      "Epoch 00057: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5446 - mean_absolute_error: 0.3918 - val_loss: 0.6847 - val_mean_absolute_error: 0.4742\n",
      "Epoch 58/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5474 - mean_absolute_error: 0.3922\n",
      "Epoch 00058: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5477 - mean_absolute_error: 0.3924 - val_loss: 0.6724 - val_mean_absolute_error: 0.4618\n",
      "Epoch 59/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5516 - mean_absolute_error: 0.3972\n",
      "Epoch 00059: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.5528 - mean_absolute_error: 0.3977 - val_loss: 0.6631 - val_mean_absolute_error: 0.4401\n",
      "Epoch 60/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5675 - mean_absolute_error: 0.3990\n",
      "Epoch 00060: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5674 - mean_absolute_error: 0.3989 - val_loss: 0.6582 - val_mean_absolute_error: 0.4386\n",
      "Epoch 61/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5230 - mean_absolute_error: 0.3777\n",
      "Epoch 00061: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5235 - mean_absolute_error: 0.3779 - val_loss: 0.7077 - val_mean_absolute_error: 0.4828\n",
      "Epoch 62/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5570 - mean_absolute_error: 0.3999\n",
      "Epoch 00062: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5579 - mean_absolute_error: 0.4004 - val_loss: 0.6960 - val_mean_absolute_error: 0.4660\n",
      "Epoch 63/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5382 - mean_absolute_error: 0.3898\n",
      "Epoch 00063: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5385 - mean_absolute_error: 0.3899 - val_loss: 0.6465 - val_mean_absolute_error: 0.4402\n",
      "Epoch 64/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5340 - mean_absolute_error: 0.3850\n",
      "Epoch 00064: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5354 - mean_absolute_error: 0.3857 - val_loss: 0.8241 - val_mean_absolute_error: 0.5793\n",
      "Epoch 65/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5434 - mean_absolute_error: 0.3961\n",
      "Epoch 00065: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5433 - mean_absolute_error: 0.3959 - val_loss: 0.7321 - val_mean_absolute_error: 0.4968\n",
      "Epoch 66/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5352 - mean_absolute_error: 0.3848\n",
      "Epoch 00066: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5353 - mean_absolute_error: 0.3849 - val_loss: 0.6569 - val_mean_absolute_error: 0.4344\n",
      "Epoch 67/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5250 - mean_absolute_error: 0.3869\n",
      "Epoch 00067: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.5251 - mean_absolute_error: 0.3870 - val_loss: 0.6877 - val_mean_absolute_error: 0.4585\n",
      "Epoch 68/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5385 - mean_absolute_error: 0.3916\n",
      "Epoch 00068: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5385 - mean_absolute_error: 0.3918 - val_loss: 0.7366 - val_mean_absolute_error: 0.5053\n",
      "Epoch 69/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5386 - mean_absolute_error: 0.3899\n",
      "Epoch 00069: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5380 - mean_absolute_error: 0.3894 - val_loss: 0.6520 - val_mean_absolute_error: 0.4332\n",
      "Epoch 70/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5110 - mean_absolute_error: 0.3746\n",
      "Epoch 00070: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.5115 - mean_absolute_error: 0.3749 - val_loss: 0.6621 - val_mean_absolute_error: 0.4539\n",
      "Epoch 71/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5351 - mean_absolute_error: 0.3900\n",
      "Epoch 00071: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5351 - mean_absolute_error: 0.3902 - val_loss: 0.6551 - val_mean_absolute_error: 0.4416\n",
      "Epoch 72/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5331 - mean_absolute_error: 0.3867\n",
      "Epoch 00072: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.5335 - mean_absolute_error: 0.3867 - val_loss: 0.6472 - val_mean_absolute_error: 0.4422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5518 - mean_absolute_error: 0.3922\n",
      "Epoch 00073: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5523 - mean_absolute_error: 0.3927 - val_loss: 0.6890 - val_mean_absolute_error: 0.4777\n",
      "Epoch 74/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5116 - mean_absolute_error: 0.3755\n",
      "Epoch 00074: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5117 - mean_absolute_error: 0.3757 - val_loss: 0.6092 - val_mean_absolute_error: 0.4306\n",
      "Epoch 75/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5288 - mean_absolute_error: 0.3925\n",
      "Epoch 00075: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5290 - mean_absolute_error: 0.3924 - val_loss: 0.6252 - val_mean_absolute_error: 0.4385\n",
      "Epoch 76/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5155 - mean_absolute_error: 0.3799\n",
      "Epoch 00076: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5153 - mean_absolute_error: 0.3796 - val_loss: 0.6472 - val_mean_absolute_error: 0.4427\n",
      "Epoch 77/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.5153 - mean_absolute_error: 0.3806\n",
      "Epoch 00077: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5154 - mean_absolute_error: 0.3807 - val_loss: 0.6501 - val_mean_absolute_error: 0.4482\n",
      "Epoch 78/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5257 - mean_absolute_error: 0.3842\n",
      "Epoch 00078: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5260 - mean_absolute_error: 0.3844 - val_loss: 0.6225 - val_mean_absolute_error: 0.4312\n",
      "Epoch 79/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5410 - mean_absolute_error: 0.3910\n",
      "Epoch 00079: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5412 - mean_absolute_error: 0.3909 - val_loss: 0.5981 - val_mean_absolute_error: 0.4130\n",
      "Epoch 80/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5061 - mean_absolute_error: 0.3748\n",
      "Epoch 00080: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5075 - mean_absolute_error: 0.3759 - val_loss: 0.6846 - val_mean_absolute_error: 0.4783\n",
      "Epoch 81/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5148 - mean_absolute_error: 0.3820\n",
      "Epoch 00081: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5152 - mean_absolute_error: 0.3826 - val_loss: 0.7469 - val_mean_absolute_error: 0.5481\n",
      "Epoch 82/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5083 - mean_absolute_error: 0.3784\n",
      "Epoch 00082: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5081 - mean_absolute_error: 0.3783 - val_loss: 0.6972 - val_mean_absolute_error: 0.4810\n",
      "Epoch 83/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5203 - mean_absolute_error: 0.3860\n",
      "Epoch 00083: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5205 - mean_absolute_error: 0.3861 - val_loss: 0.6586 - val_mean_absolute_error: 0.4473\n",
      "Epoch 84/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.5289 - mean_absolute_error: 0.3867\n",
      "Epoch 00084: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5287 - mean_absolute_error: 0.3866 - val_loss: 0.6601 - val_mean_absolute_error: 0.4565\n",
      "Epoch 85/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5080 - mean_absolute_error: 0.3752\n",
      "Epoch 00085: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5078 - mean_absolute_error: 0.3750 - val_loss: 0.6109 - val_mean_absolute_error: 0.4273\n",
      "Epoch 86/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5043 - mean_absolute_error: 0.3768\n",
      "Epoch 00086: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5046 - mean_absolute_error: 0.3773 - val_loss: 0.7554 - val_mean_absolute_error: 0.5457\n",
      "Epoch 87/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5027 - mean_absolute_error: 0.3812\n",
      "Epoch 00087: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.5028 - mean_absolute_error: 0.3811 - val_loss: 0.6413 - val_mean_absolute_error: 0.4463\n",
      "Epoch 88/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5156 - mean_absolute_error: 0.3860\n",
      "Epoch 00088: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5157 - mean_absolute_error: 0.3861 - val_loss: 0.6819 - val_mean_absolute_error: 0.4763\n",
      "Epoch 89/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.5344 - mean_absolute_error: 0.3936\n",
      "Epoch 00089: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5350 - mean_absolute_error: 0.3937 - val_loss: 0.6240 - val_mean_absolute_error: 0.4329\n",
      "Epoch 90/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5019 - mean_absolute_error: 0.3743\n",
      "Epoch 00090: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.5022 - mean_absolute_error: 0.3745 - val_loss: 0.6100 - val_mean_absolute_error: 0.4232\n",
      "Epoch 91/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5020 - mean_absolute_error: 0.3834\n",
      "Epoch 00091: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5022 - mean_absolute_error: 0.3835 - val_loss: 0.6431 - val_mean_absolute_error: 0.4584\n",
      "Epoch 92/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5053 - mean_absolute_error: 0.3788\n",
      "Epoch 00092: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5052 - mean_absolute_error: 0.3788 - val_loss: 0.6405 - val_mean_absolute_error: 0.4455\n",
      "Epoch 93/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5227 - mean_absolute_error: 0.3848\n",
      "Epoch 00093: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.5224 - mean_absolute_error: 0.3847 - val_loss: 0.6250 - val_mean_absolute_error: 0.4276\n",
      "Epoch 94/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5075 - mean_absolute_error: 0.3823\n",
      "Epoch 00094: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5076 - mean_absolute_error: 0.3824 - val_loss: 0.6596 - val_mean_absolute_error: 0.4506\n",
      "Epoch 95/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5057 - mean_absolute_error: 0.3841\n",
      "Epoch 00095: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.5062 - mean_absolute_error: 0.3846 - val_loss: 0.7275 - val_mean_absolute_error: 0.4842\n",
      "Epoch 96/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.5009 - mean_absolute_error: 0.3772\n",
      "Epoch 00096: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5014 - mean_absolute_error: 0.3774 - val_loss: 0.6145 - val_mean_absolute_error: 0.4309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.5010 - mean_absolute_error: 0.3800\n",
      "Epoch 00097: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.5009 - mean_absolute_error: 0.3799 - val_loss: 0.6397 - val_mean_absolute_error: 0.4496\n",
      "Epoch 98/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.5000 - mean_absolute_error: 0.3801\n",
      "Epoch 00098: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.5009 - mean_absolute_error: 0.3807 - val_loss: 0.5877 - val_mean_absolute_error: 0.4239\n",
      "Epoch 99/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.4942 - mean_absolute_error: 0.3743\n",
      "Epoch 00099: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.4941 - mean_absolute_error: 0.3743 - val_loss: 0.5999 - val_mean_absolute_error: 0.4259\n",
      "Epoch 100/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4894 - mean_absolute_error: 0.3745\n",
      "Epoch 00100: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.4904 - mean_absolute_error: 0.3753 - val_loss: 0.6978 - val_mean_absolute_error: 0.4903\n",
      "Epoch 101/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5012 - mean_absolute_error: 0.3801\n",
      "Epoch 00101: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5019 - mean_absolute_error: 0.3806 - val_loss: 0.6193 - val_mean_absolute_error: 0.4311\n",
      "Epoch 102/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4997 - mean_absolute_error: 0.3832\n",
      "Epoch 00102: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.5001 - mean_absolute_error: 0.3835 - val_loss: 0.6405 - val_mean_absolute_error: 0.4424\n",
      "Epoch 103/200\n",
      "20064/20282 [============================>.] - ETA: 0s - loss: 0.4997 - mean_absolute_error: 0.3793\n",
      "Epoch 00103: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.4997 - mean_absolute_error: 0.3794 - val_loss: 0.6409 - val_mean_absolute_error: 0.4521\n",
      "Epoch 104/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4847 - mean_absolute_error: 0.3720\n",
      "Epoch 00104: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.4848 - mean_absolute_error: 0.3721 - val_loss: 0.6503 - val_mean_absolute_error: 0.4609\n",
      "Epoch 105/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4998 - mean_absolute_error: 0.3832\n",
      "Epoch 00105: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.5005 - mean_absolute_error: 0.3837 - val_loss: 0.6133 - val_mean_absolute_error: 0.4318\n",
      "Epoch 106/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.4876 - mean_absolute_error: 0.3714\n",
      "Epoch 00106: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.4881 - mean_absolute_error: 0.3718 - val_loss: 0.6268 - val_mean_absolute_error: 0.4422\n",
      "Epoch 107/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.4939 - mean_absolute_error: 0.3715\n",
      "Epoch 00107: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.4940 - mean_absolute_error: 0.3716 - val_loss: 0.6077 - val_mean_absolute_error: 0.4382\n",
      "Epoch 108/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.4908 - mean_absolute_error: 0.3733\n",
      "Epoch 00108: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.4907 - mean_absolute_error: 0.3733 - val_loss: 0.8137 - val_mean_absolute_error: 0.5837\n",
      "Epoch 109/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4971 - mean_absolute_error: 0.3785\n",
      "Epoch 00109: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.4970 - mean_absolute_error: 0.3784 - val_loss: 0.6300 - val_mean_absolute_error: 0.4331\n",
      "Epoch 110/200\n",
      "20096/20282 [============================>.] - ETA: 0s - loss: 0.4777 - mean_absolute_error: 0.3676\n",
      "Epoch 00110: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.4780 - mean_absolute_error: 0.3679 - val_loss: 0.6674 - val_mean_absolute_error: 0.4970\n",
      "Epoch 111/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.5085 - mean_absolute_error: 0.3831\n",
      "Epoch 00111: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 271us/step - loss: 0.5089 - mean_absolute_error: 0.3833 - val_loss: 0.6416 - val_mean_absolute_error: 0.4453\n",
      "Epoch 112/200\n",
      "20192/20282 [============================>.] - ETA: 0s - loss: 0.4739 - mean_absolute_error: 0.3621\n",
      "Epoch 00112: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 270us/step - loss: 0.4739 - mean_absolute_error: 0.3622 - val_loss: 0.6059 - val_mean_absolute_error: 0.4314\n",
      "Epoch 113/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4849 - mean_absolute_error: 0.3727\n",
      "Epoch 00113: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.4850 - mean_absolute_error: 0.3727 - val_loss: 0.6774 - val_mean_absolute_error: 0.4744\n",
      "Epoch 114/200\n",
      "20224/20282 [============================>.] - ETA: 0s - loss: 0.4955 - mean_absolute_error: 0.3820\n",
      "Epoch 00114: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 6s 273us/step - loss: 0.4961 - mean_absolute_error: 0.3824 - val_loss: 0.6019 - val_mean_absolute_error: 0.4278\n",
      "Epoch 115/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.4843 - mean_absolute_error: 0.3697\n",
      "Epoch 00115: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 5s 269us/step - loss: 0.4842 - mean_absolute_error: 0.3696 - val_loss: 0.6695 - val_mean_absolute_error: 0.4736\n",
      "Epoch 116/200\n",
      "20256/20282 [============================>.] - ETA: 0s - loss: 0.4855 - mean_absolute_error: 0.3732\n",
      "Epoch 00116: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 6s 276us/step - loss: 0.4854 - mean_absolute_error: 0.3730 - val_loss: 0.6101 - val_mean_absolute_error: 0.4284\n",
      "Epoch 117/200\n",
      "20160/20282 [============================>.] - ETA: 0s - loss: 0.4910 - mean_absolute_error: 0.3781\n",
      "Epoch 00117: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 6s 274us/step - loss: 0.4913 - mean_absolute_error: 0.3782 - val_loss: 0.6436 - val_mean_absolute_error: 0.4446\n",
      "Epoch 118/200\n",
      "20128/20282 [============================>.] - ETA: 0s - loss: 0.4943 - mean_absolute_error: 0.3774\n",
      "Epoch 00118: saving model to session/DNN_Crowd_8_128_relu_0.01_0.001_mse/15\n",
      "20282/20282 [==============================] - 6s 274us/step - loss: 0.4950 - mean_absolute_error: 0.3779 - val_loss: 0.6035 - val_mean_absolute_error: 0.4336\n"
     ]
    }
   ],
   "source": [
    "crowd01.train_new_entities(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crowd01.plot_crowd_error(X_test_red, y_test, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABD8AAAJ4CAYAAABiREigAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3XmcLHV97//XGw7KKkQ5UeBwOBq9RlzRo9G4EdQElcBNoleMCwiKGuNy4/0ZcN9uXGM01wVRlM2ICi4gGkWRoFFAREQWjSjILgiyqhjk8/ujaqAZes70zNR0z6l5PR+Pfpza+luf+lZ1zed8uqo6VYUkSZIkSVJfbTDpACRJkiRJkhaTxQ9JkiRJktRrFj8kSZIkSVKvWfyQJEmSJEm9ZvFDkiRJkiT1msUPSZIkSZLUaxY/tE5JDkzyuo7aWp3khiQbtuMnJnl+F2237X05yV5dtTeH9b41yS+TXD7udS93SS5I8sQRlluTpJKsmGP7SfLxJL9Kcur8Ix1pXZ0cv/Pd1qUiyc5JLp50HJL6w1xmpPWay0yIuczQdsxltCjWywNK3UhyAXB34Gbg98A5wGHAQVV1C0BVvWgObT2/qr420zJVdSGw+cKivnV9bwTuXVXPHmj/yV20Pcc4VgOvBHaoqivGvX4tuscATwJWVdWNi7miSRy/krS+M5fpJA5zmX4zl5FaXvmhv6yqLYAdgLcD/wgc3PVK1tfK7QhWA1d1kSwM66P59NvUt1Hj1tN9vANwwXyShZ72hyQtReYyC2Muc9t6+7iPzWWklsUPAVBV11bVMcAzgL2SPAAgySFJ3toOb53ki0muSXJ1km8m2SDJ4TR/OI9tLwV91cDlavsmuRA4YYZL2P4oyalJrkvyhSR3bdd1h8vFpi4LTLIr8GrgGe36ftDOv/XS0zau1yb5eZIrkhyWZMt23lQceyW5sL3M8zUz9U2SLdv3X9m299q2/ScCxwPbtnEcMsP7d0tyRttv307yoGnb9I9JzgRuTLJihmn3a7fvmiRnJ9l9oI1DknwoyZeS3Aj82ZAYtk1yTLvfzkvygoHpv5nq93baTm2fbNSO75Pk3PZyya8k2WFg2UrykiQ/AX4yZL1Tff28JBe1bbwoycOTnNluz/sHlp9xv7Xzn9POu2r6Pmvfu3+Sn7bzPz24XdOW3TvJz5Jcn+T8JM8assy+wEeBR7X7903t9Be0fXh126fbzqE/Nk5yRBvfNUm+m+Tu7bzB43fvJN9K8u62z85P8uSBdu6Z5KQ2/q8l+UCSI2bY1i2THJzksiSXpLm0eWhSmeQRSU5L83n8RZL3DMz7TJLLk1zbrvv+A/MOSfLBNJe73pDkP5PcI8l72/h/lGSngeUvSHJAknPa+R9PsvEMMW2b5Og0n7/zk7xs2HKSZC5jLjOwrLkM5jIxl9F0VeVrmb6AC4AnDpl+IfDidvgQ4K3t8NuAA4GN2tdjgQxrC1gDFM2lp5sBmwxMW9EucyJwCfCAdpmjgSPaeTsDF88UL/DGqWUH5p9Ic7kqwD7AecC9aC5P/Sxw+LTYPtLG9WDgJuB+M/TTYcAXgC3a9/4XsO9McU57707AFcCfABsCe7XbceeBbToD2B7YZNi0tq/Po0mS7gTsAlwP3HdgH10LPJqmoLnxkDhOAj4IbAw8BLgS2KWddwLwgoFl3wUc2A7v0a77fjS3yb0W+PbAskWTNN11Kv5p653q6wPbdf858Fvg88AfAtu1/fP4EfbbjsANwOOAOwPvobnMeeqYeDlwMrCqnf9h4JPT4lhBc6xdN9B/2wD3n2H/7Q18a2B8F+CXwEPbdfw/4KQ59McLgWOBTdvj4WHAXYYcv3sD/w28oF3uxcCl3PZ5+w7w7vZ4eEy7PUdM39Z2/HNtX2zW9vmpwAtn2N7vAM9phzcHHjkwbx+az8CdgfcCZwzMO6Ttl4e1+/kE4HzguW38bwW+Me2zfBbNMX5X4D+57TyzM+1niuZ4/h7w+nZb7wX8DPiLSZ8/ffnytTRemMuYy5S5DOYyg/GZy/ia8TXxAHxNcOfPnDCcDLymHT5k4IP8Zpo/nPeera2Bk9a9hkwbTBjePjB/R+B37Qnm1pPGsHUwe8LwdeDvBubdtz0BrxiIY9XA/FOBPYds14ZtTDsOTHshcGI7fIc4p73/Q8Bbpk37Mbf9gbwA2GfIdu4zMP5Y4HJgg4FpnwTeOLCPDltHDNvT3Ae9xcC0twGHtMPPB05ohwNcBDyuHf8ybXLUjm8A/JrmvmDaftxlHeue6uvtBqZdBTxjYPxo4BUj7LfXA0cOzNus3TdTx8S5wBMG5m8zZJ9PJQzXAH/DkD/q0+Lfm9snDAcD7xwY37xdx5oR+2Mf4NvAg4bMO5HbJwznDczbtG37HjTfTN4MbDow/wiGJAw098HfNLidwDMZ+OM9LYaTgDcBW8/SL1u169hy4Bj8yMD8lwLnDow/ELhm2jH+ooHxpwA/nf6Zokm0L5y27gOAj68rPl++fC2fF+Yy5jJlLjPLZ2RvzGWGLWcuswxf3vaiYbYDrh4y/V00leyvtpfZ7T9CWxfNYf7Pab4Z2HqkKNdt27a9wbanTqBTBp9o/muGP8Bs6zam6W1tN2IcOwCvbC8LvCbJNTR/wLcdWGZYHw1O2xa4qNoHt80Qw7r6eVvg6qq6fob3H01zOeQ2NN9E3AJ8cyD+9w3EfjVNUjHquqf8YmD4N0PGp/p+Xftt28F1VXPv6lUDy+4AfG4g1nNpEqXBfT71vmcALwIuS3Jckj8eYRvuEF9V3dDGMGp/HA58BTgyyaVJ3jl1Se4Qtx6fVfXrdnBzbtufvx5YdqZ17kBz/F420C8fpvnWZJh9gf8B/Ki9jHU3aO69TvL29jLc62j+4MPtP6uj7uNhMf+c238mBuPfdtrn59VM26eSNIS5zG3MZcxlBpnLmMssWxY/dDtJHk5z8vvW9HlVdX1VvbKq7gXsDvxDkidMzZ6hyZmmT9l+YHg1TeX5l8CNNBXiqbg2BFbOod1LaU42g23fzO1PYqP4ZRvT9LYuGfH9FwH/t6q2GnhtWlWfHFhm2LYMTrsU2D7J4Od1egzr6o9Lgbsm2WLY+6vqV8BXaf6I/i3NNxJT7V1Ec1nhYPybVNW3R1z3XK1rv13GwPGSZFPgbgPLXgQ8eVqsG1fVHfZVVX2lqp5E843Kj2guG55zfEk2a2MYaV9U1X9X1ZuqakfgT4HdaC6nnIvLaPbnpgPTtp9h2Ytovi3ZeqBP7lJV9x+2cFX9pKqeSZNQvAM4qt3Gv6W5bPiJwJY038hAkzzO1/TP/qUzxH/+tH26RVU9ZQHrldRz5jJ3YC5jLjNjfOYy5jLLicUPAZDkLm1l9EiaS85+OGSZ3ZLcO0lo7sv8PU1lHZoT+r3msepnJ9mxPfm9GTiqqn5Pcy/qxkme2laTX0tzf96UXwBrpv0RHfRJ4H+3D1PaHPgn4FNVdfNcgmtj+TTwf5NskeYBWf9Ac2neKD4CvCjJn6SxWbtNW8z6ztucQvNtzquSbJRkZ+AvafbVKNtwEc3liW9L85CqB9FUxQe34d9o/nA9rR2eciBwwNQDodI8cOrpc4h9rta1344CdkvymCR3ojleBvf/gTT7aYc21pVJ9pi+giR3T7JH+4fwJpp7b2+Zvtw64ntekockuXMb3ylVdcEob07yZ0ke2CbA19Eko6OuG4Cq+jlwGvDGJHdK8iia42HYspfRJIP/3H7GN0jyR0keP0N8z06ysv1m7pp28i0098feRPPN0KY0271QL0myKs2D3F4DfGrIMqcC16d5aN4m7bc2D2j/YyNJt2MuM5y5jLnMkPjMZcxlliWLHzo2yfU0VcnX0Dx46XkzLHsf4Gs0J9jvAB+sqm+0894GvDbN5Vz/Zw7rP5zmHrvLaR4u9DJontgO/B3NE6ovofn2ZPCJ6Z9p/70qyelD2v1Y2/ZJNA8r+i3NvXvz8dJ2/T+j+Rbp39r2Z1VVp9E86On9wK9oLrXdey4rr6rf0fxBeDLNtzcfBJ5bVT+aQzPPpKlwX0rz0Kg3VNXXBuYfQ7N/L6+qHwys+3M0VfMj01wieFYbx2KZcb9V1dnAS2j6/zKa/hw8Jt7XbsdX22P6ZJr7LKfbgCbpu5Tm0tfH0zyEa1Ztn72O5vLay4A/Avacw/bdgybxuY7mUtb/oNneuXoW8CiaP+Bvpflje9MMyz6X5gFb59D02VE03xINsytwdpIbaPpzz6r6Dc2D8n5O81k8h6ZvF+rfaJKZnwE/bbfjdtqEfTeaB9udT3P8f5TmGxtJmmIuMztzGXMZ2hjMZcxllq2pp+1KktZTST4F/Kiq3jDpWEaR5AKaB6J9bbZlJUlS/5nLaBy88kOS1jNJHt5e8rlBkl1p7mH9/KTjkiRJGoW5jCZhxaQDkCTN2T2Az9I8oOxi4MVV9f3JhiRJkjQycxmNnbe9SJIkSZKkXvO2F0mSJEmS1GsWPyRJkiRJUq+td8/82HrrrWvNmjWTDkOSpPXe9773vV9W1cpJx7HcmMtIktSdUfOZ9a74sWbNGk477bRJhyFJ0novyc8nHcNyZC4jSVJ3Rs1nvO1FkiRJkiT1msUPSZIkSZLUaxY/JEmSJElSr1n8kCRJkiRJvWbxQ5IkSZIk9ZrFD0mSJEmS1GsWPyRJkiRJUq8tieJHkguS/DDJGUn84XtJkrRkJNkwyfeTfHHIvDsn+VSS85KckmTN+COUJEmzWTHpAAb8WVX9ctJBSJIkTfNy4FzgLkPm7Qv8qqrunWRP4B3AM8YZnCRJmt2SuPJDkiRpKUqyCngq8NEZFtkDOLQdPgp4QpKMIzZJkjS6pXLlRwFfTVLAh6vqoMGZSfYD9gNYvXr1BMKTFs+a/Y+bdAiL4oK3P3XSIUhSF94LvArYYob52wEXAVTVzUmuBe4G3O5qVnMZ9V0f8xlzGalflsqVH4+pqocCTwZekuRxgzOr6qCqWltVa1euXDmZCCVJ0rKSZDfgiqr63kLbMpeRJGmylkTxo6ouaf+9Avgc8IjJRiRJksSjgd2TXAAcCeyS5Ihpy1wCbA+QZAWwJXDVOIOUJEmzm3jxI8lmSbaYGgb+HDhrslFJkqTlrqoOqKpVVbUG2BM4oaqePW2xY4C92uGntcvUGMOUJEkjWArP/Lg78Ln22WArgH+rqn+fbEiSJEnDJXkzcFpVHQMcDBye5DzgapoiiSRJWmImXvyoqp8BD550HJIkSTOpqhOBE9vh1w9M/y3w9MlEJUmSRjXx214kSZIkSZIWk8UPSZIkSZLUaxY/JEmSJElSr1n8kCRJkiRJvWbxQ5IkSZIk9ZrFD0mSJEmS1GsWPyRJkiRJUq9Z/JAkSZIkSb1m8UOSJEmSJPWaxQ9JkiRJktRrFj8kSZIkSVKvWfyQJEmSJEm9ZvFDkiRJkiT1msUPSZIkSZLUaxY/JEmSJElSr1n8kCRJkiRJvWbxQ5IkSZIk9ZrFD0mSJEmS1GsWPyRJkiRJUq9Z/JAkSZIkSb1m8UOSJEmSJPWaxQ9JkqQhkmyc5NQkP0hydpI3DVlm7yRXJjmjfT1/ErFKkqR1WzHpACRJkpaom4BdquqGJBsB30ry5ao6edpyn6qqv59AfJIkaUQWPyRJkoaoqgJuaEc3al81uYgkSdJ8eduLJEnSDJJsmOQM4Arg+Ko6Zchif5PkzCRHJdl+zCFKkqQRWPyQJEmaQVX9vqoeAqwCHpHkAdMWORZYU1UPAo4HDh3WTpL9kpyW5LQrr7xycYOWJEl3YPFDkiRpFlV1DfANYNdp06+qqpva0Y8CD5vh/QdV1dqqWrty5crFDVaSJN2BxQ9JkqQhkqxMslU7vAnwJOBH05bZZmB0d+Dc8UUoSZJG5QNPJUmShtsGODTJhjRfGH26qr6Y5M3AaVV1DPCyJLsDNwNXA3tPLFpJkjQjix+SJElDVNWZwE5Dpr9+YPgA4IBxxiVJkubO214kSZIkSVKvWfyQJEmSJEm9ZvFDkiRJkiT1msUPSZIkSZLUaxY/JEmSJElSr1n8kCRJkiRJvWbxQ5IkSZIk9ZrFD0mSJEmS1GsWPyRJkiRJUq9Z/JAkSZIkSb22JIofSTZM8v0kX5x0LJIkSZIkqV+WRPEDeDlw7qSDkCRJkiRJ/TPx4keSVcBTgY9OOhZJkiRJktQ/Ey9+AO8FXgXcMulAJEmSJElS/6yY5MqT7AZcUVXfS7LzOpbbD9gPYPXq1WOKTkvRmv2Pm3QIkiRJkqT1zKSv/Hg0sHuSC4AjgV2SHDF9oao6qKrWVtXalStXjjtGSZIkSZK0Hpto8aOqDqiqVVW1BtgTOKGqnj3JmCRJkiRJUr9M+soPSZIkSZKkRTXRZ34MqqoTgRMnHIYkSZIkSeoZr/yQJEmSJEm9ZvFDkiRJkiT1msUPSZIkSZLUaxY/JEmShkiycZJTk/wgydlJ3jRkmTsn+VSS85KckmTN+COVJEmzsfghSZI03E3ALlX1YOAhwK5JHjltmX2BX1XVvYF/Ad4x5hglSdIILH5IkiQNUY0b2tGN2ldNW2wP4NB2+CjgCUkyphAlSdKILH5IkiTNIMmGSc4ArgCOr6pTpi2yHXARQFXdDFwL3G28UUqSpNmsmHQAkiRJS1VV/R54SJKtgM8leUBVnTXXdpLsB+wHsHr16o6jlKTRrNn/uEmHsCguePtTJx1C5/q4rya9n7zyQ5IkaRZVdQ3wDWDXabMuAbYHSLIC2BK4asj7D6qqtVW1duXKlYsdriRJmsbihyRJ0hBJVrZXfJBkE+BJwI+mLXYMsFc7/DTghKqa/lwQSZI0Yd72IkmSNNw2wKFJNqT5wujTVfXFJG8GTquqY4CDgcOTnAdcDew5uXAlSdJMLH5IkiQNUVVnAjsNmf76geHfAk8fZ1ySJGnuvO1FkiRJkiT1msUPSZIkSZLUaxY/JEmSJElSr1n8kCRJkiRJvWbxQ5IkSZIk9ZrFD0mSJEmS1GudFT+SPDrJZu3ws5O8J8kOXbUvSZI0H+YokiSpyys/PgT8OsmDgVcCPwUO67B9SZKk+TBHkSRpmeuy+HFzVRWwB/D+qvoAsEWH7UuSJM2HOYokScvcig7buj7JAcCzgccl2QDYqMP2JUmS5sMcRZKkZa7LKz+eAdwE7FtVlwOrgHd12L4kSdJ8mKNIkrTMdXblR5tMvGdg/EK8n1aSJE2YOYokSVpw8SPJ9UANmwVUVd1loeuQJEmaK3MUSZI0ZcHFj6rygWGSJGnJMUeRJElTunzmB0kek+R57fDWSe7ZZfuSJEnzYY4iSdLy1lnxI8kbgH8EDmgn3Qk4oqv2JUmS5sMcRZIkdXnlx18BuwM3AlTVpYCXm0qSpEkzR5EkaZnrsvjxu6oq2geLJdmsw7YlSZLmyxxFkqRlrsvix6eTfBjYKskLgK8BH+mwfUmSpPkwR5EkaZlb8K+9TKmqdyd5EnAdcF/g9VV1fFftS5IkzYc5iiRJ6qz4AdAmEiYTkiRpSTFHkSRpeVtw8SPJ9bT30A5TVXdZ6DokSZLmyhxFkiRNWXDxo6q2AEjyFuAy4HAgwLOAbRbaviRJ0nwsNEdJsj1wGHB3miLKQVX1vmnL7Ax8ATi/nfTZqnpzR5sgSZI60uVtL7tX1YMHxj+U5AfA6ztchyRJ0lzNN0e5GXhlVZ2eZAvge0mOr6pzpi33zararcuAJUlSt7r8tZcbkzwryYZJNkjyLODGDtuXJEmaj3nlKFV1WVWd3g5fD5wLbLfIsUqSpEXQZfHjb4H/BfwCuAJ4ejtNkiRpkhacoyRZA+wEnDJk9qOS/CDJl5Pcf2GhSpKkxdDlT91eAOzRVXuSJEldWGiOkmRz4GjgFVV13bTZpwM7VNUNSZ4CfB64z5A29gP2A1i9evV8Q5EkSfPU2ZUfSVYl+VySK9rX0UlWddW+JEnSfCwkR0myEU3h4xNV9dnp86vquqq6oR3+ErBRkq2HLHdQVa2tqrUrV65c4BZJkqS56vK2l48DxwDbtq9j22nrlGTjJKe2l4ueneRNHcYkSZI03xwlwMHAuVX1nhmWuUe7HEkeQZNbXdVR3JIkqSNd/trLyqoaTCQOSfKKEd53E7BLe7noRsC3kny5qk7uMDZJkrR8zTdHeTTwHOCHSc5op70aWA1QVQcCTwNenORm4DfAnlVV3YUuSZK60GXx46okzwY+2Y4/kxG++WgThBva0Y3al0mDJEnqynxzlG8BmWWZ9wPvX3CEkiRpUXV528s+NE9Svxy4jOabkOeN8sb2p+fOoHkC+/FVNexJ6pIkSfMx7xxFkiT1Q5e/9vJzYPd5vvf3wEOSbAV8LskDquqsqfk+IV2SJM3XQnIUSZLUD50VP5LcE3gpsGaw3aoaOdmoqmuSfAPYFThrYPpBwEEAa9eu9ZYYSZI0si5yFEmStH7r8pkfn6d5IvqxwC2jvinJSuC/28LHJsCTgHd0GJckSVre5pWjSJKk/uiy+PHbqvrXebxvG+DQJBvSPIPk01X1xQ7jkiRJy9t8cxRJktQTXRY/3pfkDcBXaX6+FoCqOn1db6qqM4GdOoxDkiRp0LxyFEmS1B9dFj8eCDwH2IXbLimtdlySJGlSzFEkSVrmuix+PB24V1X9rsM2JUmSFsocRZKkZW6DDts6C9iqw/YkSZK6YI4iSdIy1+WVH1sBP0ryXW5/P60/IydJkibJHEWSpGWuy+LHGzpsS5IkqSvmKJIkLXOdFT+q6j+6akuSJKkr5iiSJKnLZ35IkiRJkiQtORY/JEmSJElSry24+JHk6+2/71h4OJIkSd0wR5EkSVO6eObHNkn+FNg9yZFABmdW1ekdrEOSJGmuzFEkSRLQTfHj9cDrgFXAe6bNK2CXDtYhSZI0V+YokiQJ6KD4UVVHAUcleV1VvaWDmCRJkhbMHEWSJE3p8qdu35Jkd+Bx7aQTq+qLXbUvSZI0H+YokiSps197SfI24OXAOe3r5Un+qav2JUmS5sMcRZIkdXblB/BU4CFVdQtAkkOB7wOv7nAdkiRJc2WOIknSMtfZlR+trQaGt+y4bUmSpPkyR5EkaRnr8sqPtwHfT/INmp+Sexywf4ftS5Ikzce8cpQk2wOHAXen+XWYg6rqfdOWCfA+4CnAr4G9/QldSZKWni4fePrJJCcCD28n/WNVXd5V+5IkSfOxgBzlZuCVVXV6ki2A7yU5vqrOGVjmycB92tefAB9q/5UkSUtIl1d+UFWXAcd02aYkSdJCzSdHad9zWTt8fZJzge1oHpo6ZQ/gsKoq4OQkWyXZpn2vJElaIrp+5ockSVLvJFkD7AScMm3WdsBFA+MXt9MkSdIS0umVH5IkSX2TZHPgaOAVVXXdPNvYD9gPYPXq1R1GJ2mxrNn/uEmHoBG5rzSKTq78SLJhkh910ZYkSVJXFpqjJNmIpvDxiar67JBFLgG2Hxhf1U67nao6qKrWVtXalStXzjccSZI0T50UP6rq98CPk/hVhiRJWjIWkqO0v+RyMHBuVb1nhsWOAZ6bxiOBa33ehyRJS0+Xt738AXB2klOBG6cmVtXuHa5DkiRpruabozwaeA7wwyRntNNeDaxu338g8CWan7k9j+anbp/XbeiSJKkLXRY/XtdhW5IkSV2ZV45SVd8CMssyBbxkPu1LkqTx6az4UVX/kWQH4D5V9bUkmwIbdtW+JEnSfJijSJKkzn7qNskLgKOAD7eTtgM+31X7kiRJ82GOIkmSOit+0Fzy+WjgOoCq+gnwhx22L0mSNB/mKJIkLXNdFj9uqqrfTY0kWQFUh+1LkiTNhzmKJEnLXJfFj/9I8mpgkyRPAj4DHNth+5IkSfNhjiJJ0jLXZfFjf+BK4IfAC2l++u21HbYvSZI0H+YokiQtc13+2sstSQ4FTqG5lPTH7c+/SZIkTYw5iiRJ6qz4keSpwIHAT4EA90zywqr6clfrkCRJmitzFEmS1FnxA/hn4M+q6jyAJH8EHAeYWEiSpEkyR5EkaZnr8pkf108lFa2fAdd32L4kSdJ8mKNIkrTMLfjKjyR/3Q6eluRLwKdp7qd9OvDdhbYvSZI0H+YokiRpShe3vfzlwPAvgMe3w1cCm3TQviRJ0nyYo0iSJKCD4kdVPa+LQCRJkrpkjiJJkqZ0+Wsv9wReCqwZbLeqdu9qHZIkSXNljiJJkrr8tZfPAwcDxwK3dNiuJEnSQpijSJK0zHVZ/PhtVf1rh+1JkiR1wRxFkqRlrsvix/uSvAH4KnDT1MSqOn1db0qyPXAYcHeaJ7AfVFXv6zAuSZK0vM0rR5EkSf3RZfHjgcBzgF247ZLSasfX5WbglVV1epItgO8lOb6qzukwNkmStHzNN0eRJEk90WXx4+nAvarqd3N5U1VdBlzWDl+f5FxgO8DihyRJ6sK8chRJktQfG3TY1lnAVgtpIMkaYCfglA7ikSRJgg5yFEmStH7r8sqPrYAfJfkut7+fdqSfkUuyOXA08Iqqum7avP2A/QBWr17dWcCD1ux/3KK0K0mSJm5BOYokSVr/dVn8eMN835hkI5rCxyeq6rPT51fVQcBBAGvXrq15RyhJkpajeecokiSpHzorflTVf8znfUkCHAycW1Xv6SoeSZIkWFCO8jFgN+CKqnrAkPk7A18Azm8nfbaq3jzfOCVJ0uLprPiR5HqaJ6cD3AnYCLixqu4yy1sfTfME9h8mOaOd9uqq+lJXsUmSpOVrATnKIcD7gcPWscw3q2q3BQcpSZIWVZdXfmwxNdxezbEH8MgR3vctIF3FIUmSNGgBOcpJ7cPYJUnSeq7LX3u5VTU+D/zFYrQvSZI0H4uQozwqyQ+SfDnJ/TtqU5IkdazL217+emB0A2At8Nuu2pckSZqPRcxRTgd2qKobkjwF+DxwnxliWPRfrpMkSTPr8tde/nJg+GbgAprLSiVJkiZpUXKUqrpuYPhLST6YZOuq+uWQZf3lOkmSJqjLZ348r6u2JEmSurJYOUqSewC/qKpK8giaq0quWox1SZKkhVlw8SPJ69cxu6rqLQtdhyRJ0lwtNEdJ8klgZ2DrJBcDb6D5pRiq6kDgacCLk9wM/AbYs6q8qkOSpCWoiys/bhwybTNgX+BugMUPSZI0CQvKUarqmbPMfz8KqpSpAAAgAElEQVTNT+FKkqQlbsHFj6r656nhJFsALweeBxwJ/PNM75MkSVpM5iiSJGlKJ8/8SHJX4B+AZwGHAg+tql910bYkSdJ8maNIkiTo5pkf7wL+muYJ5g+sqhsWHJUkSdICmaNIkqQpG3TQxiuBbYHXApcmua59XZ/kulneK0mStFjMUSRJEtDNMz+6KKBIkiR1yhxFkiRNMSmQJEmSJEm9ZvFDkiRJkiT1msUPSZIkSZLUaxY/JEmSJElSr1n8kCRJkiRJvWbxQ5IkSZIk9ZrFD0mSJEmS1GsWPyRJkiRJUq9Z/JAkSZIkSb1m8UOSJEmSJPWaxQ9JkiRJktRrFj8kSZIkSVKvWfyQJEmSJEm9ZvFDkiRJkiT1msUPSZIkSZLUaxY/JEmSJElSr1n8kCRJkiRJvWbxQ5IkaQZJPpbkiiRnzTA/Sf41yXlJzkzy0HHHKEmSZmfxQ5IkaWaHALuuY/6Tgfu0r/2AD40hJkmSNEcWPyRJkmZQVScBV69jkT2Aw6pxMrBVkm3GE50kSRqVxQ9JkqT52w64aGD84naaJElaQlZMOgBJkqS+S7IfzW0xrF69elHWsWb/4xal3Um64O1PnXQInevjfpKk9YFXfkiSJM3fJcD2A+Or2mm3U1UHVdXaqlq7cuXKsQUnSZIaFj8kSZLm7xjgue2vvjwSuLaqLpt0UJIk6fa87UWSJGkGST4J7AxsneRi4A3ARgBVdSDwJeApwHnAr4HnTSZSSZK0LhY/JEmSZlBVz5xlfgEvGVM4kiRpnrztRZIkSZIk9ZrFD0mSJEmS1GsWPyRJkiRJUq9NvPiR5GNJrkhy1qRjkSRJkiRJ/TPx4gdwCLDrpIOQJEmSJEn9NPHiR1WdBFw96TgkSZIkSVI/Tbz4IUmSJEmStJhWTDqAUSTZD9gPYPXq1ROORtJytWb/4yYdgpaxC97+1EmHIEmStN5aL678qKqDqmptVa1duXLlpMORJEmSJEnrkfWi+CFJkiRJkjRfEy9+JPkk8B3gvkkuTrLvpGOSJEmSJEn9MfFnflTVMycdgyRJkiRJ6q+JX/khSZIkSZK0mCx+SJIkSZKkXrP4IUmSJEmSes3ihyRJkiRJ6jWLH5IkSZIkqdcsfkiSJEmSpF6z+CFJkiRJknrN4ockSZIkSeo1ix+SJEmSJKnXLH5IkiRJkqRes/ghSZI0gyS7JvlxkvOS7D9k/t5JrkxyRvt6/iTilCRJ67Zi0gFIkiQtRUk2BD4APAm4GPhukmOq6pxpi36qqv5+7AFKkqSReeWHJEnScI8Azquqn1XV74AjgT0mHJMkSZoHix+SJEnDbQdcNDB+cTttur9JcmaSo5JsP57QJEnSXFj8kCRJmr9jgTVV9SDgeODQYQsl2S/JaUlOu/LKK8caoCRJsvghSZI0k0uAwSs5VrXTblVVV1XVTe3oR4GHDWuoqg6qqrVVtXblypWLEqwkSZqZxQ9JkqThvgvcJ8k9k9wJ2BM4ZnCBJNsMjO4OnDvG+CRJ0oj8tRdJkqQhqurmJH8PfAXYEPhYVZ2d5M3AaVV1DPCyJLsDNwNXA3tPLGBJkjQjix+SJEkzqKovAV+aNu31A8MHAAeMOy5JkjQ33vYiSZIkSZJ6zeKHJEmSJEnqNYsfkiRJkiSp1yx+SJIkSZKkXrP4IUmSJEmSes3ihyRJkiRJ6jWLH5IkSZIkqdcsfkiSJEmSpF6z+CFJkiRJknrN4ockSZIkSeo1ix+SJEmSJKnXLH5IkiRJkqRes/ghSZIkSZJ6zeKHJEmSJEnqNYsfkiRJkiSp1yx+SJIkSZKkXrP4IUmSJEmSes3ihyRJkiRJ6jWLH5IkSZIkqdcsfkiSJEmSpF6z+CFJkiRJknrN4ockSZIkSeq1JVH8SLJrkh8nOS/J/pOOR5IkCWbPUZLcOcmn2vmnJFkz/iglSdJsJl78SLIh8AHgycCOwDOT7DjZqCRJ0nI3Yo6yL/Crqro38C/AO8YbpSRJGsXEix/AI4DzqupnVfU74EhgjwnHJEmSNEqOsgdwaDt8FPCEJBljjJIkaQQrJh0AsB1w0cD4xcCfDC6QZD9gv3b0hiQ/HlNsk7I18MtJB7GE2B93tOT7JOP/7nPJ98mY2R93tF73ySJ9pu67KK32x6w5yuAyVXVzkmuBuzHtWFtgLrNeH7sL0R73y3b7W26/279ct385bzv0cPvnmMvMZft3GGWhpVD8mFVVHQQcNOk4xiXJaVW1dtJxLBX2xx3ZJ3dkn9ye/XFH9skdJTlt0jEsFwvJZZb7sev2u/1u//Lc/uW87eD2L8b2L4XbXi4Bth8YX9VOkyRJmqRRcpRbl0myAtgSuGos0UmSpJEtheLHd4H7JLlnkjsBewLHTDgmSZKkUXKUY4C92uGnASdUVY0xRkmSNIKJ3/bS3h/798BXgA2Bj1XV2RMOa9KWzS0+I7I/7sg+uSP75PbsjzuyT+7IPlmHmXKUJG8GTquqY4CDgcOTnAdcTVMg6dpy309u//Lm9i9fy3nbwe3vfPvjlxOSJEmSJKnPlsJtL5IkSZIkSYvG4ockSZIkSeo1ix9LQJK7Jjk+yU/af/9ghuXemeTsJOcm+dckGXes4zCH/lid5Kttf5yTZM14Ix2fUfukXfYuSS5O8v5xxjhuo/RJkock+U77uTkzyTMmEetiSrJrkh8nOS/J/kPm3znJp9r5p/T5czJlhD75h/accWaSrycZ6bfh11ez9cfAcn+TpJIs25/VWyqSvCvJj9pj9HNJtlrHshsm+X6SL44zxsU0yvYn2T7JN9rP8tlJXj6JWBfDqPt/1M/2+ibJ09t9esu6zkdJ/ne73FlJPplk43HGuRjmsO1bJTmqPU7OTfKocca5WEbd/nbZPp77Zt3+np/7Rj3+533us/ixNOwPfL2q7gN8vR2/nSR/CjwaeBDwAODhwOPHGeQYzdofrcOAd1XV/YBHAFeMKb5JGLVPAN4CnDSWqCZrlD75NfDcqro/sCvw3nX9J2J9k2RD4APAk4EdgWcm2XHaYvsCv6qqewP/ArxjvFGO14h98n1gbVU9CDgKeOd4oxyfEfuDJFsALwdOGW+EmsHxwAPaY/S/gAPWsezLgXPHEtX4jLL9NwOvrKodgUcCLxl2bK+nZt3+UT/b66mzgL9mHblMku2Al9Gcyx9A80DixXjY8LjNuu2t9wH/XlV/DDyY/pwDRt1+6Oe5b5Tt7/O5b5TP/oLOfRY/loY9gEPb4UOB/zlkmQI2Bu4E3BnYCPjFWKIbv1n7oz3IV1TV8QBVdUNV/Xp8IY7dKMcISR4G3B346pjimqRZ+6Sq/quqftIOX0pTIFs5tggX3yOA86rqZ1X1O+BImn4ZNNhPRwFPSPp51Vhr1j6pqm8MnC9OBlaNOcZxGuUYgaZo+g7gt+MMTsNV1Ver6uZ2dMZjNMkq4KnAR8cV2ziMsv1VdVlVnd4OX0/zn6Dtxhfl4hlx/4/62V7vVNW5VfXjERZdAWySZAWwKXDp4ka2+EbZ9iRbAo+j+aUpqup3VXXNOOJbbKPu+x6f+2bd/p6f+0bZ/ws691n8WBruXlWXtcOX0/zn9Xaq6jvAN4DL2tdXqqpv1c4ps/YH8D+Aa5J8tr3k7V1tJbCvZu2TJBsA/wz8n3EGNkGjHCe3SvIImuLhTxc7sDHaDrhoYPxi7vgH8NZl2mT6WuBuY4luMkbpk0H7Al9e1Igma9b+SPJQYPuqOm6cgWlk+zDzMfpe4FXALeMLZ+zWtf0AtLfz7UQ/r1yaafvneq7rlaq6BHg3cCFNXnxtVS2HL34A7glcCXy8zYE/mmSzSQc1Zsvh3Dernp/7ZrKgc9+KzsPRUEm+BtxjyKzXDI5UVSW5w+8PJ7k3cD9uq/4fn+SxVfXNzoMdg4X2B82x+1iaD/yFwKeAvWmr4OujDvrk74AvVdXFffliv4M+mWpnG+BwYK+qWtZ/KHWbJM8G1tLfWwhn1RZN30Nz/tQYrev8VlVfaJd5Dc0lzp8Y8v7dgCuq6ntJdl7MWBfDQrd/oJ3NgaOBV1TVdYsR62LoavvXV6Ns/yzv/wOab3vvCVwDfCbJs6vqiG4j7d5Ct50mB34o8NKqOiXJ+2hu/X1dh2Eumg72fe/PfSO209tz32Ky+DEmVfXEmeYl+UWSbarqsvY/acOeXfFXwMlVdUP7ni8DjwLWy+JHB/1xMXBGVf2sfc/nae57W2+LHx30yaOAxyb5O2Bz4E5Jbqiq9fYhaB30CUnuAhxHc1I9eZFCnZRLgO0Hxle104Ytc3F7afCWwFXjCW8iRukTkjyRpoj2+Kq6aUyxTcJs/bEFzXOkTmyLpvcAjkmye1WdNrYol6F1nd8AkuwN7AY8oaqGFXcfDeye5Ck0t8XeJckRVfXszoNdBB1sP0k2okn+P1FVn+08yEXUwfaPdK5bqmbb/hE8ETi/qq4ESPJZ4E+BJV/86GDbLwYurqqpb/uPYt3PgltSOtj+Xp/7RtHnc98IFnTu87aXpeEYYK92eC9gWNXrQuDxSVa0B/zj6d9DfqaM0h/fBbZKMvX8hl2Ac8YQ26TM2idV9ayqWl1Va2hufTlsfS58jGDWPklyJ+BzNH1x1BhjG5fvAvdJcs92W/ek6ZdBg/30NOCEmf4j0ROz9kmSnYAPA7tXVZ8flAyz9EdVXVtVW1fVmvbccTJNv1j4mKAku9Jc0r37TM+zqqoDqmpVu9/2pPlsrxfJ/2xG2f722UUHA+dW1XvGGd9iG2X7Ge3832cXAo9Msml7LDyB/ubFt1NVlwMXJblvO+kJ9DsHvp0+n/tG0edz34gWdO6z+LE0vB14UpKf0FSy3w6QZG2SqQf5HEXzrIIfAj8AflBVx04i2DGYtT+q6vc0/8H/epIfAgE+MqF4x2GUY2S5GaVP/hfNQ8H2TnJG+3rIZMLtXvsMj78HvkKT9H26qs5O8uYku7eLHQzcLcl5wD+wHn07NB8j9sm7aK6O+kx7TPT2Pwwj9oeWnvfTXJVzfHuMHgiQZNskX5psaGMxyvY/GngOsMvA+f0pE4q3a7Nu/0yf7UkF3KUkf5XkYporWo9L8pV2+uD2n0KTG59OkxtvABw0oZA7M8q2t14KfCLJmcBDgH8af7Tdm8P299KI29/bc9+In/0FnfvS7y8AJUmSJEnScueVH5IkSZIkqdcsfkiSJEmSpF6z+CFJkiRJknrN4ockSZIkSeo1ix+SJEmSJKnXVkw6AEnrjyS/p/lJuSlHVtXbJxWPJEnSXJjLSMuXP3UraWRJbqiqzWdZZsOq+v3A+Ir2N7lna3uk5SRJkubLXEZavrztRdKCJbkgyTuSnA48PcmJSd6b5DTg5UnWJDkhyZlJvp5kdfu+Q5IcmOQU4J0T3QhJkrRsmctI/edtL5LmYpMkZwyMv62qPtUOX1VVDwVI8iLgTlW1th0/Fji0qg5Nsg/wr8D/bN+3CvjTwW9YJEmSFom5jLRMWfyQNBe/qaqHzDDvU+sYfxTw1+3w4dz+m5HPmCxIkqQxMZeRlilve5HUlRtnGR/1fZIkSZNgLiP1mMUPSePwbWDPdvhZwDcnGIskSdJcmctI6zlve5E0F9Pvk/33qtp/hPe9FPh4kv8PuBJ43qJEJ0mStG7mMtIy5U/dSpIkSZKkXvO2F0mSJEmS1GsWPyRJkiRJUq9Z/JAkSZIkSb1m8UOSJEmSJPWaxQ9JkiRJktRrFj8kSZIkSVKvWfzQOiU5MMnrOmprdZIbkmzYjp+Y5PldtN229+Uke3XV3hzW+9Ykv0xy+bjXvdwluSDJE0dYbk2SSrJiju0nyceT/CrJqfOPdKR1dXL8zndbl4okOye5eNJxSOoPc5mR1msuMyHmMkPbMZfRolgvDyh1I8kFwN2Bm4HfA+cAhwEHVdUtAFX1ojm09fyq+tpMy1TVhcDmC4v61vW9Ebh3VT17oP0nd9H2HONYDbwS2KGqrhj3+rXoHgM8CVhVVTcu5oomcfxK0vrOXKaTOMxl+s1cRmp55Yf+sqq2AHYA3g78I3Bw1ytZXyu3I1gNXNVFsjCsj+bTb1PfRo1bT/fxDsAF80kWetofkrQUmcssjLnMbevt4z42l5FaFj8EQFVdW1XHAM8A9kryAIAkhyR5azu8dZIvJrkmydVJvplkgySH0/zhPLa9FPRVA5er7ZvkQuCEGS5h+6Mkpya5LskXkty1XdcdLhebuiwwya7Aq4FntOv7QTv/1ktP27hem+TnSa5IcliSLdt5U3HsleTC9jLP18zUN0m2bN9/Zdvea9v2nwgcD2zbxnHIDO/fLckZbb99O8mDpm3TPyY5E7gxyYoZpt2v3b5rkpydZPeBNg5J8qEkX0pyI/BnQ2LYNskx7X47L8kLBqb/Zqrf22k7tX2yUTu+T5Jz28slv5Jkh4FlK8lLkvwE+MmQ9U719fOSXNS28aIkD09yZrs97x9Yfsb91s5/Tjvvqun7rH3v/kl+2s7/9OB2TVt27yQ/S3J9kvOTPGvIMvsCHwUe1e7fN7XTX9D24dVtn247h/7YOMkRbXzXJPlukru38waP372TfCvJu9s+Oz/JkwfauWeSk9r4v5bkA0mOmGFbt0xycJLLklyS5tLmoUllkkckOS3N5/EXSd4zMO8zSS5Pcm277vsPzDskyQfTXO56Q5L/THKPJO9t4/9Rkp0Glr8gyQFJzmnnfzzJxjPEtG2So9N8/s5P8rJhy0mSuYy5zMCy5jKYy8RcRtNVla9l+gIuAJ44ZPqFwIvb4UOAt7bDbwMOBDZqX48FMqwtYA1QNJeebgZsMjBtRbvMicAlwAPaZY4Gjmjn7QxcPFO8wBunlh2YfyLN5aoA+wDnAfeiuTz1s8Dh02L7SBvXg4GbgPvN0E+HAV8Atmjf+1/AvjPFOe29OwFXAH8CbAjs1W7HnQe26Qxge2CTYdPavj6PJkm6E7ALcD1w34F9dC3waJqC5sZD4jgJ+CCwMfAQ4Epgl3beCcALBpZ9F3BgO7xHu+770dwm91rg2wPLFk3SdNep+Ketd6qvD2zX/efAb4HPA38IbNf2z+NH2G87AjcAjwPuDLyH5jLnqWPi5cDJwKp2/oeBT06LYwXNsXbdQP9tA9x/hv23N/CtgfFdgF8CD23X8f+Ak+bQHy8EjgU2bY+HhwF3GXL87g38N/CCdrkXA5dy2+ftO8C72+PhMe32HDF9W9vxz7V9sVnb56cCL5xhe78DPKcd3hx45MC8fWg+A3cG3gucMTDvkLZfHtbu5xOA84HntvG/FfjGtM/yWTTH+F2B/+S288zOtJ8pmuP5e8Dr2229F/Az4C8mff705cvX0nhhLmMuU+YymMsMxmcu42vG18QD8DXBnT9zwnAy8Jp2+JCBD/Kbaf5w3nu2tgZOWvcaMm0wYXj7wPwdgd+1J5hbTxrD1sHsCcPXgb8bmHff9gS8YiCOVQPzTwX2HLJdG7Yx7Tgw7YXAie3wHeKc9v4PAW+ZNu3H3PYH8gJgnyHbuc/A+GOBy4ENBqZ9EnjjwD46bB0xbE9zH/QWA9PeBhzSDj8fOKEdDnAR8Lh2/Mu0yVE7vgHwa5r7gmn7cZd1rHuqr7cbmHYV8IyB8aOBV4yw314PHDkwb7N230wdE+cCTxiYv82QfT6VMFwD/A1D/qhPi39vbp8wHAy8c2B883Yda0bsj32AbwMPGjLvRG6fMJw3MG/Ttu170HwzeTOw6cD8IxiSMNDcB3/T4HYCz2Tgj/e0GE4C3gRsPUu/bNWuY8uBY/AjA/NfCpw7MP5A4Jppx/iLBsafAvx0+meKJtG+cNq6DwA+vq74fPnytXxemMuYy5S5zCyfkb0xlxm2nLnMMnx524uG2Q64esj0d9FUsr/aXma3/whtXTSH+T+n+WZg65GiXLdt2/YG2546gU4ZfKL5rxn+ALOt25imt7XdiHHsALyyvSzwmiTX0PwB33ZgmWF9NDhtW+Ciah/cNkMM6+rnbYGrq+r6Gd5/NM3lkNvQfBNxC/DNgfjfNxD71TRJxajrnvKLgeHfDBmf6vt17bdtB9dVzb2rVw0suwPwuYFYz6VJlAb3+dT7ngG8CLgsyXFJ/niEbbhDfFV1QxvDqP1xOPAV4Mj/v717D7esLu8E/33l4hVlWk63BCjLJGSeMWrUVIjGfjpE22dQCUwn2g3xEmiT6thqzGhfwCSQ6KTVzmhaByOh1Yh2Ihg0Tqk4BiPeJi1SIqJcnK4YbG4JiMrFC3bpO3/sXfFwPKfOPpe9T511Pp/n2Q/r8ttrv/u3d+3z8q7f+q2qurmq/uO+IbmL+PvvZ3d/c7z4oHz/8/zmvLZLvebDM/r+3jKvX/4oo7Mmi3l+kh9Lct14GOuJyeja66p69XgY7p0Z/cFP7v1vddLPeLGYv5x7/5uYH/8PLfj38/Is+EwBFiGX+T65jFxmPrmMXGbLUvzgXqrqpzL68fvkwn3dfVd3v6y7fzjJSUleWlVP2bd7iUMutX2fY+Ytb8uo8vyVJN/IqEK8L66Dksyt4Lg3Z/RjM//Ye3PvH7FJfGUc08Jj3TTh829I8nvdffi8xwO6+53z2iz2XuZvuznJMVU1/9/rwhj21x83J/kHVXXYYs/v7q8l+YuM/oj+UkZnJPYd74aMhhXOj//+3f1XE772Su3vc7sl874vVfWAJA+d1/aGJE9bEOv9uvsHPqvu/lB3PzWjMyrXZTRseMXxVdUDxzFM9Fl09//o7t/t7kcm+ZkkJ2Y0nHIlbsno83zAvG3HLNH2hozOlhwxr08e3N0/vljj7v5v3X1qRgnFa5JcNH6Pv5TRsOF/muQhGZ2RSUbJ42ot/Ld/8xLx/82Cz/Sw7n76Gl4XGDi5zA+Qy8hlloxPLiOX2UoUP0iSVNWDx5XRCzIacvb5RdqcWFU/WlWV0XWZ382osp6MftB/eBUv/ZyqeuT4x+8VSS7q7u9mdC3q/arqGeNq8m9ldH3ePn+XZPuCP6LzvTPJ/z6eTOlBSf5Dkgu7e+9KghvH8q4kv1dVh9VogqyXZjQ0bxL/OcmvVdVP18gDx+/psGWf+X2XZXQ2599V1SFVdXySn8/os5rkPdyQ0fDEV9VokqrHZFQVn/8e/jSjP1zPHC/vc26SM/dNCFWjCaeetYLYV2p/n9tFSU6sqn9cVYdm9H2Z//mfm9Hn9PBxrHNVdfLCF6iqf1RVJ4//EN6T0bW331vYbj/xnV5Vj62q+47ju6y7r5/kyVX1c1X16HECfGdGyeikr50k6e4vJ9md5Heq6tCqemJG34fF2t6SUTL42vG/8ftU1Y9U1c8uEd9zqmpufGbu6+PN38vo+th7Mjoz9ICM3vdavbCqjq7RRG6/meTCRdp8OsldNZo07/7jszaPGv+PDcC9yGUWJ5eRyywSn1xGLrMlKX7wvqq6K6Oq5G9mNPHS6Uu0PTbJhzP6gf2vSf6wuy8d73tVkt+q0XCuf7OC139HRtfY/W1Gkwv9ejKasT3Jv85ohuqbMjp7Mn/G9D8b//f2qrpikeO+dXzsj2c0WdG3M7p2bzVePH79L2V0FulPx8dfVnfvzmiip3OSfC2jobanreTFu/s7Gf1BeFpGZ2/+MMnzuvu6FRzm1Iwq3DdnNGnU2d394Xn7d2X0+f5td39u3mv/eUZV8wtqNETwC+M4pmXJz627r07ywoz6/5aM+nP+d+L14/fxF+Pv9Kcyus5yoftklPTdnNHQ15/NaBKuZY377LczGl57S5IfSXLKCt7fwzJKfO7MaCjrxzJ6vyv17CRPzOgP+P+R0R/be5Zo+7yMJti6JqM+uyijs0SLOSHJ1VV1d0b9eUp3fyujifK+nNG/xWsy6tu1+tOMkpkvJfnr8fu4l3HCfmJGE9v9TUbf/zdndMYGYB+5zPLkMnKZjGOQy8hltqx9s+0CsElV1YVJruvuszc6lklU1fUZTYj24eXaAgDDJ5dhFoz8ANhkquqnxkM+71NVJ2R0Det7NzouAIBJyGXYCAdvdAAArNjDkrwnownKbkzygu7+7MaGBAAwMbkMM+eyFwAAAGDQXPYCAAAADNqmu+zliCOO6O3bt290GACw6X3mM5/5SnfPbXQcW41cBgDWz6T5zKYrfmzfvj27d+/e6DAAYNOrqi9vdAxbkVwGANbPpPmMy14AAACAQVP8AAAAAAZN8QMAAAAYNMUPAAAAYNAUPwAAAIBBU/wAAAAABk3xAwAAABi0qRU/qup+VfXpqvpcVV1dVb+7SJv7VtWFVbWnqi6rqu3TigcAYDWq6qCq+mxVvX+RfXIZANgEpjny454kT+7un0jy2CQnVNUTFrR5fpKvdfePJvmDJK+ZYjwAAKvxkiTXLrFPLgMAm8DUih89cvd49ZDxoxc0OznJ+ePli5I8papqWjEBAKxEVR2d5BlJ3rxEE7kMAGwCU53zYzxM9Moktya5pLsvW9DkqCQ3JEl3701yR5KHTjMmAIAV+E9J/l2S7y2xXy4DAJvAwdM8eHd/N8ljq+rwJH9eVY/q7i+s9DhVtTPJziTZtm3bOkfJZrL9jA9sdAhsYde/+hkbHQIwQ1V1YpJbu/szVXX8Go8llyHJcHOZIf6NHOJnNcTPCSY1k7u9dPfXk1ya5IQFu25KckySVNXBSR6S5PZFnn9ed+/o7h1zc3PTDhcAIEmelOSkqro+yQVJnlxV/2VBG7kMAGwC07zby9x4xEeq6v5JnprkugXNdiX55fHyM5N8pLsXzgsCADBz3X1mdx/d3duTnJJRnvKcBc3kMgCwCUzzspcjk5xfVQdlVGR5V3e/v6pekWR3d+9K8pYk76iqPUm+mlFiAQBwwJLLAMDmM7XiR3dfleRxi2w/a97yt5M8a1oxAACsh+7+aJKPjpflMgCwycxkzg8AAACAjaL4AQAAAAya4gcAAAAwaIofAAAAwKApfgAAAACDpvgBAAAADJriBwAAADBoih8AAADAoCl+AAzQ7fYAAB9ISURBVAAAAIOm+AEAAAAMmuIHAAAAMGiKHwAAAMCgKX4AAAAAg6b4AQAAAAya4gcAAAAwaIofAAAAwKApfgAAAACDpvgBAAAADJriBwAAADBoih8AAADAoCl+AAAAAIOm+AEAAAAMmuIHAMAiqup+VfXpqvpcVV1dVb+7SJvTquq2qrpy/PiVjYgVANi/gzc6AACAA9Q9SZ7c3XdX1SFJPllVH+zuTy1od2F3v2gD4gMAJqT4AQCwiO7uJHePVw8ZP3rjIgIAVstlLwAAS6iqg6rqyiS3Jrmkuy9bpNkvVtVVVXVRVR0z4xABgAkofgAALKG7v9vdj01ydJLjqupRC5q8L8n27n5MkkuSnL/YcapqZ1Xtrqrdt91223SDBgB+gOIHAMAyuvvrSS5NcsKC7bd39z3j1Tcn+cklnn9ed+/o7h1zc3PTDRYA+AGKHwAAi6iquao6fLx8/yRPTXLdgjZHzls9Kcm1s4sQAJiUCU8BABZ3ZJLzq+qgjE4Yvau7319Vr0iyu7t3Jfn1qjopyd4kX01y2oZFCwAsSfEDAGAR3X1Vksctsv2sectnJjlzlnEBACvnshcAAABg0KZW/KiqY6rq0qq6pqqurqqXLNLm+Kq6o6quHD/OWuxYAAAAAKs1zcte9iZ5WXdfUVWHJflMVV3S3dcsaPeJ7j5xinEAAAAAW9jURn509y3dfcV4+a6MZj8/alqvBwAAALCYmcz5UVXbM5ow7LJFdj+xqj5XVR+sqh+fRTwAAADA1jH1u71U1YOSvDvJb3T3nQt2X5Hk4d19d1U9Pcl7kxy7yDF2JtmZJNu2bZtyxAAAAMCQTHXkR1UdklHh40+6+z0L93f3nd1993j54iSHVNURi7Q7r7t3dPeOubm5aYYMAAAADMw07/ZSSd6S5Nruft0SbR42bpeqOm4cz+3TigkAAADYeqZ52cuTkjw3yeer6srxtpcn2ZYk3X1ukmcmeUFV7U3yrSSndHdPMSYAAABgi5la8aO7P5mklmlzTpJzphUDAAAAwEzu9gIAAACwURQ/AAAAgEFT/AAAAAAGTfEDAAAAGDTFDwAAAGDQFD8AAACAQVP8AAAAAAZN8QMAAAAYNMUPAAAAYNAUPwAAAIBBU/wAAAAABk3xAwAAABg0xQ8AgEVU1f2q6tNV9bmqurqqfneRNvetqgurak9VXVZV22cfKQCwHMUPAIDF3ZPkyd39E0kem+SEqnrCgjbPT/K17v7RJH+Q5DUzjhEAmIDiBwDAInrk7vHqIeNHL2h2cpLzx8sXJXlKVdWMQgQAJqT4AQCwhKo6qKquTHJrkku6+7IFTY5KckOSdPfeJHckeegix9lZVburavdtt9027bABgAUUPwAAltDd3+3uxyY5OslxVfWoVR7nvO7e0d075ubm1jdIAGBZih8AAMvo7q8nuTTJCQt23ZTkmCSpqoOTPCTJ7bONDgBYjuIHAMAiqmquqg4fL98/yVOTXLeg2a4kvzxefmaSj3T3wnlBAIANdvBGBwAAcIA6Msn5VXVQRieM3tXd76+qVyTZ3d27krwlyTuqak+SryY5ZePCBQCWovgBALCI7r4qyeMW2X7WvOVvJ3nWLOMCAFbOZS8AAADAoCl+AAAAAIOm+AEAAAAMmuIHAAAAMGiKHwAAAMCgLVv8qKonVdUDx8vPqarXVdXDpx8aAMDayWUAgElGfrwpyTer6ieSvCzJXyd5+1SjAgBYP3IZANjiJil+7O3uTnJyknO6+41JDptuWAAA60YuAwBb3METtLmrqs5M8pwk/6Sq7pPkkOmGBQCwbuQyALDFTTLy418kuSfJ87v7b5McneT3pxoVAMD6kcsAwBa37MiPcZLwunnr/z2ukwUANgm5DACwZPGjqu5K0ovtStLd/eD9HbiqjskosfhH4+Oc192vX9Cmkrw+ydOTfDPJad19xYreAQDAItaaywAAw7Fk8aO71zoR2N4kL+vuK6rqsCSfqapLuvuaeW2eluTY8eOnM5qN/afX+LoAAOuRywAAAzHJnB+pqn9cVaePl4+oqkcs95zuvmXfKI7uvivJtUmOWtDs5CRv75FPJTm8qo5c0TsAAFjGanIZAGA4li1+VNXZSf59kjPHmw5N8l9W8iJVtT3J45JctmDXUUlumLd+Y36wQAIAsGrrkcsAAJvbJLe6/WcZFS72jeK4eXwZy0Sq6kFJ3p3kN7r7ztUEWVU7k+xMkm3btq3mEMvafsYHpnLcjXT9q5+x0SHAoPidgE1rTbkMALD5TXLZy3e6uzOeMKyqHjjpwavqkIwKH3/S3e9ZpMlNSY6Zt370eNu9dPd53b2ju3fMzc1N+vIAAMkachkAYBgmKX68q6r+KKP5OH41yYeT/OflnjS+k8tbklzb3a9botmuJM+rkSckuaO7b5kwdgCASawqlwEAhmPZy166+/+sqqcmuTPJ/5zkrO6+ZIJjPynJc5N8vqquHG97eZJt4+Oem+TijG5zuyejW92evuJ3AACwH2vIZQCAgZhkzo+ME4QVJQnd/ckktUybTvLClRwXAGClVpPLAADDsWTxo6ruyvja2MV094OnEhEAwDqQywAA+yxZ/Ojuw5Kkql6Z5JYk78hoJMezkxw5k+gAAFZJLgMA7DPJhKcndfcfdvdd3X1nd78pycnTDgwAYJ2sKpepqmOq6tKquqaqrq6qlyzS5viquqOqrhw/zprKOwAA1mSSOT++UVXPTnJBRkNHT03yjalGBQCwflaby+xN8rLuvqKqDkvymaq6pLuvWdDuE9194vqGDACsp0lGfvxSkn+e5O+S3JrkWeNtAACbwapyme6+pbuvGC/fleTaJEdNMU4AYEomudXt9XGZCwCwSa1HLlNV25M8Lslli+x+YlV9LsnNSf5Nd1+9yPN3JtmZJNu2bVtLKADAKiw78qOqjq6qP6+qW8ePd1fV0bMIDgBgrdaay1TVg5K8O8lvdPedC3ZfkeTh3f0TSf6vJO9d7BjdfV537+juHXNzc6t9KwDAKk1y2csfJ9mV5IfGj/eNtwEAbAarzmWq6pCMCh9/0t3vWbh/PIHq3ePli5McUlVHrFfgAMD6mKT4Mdfdf9zde8ePtyVxygIA2CxWlctUVSV5S5Jru/t1S7R52Lhdquq4jHKr29cvdABgPUxyt5fbq+o5Sd45Xj81/qgDAJvHanOZJyV5bpLPV9WV420vT7ItSbr73CTPTPKCqtqb5FtJTunuXs/gAYC1m6T48S8zuob1DzK6PdxfJTl9mkEBAKyjVeUy3f3JJLVMm3OSnLMOMQIAUzTJ3V6+nOSkGcQCALDu5DIAwLLFj6p6RJIXJ9k+v313SyIAgAOeXAYAmOSyl/dmNNnX+5J8b7rhAACsO7kMAGxxkxQ/vt3db5h6JAAA0yGXAYAtbpLix+ur6uwkf5Hknn0bu/uKqUUFALB+5DIAsMVNUvx4dEa3eXtyvj9UtMfrAAAHOrkMAGxxkxQ/npXkh7v7O9MOBgBgCuQyALDF3WeCNl9Icvi0AwEAmBK5DABscZOM/Dg8yXVVdXnufZ2s28MBAJuBXAYAtrhJih9nTz0KAIDpkcsAwBa3bPGjuz82i0AAAKZBLgMATDLnBwAAAMCmpfgBAAAADNqSxY+q+svxf18zu3AAANaHXAYA2Gd/c34cWVU/k+SkqrogSc3f2d1XTDUyAIC1kcsAAEn2X/w4K8lvJzk6yesW7OskT55WUAAA60AuAwAk2U/xo7svSnJRVf12d79yhjEBAKyZXAYA2GeSW92+sqpOSvJPxps+2t3vn25YAADrQy4DACx7t5eqelWSlyS5Zvx4SVX9h2kHBgCwHuQyAMCyIz+SPCPJY7v7e0lSVecn+WySl08zMACAdSKXAYAtbtmRH2OHz1t+yDQCAQCYIrkMAGxhkxQ/XpXks1X1tvGZks8k+b3lnlRVb62qW6vqC0vsP76q7qiqK8ePs1YWOgDARFabyxxTVZdW1TVVdXVVvWSRNlVVb6iqPVV1VVU9fgrxAwBrNMmEp++sqo8m+anxpn/f3X87wbHfluScJG/fT5tPdPeJExwLAGBV1pDL7E3ysu6+oqoOS/KZqrqku6+Z1+ZpSY4dP346yZvG/wUADiCTzPmR7r4lya6VHLi7P15V21cREwDAulplLnNLklvGy3dV1bVJjspo0tR9Tk7y9u7uJJ+qqsOr6sjxcwGAA8Skc35MyxOr6nNV9cGq+vENjgUAYFHjEzqPS3LZgl1HJblh3vqN420AwAFkopEfU3JFkod3991V9fQk781oyOgPqKqdSXYmybZt22YXIQCw5VXVg5K8O8lvdPedqzzG1HOZ7Wd8YCrH3UjXv/oZGx0CsAn4/WMS+x35UVUHVdV103jh7r6zu+8eL1+c5JCqOmKJtud1947u3jE3NzeNcACAAVprLlNVh2RU+PiT7n7PIk1uSnLMvPWjx9vuRS4DABtrv8WP7v5uki9W1bqfoqiqh1VVjZePG8dy+3q/DgCwda0llxnnKW9Jcm13v26JZruSPG9815cnJLnDfB8AcOCZ5LKX/ynJ1VX16STf2Lexu0/a35Oq6p1Jjk9yRFXdmOTsJIeMn3tukmcmeUFV7U3yrSSnjCcLAwBYT6vKZZI8Kclzk3y+qq4cb3t5km3j55+b5OIkT0+yJ8k3k5y+vqEDAOthkuLHb6/mwN196jL7z8noVrgAANO02lzmk0lqmTad5IWrOT4AMDvLFj+6+2NV9fAkx3b3h6vqAUkOmn5oAABrJ5cBAJa91W1V/WqSi5L80XjTURndmQUA4IAnlwEAli1+ZDSU80lJ7kyS7v5vSf7hNIMCAFhHchkA2OImKX7c093f2bdSVQcnMTEpALBZyGUAYIubpPjxsap6eZL7V9VTk/xZkvdNNywAgHUjlwGALW6S4scZSW5L8vkk/yqjW7r91jSDAgBYR3IZANjiJrnby/eq6vwkl2U0RPSL49u6AQAc8OQyAMCyxY+qekaSc5P8dUb3un9EVf2r7v7gtIMDAFgruQwAsGzxI8lrk/xcd+9Jkqr6kSQfSCJhAAA2A7kMAGxxk8z5cde+ZGHsS0numlI8AADrTS4DAFvckiM/quoXxou7q+riJO/K6DrZZyW5fAaxAQCsmlwGANhnf5e9/Py85b9L8rPj5duS3H9qEQEArA+5DACQZD/Fj+4+fZaBAACsJ7kMALDPJHd7eUSSFyfZPr99d580vbAAANaHXAYAmORuL+9N8pYk70vyvemGAwCw7uQyALDFTVL8+HZ3v2HqkQAATIdcBgC2uEmKH6+vqrOT/EWSe/Zt7O4rphYVAMD6kcsAwBY3SfHj0Umem+TJ+f5Q0R6vAwAc6OQyALDFTVL8eFaSH+7u70w7GACAKZDLAMAWd58J2nwhyeHTDgQAYErkMgCwxU0y8uPwJNdV1eW593Wybg8HAGwGchkA2OImKX6cPfUoAACmRy4DAFvcssWP7v7YLAIBAJiG1eYyVfXWJCcmubW7H7XI/uOT/N9J/ma86T3d/YrVxgkATM+yxY+quiujGdGT5NAkhyT5Rnc/eJqBAQCshzXkMm9Lck6St++nzSe6+8Q1BwkATNUkIz8O27dcVZXk5CRPmGZQAADrZbW5THd/vKq2Ty8yAGBWJrnby9/rkfcm+V+nFA8AwNRMIZd5YlV9rqo+WFU/vk7HBADW2SSXvfzCvNX7JNmR5NtTiwgAYB1NMZe5IsnDu/vuqnp6kvcmOXaJGHYm2Zkk27ZtW4eXBgBWYpK7vfz8vOW9Sa7PaLgoAMBmMJVcprvvnLd8cVX9YVUd0d1fWaTteUnOS5IdO3b0wv0AwHRNMufH6bMIBABgGqaVy1TVw5L8XXd3VR2X0aiS26fxWgDA2ixZ/Kiqs/bzvO7uV04hHgCAdbHWXKaq3pnk+CRHVNWNSc7O6E4x6e5zkzwzyQuqam+SbyU5pbuN6gCAA9D+Rn58Y5FtD0zy/CQPTaL4AQAcyNaUy3T3qcvsPyejW+ECAAe4JYsf3f3afctVdViSlyQ5PckFSV671PMAAA4EchkAYJ/9zvlRVf8gyUuTPDvJ+Uke391fm0VgAABrJZcBAJLRxFyLqqrfT3J5kruSPLq7f2clyUJVvbWqbq2qLyyxv6rqDVW1p6quqqrHrzh6AIAlrDWXAQCGY8niR5KXJfmhJL+V5OaqunP8uKuq7tzP8/Z5W5IT9rP/aUmOHT92JnnTZCEDAExkrbkMADAQ+5vzY3+FkWV198eravt+mpyc5O3jWdE/VVWHV9WR3X3LWl4XACBZey4DAAzHfuf8mLKjktwwb/3G8bYfKH5U1c6MRodk27ZtMwluCLaf8YGNDgE4wPmd2Dyuf/UzNjoEAIBNa1OcEenu87p7R3fvmJub2+hwAAAAgE1kI4sfNyU5Zt760eNtAAAAAOtmI4sfu5I8b3zXlyckucN8HwAAAMB6m9qcH1X1ziTHJzmiqm5McnaSQ5Kku89NcnGSpyfZk+SbSU6fViwAAADA1jW14kd3n7rM/k7ywmm9PgAAAECySSY8BQAAAFgtxQ8AAABg0BQ/AAAAgEFT/AAAAAAGTfEDAAAAGDTFDwAAAGDQFD8AAACAQVP8AAAAAAZN8QMAAAAYNMUPAAAAYNAUPwAAAIBBU/wAAFhCVb21qm6tqi8ssb+q6g1Vtaeqrqqqx886RgBgeYofAABLe1uSE/az/2lJjh0/diZ50wxiAgBWSPEDAGAJ3f3xJF/dT5OTk7y9Rz6V5PCqOnI20QEAk1L8AABYvaOS3DBv/cbxNgDgAHLwRgcAADB0VbUzo8tism3btg2OZvPYfsYHNjoEJuSz2hx8TpvHED+r61/9jA19fSM/AABW76Ykx8xbP3q87V66+7zu3tHdO+bm5mYWHAAwovgBALB6u5I8b3zXlyckuaO7b9nooACAe3PZCwDAEqrqnUmOT3JEVd2Y5OwkhyRJd5+b5OIkT0+yJ8k3k5y+MZECAPuj+AEAsITuPnWZ/Z3khTMKBwBYJZe9AAAAAIOm+AEAAAAMmuIHAAAAMGiKHwAAAMCgKX4AAAAAg6b4AQAAAAya4gcAAAAwaIofAAAAwKApfgAAAACDpvgBAAAADJriBwAAADBoih8AAADAoE21+FFVJ1TVF6tqT1Wdscj+06rqtqq6cvz4lWnGAwAAAGw9B0/rwFV1UJI3JnlqkhuTXF5Vu7r7mgVNL+zuF00rDgAAAGBrm+bIj+OS7OnuL3X3d5JckOTkKb4eAAAAwA+YZvHjqCQ3zFu/cbxtoV+sqquq6qKqOmaK8QAAAABb0EZPePq+JNu7+zFJLkly/mKNqmpnVe2uqt233XbbTAMEAAAANrdpFj9uSjJ/JMfR421/r7tv7+57xqtvTvKTix2ou8/r7h3dvWNubm4qwQIAAADDNM3ix+VJjq2qR1TVoUlOSbJrfoOqOnLe6klJrp1iPAAAAMAWNLW7vXT33qp6UZIPJTkoyVu7++qqekWS3d29K8mvV9VJSfYm+WqS06YVDwAAALA1Ta34kSTdfXGSixdsO2ve8plJzpxmDAAAAMDWttETngIAAABMleIHAMASquqEqvpiVe2pqjMW2X9aVd1WVVeOH7+yEXECAPs31cteAAA2q6o6KMkbkzw1yY1JLq+qXd19zYKmF3b3i2YeIAAwMSM/AAAWd1ySPd39pe7+TpILkpy8wTEBAKug+AEAsLijktwwb/3G8baFfrGqrqqqi6rqmNmEBgCshOIHAMDqvS/J9u5+TJJLkpy/WKOq2llVu6tq92233TbTAAEAxQ8AgKXclGT+SI6jx9v+Xnff3t33jFffnOQnFztQd5/X3Tu6e8fc3NxUggUAlqb4AQCwuMuTHFtVj6iqQ5OckmTX/AZVdeS81ZOSXDvD+ACACbnbCwDAIrp7b1W9KMmHkhyU5K3dfXVVvSLJ7u7eleTXq+qkJHuTfDXJaRsWMACwJMUPAIAldPfFSS5esO2sectnJjlz1nEBACvjshcAAABg0BQ/AAAAgEFT/AAAAAAGTfEDAAAAGDTFDwAAAGDQFD8AAACAQVP8AAAAAAZN8QMAAAAYNMUPAAAAYNAUPwAAAIBBU/wAAAAABk3xAwAAABg0xQ8AAABg0BQ/AAAAgEFT/AAAAAAGTfEDAAAAGDTFDwAAAGDQFD8AAACAQVP8AAAAAAZN8QMAAAAYNMUPAAAAYNAUPwAAAIBBm2rxo6pOqKovVtWeqjpjkf33raoLx/svq6rt04wHAGAl5DIAMAxTK35U1UFJ3pjkaUkemeTUqnrkgmbPT/K17v7RJH+Q5DXTigcAYCXkMgAwHNMc+XFckj3d/aXu/k6SC5KcvKDNyUnOHy9flOQpVVVTjAkAYFJyGQAYiGkWP45KcsO89RvH2xZt0917k9yR5KFTjAkAYFJyGQAYiIM3OoBJVNXOJDvHq3dX1Rc3Mp4BOSLJVzY6iC1K328M/b4x9Ps6qJVfTDFJvz98VcGwYnKZqfDbMhv6eXb09Wzo59m5V1+vIpeZ1ET5zDSLHzclOWbe+tHjbYu1ubGqDk7ykCS3LzxQd5+X5LwpxbllVdXu7t6x0XFsRfp+Y+j3jaHfN4Z+XxdymQOY7/hs6OfZ0dezoZ9n50Dr62le9nJ5kmOr6hFVdWiSU5LsWtBmV5JfHi8/M8lHurunGBMAwKTkMgAwEFMb+dHde6vqRUk+lOSgJG/t7qur6hVJdnf3riRvSfKOqtqT5KsZJRUAABtOLgMAwzHVOT+6++IkFy/Ydta85W8nedY0Y2C/DL/dOPp+Y+j3jaHfN4Z+XwdymQOa7/hs6OfZ0dezoZ9n54Dq6zIyEwAAABiyac75AQAAALDhFD+2gKo6oaq+WFV7quqMRfbft6ouHO+/rKq2zz7K4Zmg319aVddU1VVV9ZdV5ZaT62C5fp/X7herqqvqgJmBejObpN+r6p+Pv/NXV9WfzjrGoZrgt2ZbVV1aVZ8d/948fSPihNWQw8yOvGV25CqzITeZnc2Si7jsZeCq6qAk/1+Spya5MaOZ60/t7mvmtfnXSR7T3b9WVack+Wfd/S82JOCBmLDffy7JZd39zap6QZLj9fvaTNLv43aHJflAkkOTvKi7d8861iGZ8Pt+bJJ3JXlyd3+tqv5hd9+6IQEPyIR9f16Sz3b3m6rqkUku7u7tGxEvrIQcZnbkLbMjV5kNucnsbKZcxMiP4TsuyZ7u/lJ3fyfJBUlOXtDm5CTnj5cvSvKUqqoZxjhEy/Z7d1/a3d8cr34qydEzjnGIJvm+J8krk7wmybdnGdyATdLvv5rkjd39tSSRXKybSfq+kzx4vPyQJDfPMD5YCznM7MhbZkeuMhtyk9nZNLmI4sfwHZXkhnnrN463Ldqmu/cmuSPJQ2cS3XBN0u/zPT/JB6ca0dawbL9X1eOTHNPdH5hlYAM3yff9x5L8WFX9v1X1qao6YWbRDdskff87SZ5TVTdmdNeSF88mNFgzOczsyFtmR64yG3KT2dk0uchUb3ULLK+qnpNkR5Kf3ehYhq6q7pPkdUlO2+BQtqKDkxyb5PiMzhZ+vKoe3d1f39CotoZTk7ytu19bVU9M8o6qelR3f2+jAwM2H3nLdMlVZkpuMjsHRC5i5Mfw3ZTkmHnrR4+3Ldqmqg7OaCjS7TOJbrgm6fdU1T9N8ptJTurue2YU25At1++HJXlUko9W1fVJnpBkl4nE1myS7/uNSXZ19//o7r/J6NrQY2cU35BN0vfPz+ia5nT3f01yvyRHzCQ6WBs5zOzIW2ZHrjIbcpPZ2TS5iOLH8F2e5NiqekRVHZrklCS7FrTZleSXx8vPTPKRNhPuWi3b71X1uCR/lFEC4RrD9bHffu/uO7r7iO7ePp5k6VMZ9b9JxNZmkt+Z92Z0ZiVVdURGQ02/NMsgB2qSvv/vSZ6SJFX1v2SUcNw20yhhdeQwsyNvmR25ymzITWZn0+Qiih8DN77+9UVJPpTk2iTv6u6rq+oVVXXSuNlbkjy0qvYkeWmSJW+5xWQm7PffT/KgJH9WVVdW1cIfCVZown5nnU3Y7x9KcntVXZPk0iT/trudnV2jCfv+ZUl+tao+l+SdSU7zP4dsBnKY2ZG3zI5cZTbkJrOzmXIRt7oFAAAABs3IDwAAAGDQFD8AAACAQVP8AAAAAAZN8QMAAAAYNMUPAAAAYNAO3ugAgM2jqr6b5PPzNl3Q3a/eqHgAAFZCLgNbl1vdAhOrqru7+0HLtDmou787b/3g8f2/lzv2RO0AAFZLLgNbl8tegDWrquur6jVVdUWSZ1XVR6vqP1XV7iQvqartVfWRqrqqqv6yqraNn/e2qjq3qi5L8h839E0AAFuWXAaGz2UvwErcv6qunLf+qu6+cLx8e3c/Pkmq6teSHNrdO8br70tyfnefX1X/Mskbkvxv4+cdneRn5p9hAQCYErkMbFGKH8BKfKu7H7vEvgv3s/7EJL8wXn5H7n1m5M8kCwDAjMhlYIty2QuwXr6xzPqkzwMA2AhyGRgwxQ9gFv4qySnj5Wcn+cQGxgIAsFJyGdjkXPYCrMTC62T/n+4+Y4LnvTjJH1fVv01yW5LTpxIdAMD+yWVgi3KrWwAAAGDQXPYCAAAADJriBwAAADBoih8AAADAoCl+AAAAAIOm+AEAAAAMmuIHAAAAMGiKHwAAAMCgKX4AAAAAg/b/Ax8JDGXzS3m1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1332x756 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_bins = 8\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.subplot(221)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[0], y_test[0], basic_error, show = False, bins = nb_bins)\n",
    "plt.subplot(222)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[1], y_test[1], basic_error, show = False, bins = nb_bins)\n",
    "plt.subplot(223)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[2], y_test[2], basic_error, show = False, bins = nb_bins)\n",
    "plt.subplot(224)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[3], y_test[3], basic_error, show = False, bins = nb_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4442079632254848"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(crowd01.predict(X_test_red), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The results are good, however we remark a bias which has to be corrected using other networks in the crowd (of other type maybe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Dropout layers\n",
    "Dropout layers have been reported in the litterature to bring good results to avoid overfitting in combination with L2 regularizers http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf (Srivastava et al.). It will train the model while keeping only a neuron active with probability p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dropout() got an unexpected keyword argument 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-89512d890d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model = tf.keras.Sequential([\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Assuming each layer represent a link between particules, we begin with 4 layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dropout() got an unexpected keyword argument 'activation'"
     ]
    }
   ],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Assuming each layer represent a link between particules, we begin with 4 layers\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train the model on our data\n",
    "# Number of epochs the network should run through\n",
    "EPOCHS = 100\n",
    "# Size of the batch for optimization\n",
    "BATCH_SIZE = 32\n",
    "# Set up validation split\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "# This will avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature selection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 3004)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized_red.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")\n",
    "X_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(X_red) * TRAIN_SET_PERC)\n",
    "X_train_red = X_red[: train_set_size]\n",
    "X_test_red = X_red[train_set_size:]\n",
    "y_train = y[: train_set_size]\n",
    "y_test = y[train_set_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_red: (30049, 3004)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_red: \" + str(X_red.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Number of layers and neurons doesn't really matter, we need as much as possible.\n",
    "    # We well take care of overfitting with regularizers.\n",
    "    # We chose relu activation (relative usual choice when working on regression)\n",
    "    # We add L2 regularizers on hidden layers to avoid overfitting the data. Threshold should be tuned.\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24339/24339 [==============================] - 21s 882us/step - loss: 16.2423 - mean_absolute_error: 2.7712 - val_loss: 11.7952 - val_mean_absolute_error: 2.7973\n",
      "Epoch 2/200\n",
      "24339/24339 [==============================] - 20s 823us/step - loss: 2.7857 - mean_absolute_error: 1.0994 - val_loss: 2.2373 - val_mean_absolute_error: 0.9991\n",
      "Epoch 3/200\n",
      "24339/24339 [==============================] - 20s 836us/step - loss: 0.8024 - mean_absolute_error: 0.4852 - val_loss: 1.8001 - val_mean_absolute_error: 0.8622\n",
      "Epoch 4/200\n",
      "24339/24339 [==============================] - 21s 855us/step - loss: 0.6898 - mean_absolute_error: 0.4331 - val_loss: 1.5499 - val_mean_absolute_error: 0.7983\n",
      "Epoch 5/200\n",
      "24339/24339 [==============================] - 20s 808us/step - loss: 0.7234 - mean_absolute_error: 0.4703 - val_loss: 1.5848 - val_mean_absolute_error: 0.8310\n",
      "Epoch 6/200\n",
      "24339/24339 [==============================] - 19s 799us/step - loss: 0.7371 - mean_absolute_error: 0.4794 - val_loss: 1.2641 - val_mean_absolute_error: 0.7065\n",
      "Epoch 7/200\n",
      "24339/24339 [==============================] - 19s 790us/step - loss: 0.6793 - mean_absolute_error: 0.4450 - val_loss: 1.2880 - val_mean_absolute_error: 0.7394\n",
      "Epoch 8/200\n",
      "24339/24339 [==============================] - 20s 823us/step - loss: 0.7408 - mean_absolute_error: 0.4802 - val_loss: 1.2129 - val_mean_absolute_error: 0.7189\n",
      "Epoch 9/200\n",
      "24339/24339 [==============================] - 20s 840us/step - loss: 0.7020 - mean_absolute_error: 0.4618 - val_loss: 1.1131 - val_mean_absolute_error: 0.6642\n",
      "Epoch 10/200\n",
      "24339/24339 [==============================] - 19s 799us/step - loss: 0.6423 - mean_absolute_error: 0.4366 - val_loss: 1.0270 - val_mean_absolute_error: 0.6376\n",
      "Epoch 11/200\n",
      "24339/24339 [==============================] - 20s 823us/step - loss: 0.5638 - mean_absolute_error: 0.3984 - val_loss: 1.0245 - val_mean_absolute_error: 0.6241\n",
      "Epoch 12/200\n",
      "24339/24339 [==============================] - 20s 811us/step - loss: 0.5283 - mean_absolute_error: 0.4005 - val_loss: 0.9990 - val_mean_absolute_error: 0.6395\n",
      "Epoch 13/200\n",
      "24339/24339 [==============================] - 19s 773us/step - loss: 0.4806 - mean_absolute_error: 0.3786 - val_loss: 0.8085 - val_mean_absolute_error: 0.5569\n",
      "Epoch 14/200\n",
      "24339/24339 [==============================] - 19s 799us/step - loss: 0.4715 - mean_absolute_error: 0.3770 - val_loss: 0.8427 - val_mean_absolute_error: 0.5616\n",
      "Epoch 15/200\n",
      "24339/24339 [==============================] - 19s 797us/step - loss: 0.4305 - mean_absolute_error: 0.3601 - val_loss: 0.8673 - val_mean_absolute_error: 0.6014\n",
      "Epoch 16/200\n",
      "24339/24339 [==============================] - 20s 802us/step - loss: 0.4215 - mean_absolute_error: 0.3613 - val_loss: 0.7645 - val_mean_absolute_error: 0.5379\n",
      "Epoch 17/200\n",
      "24339/24339 [==============================] - 19s 777us/step - loss: 0.4063 - mean_absolute_error: 0.3540 - val_loss: 1.4885 - val_mean_absolute_error: 0.9263\n",
      "Epoch 18/200\n",
      "24339/24339 [==============================] - 23s 931us/step - loss: 0.4090 - mean_absolute_error: 0.3639 - val_loss: 0.7458 - val_mean_absolute_error: 0.5332\n",
      "Epoch 19/200\n",
      "24339/24339 [==============================] - 23s 953us/step - loss: 0.3557 - mean_absolute_error: 0.3266 - val_loss: 0.8022 - val_mean_absolute_error: 0.5676\n",
      "Epoch 20/200\n",
      "24339/24339 [==============================] - 20s 840us/step - loss: 0.3305 - mean_absolute_error: 0.3058 - val_loss: 0.8590 - val_mean_absolute_error: 0.6080\n",
      "Epoch 21/200\n",
      "24339/24339 [==============================] - 20s 812us/step - loss: 0.3199 - mean_absolute_error: 0.3069 - val_loss: 0.7241 - val_mean_absolute_error: 0.5287\n",
      "Epoch 22/200\n",
      "24339/24339 [==============================] - 23s 937us/step - loss: 0.3112 - mean_absolute_error: 0.3044 - val_loss: 0.7433 - val_mean_absolute_error: 0.5512\n",
      "Epoch 23/200\n",
      "24339/24339 [==============================] - 23s 933us/step - loss: 0.2952 - mean_absolute_error: 0.2894 - val_loss: 0.6752 - val_mean_absolute_error: 0.5300\n",
      "Epoch 24/200\n",
      "24339/24339 [==============================] - 23s 928us/step - loss: 0.2855 - mean_absolute_error: 0.2936 - val_loss: 0.6530 - val_mean_absolute_error: 0.5126\n",
      "Epoch 25/200\n",
      "24339/24339 [==============================] - 23s 941us/step - loss: 0.2668 - mean_absolute_error: 0.2820 - val_loss: 0.6783 - val_mean_absolute_error: 0.5221\n",
      "Epoch 26/200\n",
      "24339/24339 [==============================] - 20s 825us/step - loss: 0.2892 - mean_absolute_error: 0.2930 - val_loss: 0.7017 - val_mean_absolute_error: 0.5235\n",
      "Epoch 27/200\n",
      "24339/24339 [==============================] - 20s 841us/step - loss: 0.2647 - mean_absolute_error: 0.2690 - val_loss: 0.7243 - val_mean_absolute_error: 0.5336\n",
      "Epoch 28/200\n",
      "24339/24339 [==============================] - 20s 841us/step - loss: 0.2390 - mean_absolute_error: 0.2575 - val_loss: 0.6537 - val_mean_absolute_error: 0.5297\n",
      "Epoch 29/200\n",
      "24339/24339 [==============================] - 19s 789us/step - loss: 0.2182 - mean_absolute_error: 0.2490 - val_loss: 0.6120 - val_mean_absolute_error: 0.4993\n",
      "Epoch 30/200\n",
      "24339/24339 [==============================] - 20s 826us/step - loss: 0.2359 - mean_absolute_error: 0.2596 - val_loss: 0.6368 - val_mean_absolute_error: 0.5054\n",
      "Epoch 31/200\n",
      "24339/24339 [==============================] - 19s 785us/step - loss: 0.2197 - mean_absolute_error: 0.2545 - val_loss: 0.6418 - val_mean_absolute_error: 0.5116\n",
      "Epoch 32/200\n",
      "24339/24339 [==============================] - 20s 810us/step - loss: 0.2394 - mean_absolute_error: 0.2635 - val_loss: 0.6511 - val_mean_absolute_error: 0.5039\n",
      "Epoch 33/200\n",
      "24339/24339 [==============================] - 22s 916us/step - loss: 0.2427 - mean_absolute_error: 0.2601 - val_loss: 0.7265 - val_mean_absolute_error: 0.5330\n",
      "Epoch 34/200\n",
      "24339/24339 [==============================] - 22s 911us/step - loss: 0.2086 - mean_absolute_error: 0.2293 - val_loss: 0.6749 - val_mean_absolute_error: 0.5096\n",
      "Epoch 35/200\n",
      "24339/24339 [==============================] - 23s 944us/step - loss: 0.2037 - mean_absolute_error: 0.2382 - val_loss: 0.6290 - val_mean_absolute_error: 0.5074\n",
      "Epoch 36/200\n",
      "24339/24339 [==============================] - 23s 954us/step - loss: 0.1883 - mean_absolute_error: 0.2320 - val_loss: 0.7271 - val_mean_absolute_error: 0.5856\n",
      "Epoch 37/200\n",
      "24339/24339 [==============================] - 23s 929us/step - loss: 0.1802 - mean_absolute_error: 0.2271 - val_loss: 0.6096 - val_mean_absolute_error: 0.5055\n",
      "Epoch 38/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.2456 - mean_absolute_error: 0.2600 - val_loss: 0.6939 - val_mean_absolute_error: 0.5281\n",
      "Epoch 39/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.2102 - mean_absolute_error: 0.2284 - val_loss: 0.6167 - val_mean_absolute_error: 0.5061\n",
      "Epoch 40/200\n",
      "24339/24339 [==============================] - 23s 933us/step - loss: 0.1808 - mean_absolute_error: 0.2239 - val_loss: 0.6464 - val_mean_absolute_error: 0.5053\n",
      "Epoch 41/200\n",
      "24339/24339 [==============================] - 23s 937us/step - loss: 0.1664 - mean_absolute_error: 0.2146 - val_loss: 0.6742 - val_mean_absolute_error: 0.5446\n",
      "Epoch 42/200\n",
      "24339/24339 [==============================] - 24s 973us/step - loss: 0.1646 - mean_absolute_error: 0.2185 - val_loss: 0.6145 - val_mean_absolute_error: 0.5169\n",
      "Epoch 43/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1732 - mean_absolute_error: 0.2273 - val_loss: 0.6063 - val_mean_absolute_error: 0.4985\n",
      "Epoch 44/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1905 - mean_absolute_error: 0.2318 - val_loss: 0.6006 - val_mean_absolute_error: 0.4967\n",
      "Epoch 45/200\n",
      "24339/24339 [==============================] - 23s 929us/step - loss: 0.1677 - mean_absolute_error: 0.2173 - val_loss: 0.6333 - val_mean_absolute_error: 0.5065\n",
      "Epoch 46/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1485 - mean_absolute_error: 0.2049 - val_loss: 0.6053 - val_mean_absolute_error: 0.5040\n",
      "Epoch 47/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1506 - mean_absolute_error: 0.2077 - val_loss: 0.6334 - val_mean_absolute_error: 0.5152\n",
      "Epoch 48/200\n",
      "24339/24339 [==============================] - 21s 849us/step - loss: 0.1800 - mean_absolute_error: 0.2255 - val_loss: 0.7606 - val_mean_absolute_error: 0.5862\n",
      "Epoch 49/200\n",
      "24339/24339 [==============================] - 20s 839us/step - loss: 0.1715 - mean_absolute_error: 0.2152 - val_loss: 0.6018 - val_mean_absolute_error: 0.4932\n",
      "Epoch 50/200\n",
      "24339/24339 [==============================] - 21s 847us/step - loss: 0.1471 - mean_absolute_error: 0.1995 - val_loss: 0.6093 - val_mean_absolute_error: 0.5032\n",
      "Epoch 51/200\n",
      "24339/24339 [==============================] - 21s 853us/step - loss: 0.1470 - mean_absolute_error: 0.2052 - val_loss: 0.7892 - val_mean_absolute_error: 0.6186\n",
      "Epoch 52/200\n",
      "24339/24339 [==============================] - 21s 848us/step - loss: 0.1377 - mean_absolute_error: 0.1978 - val_loss: 0.6148 - val_mean_absolute_error: 0.5033\n",
      "Epoch 53/200\n",
      "24339/24339 [==============================] - 21s 850us/step - loss: 0.1454 - mean_absolute_error: 0.2076 - val_loss: 0.6417 - val_mean_absolute_error: 0.5099\n",
      "Epoch 54/200\n",
      "24339/24339 [==============================] - 21s 846us/step - loss: 0.1496 - mean_absolute_error: 0.2062 - val_loss: 0.6763 - val_mean_absolute_error: 0.5237\n",
      "Epoch 55/200\n",
      "24339/24339 [==============================] - 21s 851us/step - loss: 0.1593 - mean_absolute_error: 0.2119 - val_loss: 0.6438 - val_mean_absolute_error: 0.5134\n",
      "Epoch 56/200\n",
      "24339/24339 [==============================] - 21s 855us/step - loss: 0.1354 - mean_absolute_error: 0.1942 - val_loss: 0.6616 - val_mean_absolute_error: 0.5347\n",
      "Epoch 57/200\n",
      "24339/24339 [==============================] - 21s 850us/step - loss: 0.1306 - mean_absolute_error: 0.1938 - val_loss: 0.6340 - val_mean_absolute_error: 0.5216\n",
      "Epoch 58/200\n",
      "24339/24339 [==============================] - 22s 896us/step - loss: 0.1341 - mean_absolute_error: 0.2000 - val_loss: 0.6204 - val_mean_absolute_error: 0.5107\n",
      "Epoch 59/200\n",
      "24339/24339 [==============================] - 22s 901us/step - loss: 0.1411 - mean_absolute_error: 0.2084 - val_loss: 0.6909 - val_mean_absolute_error: 0.5418\n",
      "Epoch 60/200\n",
      "24339/24339 [==============================] - 22s 897us/step - loss: 0.1452 - mean_absolute_error: 0.2076 - val_loss: 0.6232 - val_mean_absolute_error: 0.5106\n",
      "Epoch 61/200\n",
      "24339/24339 [==============================] - 22s 899us/step - loss: 0.1310 - mean_absolute_error: 0.1935 - val_loss: 0.5990 - val_mean_absolute_error: 0.5041\n",
      "Epoch 62/200\n",
      "24339/24339 [==============================] - 22s 901us/step - loss: 0.1302 - mean_absolute_error: 0.1952 - val_loss: 0.6449 - val_mean_absolute_error: 0.5356\n",
      "Epoch 63/200\n",
      "24339/24339 [==============================] - 22s 907us/step - loss: 0.1372 - mean_absolute_error: 0.2017 - val_loss: 0.6185 - val_mean_absolute_error: 0.5046\n",
      "Epoch 64/200\n",
      "24339/24339 [==============================] - 22s 907us/step - loss: 0.1312 - mean_absolute_error: 0.1951 - val_loss: 0.6098 - val_mean_absolute_error: 0.5072\n",
      "Epoch 65/200\n",
      "24339/24339 [==============================] - 22s 898us/step - loss: 0.1250 - mean_absolute_error: 0.1919 - val_loss: 0.5898 - val_mean_absolute_error: 0.5003\n",
      "Epoch 66/200\n",
      "24339/24339 [==============================] - 22s 907us/step - loss: 0.1355 - mean_absolute_error: 0.2012 - val_loss: 0.6412 - val_mean_absolute_error: 0.5416\n",
      "Epoch 67/200\n",
      "24339/24339 [==============================] - 22s 909us/step - loss: 0.1308 - mean_absolute_error: 0.1983 - val_loss: 0.6126 - val_mean_absolute_error: 0.5030\n",
      "Epoch 68/200\n",
      "24339/24339 [==============================] - 23s 961us/step - loss: 0.1226 - mean_absolute_error: 0.1887 - val_loss: 0.5786 - val_mean_absolute_error: 0.4958\n",
      "Epoch 69/200\n",
      "24339/24339 [==============================] - 22s 913us/step - loss: 0.1266 - mean_absolute_error: 0.1952 - val_loss: 0.5816 - val_mean_absolute_error: 0.4979\n",
      "Epoch 70/200\n",
      "24339/24339 [==============================] - 23s 925us/step - loss: 0.1257 - mean_absolute_error: 0.1919 - val_loss: 0.6068 - val_mean_absolute_error: 0.5106\n",
      "Epoch 71/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1278 - mean_absolute_error: 0.1955 - val_loss: 0.6461 - val_mean_absolute_error: 0.5298\n",
      "Epoch 72/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1219 - mean_absolute_error: 0.1923 - val_loss: 0.6258 - val_mean_absolute_error: 0.5110\n",
      "Epoch 73/200\n",
      "24339/24339 [==============================] - 23s 925us/step - loss: 0.1284 - mean_absolute_error: 0.2005 - val_loss: 0.6229 - val_mean_absolute_error: 0.5189\n",
      "Epoch 74/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1216 - mean_absolute_error: 0.1907 - val_loss: 0.6717 - val_mean_absolute_error: 0.5375\n",
      "Epoch 75/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1152 - mean_absolute_error: 0.1857 - val_loss: 0.6278 - val_mean_absolute_error: 0.5089\n",
      "Epoch 76/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1181 - mean_absolute_error: 0.1922 - val_loss: 0.6200 - val_mean_absolute_error: 0.5128\n",
      "Epoch 77/200\n",
      "24339/24339 [==============================] - 22s 924us/step - loss: 0.1290 - mean_absolute_error: 0.2062 - val_loss: 0.6251 - val_mean_absolute_error: 0.5172\n",
      "Epoch 78/200\n",
      "24339/24339 [==============================] - 22s 918us/step - loss: 0.1158 - mean_absolute_error: 0.1838 - val_loss: 0.6042 - val_mean_absolute_error: 0.5040\n",
      "Epoch 79/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1142 - mean_absolute_error: 0.1850 - val_loss: 0.5741 - val_mean_absolute_error: 0.4919\n",
      "Epoch 80/200\n",
      "24339/24339 [==============================] - 22s 918us/step - loss: 0.1277 - mean_absolute_error: 0.1991 - val_loss: 0.6381 - val_mean_absolute_error: 0.5103\n",
      "Epoch 81/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1309 - mean_absolute_error: 0.1953 - val_loss: 0.6366 - val_mean_absolute_error: 0.5025\n",
      "Epoch 82/200\n",
      "24339/24339 [==============================] - 22s 915us/step - loss: 0.1137 - mean_absolute_error: 0.1777 - val_loss: 0.6158 - val_mean_absolute_error: 0.5008\n",
      "Epoch 83/200\n",
      "24339/24339 [==============================] - 23s 926us/step - loss: 0.1119 - mean_absolute_error: 0.1805 - val_loss: 0.5786 - val_mean_absolute_error: 0.4972\n",
      "Epoch 84/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1180 - mean_absolute_error: 0.1902 - val_loss: 0.6017 - val_mean_absolute_error: 0.4994\n",
      "Epoch 85/200\n",
      "24339/24339 [==============================] - 22s 917us/step - loss: 0.1243 - mean_absolute_error: 0.1952 - val_loss: 0.6333 - val_mean_absolute_error: 0.5171\n",
      "Epoch 86/200\n",
      "24339/24339 [==============================] - 22s 924us/step - loss: 0.1151 - mean_absolute_error: 0.1823 - val_loss: 0.6074 - val_mean_absolute_error: 0.5019\n",
      "Epoch 87/200\n",
      "24339/24339 [==============================] - 23s 928us/step - loss: 0.1120 - mean_absolute_error: 0.1824 - val_loss: 0.6273 - val_mean_absolute_error: 0.5156\n",
      "Epoch 88/200\n",
      "24339/24339 [==============================] - 22s 916us/step - loss: 0.1131 - mean_absolute_error: 0.1853 - val_loss: 0.6407 - val_mean_absolute_error: 0.5204\n",
      "Epoch 89/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1284 - mean_absolute_error: 0.1996 - val_loss: 0.5835 - val_mean_absolute_error: 0.5040\n",
      "Epoch 90/200\n",
      "24339/24339 [==============================] - 23s 935us/step - loss: 0.1199 - mean_absolute_error: 0.1893 - val_loss: 0.6028 - val_mean_absolute_error: 0.4999\n",
      "Epoch 91/200\n",
      "24339/24339 [==============================] - 23s 928us/step - loss: 0.1162 - mean_absolute_error: 0.1815 - val_loss: 0.6563 - val_mean_absolute_error: 0.5336\n",
      "Epoch 92/200\n",
      "24339/24339 [==============================] - 23s 937us/step - loss: 0.1119 - mean_absolute_error: 0.1781 - val_loss: 0.6062 - val_mean_absolute_error: 0.5050\n",
      "Epoch 93/200\n",
      "24339/24339 [==============================] - 23s 940us/step - loss: 0.1161 - mean_absolute_error: 0.1871 - val_loss: 0.6555 - val_mean_absolute_error: 0.5338\n",
      "Epoch 94/200\n",
      "24339/24339 [==============================] - 23s 938us/step - loss: 0.1189 - mean_absolute_error: 0.1909 - val_loss: 0.5772 - val_mean_absolute_error: 0.4925\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24339/24339 [==============================] - 21s 851us/step - loss: 0.1102 - mean_absolute_error: 0.1804 - val_loss: 0.6129 - val_mean_absolute_error: 0.5024\n",
      "Epoch 96/200\n",
      "24339/24339 [==============================] - 20s 839us/step - loss: 0.1113 - mean_absolute_error: 0.1835 - val_loss: 0.6052 - val_mean_absolute_error: 0.4992\n",
      "Epoch 97/200\n",
      "24339/24339 [==============================] - 21s 848us/step - loss: 0.1150 - mean_absolute_error: 0.1902 - val_loss: 0.6312 - val_mean_absolute_error: 0.5190\n",
      "Epoch 98/200\n",
      "24339/24339 [==============================] - 21s 849us/step - loss: 0.1101 - mean_absolute_error: 0.1823 - val_loss: 0.6291 - val_mean_absolute_error: 0.5101\n",
      "Epoch 99/200\n",
      "24339/24339 [==============================] - 21s 849us/step - loss: 0.1202 - mean_absolute_error: 0.1958 - val_loss: 0.6232 - val_mean_absolute_error: 0.5087\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  1538560   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  513       \n",
      "=================================================================\n",
      "Total params: 3,377,665\n",
      "Trainable params: 3,377,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.1\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(X_train_red, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6834309411311952"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_test_red, batch_size=32)\n",
    "rmse(result, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of feature selection matrix - polynomial expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized_red.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 3004)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = build_poly(X_red, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 6008)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(X_red) * TRAIN_SET_PERC)\n",
    "X_poly_train_red = X_poly[: train_set_size]\n",
    "X_poly_test_red = X_poly[train_set_size:]\n",
    "y_train = y[: train_set_size]\n",
    "y_test = y[train_set_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_poly_red: (30049, 6008)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_poly_red: \" + str(X_poly.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Number of layers and neurons doesn't really matter, we need as much as possible.\n",
    "    # We well take care of overfitting with regularizers.\n",
    "    # We chose relu activation (relative usual choice when working on regression)\n",
    "    # We add L2 regularizers on hidden layers to avoid overfitting the data. Threshold should be tuned.\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24339/24339 [==============================] - 15s 609us/step - loss: 68.8399 - mean_absolute_error: 5.7557 - val_loss: 27.8898 - val_mean_absolute_error: 3.7220\n",
      "Epoch 2/200\n",
      "24339/24339 [==============================] - 12s 498us/step - loss: 6.5372 - mean_absolute_error: 1.8642 - val_loss: 18.6232 - val_mean_absolute_error: 2.6665\n",
      "Epoch 3/200\n",
      "24339/24339 [==============================] - 12s 502us/step - loss: 2.9390 - mean_absolute_error: 1.2613 - val_loss: 13.8524 - val_mean_absolute_error: 2.5427\n",
      "Epoch 4/200\n",
      "24339/24339 [==============================] - 12s 504us/step - loss: 2.3184 - mean_absolute_error: 1.1061 - val_loss: 16.8185 - val_mean_absolute_error: 2.3774\n",
      "Epoch 5/200\n",
      "24339/24339 [==============================] - 12s 508us/step - loss: 2.9168 - mean_absolute_error: 1.1900 - val_loss: 16.8111 - val_mean_absolute_error: 3.0914\n",
      "Epoch 6/200\n",
      "24339/24339 [==============================] - 12s 512us/step - loss: 4.4732 - mean_absolute_error: 1.3325 - val_loss: 9.7703 - val_mean_absolute_error: 1.8556\n",
      "Epoch 7/200\n",
      "24339/24339 [==============================] - 13s 516us/step - loss: 1.1854 - mean_absolute_error: 0.8141 - val_loss: 7.0981 - val_mean_absolute_error: 1.6146\n",
      "Epoch 8/200\n",
      "24339/24339 [==============================] - 12s 512us/step - loss: 0.8139 - mean_absolute_error: 0.6580 - val_loss: 6.5084 - val_mean_absolute_error: 1.5337\n",
      "Epoch 9/200\n",
      "24339/24339 [==============================] - 13s 521us/step - loss: 0.7479 - mean_absolute_error: 0.6342 - val_loss: 5.2058 - val_mean_absolute_error: 1.5439\n",
      "Epoch 10/200\n",
      "24339/24339 [==============================] - 13s 516us/step - loss: 0.7438 - mean_absolute_error: 0.6332 - val_loss: 3.6742 - val_mean_absolute_error: 1.1958\n",
      "Epoch 11/200\n",
      "24339/24339 [==============================] - 13s 522us/step - loss: 0.5379 - mean_absolute_error: 0.5337 - val_loss: 2.9012 - val_mean_absolute_error: 1.1089\n",
      "Epoch 12/200\n",
      "24339/24339 [==============================] - 13s 527us/step - loss: 0.5180 - mean_absolute_error: 0.5134 - val_loss: 3.3346 - val_mean_absolute_error: 1.1598\n",
      "Epoch 13/200\n",
      "24339/24339 [==============================] - 13s 528us/step - loss: 0.6059 - mean_absolute_error: 0.5599 - val_loss: 2.2220 - val_mean_absolute_error: 0.9951\n",
      "Epoch 14/200\n",
      "24339/24339 [==============================] - 13s 532us/step - loss: 0.5314 - mean_absolute_error: 0.5017 - val_loss: 2.0240 - val_mean_absolute_error: 0.9474\n",
      "Epoch 15/200\n",
      "24339/24339 [==============================] - 13s 531us/step - loss: 2.2644 - mean_absolute_error: 0.7110 - val_loss: 2.7938 - val_mean_absolute_error: 1.1779\n",
      "Epoch 16/200\n",
      "24339/24339 [==============================] - 13s 533us/step - loss: 0.8219 - mean_absolute_error: 0.5439 - val_loss: 1.8506 - val_mean_absolute_error: 0.8835\n",
      "Epoch 17/200\n",
      "24339/24339 [==============================] - 13s 526us/step - loss: 0.3273 - mean_absolute_error: 0.3787 - val_loss: 1.6629 - val_mean_absolute_error: 0.8276\n",
      "Epoch 18/200\n",
      "24339/24339 [==============================] - 12s 502us/step - loss: 0.2710 - mean_absolute_error: 0.3419 - val_loss: 1.7931 - val_mean_absolute_error: 0.8653\n",
      "Epoch 19/200\n",
      "24339/24339 [==============================] - 12s 492us/step - loss: 0.2916 - mean_absolute_error: 0.3579 - val_loss: 1.5916 - val_mean_absolute_error: 0.8690\n",
      "Epoch 20/200\n",
      "24339/24339 [==============================] - 16s 667us/step - loss: 0.2920 - mean_absolute_error: 0.3528 - val_loss: 1.6668 - val_mean_absolute_error: 0.8014\n",
      "Epoch 21/200\n",
      "24339/24339 [==============================] - 12s 474us/step - loss: 0.4287 - mean_absolute_error: 0.4046 - val_loss: 1.8885 - val_mean_absolute_error: 1.0049\n",
      "Epoch 22/200\n",
      "24339/24339 [==============================] - 12s 486us/step - loss: 0.3567 - mean_absolute_error: 0.3822 - val_loss: 1.4134 - val_mean_absolute_error: 0.7727\n",
      "Epoch 23/200\n",
      "24339/24339 [==============================] - 12s 473us/step - loss: 0.2337 - mean_absolute_error: 0.3088 - val_loss: 1.3867 - val_mean_absolute_error: 0.7517\n",
      "Epoch 24/200\n",
      "24339/24339 [==============================] - 11s 472us/step - loss: 0.2565 - mean_absolute_error: 0.3309 - val_loss: 1.3309 - val_mean_absolute_error: 0.7459\n",
      "Epoch 25/200\n",
      "24339/24339 [==============================] - 12s 474us/step - loss: 0.2705 - mean_absolute_error: 0.3324 - val_loss: 1.3334 - val_mean_absolute_error: 0.7598\n",
      "Epoch 26/200\n",
      "24339/24339 [==============================] - 12s 473us/step - loss: 0.3887 - mean_absolute_error: 0.3723 - val_loss: 1.4272 - val_mean_absolute_error: 0.7705\n",
      "Epoch 27/200\n",
      "24339/24339 [==============================] - 13s 517us/step - loss: 0.2545 - mean_absolute_error: 0.3153 - val_loss: 1.3307 - val_mean_absolute_error: 0.7335\n",
      "Epoch 28/200\n",
      "24339/24339 [==============================] - 12s 496us/step - loss: 0.6821 - mean_absolute_error: 0.4172 - val_loss: 1.3574 - val_mean_absolute_error: 0.7251\n",
      "Epoch 29/200\n",
      "24339/24339 [==============================] - 12s 480us/step - loss: 0.3379 - mean_absolute_error: 0.3088 - val_loss: 1.3126 - val_mean_absolute_error: 0.7270\n",
      "Epoch 30/200\n",
      "24339/24339 [==============================] - 13s 521us/step - loss: 0.4225 - mean_absolute_error: 0.3220 - val_loss: 1.3091 - val_mean_absolute_error: 0.7328\n",
      "Epoch 31/200\n",
      "24339/24339 [==============================] - 13s 519us/step - loss: 0.2132 - mean_absolute_error: 0.2818 - val_loss: 1.3056 - val_mean_absolute_error: 0.7237\n",
      "Epoch 32/200\n",
      "24339/24339 [==============================] - 13s 548us/step - loss: 0.1777 - mean_absolute_error: 0.2564 - val_loss: 1.2970 - val_mean_absolute_error: 0.7180\n",
      "Epoch 33/200\n",
      "24339/24339 [==============================] - 14s 555us/step - loss: 0.2007 - mean_absolute_error: 0.2740 - val_loss: 1.2958 - val_mean_absolute_error: 0.7564\n",
      "Epoch 34/200\n",
      "24339/24339 [==============================] - 13s 552us/step - loss: 0.2050 - mean_absolute_error: 0.2827 - val_loss: 1.2785 - val_mean_absolute_error: 0.7185\n",
      "Epoch 35/200\n",
      "24339/24339 [==============================] - 13s 554us/step - loss: 0.1758 - mean_absolute_error: 0.2545 - val_loss: 1.2339 - val_mean_absolute_error: 0.7032\n",
      "Epoch 36/200\n",
      "24339/24339 [==============================] - 13s 528us/step - loss: 0.1981 - mean_absolute_error: 0.2731 - val_loss: 1.3682 - val_mean_absolute_error: 0.7372\n",
      "Epoch 37/200\n",
      "24339/24339 [==============================] - 13s 527us/step - loss: 0.2034 - mean_absolute_error: 0.2777 - val_loss: 1.3166 - val_mean_absolute_error: 0.7328\n",
      "Epoch 38/200\n",
      "24339/24339 [==============================] - 13s 529us/step - loss: 0.1709 - mean_absolute_error: 0.2543 - val_loss: 1.3938 - val_mean_absolute_error: 0.8046\n",
      "Epoch 39/200\n",
      "24339/24339 [==============================] - 13s 525us/step - loss: 0.1632 - mean_absolute_error: 0.2478 - val_loss: 1.4540 - val_mean_absolute_error: 0.7540\n",
      "Epoch 40/200\n",
      "24339/24339 [==============================] - 13s 524us/step - loss: 0.1881 - mean_absolute_error: 0.2718 - val_loss: 1.3903 - val_mean_absolute_error: 0.7322\n",
      "Epoch 41/200\n",
      "24339/24339 [==============================] - 13s 526us/step - loss: 0.1699 - mean_absolute_error: 0.2463 - val_loss: 1.3020 - val_mean_absolute_error: 0.7335\n",
      "Epoch 42/200\n",
      "24339/24339 [==============================] - 13s 522us/step - loss: 0.2055 - mean_absolute_error: 0.2639 - val_loss: 1.4099 - val_mean_absolute_error: 0.7578\n",
      "Epoch 43/200\n",
      "24339/24339 [==============================] - 13s 529us/step - loss: 0.1512 - mean_absolute_error: 0.2337 - val_loss: 1.3557 - val_mean_absolute_error: 0.7119\n",
      "Epoch 44/200\n",
      "24339/24339 [==============================] - 13s 530us/step - loss: 0.1430 - mean_absolute_error: 0.2267 - val_loss: 1.3583 - val_mean_absolute_error: 0.7134\n",
      "Epoch 45/200\n",
      "24339/24339 [==============================] - 13s 530us/step - loss: 0.1501 - mean_absolute_error: 0.2354 - val_loss: 1.4310 - val_mean_absolute_error: 0.7364\n",
      "Epoch 46/200\n",
      "24339/24339 [==============================] - 13s 530us/step - loss: 0.1623 - mean_absolute_error: 0.2478 - val_loss: 1.3734 - val_mean_absolute_error: 0.7279\n",
      "Epoch 47/200\n",
      "24339/24339 [==============================] - 13s 536us/step - loss: 0.1393 - mean_absolute_error: 0.2235 - val_loss: 1.2579 - val_mean_absolute_error: 0.6938\n",
      "Epoch 48/200\n",
      "24339/24339 [==============================] - 12s 502us/step - loss: 0.1374 - mean_absolute_error: 0.2193 - val_loss: 1.3505 - val_mean_absolute_error: 0.7038\n",
      "Epoch 49/200\n",
      "24339/24339 [==============================] - 12s 504us/step - loss: 0.1371 - mean_absolute_error: 0.2251 - val_loss: 1.3210 - val_mean_absolute_error: 0.7144\n",
      "Epoch 50/200\n",
      "24339/24339 [==============================] - 12s 511us/step - loss: 0.8432 - mean_absolute_error: 0.2880 - val_loss: 1.5669 - val_mean_absolute_error: 0.7369\n",
      "Epoch 51/200\n",
      "24339/24339 [==============================] - 12s 508us/step - loss: 0.1758 - mean_absolute_error: 0.2401 - val_loss: 1.3623 - val_mean_absolute_error: 0.7159\n",
      "Epoch 52/200\n",
      "24339/24339 [==============================] - 12s 508us/step - loss: 0.1293 - mean_absolute_error: 0.1938 - val_loss: 1.3155 - val_mean_absolute_error: 0.7173\n",
      "Epoch 53/200\n",
      "24339/24339 [==============================] - 12s 505us/step - loss: 0.1244 - mean_absolute_error: 0.1959 - val_loss: 1.5086 - val_mean_absolute_error: 0.7373\n",
      "Epoch 54/200\n",
      "24339/24339 [==============================] - 12s 499us/step - loss: 0.1338 - mean_absolute_error: 0.2142 - val_loss: 1.4460 - val_mean_absolute_error: 0.7117\n",
      "Epoch 55/200\n",
      "24339/24339 [==============================] - 12s 492us/step - loss: 0.1461 - mean_absolute_error: 0.2244 - val_loss: 1.4769 - val_mean_absolute_error: 0.7251\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              multiple                  1538304   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  257       \n",
      "=================================================================\n",
      "Total params: 1,999,105\n",
      "Trainable params: 1,999,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.1\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(X_poly_train_red, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0123385147545783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_poly_test_red, batch_size=32)\n",
    "rmse(result, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
