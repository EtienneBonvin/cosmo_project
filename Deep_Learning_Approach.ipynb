{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating data using deep learning\n",
    "\n",
    "Note that for this approach we based ourselves on the Standford lecture notes on convolutional neural networks for visual recognition.\n",
    "\n",
    "This lecture is open source and can be found on http://cs231n.github.io/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Clean up the memory\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "\n",
    "import crowd\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "SESSION_FOLDER = \"session/\"\n",
    "\n",
    "TRAIN_SET_PERC = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, real, loop = True):\n",
    "    '''\n",
    "    Computes RMSE between predictions and real values\n",
    "    :param : float[]\n",
    "    :param : float[]\n",
    "    :return : float\n",
    "    '''\n",
    "    if len(pred) != len(real):\n",
    "        print(\"RMSE Error : Predictions and real values arrays do not have the same length, aborting.\")\n",
    "        return None\n",
    "    \n",
    "    if loop:\n",
    "        mse = 0\n",
    "        for i in range(len(pred)):\n",
    "            mse += (pred[i] - real[i])**2\n",
    "        return math.sqrt(mse/len(pred))\n",
    "    else:\n",
    "        # The creation of the array may produce memory error\n",
    "        err = pred - real\n",
    "        mse = err.T @ err\n",
    "        return math.sqrt(2 * mse / len(pred))\n",
    "    \n",
    "    \n",
    "def basic_error(pred, real):\n",
    "    '''\n",
    "    Compute basic error. Used to notify bias.\n",
    "    :param : float[]\n",
    "    :param : float[]\n",
    "    :return : float\n",
    "    '''\n",
    "    err = 0\n",
    "    for i in range(len(pred)):\n",
    "        err += (pred[i][0][0] - real[i])\n",
    "    return err\n",
    "    \n",
    "    \n",
    "def build_poly(X, degree):\n",
    "    poly = np.ones((len(X), 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        poly = np.c_[poly, np.power(X, deg)]\n",
    "    return poly[:, 1:]\n",
    "\n",
    "def garbage_collection():\n",
    "    '''\n",
    "    Calls garbage collection to clean unused memory\n",
    "    '''\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    '''\n",
    "    Plots the history of the training error\n",
    "    Usefull \n",
    "    '''\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use non normalized feature matrix\n",
    "# For now best results are given with this one\n",
    "#X = np.load(DATA_FOLDER + \"feature_mat_radial_compression.npy\")\n",
    "\n",
    "# Use normalized feature matrix\n",
    "################################################################################################\n",
    "# Careful                                                                                      #\n",
    "# Normally, normalisation should be done one each train/val/test matrices. It is not done here #\n",
    "################################################################################################\n",
    "X = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test set\n",
    "\n",
    "train_set_size = int(len(X) * TRAIN_SET_PERC)\n",
    "X_train = X[: train_set_size]\n",
    "X_test = X[train_set_size:]\n",
    "y_train = y[: train_set_size]\n",
    "y_test = y[train_set_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (30049, 15961)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \" + str(X.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single neural network model approach\n",
    "\n",
    "First we will do a single model approach, the goal is to see quickly how we can build a model using neural networks and how well it does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Number of layers and neurons doesn't really matter, we need as much as possible.\n",
    "    # We well take care of overfitting with regularizers.\n",
    "    # We chose relu activation (relative usual choice when working on regression)\n",
    "    # We add L2 regularizers on hidden layers to avoid overfitting the data. Threshold should be tuned.\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 16.2263 - mean_absolute_error: 2.3938 - val_loss: 6.2262 - val_mean_absolute_error: 1.8358\n",
      "Epoch 2/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 3.2662 - mean_absolute_error: 1.3039 - val_loss: 4.0006 - val_mean_absolute_error: 1.4015\n",
      "Epoch 3/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 1.8035 - mean_absolute_error: 0.9428 - val_loss: 4.2133 - val_mean_absolute_error: 1.4561\n",
      "Epoch 4/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 1.7472 - mean_absolute_error: 0.9308 - val_loss: 3.5445 - val_mean_absolute_error: 1.3147\n",
      "Epoch 5/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 1.4083 - mean_absolute_error: 0.8200 - val_loss: 3.1718 - val_mean_absolute_error: 1.2550\n",
      "Epoch 6/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.9822 - mean_absolute_error: 0.6464 - val_loss: 2.8547 - val_mean_absolute_error: 1.2234\n",
      "Epoch 7/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.7532 - mean_absolute_error: 0.5284 - val_loss: 1.6163 - val_mean_absolute_error: 0.8387\n",
      "Epoch 8/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.6380 - mean_absolute_error: 0.4690 - val_loss: 1.7268 - val_mean_absolute_error: 0.9506\n",
      "Epoch 9/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.6413 - mean_absolute_error: 0.4633 - val_loss: 1.3230 - val_mean_absolute_error: 0.7415\n",
      "Epoch 10/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 1.0058 - mean_absolute_error: 0.5477 - val_loss: 1.2332 - val_mean_absolute_error: 0.7133\n",
      "Epoch 11/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.5902 - mean_absolute_error: 0.4079 - val_loss: 1.1017 - val_mean_absolute_error: 0.6778\n",
      "Epoch 12/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.6531 - mean_absolute_error: 0.4508 - val_loss: 0.9402 - val_mean_absolute_error: 0.5992\n",
      "Epoch 13/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.5837 - mean_absolute_error: 0.3987 - val_loss: 1.1087 - val_mean_absolute_error: 0.6789\n",
      "Epoch 14/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.6055 - mean_absolute_error: 0.4121 - val_loss: 1.1925 - val_mean_absolute_error: 0.6696\n",
      "Epoch 15/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.6412 - mean_absolute_error: 0.4260 - val_loss: 0.9671 - val_mean_absolute_error: 0.5941\n",
      "Epoch 16/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.5682 - mean_absolute_error: 0.3909 - val_loss: 0.9031 - val_mean_absolute_error: 0.5809\n",
      "Epoch 17/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.5491 - mean_absolute_error: 0.3745 - val_loss: 0.8629 - val_mean_absolute_error: 0.5548\n",
      "Epoch 18/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.6261 - mean_absolute_error: 0.3981 - val_loss: 0.8705 - val_mean_absolute_error: 0.5569\n",
      "Epoch 19/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.5072 - mean_absolute_error: 0.3575 - val_loss: 0.8613 - val_mean_absolute_error: 0.5617\n",
      "Epoch 20/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.5018 - mean_absolute_error: 0.3553 - val_loss: 0.7478 - val_mean_absolute_error: 0.5213\n",
      "Epoch 21/200\n",
      "24339/24339 [==============================] - 38s 2ms/step - loss: 0.4505 - mean_absolute_error: 0.3590 - val_loss: 0.7303 - val_mean_absolute_error: 0.5263\n",
      "Epoch 22/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.4143 - mean_absolute_error: 0.3378 - val_loss: 0.8341 - val_mean_absolute_error: 0.5996\n",
      "Epoch 23/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.3978 - mean_absolute_error: 0.3332 - val_loss: 0.6541 - val_mean_absolute_error: 0.5093\n",
      "Epoch 24/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.3751 - mean_absolute_error: 0.3251 - val_loss: 0.7203 - val_mean_absolute_error: 0.5365\n",
      "Epoch 25/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.4049 - mean_absolute_error: 0.3355 - val_loss: 0.8044 - val_mean_absolute_error: 0.5754\n",
      "Epoch 26/200\n",
      "24339/24339 [==============================] - 37s 2ms/step - loss: 0.3539 - mean_absolute_error: 0.3089 - val_loss: 0.6578 - val_mean_absolute_error: 0.5158\n",
      "Epoch 27/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.3337 - mean_absolute_error: 0.3106 - val_loss: 0.7845 - val_mean_absolute_error: 0.5752\n",
      "Epoch 28/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.3393 - mean_absolute_error: 0.3081 - val_loss: 0.6603 - val_mean_absolute_error: 0.5195\n",
      "Epoch 29/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.3245 - mean_absolute_error: 0.3094 - val_loss: 0.7355 - val_mean_absolute_error: 0.5460\n",
      "Epoch 30/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.3205 - mean_absolute_error: 0.2984 - val_loss: 0.6860 - val_mean_absolute_error: 0.5557\n",
      "Epoch 31/200\n",
      "24339/24339 [==============================] - 40s 2ms/step - loss: 0.3256 - mean_absolute_error: 0.3047 - val_loss: 0.6606 - val_mean_absolute_error: 0.5174\n",
      "Epoch 32/200\n",
      "24339/24339 [==============================] - 37s 2ms/step - loss: 0.2948 - mean_absolute_error: 0.2879 - val_loss: 0.6690 - val_mean_absolute_error: 0.5211\n",
      "Epoch 33/200\n",
      "24339/24339 [==============================] - 39s 2ms/step - loss: 0.2970 - mean_absolute_error: 0.2843 - val_loss: 0.6379 - val_mean_absolute_error: 0.5156\n",
      "Epoch 34/200\n",
      "24339/24339 [==============================] - 40s 2ms/step - loss: 0.2931 - mean_absolute_error: 0.2907 - val_loss: 0.6759 - val_mean_absolute_error: 0.5334\n",
      "Epoch 35/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2864 - mean_absolute_error: 0.2872 - val_loss: 0.8213 - val_mean_absolute_error: 0.5945\n",
      "Epoch 36/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.3080 - mean_absolute_error: 0.2903 - val_loss: 0.6526 - val_mean_absolute_error: 0.5189\n",
      "Epoch 37/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2936 - mean_absolute_error: 0.2863 - val_loss: 0.7532 - val_mean_absolute_error: 0.5499\n",
      "Epoch 38/200\n",
      "24339/24339 [==============================] - 29s 1ms/step - loss: 0.2953 - mean_absolute_error: 0.2876 - val_loss: 0.6534 - val_mean_absolute_error: 0.5130\n",
      "Epoch 39/200\n",
      "24339/24339 [==============================] - 36s 1ms/step - loss: 0.3182 - mean_absolute_error: 0.2898 - val_loss: 0.6356 - val_mean_absolute_error: 0.5121\n",
      "Epoch 40/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2631 - mean_absolute_error: 0.2730 - val_loss: 0.6493 - val_mean_absolute_error: 0.5156\n",
      "Epoch 41/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.3078 - mean_absolute_error: 0.2886 - val_loss: 0.7755 - val_mean_absolute_error: 0.5807\n",
      "Epoch 42/200\n",
      "24339/24339 [==============================] - 37s 2ms/step - loss: 0.2728 - mean_absolute_error: 0.2687 - val_loss: 0.6954 - val_mean_absolute_error: 0.5628\n",
      "Epoch 43/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2728 - mean_absolute_error: 0.2744 - val_loss: 0.6116 - val_mean_absolute_error: 0.5099\n",
      "Epoch 44/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2520 - mean_absolute_error: 0.2633 - val_loss: 0.6216 - val_mean_absolute_error: 0.5055\n",
      "Epoch 45/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2637 - mean_absolute_error: 0.2696 - val_loss: 0.7737 - val_mean_absolute_error: 0.6197\n",
      "Epoch 46/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2471 - mean_absolute_error: 0.2690 - val_loss: 0.6230 - val_mean_absolute_error: 0.5164\n",
      "Epoch 47/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.3048 - mean_absolute_error: 0.2866 - val_loss: 0.6951 - val_mean_absolute_error: 0.5434\n",
      "Epoch 48/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.2303 - mean_absolute_error: 0.2493 - val_loss: 0.6046 - val_mean_absolute_error: 0.5190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2332 - mean_absolute_error: 0.2662 - val_loss: 0.6181 - val_mean_absolute_error: 0.5156\n",
      "Epoch 50/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.2462 - mean_absolute_error: 0.2666 - val_loss: 0.5834 - val_mean_absolute_error: 0.4958\n",
      "Epoch 51/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2626 - mean_absolute_error: 0.2700 - val_loss: 0.6383 - val_mean_absolute_error: 0.5298\n",
      "Epoch 52/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2387 - mean_absolute_error: 0.2609 - val_loss: 0.6260 - val_mean_absolute_error: 0.5193\n",
      "Epoch 53/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2534 - mean_absolute_error: 0.2679 - val_loss: 0.7373 - val_mean_absolute_error: 0.5672\n",
      "Epoch 54/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2392 - mean_absolute_error: 0.2541 - val_loss: 0.6180 - val_mean_absolute_error: 0.5061\n",
      "Epoch 55/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.2167 - mean_absolute_error: 0.2547 - val_loss: 0.6057 - val_mean_absolute_error: 0.5170\n",
      "Epoch 56/200\n",
      "24339/24339 [==============================] - 32s 1ms/step - loss: 0.2207 - mean_absolute_error: 0.2554 - val_loss: 0.6085 - val_mean_absolute_error: 0.5143\n",
      "Epoch 57/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2359 - mean_absolute_error: 0.2661 - val_loss: 0.6436 - val_mean_absolute_error: 0.5293\n",
      "Epoch 58/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2169 - mean_absolute_error: 0.2506 - val_loss: 0.6402 - val_mean_absolute_error: 0.5248\n",
      "Epoch 59/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2213 - mean_absolute_error: 0.2618 - val_loss: 0.5848 - val_mean_absolute_error: 0.5069\n",
      "Epoch 60/200\n",
      "24339/24339 [==============================] - 30s 1ms/step - loss: 0.2135 - mean_absolute_error: 0.2528 - val_loss: 0.6369 - val_mean_absolute_error: 0.5199\n",
      "Epoch 61/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.2195 - mean_absolute_error: 0.2571 - val_loss: 0.6041 - val_mean_absolute_error: 0.5037\n",
      "Epoch 62/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2193 - mean_absolute_error: 0.2581 - val_loss: 0.6079 - val_mean_absolute_error: 0.5177\n",
      "Epoch 63/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2122 - mean_absolute_error: 0.2563 - val_loss: 0.5820 - val_mean_absolute_error: 0.5088\n",
      "Epoch 64/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2347 - mean_absolute_error: 0.2615 - val_loss: 0.6006 - val_mean_absolute_error: 0.5042\n",
      "Epoch 65/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.2219 - mean_absolute_error: 0.2554 - val_loss: 0.5831 - val_mean_absolute_error: 0.5043\n",
      "Epoch 66/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1959 - mean_absolute_error: 0.2435 - val_loss: 0.5681 - val_mean_absolute_error: 0.5126\n",
      "Epoch 67/200\n",
      "24339/24339 [==============================] - 33s 1ms/step - loss: 0.1909 - mean_absolute_error: 0.2416 - val_loss: 0.6328 - val_mean_absolute_error: 0.5310\n",
      "Epoch 68/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2136 - mean_absolute_error: 0.2573 - val_loss: 0.5824 - val_mean_absolute_error: 0.5037\n",
      "Epoch 69/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2052 - mean_absolute_error: 0.2529 - val_loss: 0.5619 - val_mean_absolute_error: 0.5012\n",
      "Epoch 70/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2023 - mean_absolute_error: 0.2523 - val_loss: 0.5683 - val_mean_absolute_error: 0.4953\n",
      "Epoch 71/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1965 - mean_absolute_error: 0.2471 - val_loss: 0.5831 - val_mean_absolute_error: 0.5194\n",
      "Epoch 72/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2034 - mean_absolute_error: 0.2531 - val_loss: 0.6741 - val_mean_absolute_error: 0.5551\n",
      "Epoch 73/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1982 - mean_absolute_error: 0.2460 - val_loss: 0.6421 - val_mean_absolute_error: 0.5437\n",
      "Epoch 74/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1968 - mean_absolute_error: 0.2460 - val_loss: 0.5914 - val_mean_absolute_error: 0.5165\n",
      "Epoch 75/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1990 - mean_absolute_error: 0.2498 - val_loss: 0.5744 - val_mean_absolute_error: 0.5016\n",
      "Epoch 76/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1803 - mean_absolute_error: 0.2357 - val_loss: 0.5592 - val_mean_absolute_error: 0.4956\n",
      "Epoch 77/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1927 - mean_absolute_error: 0.2504 - val_loss: 0.5857 - val_mean_absolute_error: 0.5103\n",
      "Epoch 78/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1916 - mean_absolute_error: 0.2483 - val_loss: 0.5946 - val_mean_absolute_error: 0.5198\n",
      "Epoch 79/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.1980 - mean_absolute_error: 0.2526 - val_loss: 0.6112 - val_mean_absolute_error: 0.5236\n",
      "Epoch 80/200\n",
      "24339/24339 [==============================] - 34s 1ms/step - loss: 0.2006 - mean_absolute_error: 0.2514 - val_loss: 0.5573 - val_mean_absolute_error: 0.4972\n",
      "Epoch 81/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1844 - mean_absolute_error: 0.2380 - val_loss: 0.5463 - val_mean_absolute_error: 0.4918\n",
      "Epoch 82/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1821 - mean_absolute_error: 0.2413 - val_loss: 0.5964 - val_mean_absolute_error: 0.5232\n",
      "Epoch 83/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1865 - mean_absolute_error: 0.2433 - val_loss: 0.5576 - val_mean_absolute_error: 0.4971\n",
      "Epoch 84/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1820 - mean_absolute_error: 0.2384 - val_loss: 0.5561 - val_mean_absolute_error: 0.5038\n",
      "Epoch 85/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1853 - mean_absolute_error: 0.2459 - val_loss: 0.6114 - val_mean_absolute_error: 0.5239\n",
      "Epoch 86/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1956 - mean_absolute_error: 0.2508 - val_loss: 0.5809 - val_mean_absolute_error: 0.5108\n",
      "Epoch 87/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1939 - mean_absolute_error: 0.2511 - val_loss: 0.5912 - val_mean_absolute_error: 0.5154\n",
      "Epoch 88/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1784 - mean_absolute_error: 0.2376 - val_loss: 0.5700 - val_mean_absolute_error: 0.5078\n",
      "Epoch 89/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1898 - mean_absolute_error: 0.2457 - val_loss: 0.5670 - val_mean_absolute_error: 0.5093\n",
      "Epoch 90/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1803 - mean_absolute_error: 0.2396 - val_loss: 0.5564 - val_mean_absolute_error: 0.5028\n",
      "Epoch 91/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1761 - mean_absolute_error: 0.2375 - val_loss: 0.5721 - val_mean_absolute_error: 0.5104\n",
      "Epoch 92/200\n",
      "24339/24339 [==============================] - 36s 1ms/step - loss: 0.1812 - mean_absolute_error: 0.2425 - val_loss: 0.5921 - val_mean_absolute_error: 0.5146\n",
      "Epoch 93/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.2036 - mean_absolute_error: 0.2597 - val_loss: 0.5486 - val_mean_absolute_error: 0.4927\n",
      "Epoch 94/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1754 - mean_absolute_error: 0.2297 - val_loss: 0.5646 - val_mean_absolute_error: 0.4966\n",
      "Epoch 95/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1738 - mean_absolute_error: 0.2328 - val_loss: 0.5893 - val_mean_absolute_error: 0.5087\n",
      "Epoch 96/200\n",
      "24339/24339 [==============================] - 35s 1ms/step - loss: 0.1862 - mean_absolute_error: 0.2442 - val_loss: 0.6873 - val_mean_absolute_error: 0.5700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1789 - mean_absolute_error: 0.2405 - val_loss: 0.6396 - val_mean_absolute_error: 0.5494\n",
      "Epoch 98/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1754 - mean_absolute_error: 0.2384 - val_loss: 0.5826 - val_mean_absolute_error: 0.5109\n",
      "Epoch 99/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1846 - mean_absolute_error: 0.2464 - val_loss: 0.6068 - val_mean_absolute_error: 0.5251\n",
      "Epoch 100/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1732 - mean_absolute_error: 0.2346 - val_loss: 0.5752 - val_mean_absolute_error: 0.4983\n",
      "Epoch 101/200\n",
      "24339/24339 [==============================] - 31s 1ms/step - loss: 0.1945 - mean_absolute_error: 0.2554 - val_loss: 0.5877 - val_mean_absolute_error: 0.5083\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  4086272   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  257       \n",
      "=================================================================\n",
      "Total params: 4,547,073\n",
      "Trainable params: 4,547,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We train the model on our data\n",
    "# Number of epochs the network should run through\n",
    "EPOCHS = 200\n",
    "# Size of the batch for optimization\n",
    "BATCH_SIZE = 32\n",
    "# Set up validation split\n",
    "VALIDATION_SPLIT = 0.1\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "# This will avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6604633181447641"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_test, batch_size=32)\n",
    "rmse(result, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "For the following model :\n",
    "    - 4 hidden layers of 64 neurons - relu activation.\n",
    "    - A result layer of 1 neuron - relu activation.\n",
    "    - Early stopping callback\n",
    "    - Test split of 0.2\n",
    "    - Using AdamOptimizer gives best results.\n",
    "    - No cross validation.\n",
    "    \n",
    "Network size :\n",
    "- $4*64 + 1 = 257$ neurons (biases)\n",
    "- $30049*64 + 64*64 + 64*64 + 64 = 1931392$ weights\n",
    "- Total of $1931649$ learnable parameters (almost 2 millions)\n",
    "\n",
    "With the above, we reached a RMSE of 0.5. But this is without separating the data into train and test set. This can lead to overfitting. Now we need to ensure that we are not overfitting.\n",
    "\n",
    "For this we will test 2 solutions :\n",
    "\n",
    "### Change our implementation to add regulizer that will avoid this overfitting\n",
    "\n",
    "### Cross validation over multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi neural network approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 3004)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized_red.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")\n",
    "X_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(X_red) * TRAIN_SET_PERC)\n",
    "\n",
    "# Select random rows of the matrix for train / test set\n",
    "# Random seed for reproducibility \n",
    "np.random.seed(100)\n",
    "train_idx = np.random.choice(len(X_red), size=train_set_size, replace = False)\n",
    "test_idx = [i for i in range(len(X_red)) if i not in train_idx]\n",
    "X_train_red = X_red[train_idx, :]\n",
    "X_test_red = X_red[test_idx, :]\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_red: (30049, 3004)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_red: \" + str(X_red.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 20 entities from session/Crowd01/20\n"
     ]
    }
   ],
   "source": [
    "crowd01 = crowd.Crowd(X_train_red, y_train, \"Crowd01\")\n",
    "crowd01.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 31.2337 - mean_absolute_error: 2.9543\n",
      "Epoch 00001: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 8s 310us/step - loss: 31.1038 - mean_absolute_error: 2.9459 - val_loss: 13.1879 - val_mean_absolute_error: 1.7464\n",
      "Epoch 2/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 10.5435 - mean_absolute_error: 1.4144\n",
      "Epoch 00002: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 225us/step - loss: 10.5296 - mean_absolute_error: 1.4122 - val_loss: 7.5137 - val_mean_absolute_error: 0.9370\n",
      "Epoch 3/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 6.2404 - mean_absolute_error: 0.7555\n",
      "Epoch 00003: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 6.2390 - mean_absolute_error: 0.7556 - val_loss: 6.1505 - val_mean_absolute_error: 1.0661\n",
      "Epoch 4/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 4.4963 - mean_absolute_error: 0.5604\n",
      "Epoch 00004: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 4.4925 - mean_absolute_error: 0.5604 - val_loss: 4.1380 - val_mean_absolute_error: 0.6241\n",
      "Epoch 5/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 3.5080 - mean_absolute_error: 0.5548\n",
      "Epoch 00005: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 3.5076 - mean_absolute_error: 0.5551 - val_loss: 3.2305 - val_mean_absolute_error: 0.6051\n",
      "Epoch 6/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 2.7363 - mean_absolute_error: 0.5428\n",
      "Epoch 00006: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 2.7349 - mean_absolute_error: 0.5426 - val_loss: 2.5188 - val_mean_absolute_error: 0.5897\n",
      "Epoch 7/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 2.1222 - mean_absolute_error: 0.5095\n",
      "Epoch 00007: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 2.1218 - mean_absolute_error: 0.5096 - val_loss: 2.0831 - val_mean_absolute_error: 0.6158\n",
      "Epoch 8/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 1.7726 - mean_absolute_error: 0.5257\n",
      "Epoch 00008: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 1.7715 - mean_absolute_error: 0.5260 - val_loss: 1.6236 - val_mean_absolute_error: 0.5130\n",
      "Epoch 9/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 1.5013 - mean_absolute_error: 0.5254\n",
      "Epoch 00009: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 1.5018 - mean_absolute_error: 0.5260 - val_loss: 1.7303 - val_mean_absolute_error: 0.6799\n",
      "Epoch 10/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 1.3217 - mean_absolute_error: 0.5090\n",
      "Epoch 00010: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 1.3223 - mean_absolute_error: 0.5093 - val_loss: 1.7090 - val_mean_absolute_error: 0.7875\n",
      "Epoch 11/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 1.2015 - mean_absolute_error: 0.5025\n",
      "Epoch 00011: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 1.2016 - mean_absolute_error: 0.5031 - val_loss: 1.1642 - val_mean_absolute_error: 0.4929\n",
      "Epoch 12/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 1.1740 - mean_absolute_error: 0.5233\n",
      "Epoch 00012: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 1.1732 - mean_absolute_error: 0.5228 - val_loss: 1.2856 - val_mean_absolute_error: 0.5744\n",
      "Epoch 13/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 1.0707 - mean_absolute_error: 0.4908\n",
      "Epoch 00013: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 1.0704 - mean_absolute_error: 0.4907 - val_loss: 1.1087 - val_mean_absolute_error: 0.5039\n",
      "Epoch 14/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 1.0385 - mean_absolute_error: 0.4929\n",
      "Epoch 00014: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 1.0376 - mean_absolute_error: 0.4928 - val_loss: 0.9907 - val_mean_absolute_error: 0.4711\n",
      "Epoch 15/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.9343 - mean_absolute_error: 0.4635\n",
      "Epoch 00015: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.9342 - mean_absolute_error: 0.4634 - val_loss: 0.9686 - val_mean_absolute_error: 0.4828\n",
      "Epoch 16/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.9167 - mean_absolute_error: 0.4631\n",
      "Epoch 00016: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.9172 - mean_absolute_error: 0.4635 - val_loss: 0.9876 - val_mean_absolute_error: 0.4720\n",
      "Epoch 17/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.8740 - mean_absolute_error: 0.4622\n",
      "Epoch 00017: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.8740 - mean_absolute_error: 0.4621 - val_loss: 0.8803 - val_mean_absolute_error: 0.4457\n",
      "Epoch 18/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.8389 - mean_absolute_error: 0.4599\n",
      "Epoch 00018: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.8391 - mean_absolute_error: 0.4601 - val_loss: 0.9093 - val_mean_absolute_error: 0.4823\n",
      "Epoch 19/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.7897 - mean_absolute_error: 0.4360\n",
      "Epoch 00019: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.7900 - mean_absolute_error: 0.4363 - val_loss: 0.8609 - val_mean_absolute_error: 0.4972\n",
      "Epoch 20/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.7949 - mean_absolute_error: 0.4411\n",
      "Epoch 00020: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 0.7960 - mean_absolute_error: 0.4415 - val_loss: 0.9191 - val_mean_absolute_error: 0.4752\n",
      "Epoch 21/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.7695 - mean_absolute_error: 0.4387\n",
      "Epoch 00021: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 0.7697 - mean_absolute_error: 0.4387 - val_loss: 0.8703 - val_mean_absolute_error: 0.5106\n",
      "Epoch 22/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.6941 - mean_absolute_error: 0.4248\n",
      "Epoch 00022: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 201us/step - loss: 0.6942 - mean_absolute_error: 0.4248 - val_loss: 0.8851 - val_mean_absolute_error: 0.5258\n",
      "Epoch 23/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.7140 - mean_absolute_error: 0.4354\n",
      "Epoch 00023: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.7143 - mean_absolute_error: 0.4354 - val_loss: 0.8085 - val_mean_absolute_error: 0.4596\n",
      "Epoch 24/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.7160 - mean_absolute_error: 0.4460\n",
      "Epoch 00024: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 0.7155 - mean_absolute_error: 0.4457 - val_loss: 0.7352 - val_mean_absolute_error: 0.4589\n",
      "Epoch 25/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.6627 - mean_absolute_error: 0.4239\n",
      "Epoch 00025: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.6636 - mean_absolute_error: 0.4242 - val_loss: 0.7572 - val_mean_absolute_error: 0.4681\n",
      "Epoch 26/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.6472 - mean_absolute_error: 0.4133\n",
      "Epoch 00026: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.6480 - mean_absolute_error: 0.4139 - val_loss: 0.7743 - val_mean_absolute_error: 0.4707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.6519 - mean_absolute_error: 0.4217\n",
      "Epoch 00027: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.6515 - mean_absolute_error: 0.4214 - val_loss: 0.7188 - val_mean_absolute_error: 0.4608\n",
      "Epoch 28/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.6490 - mean_absolute_error: 0.4237\n",
      "Epoch 00028: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.6492 - mean_absolute_error: 0.4238 - val_loss: 0.7281 - val_mean_absolute_error: 0.4754\n",
      "Epoch 29/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.6183 - mean_absolute_error: 0.4108\n",
      "Epoch 00029: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.6187 - mean_absolute_error: 0.4110 - val_loss: 0.8310 - val_mean_absolute_error: 0.5362\n",
      "Epoch 30/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.6131 - mean_absolute_error: 0.4099\n",
      "Epoch 00030: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.6135 - mean_absolute_error: 0.4100 - val_loss: 0.6327 - val_mean_absolute_error: 0.4223\n",
      "Epoch 31/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.6057 - mean_absolute_error: 0.4150\n",
      "Epoch 00031: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.6063 - mean_absolute_error: 0.4154 - val_loss: 0.7011 - val_mean_absolute_error: 0.4459\n",
      "Epoch 32/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.6177 - mean_absolute_error: 0.4170\n",
      "Epoch 00032: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.6180 - mean_absolute_error: 0.4173 - val_loss: 0.8692 - val_mean_absolute_error: 0.5876\n",
      "Epoch 33/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.6129 - mean_absolute_error: 0.4207\n",
      "Epoch 00033: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.6133 - mean_absolute_error: 0.4209 - val_loss: 0.6412 - val_mean_absolute_error: 0.4118\n",
      "Epoch 34/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5868 - mean_absolute_error: 0.4032\n",
      "Epoch 00034: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5876 - mean_absolute_error: 0.4038 - val_loss: 0.6700 - val_mean_absolute_error: 0.4483\n",
      "Epoch 35/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5992 - mean_absolute_error: 0.4069\n",
      "Epoch 00035: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 0.5993 - mean_absolute_error: 0.4068 - val_loss: 0.6903 - val_mean_absolute_error: 0.4416\n",
      "Epoch 36/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5961 - mean_absolute_error: 0.4114\n",
      "Epoch 00036: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5961 - mean_absolute_error: 0.4115 - val_loss: 0.6411 - val_mean_absolute_error: 0.4333\n",
      "Epoch 37/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5855 - mean_absolute_error: 0.4084\n",
      "Epoch 00037: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5872 - mean_absolute_error: 0.4092 - val_loss: 0.7408 - val_mean_absolute_error: 0.4557\n",
      "Epoch 38/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5964 - mean_absolute_error: 0.4028\n",
      "Epoch 00038: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5962 - mean_absolute_error: 0.4028 - val_loss: 0.7254 - val_mean_absolute_error: 0.5013\n",
      "Epoch 39/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5660 - mean_absolute_error: 0.4010\n",
      "Epoch 00039: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5663 - mean_absolute_error: 0.4013 - val_loss: 0.6395 - val_mean_absolute_error: 0.4323\n",
      "Epoch 40/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5672 - mean_absolute_error: 0.3978\n",
      "Epoch 00040: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5668 - mean_absolute_error: 0.3976 - val_loss: 0.7000 - val_mean_absolute_error: 0.4958\n",
      "Epoch 41/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5761 - mean_absolute_error: 0.4085\n",
      "Epoch 00041: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5758 - mean_absolute_error: 0.4084 - val_loss: 0.6713 - val_mean_absolute_error: 0.4281\n",
      "Epoch 42/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5711 - mean_absolute_error: 0.4059\n",
      "Epoch 00042: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5710 - mean_absolute_error: 0.4060 - val_loss: 0.7186 - val_mean_absolute_error: 0.4914\n",
      "Epoch 43/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5587 - mean_absolute_error: 0.3944\n",
      "Epoch 00043: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5589 - mean_absolute_error: 0.3947 - val_loss: 0.6390 - val_mean_absolute_error: 0.4385\n",
      "Epoch 44/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5716 - mean_absolute_error: 0.4045\n",
      "Epoch 00044: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5720 - mean_absolute_error: 0.4049 - val_loss: 0.6386 - val_mean_absolute_error: 0.4261\n",
      "Epoch 45/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5577 - mean_absolute_error: 0.3949\n",
      "Epoch 00045: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5585 - mean_absolute_error: 0.3954 - val_loss: 0.5900 - val_mean_absolute_error: 0.4062\n",
      "Epoch 46/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5414 - mean_absolute_error: 0.3933\n",
      "Epoch 00046: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5414 - mean_absolute_error: 0.3934 - val_loss: 0.6045 - val_mean_absolute_error: 0.4396\n",
      "Epoch 47/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5521 - mean_absolute_error: 0.4013\n",
      "Epoch 00047: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5541 - mean_absolute_error: 0.4022 - val_loss: 0.9275 - val_mean_absolute_error: 0.6552\n",
      "Epoch 48/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5626 - mean_absolute_error: 0.4028\n",
      "Epoch 00048: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5625 - mean_absolute_error: 0.4027 - val_loss: 0.5860 - val_mean_absolute_error: 0.4162\n",
      "Epoch 49/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5490 - mean_absolute_error: 0.3951\n",
      "Epoch 00049: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5489 - mean_absolute_error: 0.3953 - val_loss: 0.6274 - val_mean_absolute_error: 0.4293\n",
      "Epoch 50/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5440 - mean_absolute_error: 0.3924\n",
      "Epoch 00050: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5442 - mean_absolute_error: 0.3925 - val_loss: 0.6690 - val_mean_absolute_error: 0.4805\n",
      "Epoch 51/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5410 - mean_absolute_error: 0.3920\n",
      "Epoch 00051: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5412 - mean_absolute_error: 0.3920 - val_loss: 0.6078 - val_mean_absolute_error: 0.4266\n",
      "Epoch 52/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5518 - mean_absolute_error: 0.3966\n",
      "Epoch 00052: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 0.5515 - mean_absolute_error: 0.3964 - val_loss: 0.6377 - val_mean_absolute_error: 0.4260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5405 - mean_absolute_error: 0.3906\n",
      "Epoch 00053: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5400 - mean_absolute_error: 0.3905 - val_loss: 0.5886 - val_mean_absolute_error: 0.4145\n",
      "Epoch 54/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5262 - mean_absolute_error: 0.3812\n",
      "Epoch 00054: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5259 - mean_absolute_error: 0.3813 - val_loss: 0.6033 - val_mean_absolute_error: 0.4301\n",
      "Epoch 55/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5263 - mean_absolute_error: 0.3911\n",
      "Epoch 00055: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5263 - mean_absolute_error: 0.3912 - val_loss: 0.6185 - val_mean_absolute_error: 0.4453\n",
      "Epoch 56/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5373 - mean_absolute_error: 0.3959\n",
      "Epoch 00056: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5379 - mean_absolute_error: 0.3962 - val_loss: 0.6187 - val_mean_absolute_error: 0.4313\n",
      "Epoch 57/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5317 - mean_absolute_error: 0.3867\n",
      "Epoch 00057: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5315 - mean_absolute_error: 0.3866 - val_loss: 0.7411 - val_mean_absolute_error: 0.5426\n",
      "Epoch 58/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5183 - mean_absolute_error: 0.3822\n",
      "Epoch 00058: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5187 - mean_absolute_error: 0.3826 - val_loss: 0.6184 - val_mean_absolute_error: 0.4353\n",
      "Epoch 59/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5120 - mean_absolute_error: 0.3831\n",
      "Epoch 00059: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5122 - mean_absolute_error: 0.3832 - val_loss: 0.5715 - val_mean_absolute_error: 0.4134\n",
      "Epoch 60/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5305 - mean_absolute_error: 0.3940\n",
      "Epoch 00060: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5306 - mean_absolute_error: 0.3939 - val_loss: 0.6451 - val_mean_absolute_error: 0.4775\n",
      "Epoch 61/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5197 - mean_absolute_error: 0.3858\n",
      "Epoch 00061: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5209 - mean_absolute_error: 0.3866 - val_loss: 0.6007 - val_mean_absolute_error: 0.4276\n",
      "Epoch 62/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5300 - mean_absolute_error: 0.3955\n",
      "Epoch 00062: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5301 - mean_absolute_error: 0.3954 - val_loss: 0.6140 - val_mean_absolute_error: 0.4355\n",
      "Epoch 63/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5337 - mean_absolute_error: 0.3887\n",
      "Epoch 00063: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5337 - mean_absolute_error: 0.3888 - val_loss: 0.6007 - val_mean_absolute_error: 0.4371\n",
      "Epoch 64/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5098 - mean_absolute_error: 0.3816\n",
      "Epoch 00064: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5107 - mean_absolute_error: 0.3819 - val_loss: 0.6130 - val_mean_absolute_error: 0.4414\n",
      "Epoch 65/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5254 - mean_absolute_error: 0.3864\n",
      "Epoch 00065: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5247 - mean_absolute_error: 0.3858 - val_loss: 0.6288 - val_mean_absolute_error: 0.4400\n",
      "Epoch 66/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5155 - mean_absolute_error: 0.3822\n",
      "Epoch 00066: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5156 - mean_absolute_error: 0.3822 - val_loss: 0.5607 - val_mean_absolute_error: 0.4114\n",
      "Epoch 67/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5206 - mean_absolute_error: 0.3910\n",
      "Epoch 00067: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5207 - mean_absolute_error: 0.3912 - val_loss: 0.6398 - val_mean_absolute_error: 0.4533\n",
      "Epoch 68/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5204 - mean_absolute_error: 0.3869\n",
      "Epoch 00068: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5217 - mean_absolute_error: 0.3880 - val_loss: 0.7974 - val_mean_absolute_error: 0.5848\n",
      "Epoch 69/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5085 - mean_absolute_error: 0.3819\n",
      "Epoch 00069: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5082 - mean_absolute_error: 0.3818 - val_loss: 0.5587 - val_mean_absolute_error: 0.4062\n",
      "Epoch 70/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5265 - mean_absolute_error: 0.3951\n",
      "Epoch 00070: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5267 - mean_absolute_error: 0.3952 - val_loss: 0.5990 - val_mean_absolute_error: 0.4251\n",
      "Epoch 71/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5178 - mean_absolute_error: 0.3855\n",
      "Epoch 00071: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5174 - mean_absolute_error: 0.3853 - val_loss: 0.6043 - val_mean_absolute_error: 0.4311\n",
      "Epoch 72/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5054 - mean_absolute_error: 0.3827\n",
      "Epoch 00072: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5062 - mean_absolute_error: 0.3834 - val_loss: 0.5935 - val_mean_absolute_error: 0.4387\n",
      "Epoch 73/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5305 - mean_absolute_error: 0.3905\n",
      "Epoch 00073: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 0.5299 - mean_absolute_error: 0.3902 - val_loss: 0.5877 - val_mean_absolute_error: 0.4193\n",
      "Epoch 74/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5060 - mean_absolute_error: 0.3801\n",
      "Epoch 00074: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5063 - mean_absolute_error: 0.3805 - val_loss: 0.5448 - val_mean_absolute_error: 0.4005\n",
      "Epoch 75/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5104 - mean_absolute_error: 0.3856\n",
      "Epoch 00075: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5105 - mean_absolute_error: 0.3860 - val_loss: 0.6620 - val_mean_absolute_error: 0.4772\n",
      "Epoch 76/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5047 - mean_absolute_error: 0.3820\n",
      "Epoch 00076: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5050 - mean_absolute_error: 0.3822 - val_loss: 0.6396 - val_mean_absolute_error: 0.4493\n",
      "Epoch 77/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5091 - mean_absolute_error: 0.3819\n",
      "Epoch 00077: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5094 - mean_absolute_error: 0.3822 - val_loss: 0.6639 - val_mean_absolute_error: 0.4784\n",
      "Epoch 78/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5135 - mean_absolute_error: 0.3832\n",
      "Epoch 00078: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5137 - mean_absolute_error: 0.3833 - val_loss: 0.5971 - val_mean_absolute_error: 0.4394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5012 - mean_absolute_error: 0.3793\n",
      "Epoch 00079: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5012 - mean_absolute_error: 0.3793 - val_loss: 0.6749 - val_mean_absolute_error: 0.4879\n",
      "Epoch 80/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5217 - mean_absolute_error: 0.3877\n",
      "Epoch 00080: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5217 - mean_absolute_error: 0.3876 - val_loss: 0.6106 - val_mean_absolute_error: 0.4264\n",
      "Epoch 81/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5161 - mean_absolute_error: 0.3840\n",
      "Epoch 00081: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5165 - mean_absolute_error: 0.3842 - val_loss: 0.6400 - val_mean_absolute_error: 0.4644\n",
      "Epoch 82/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5178 - mean_absolute_error: 0.3900\n",
      "Epoch 00082: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5175 - mean_absolute_error: 0.3898 - val_loss: 0.5569 - val_mean_absolute_error: 0.4070\n",
      "Epoch 83/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5036 - mean_absolute_error: 0.3799\n",
      "Epoch 00083: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5041 - mean_absolute_error: 0.3801 - val_loss: 0.6067 - val_mean_absolute_error: 0.4470\n",
      "Epoch 84/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4977 - mean_absolute_error: 0.3793\n",
      "Epoch 00084: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.4979 - mean_absolute_error: 0.3795 - val_loss: 0.5629 - val_mean_absolute_error: 0.4135\n",
      "Epoch 85/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5009 - mean_absolute_error: 0.3834\n",
      "Epoch 00085: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5012 - mean_absolute_error: 0.3838 - val_loss: 0.6201 - val_mean_absolute_error: 0.4598\n",
      "Epoch 86/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5043 - mean_absolute_error: 0.3825\n",
      "Epoch 00086: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5044 - mean_absolute_error: 0.3828 - val_loss: 0.6388 - val_mean_absolute_error: 0.4576\n",
      "Epoch 87/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5043 - mean_absolute_error: 0.3799\n",
      "Epoch 00087: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 200us/step - loss: 0.5050 - mean_absolute_error: 0.3804 - val_loss: 0.6882 - val_mean_absolute_error: 0.5229\n",
      "Epoch 88/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5168 - mean_absolute_error: 0.3917\n",
      "Epoch 00088: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5167 - mean_absolute_error: 0.3918 - val_loss: 0.6515 - val_mean_absolute_error: 0.4926\n",
      "Epoch 89/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4894 - mean_absolute_error: 0.3752\n",
      "Epoch 00089: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.4896 - mean_absolute_error: 0.3754 - val_loss: 0.6060 - val_mean_absolute_error: 0.4417\n",
      "Epoch 90/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5000 - mean_absolute_error: 0.3814\n",
      "Epoch 00090: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5007 - mean_absolute_error: 0.3816 - val_loss: 0.5821 - val_mean_absolute_error: 0.4183\n",
      "Epoch 91/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5013 - mean_absolute_error: 0.3838\n",
      "Epoch 00091: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5011 - mean_absolute_error: 0.3836 - val_loss: 0.5660 - val_mean_absolute_error: 0.4282\n",
      "Epoch 92/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.4841 - mean_absolute_error: 0.3755\n",
      "Epoch 00092: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.4844 - mean_absolute_error: 0.3757 - val_loss: 0.5730 - val_mean_absolute_error: 0.4146\n",
      "Epoch 93/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5114 - mean_absolute_error: 0.3818\n",
      "Epoch 00093: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 199us/step - loss: 0.5109 - mean_absolute_error: 0.3816 - val_loss: 0.5510 - val_mean_absolute_error: 0.4034\n",
      "Epoch 94/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5088 - mean_absolute_error: 0.3820\n",
      "Epoch 00094: saving model to session/Crowd01/16\n",
      "24339/24339 [==============================] - 5s 198us/step - loss: 0.5088 - mean_absolute_error: 0.3820 - val_loss: 0.5826 - val_mean_absolute_error: 0.4222\n",
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 28.8272 - mean_absolute_error: 2.7991\n",
      "Epoch 00001: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 7s 303us/step - loss: 28.7974 - mean_absolute_error: 2.7971 - val_loss: 12.8705 - val_mean_absolute_error: 1.6957\n",
      "Epoch 2/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 10.6872 - mean_absolute_error: 1.3992\n",
      "Epoch 00002: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 10.6549 - mean_absolute_error: 1.3937 - val_loss: 7.5267 - val_mean_absolute_error: 0.8791\n",
      "Epoch 3/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 6.3728 - mean_absolute_error: 0.7251\n",
      "Epoch 00003: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 6.3609 - mean_absolute_error: 0.7233 - val_loss: 5.3520 - val_mean_absolute_error: 0.5894\n",
      "Epoch 4/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 4.5685 - mean_absolute_error: 0.5062\n",
      "Epoch 00004: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 4.5682 - mean_absolute_error: 0.5064 - val_loss: 4.1247 - val_mean_absolute_error: 0.5645\n",
      "Epoch 5/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 3.6180 - mean_absolute_error: 0.5397\n",
      "Epoch 00005: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 3.6165 - mean_absolute_error: 0.5397 - val_loss: 3.2881 - val_mean_absolute_error: 0.5745\n",
      "Epoch 6/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 2.8201 - mean_absolute_error: 0.5375\n",
      "Epoch 00006: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 2.8178 - mean_absolute_error: 0.5373 - val_loss: 2.5297 - val_mean_absolute_error: 0.5505\n",
      "Epoch 7/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 2.2155 - mean_absolute_error: 0.5217\n",
      "Epoch 00007: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 2.2129 - mean_absolute_error: 0.5214 - val_loss: 1.9599 - val_mean_absolute_error: 0.5160\n",
      "Epoch 8/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 1.7565 - mean_absolute_error: 0.5013\n",
      "Epoch 00008: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 1.7543 - mean_absolute_error: 0.5010 - val_loss: 1.7775 - val_mean_absolute_error: 0.5706\n",
      "Epoch 9/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 1.5651 - mean_absolute_error: 0.5420\n",
      "Epoch 00009: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 1.5637 - mean_absolute_error: 0.5418 - val_loss: 1.4855 - val_mean_absolute_error: 0.5284\n",
      "Epoch 10/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 1.3664 - mean_absolute_error: 0.5252\n",
      "Epoch 00010: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 1.3664 - mean_absolute_error: 0.5252 - val_loss: 1.4198 - val_mean_absolute_error: 0.5766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 1.2283 - mean_absolute_error: 0.5093\n",
      "Epoch 00011: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 1.2282 - mean_absolute_error: 0.5092 - val_loss: 1.1727 - val_mean_absolute_error: 0.4856\n",
      "Epoch 12/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 1.1756 - mean_absolute_error: 0.5188\n",
      "Epoch 00012: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 1.1754 - mean_absolute_error: 0.5189 - val_loss: 1.1584 - val_mean_absolute_error: 0.5100\n",
      "Epoch 13/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 1.0997 - mean_absolute_error: 0.5141\n",
      "Epoch 00013: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 1.0995 - mean_absolute_error: 0.5140 - val_loss: 1.0821 - val_mean_absolute_error: 0.4978\n",
      "Epoch 14/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 1.0122 - mean_absolute_error: 0.4829\n",
      "Epoch 00014: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 1.0113 - mean_absolute_error: 0.4824 - val_loss: 1.0091 - val_mean_absolute_error: 0.4819\n",
      "Epoch 15/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 1.0149 - mean_absolute_error: 0.4898\n",
      "Epoch 00015: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 1.0139 - mean_absolute_error: 0.4893 - val_loss: 1.0126 - val_mean_absolute_error: 0.4908\n",
      "Epoch 16/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.9056 - mean_absolute_error: 0.4624\n",
      "Epoch 00016: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.9059 - mean_absolute_error: 0.4627 - val_loss: 0.9192 - val_mean_absolute_error: 0.4694\n",
      "Epoch 17/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.9316 - mean_absolute_error: 0.4766\n",
      "Epoch 00017: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.9314 - mean_absolute_error: 0.4763 - val_loss: 1.0250 - val_mean_absolute_error: 0.5028\n",
      "Epoch 18/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.8613 - mean_absolute_error: 0.4630\n",
      "Epoch 00018: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.8612 - mean_absolute_error: 0.4629 - val_loss: 0.9098 - val_mean_absolute_error: 0.4701\n",
      "Epoch 19/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.7890 - mean_absolute_error: 0.4432\n",
      "Epoch 00019: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.7890 - mean_absolute_error: 0.4432 - val_loss: 0.8578 - val_mean_absolute_error: 0.4678\n",
      "Epoch 20/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.7984 - mean_absolute_error: 0.4523\n",
      "Epoch 00020: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.7989 - mean_absolute_error: 0.4527 - val_loss: 0.8945 - val_mean_absolute_error: 0.4859\n",
      "Epoch 21/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.7802 - mean_absolute_error: 0.4463\n",
      "Epoch 00021: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.7801 - mean_absolute_error: 0.4464 - val_loss: 0.7793 - val_mean_absolute_error: 0.4416\n",
      "Epoch 22/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6912 - mean_absolute_error: 0.4227\n",
      "Epoch 00022: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.6916 - mean_absolute_error: 0.4229 - val_loss: 0.7285 - val_mean_absolute_error: 0.4388\n",
      "Epoch 23/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6878 - mean_absolute_error: 0.4328\n",
      "Epoch 00023: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.6878 - mean_absolute_error: 0.4329 - val_loss: 0.7354 - val_mean_absolute_error: 0.4506\n",
      "Epoch 24/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6738 - mean_absolute_error: 0.4308\n",
      "Epoch 00024: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.6740 - mean_absolute_error: 0.4309 - val_loss: 0.7554 - val_mean_absolute_error: 0.4799\n",
      "Epoch 25/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.6673 - mean_absolute_error: 0.4257\n",
      "Epoch 00025: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.6678 - mean_absolute_error: 0.4260 - val_loss: 0.8362 - val_mean_absolute_error: 0.5149\n",
      "Epoch 26/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.6673 - mean_absolute_error: 0.4295\n",
      "Epoch 00026: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.6673 - mean_absolute_error: 0.4296 - val_loss: 0.6834 - val_mean_absolute_error: 0.4412\n",
      "Epoch 27/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.6442 - mean_absolute_error: 0.4290\n",
      "Epoch 00027: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.6444 - mean_absolute_error: 0.4292 - val_loss: 0.7397 - val_mean_absolute_error: 0.4744\n",
      "Epoch 28/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6530 - mean_absolute_error: 0.4330\n",
      "Epoch 00028: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.6528 - mean_absolute_error: 0.4331 - val_loss: 0.6595 - val_mean_absolute_error: 0.4257\n",
      "Epoch 29/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.6221 - mean_absolute_error: 0.4181\n",
      "Epoch 00029: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.6221 - mean_absolute_error: 0.4182 - val_loss: 0.6895 - val_mean_absolute_error: 0.4438\n",
      "Epoch 30/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5943 - mean_absolute_error: 0.4049\n",
      "Epoch 00030: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5945 - mean_absolute_error: 0.4050 - val_loss: 0.6637 - val_mean_absolute_error: 0.4311\n",
      "Epoch 31/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.6237 - mean_absolute_error: 0.4163\n",
      "Epoch 00031: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 0.6236 - mean_absolute_error: 0.4162 - val_loss: 1.2358 - val_mean_absolute_error: 0.7939\n",
      "Epoch 32/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.6085 - mean_absolute_error: 0.4150\n",
      "Epoch 00032: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.6083 - mean_absolute_error: 0.4149 - val_loss: 0.6583 - val_mean_absolute_error: 0.4268\n",
      "Epoch 33/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.6120 - mean_absolute_error: 0.4190\n",
      "Epoch 00033: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 0.6122 - mean_absolute_error: 0.4190 - val_loss: 0.6649 - val_mean_absolute_error: 0.4371\n",
      "Epoch 34/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5941 - mean_absolute_error: 0.4097\n",
      "Epoch 00034: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5941 - mean_absolute_error: 0.4097 - val_loss: 0.6622 - val_mean_absolute_error: 0.4331\n",
      "Epoch 35/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5938 - mean_absolute_error: 0.4054\n",
      "Epoch 00035: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5938 - mean_absolute_error: 0.4055 - val_loss: 0.6545 - val_mean_absolute_error: 0.4261\n",
      "Epoch 36/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5924 - mean_absolute_error: 0.4114\n",
      "Epoch 00036: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5924 - mean_absolute_error: 0.4114 - val_loss: 0.6600 - val_mean_absolute_error: 0.4331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5967 - mean_absolute_error: 0.4198\n",
      "Epoch 00037: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5972 - mean_absolute_error: 0.4200 - val_loss: 0.6552 - val_mean_absolute_error: 0.4516\n",
      "Epoch 38/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5697 - mean_absolute_error: 0.4013\n",
      "Epoch 00038: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5696 - mean_absolute_error: 0.4012 - val_loss: 0.6285 - val_mean_absolute_error: 0.4297\n",
      "Epoch 39/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5877 - mean_absolute_error: 0.4094\n",
      "Epoch 00039: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5882 - mean_absolute_error: 0.4098 - val_loss: 0.6645 - val_mean_absolute_error: 0.4494\n",
      "Epoch 40/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5703 - mean_absolute_error: 0.4026\n",
      "Epoch 00040: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5706 - mean_absolute_error: 0.4026 - val_loss: 0.6159 - val_mean_absolute_error: 0.4195\n",
      "Epoch 41/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5928 - mean_absolute_error: 0.4184\n",
      "Epoch 00041: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5927 - mean_absolute_error: 0.4183 - val_loss: 0.6447 - val_mean_absolute_error: 0.4432\n",
      "Epoch 42/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5625 - mean_absolute_error: 0.4001\n",
      "Epoch 00042: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5630 - mean_absolute_error: 0.4004 - val_loss: 0.6243 - val_mean_absolute_error: 0.4229\n",
      "Epoch 43/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5618 - mean_absolute_error: 0.3976\n",
      "Epoch 00043: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5620 - mean_absolute_error: 0.3977 - val_loss: 0.6636 - val_mean_absolute_error: 0.4625\n",
      "Epoch 44/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5612 - mean_absolute_error: 0.4026\n",
      "Epoch 00044: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5614 - mean_absolute_error: 0.4026 - val_loss: 0.6318 - val_mean_absolute_error: 0.4423\n",
      "Epoch 45/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5744 - mean_absolute_error: 0.4102\n",
      "Epoch 00045: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5744 - mean_absolute_error: 0.4101 - val_loss: 0.6990 - val_mean_absolute_error: 0.4656\n",
      "Epoch 46/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5664 - mean_absolute_error: 0.4040\n",
      "Epoch 00046: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5662 - mean_absolute_error: 0.4040 - val_loss: 0.6632 - val_mean_absolute_error: 0.4700\n",
      "Epoch 47/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5617 - mean_absolute_error: 0.4025\n",
      "Epoch 00047: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5618 - mean_absolute_error: 0.4023 - val_loss: 0.6776 - val_mean_absolute_error: 0.4652\n",
      "Epoch 48/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5752 - mean_absolute_error: 0.4121\n",
      "Epoch 00048: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5747 - mean_absolute_error: 0.4117 - val_loss: 0.6616 - val_mean_absolute_error: 0.4474\n",
      "Epoch 49/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5481 - mean_absolute_error: 0.3952\n",
      "Epoch 00049: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5482 - mean_absolute_error: 0.3952 - val_loss: 0.6298 - val_mean_absolute_error: 0.4470\n",
      "Epoch 50/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5674 - mean_absolute_error: 0.4080\n",
      "Epoch 00050: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5677 - mean_absolute_error: 0.4082 - val_loss: 0.6041 - val_mean_absolute_error: 0.4282\n",
      "Epoch 51/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5568 - mean_absolute_error: 0.4048\n",
      "Epoch 00051: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5567 - mean_absolute_error: 0.4047 - val_loss: 0.6511 - val_mean_absolute_error: 0.4530\n",
      "Epoch 52/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5624 - mean_absolute_error: 0.4029\n",
      "Epoch 00052: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5621 - mean_absolute_error: 0.4028 - val_loss: 0.6385 - val_mean_absolute_error: 0.4521\n",
      "Epoch 53/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5481 - mean_absolute_error: 0.3954\n",
      "Epoch 00053: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 0.5479 - mean_absolute_error: 0.3952 - val_loss: 0.6946 - val_mean_absolute_error: 0.4912\n",
      "Epoch 54/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5429 - mean_absolute_error: 0.3930\n",
      "Epoch 00054: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5428 - mean_absolute_error: 0.3929 - val_loss: 0.5994 - val_mean_absolute_error: 0.4255\n",
      "Epoch 55/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5535 - mean_absolute_error: 0.4006\n",
      "Epoch 00055: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5535 - mean_absolute_error: 0.4006 - val_loss: 0.6163 - val_mean_absolute_error: 0.4304\n",
      "Epoch 56/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5513 - mean_absolute_error: 0.4023\n",
      "Epoch 00056: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5511 - mean_absolute_error: 0.4021 - val_loss: 0.6103 - val_mean_absolute_error: 0.4242\n",
      "Epoch 57/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5670 - mean_absolute_error: 0.4106\n",
      "Epoch 00057: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5668 - mean_absolute_error: 0.4103 - val_loss: 0.6274 - val_mean_absolute_error: 0.4424\n",
      "Epoch 58/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5375 - mean_absolute_error: 0.3903\n",
      "Epoch 00058: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5377 - mean_absolute_error: 0.3905 - val_loss: 0.8206 - val_mean_absolute_error: 0.5952\n",
      "Epoch 59/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5437 - mean_absolute_error: 0.3950\n",
      "Epoch 00059: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5441 - mean_absolute_error: 0.3953 - val_loss: 0.6773 - val_mean_absolute_error: 0.4891\n",
      "Epoch 60/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5435 - mean_absolute_error: 0.3932\n",
      "Epoch 00060: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5438 - mean_absolute_error: 0.3934 - val_loss: 0.6317 - val_mean_absolute_error: 0.4460\n",
      "Epoch 61/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5377 - mean_absolute_error: 0.3904\n",
      "Epoch 00061: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5389 - mean_absolute_error: 0.3913 - val_loss: 0.6234 - val_mean_absolute_error: 0.4322\n",
      "Epoch 62/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5386 - mean_absolute_error: 0.3930\n",
      "Epoch 00062: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5388 - mean_absolute_error: 0.3931 - val_loss: 0.5954 - val_mean_absolute_error: 0.4291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5352 - mean_absolute_error: 0.3916\n",
      "Epoch 00063: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5354 - mean_absolute_error: 0.3915 - val_loss: 0.5899 - val_mean_absolute_error: 0.4165\n",
      "Epoch 64/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5512 - mean_absolute_error: 0.3984\n",
      "Epoch 00064: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5510 - mean_absolute_error: 0.3983 - val_loss: 0.6253 - val_mean_absolute_error: 0.4255\n",
      "Epoch 65/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5482 - mean_absolute_error: 0.4006\n",
      "Epoch 00065: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5482 - mean_absolute_error: 0.4006 - val_loss: 0.6038 - val_mean_absolute_error: 0.4250\n",
      "Epoch 66/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5254 - mean_absolute_error: 0.3823\n",
      "Epoch 00066: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5252 - mean_absolute_error: 0.3822 - val_loss: 0.6266 - val_mean_absolute_error: 0.4356\n",
      "Epoch 67/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5369 - mean_absolute_error: 0.3948\n",
      "Epoch 00067: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5366 - mean_absolute_error: 0.3946 - val_loss: 0.6120 - val_mean_absolute_error: 0.4372\n",
      "Epoch 68/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5465 - mean_absolute_error: 0.4021\n",
      "Epoch 00068: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5466 - mean_absolute_error: 0.4022 - val_loss: 0.6515 - val_mean_absolute_error: 0.4702\n",
      "Epoch 69/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5296 - mean_absolute_error: 0.3886\n",
      "Epoch 00069: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5294 - mean_absolute_error: 0.3886 - val_loss: 0.6608 - val_mean_absolute_error: 0.4864\n",
      "Epoch 70/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5242 - mean_absolute_error: 0.3891\n",
      "Epoch 00070: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5245 - mean_absolute_error: 0.3895 - val_loss: 0.6976 - val_mean_absolute_error: 0.5070\n",
      "Epoch 71/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5342 - mean_absolute_error: 0.3912\n",
      "Epoch 00071: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5341 - mean_absolute_error: 0.3911 - val_loss: 0.6087 - val_mean_absolute_error: 0.4330\n",
      "Epoch 72/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5363 - mean_absolute_error: 0.3966\n",
      "Epoch 00072: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5362 - mean_absolute_error: 0.3965 - val_loss: 0.6264 - val_mean_absolute_error: 0.4448\n",
      "Epoch 73/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5183 - mean_absolute_error: 0.3812\n",
      "Epoch 00073: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5187 - mean_absolute_error: 0.3816 - val_loss: 0.5951 - val_mean_absolute_error: 0.4342\n",
      "Epoch 74/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5186 - mean_absolute_error: 0.3852\n",
      "Epoch 00074: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5187 - mean_absolute_error: 0.3852 - val_loss: 0.7137 - val_mean_absolute_error: 0.5139\n",
      "Epoch 75/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5204 - mean_absolute_error: 0.3851\n",
      "Epoch 00075: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5205 - mean_absolute_error: 0.3851 - val_loss: 0.6069 - val_mean_absolute_error: 0.4126\n",
      "Epoch 76/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5227 - mean_absolute_error: 0.3865\n",
      "Epoch 00076: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5231 - mean_absolute_error: 0.3869 - val_loss: 0.5941 - val_mean_absolute_error: 0.4248\n",
      "Epoch 77/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5291 - mean_absolute_error: 0.3903\n",
      "Epoch 00077: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5292 - mean_absolute_error: 0.3904 - val_loss: 0.6268 - val_mean_absolute_error: 0.4408\n",
      "Epoch 78/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5238 - mean_absolute_error: 0.3845\n",
      "Epoch 00078: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5245 - mean_absolute_error: 0.3851 - val_loss: 0.8209 - val_mean_absolute_error: 0.5954\n",
      "Epoch 79/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5209 - mean_absolute_error: 0.3884\n",
      "Epoch 00079: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5220 - mean_absolute_error: 0.3892 - val_loss: 0.8798 - val_mean_absolute_error: 0.6264\n",
      "Epoch 80/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5169 - mean_absolute_error: 0.3848\n",
      "Epoch 00080: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5172 - mean_absolute_error: 0.3851 - val_loss: 0.5884 - val_mean_absolute_error: 0.4183\n",
      "Epoch 81/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5239 - mean_absolute_error: 0.3863\n",
      "Epoch 00081: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5242 - mean_absolute_error: 0.3865 - val_loss: 0.7778 - val_mean_absolute_error: 0.5731\n",
      "Epoch 82/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5258 - mean_absolute_error: 0.3889\n",
      "Epoch 00082: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5258 - mean_absolute_error: 0.3888 - val_loss: 0.5830 - val_mean_absolute_error: 0.4158\n",
      "Epoch 83/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5268 - mean_absolute_error: 0.3909\n",
      "Epoch 00083: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5268 - mean_absolute_error: 0.3909 - val_loss: 0.6278 - val_mean_absolute_error: 0.4633\n",
      "Epoch 84/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5129 - mean_absolute_error: 0.3810\n",
      "Epoch 00084: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5136 - mean_absolute_error: 0.3814 - val_loss: 0.6554 - val_mean_absolute_error: 0.4759\n",
      "Epoch 85/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5259 - mean_absolute_error: 0.3880\n",
      "Epoch 00085: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5257 - mean_absolute_error: 0.3880 - val_loss: 0.6077 - val_mean_absolute_error: 0.4371\n",
      "Epoch 86/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5144 - mean_absolute_error: 0.3836\n",
      "Epoch 00086: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5151 - mean_absolute_error: 0.3841 - val_loss: 0.6403 - val_mean_absolute_error: 0.4741\n",
      "Epoch 87/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5215 - mean_absolute_error: 0.3886\n",
      "Epoch 00087: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5212 - mean_absolute_error: 0.3884 - val_loss: 0.6399 - val_mean_absolute_error: 0.4532\n",
      "Epoch 88/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5177 - mean_absolute_error: 0.3831\n",
      "Epoch 00088: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5185 - mean_absolute_error: 0.3837 - val_loss: 0.5797 - val_mean_absolute_error: 0.4171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5208 - mean_absolute_error: 0.3872\n",
      "Epoch 00089: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5203 - mean_absolute_error: 0.3869 - val_loss: 0.5835 - val_mean_absolute_error: 0.4125\n",
      "Epoch 90/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5213 - mean_absolute_error: 0.3849\n",
      "Epoch 00090: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5213 - mean_absolute_error: 0.3849 - val_loss: 0.5595 - val_mean_absolute_error: 0.4127\n",
      "Epoch 91/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5283 - mean_absolute_error: 0.3912\n",
      "Epoch 00091: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5282 - mean_absolute_error: 0.3911 - val_loss: 0.5791 - val_mean_absolute_error: 0.4113\n",
      "Epoch 92/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5154 - mean_absolute_error: 0.3820\n",
      "Epoch 00092: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5164 - mean_absolute_error: 0.3822 - val_loss: 0.5649 - val_mean_absolute_error: 0.4120\n",
      "Epoch 93/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5066 - mean_absolute_error: 0.3794\n",
      "Epoch 00093: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5066 - mean_absolute_error: 0.3794 - val_loss: 0.5793 - val_mean_absolute_error: 0.4256\n",
      "Epoch 94/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5202 - mean_absolute_error: 0.3903\n",
      "Epoch 00094: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5201 - mean_absolute_error: 0.3903 - val_loss: 0.5755 - val_mean_absolute_error: 0.4167\n",
      "Epoch 95/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5098 - mean_absolute_error: 0.3802\n",
      "Epoch 00095: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5096 - mean_absolute_error: 0.3801 - val_loss: 0.6526 - val_mean_absolute_error: 0.4795\n",
      "Epoch 96/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5181 - mean_absolute_error: 0.3838\n",
      "Epoch 00096: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5180 - mean_absolute_error: 0.3838 - val_loss: 0.6164 - val_mean_absolute_error: 0.4471\n",
      "Epoch 97/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5102 - mean_absolute_error: 0.3818\n",
      "Epoch 00097: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5100 - mean_absolute_error: 0.3815 - val_loss: 0.5817 - val_mean_absolute_error: 0.4184\n",
      "Epoch 98/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5137 - mean_absolute_error: 0.3859\n",
      "Epoch 00098: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5142 - mean_absolute_error: 0.3861 - val_loss: 0.6218 - val_mean_absolute_error: 0.4550\n",
      "Epoch 99/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4990 - mean_absolute_error: 0.3770\n",
      "Epoch 00099: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4992 - mean_absolute_error: 0.3772 - val_loss: 0.7578 - val_mean_absolute_error: 0.5682\n",
      "Epoch 100/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5202 - mean_absolute_error: 0.3901\n",
      "Epoch 00100: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5200 - mean_absolute_error: 0.3900 - val_loss: 0.5801 - val_mean_absolute_error: 0.4170\n",
      "Epoch 101/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5029 - mean_absolute_error: 0.3745\n",
      "Epoch 00101: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5030 - mean_absolute_error: 0.3745 - val_loss: 0.5992 - val_mean_absolute_error: 0.4510\n",
      "Epoch 102/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5024 - mean_absolute_error: 0.3808\n",
      "Epoch 00102: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5025 - mean_absolute_error: 0.3809 - val_loss: 0.5975 - val_mean_absolute_error: 0.4272\n",
      "Epoch 103/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5028 - mean_absolute_error: 0.3804\n",
      "Epoch 00103: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 0.5028 - mean_absolute_error: 0.3805 - val_loss: 0.5782 - val_mean_absolute_error: 0.4212\n",
      "Epoch 104/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5199 - mean_absolute_error: 0.3881\n",
      "Epoch 00104: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5196 - mean_absolute_error: 0.3879 - val_loss: 0.6229 - val_mean_absolute_error: 0.4579\n",
      "Epoch 105/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5109 - mean_absolute_error: 0.3827\n",
      "Epoch 00105: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5110 - mean_absolute_error: 0.3828 - val_loss: 0.5906 - val_mean_absolute_error: 0.4198\n",
      "Epoch 106/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5090 - mean_absolute_error: 0.3793\n",
      "Epoch 00106: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5093 - mean_absolute_error: 0.3793 - val_loss: 0.5603 - val_mean_absolute_error: 0.4116\n",
      "Epoch 107/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4995 - mean_absolute_error: 0.3770\n",
      "Epoch 00107: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.4996 - mean_absolute_error: 0.3771 - val_loss: 0.5592 - val_mean_absolute_error: 0.4154\n",
      "Epoch 108/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5022 - mean_absolute_error: 0.3797\n",
      "Epoch 00108: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5022 - mean_absolute_error: 0.3797 - val_loss: 0.5811 - val_mean_absolute_error: 0.4171\n",
      "Epoch 109/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5035 - mean_absolute_error: 0.3790\n",
      "Epoch 00109: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5034 - mean_absolute_error: 0.3791 - val_loss: 0.5903 - val_mean_absolute_error: 0.4285\n",
      "Epoch 110/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4955 - mean_absolute_error: 0.3797\n",
      "Epoch 00110: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4953 - mean_absolute_error: 0.3796 - val_loss: 0.6015 - val_mean_absolute_error: 0.4410\n",
      "Epoch 111/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5010 - mean_absolute_error: 0.3785\n",
      "Epoch 00111: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5016 - mean_absolute_error: 0.3786 - val_loss: 0.5843 - val_mean_absolute_error: 0.4317\n",
      "Epoch 112/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5016 - mean_absolute_error: 0.3806\n",
      "Epoch 00112: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5019 - mean_absolute_error: 0.3810 - val_loss: 0.7007 - val_mean_absolute_error: 0.5085\n",
      "Epoch 113/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5048 - mean_absolute_error: 0.3817\n",
      "Epoch 00113: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5054 - mean_absolute_error: 0.3821 - val_loss: 0.5874 - val_mean_absolute_error: 0.4247\n",
      "Epoch 114/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4988 - mean_absolute_error: 0.3764\n",
      "Epoch 00114: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4989 - mean_absolute_error: 0.3765 - val_loss: 0.5518 - val_mean_absolute_error: 0.4111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4987 - mean_absolute_error: 0.3814\n",
      "Epoch 00115: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.4989 - mean_absolute_error: 0.3816 - val_loss: 0.5741 - val_mean_absolute_error: 0.4295\n",
      "Epoch 116/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5167 - mean_absolute_error: 0.3870\n",
      "Epoch 00116: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 219us/step - loss: 0.5167 - mean_absolute_error: 0.3871 - val_loss: 0.5426 - val_mean_absolute_error: 0.4047\n",
      "Epoch 117/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4877 - mean_absolute_error: 0.3725\n",
      "Epoch 00117: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 207us/step - loss: 0.4877 - mean_absolute_error: 0.3725 - val_loss: 0.5874 - val_mean_absolute_error: 0.4318\n",
      "Epoch 118/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5070 - mean_absolute_error: 0.3845\n",
      "Epoch 00118: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 211us/step - loss: 0.5076 - mean_absolute_error: 0.3850 - val_loss: 0.6020 - val_mean_absolute_error: 0.4456\n",
      "Epoch 119/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.5008 - mean_absolute_error: 0.3826\n",
      "Epoch 00119: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 0.5014 - mean_absolute_error: 0.3832 - val_loss: 0.5900 - val_mean_absolute_error: 0.4191\n",
      "Epoch 120/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4990 - mean_absolute_error: 0.3785\n",
      "Epoch 00120: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 215us/step - loss: 0.4992 - mean_absolute_error: 0.3785 - val_loss: 0.5663 - val_mean_absolute_error: 0.4163\n",
      "Epoch 121/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5050 - mean_absolute_error: 0.3806\n",
      "Epoch 00121: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5050 - mean_absolute_error: 0.3806 - val_loss: 0.6074 - val_mean_absolute_error: 0.4473\n",
      "Epoch 122/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4839 - mean_absolute_error: 0.3699\n",
      "Epoch 00122: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4839 - mean_absolute_error: 0.3700 - val_loss: 0.5823 - val_mean_absolute_error: 0.4363\n",
      "Epoch 123/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5149 - mean_absolute_error: 0.3910\n",
      "Epoch 00123: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5146 - mean_absolute_error: 0.3908 - val_loss: 0.5647 - val_mean_absolute_error: 0.4117\n",
      "Epoch 124/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4944 - mean_absolute_error: 0.3801\n",
      "Epoch 00124: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.4945 - mean_absolute_error: 0.3802 - val_loss: 0.5961 - val_mean_absolute_error: 0.4279\n",
      "Epoch 125/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4974 - mean_absolute_error: 0.3765\n",
      "Epoch 00125: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.4971 - mean_absolute_error: 0.3762 - val_loss: 0.5468 - val_mean_absolute_error: 0.4055\n",
      "Epoch 126/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4988 - mean_absolute_error: 0.3775\n",
      "Epoch 00126: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.4987 - mean_absolute_error: 0.3775 - val_loss: 0.5899 - val_mean_absolute_error: 0.4467\n",
      "Epoch 127/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.4859 - mean_absolute_error: 0.3732\n",
      "Epoch 00127: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 208us/step - loss: 0.4861 - mean_absolute_error: 0.3733 - val_loss: 0.6265 - val_mean_absolute_error: 0.4767\n",
      "Epoch 128/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.4936 - mean_absolute_error: 0.3807\n",
      "Epoch 00128: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4937 - mean_absolute_error: 0.3809 - val_loss: 0.5563 - val_mean_absolute_error: 0.4160\n",
      "Epoch 129/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5023 - mean_absolute_error: 0.3857\n",
      "Epoch 00129: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5022 - mean_absolute_error: 0.3856 - val_loss: 0.6179 - val_mean_absolute_error: 0.4735\n",
      "Epoch 130/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5056 - mean_absolute_error: 0.3797\n",
      "Epoch 00130: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.5056 - mean_absolute_error: 0.3797 - val_loss: 0.5562 - val_mean_absolute_error: 0.4094\n",
      "Epoch 131/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4872 - mean_absolute_error: 0.3733\n",
      "Epoch 00131: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 203us/step - loss: 0.4873 - mean_absolute_error: 0.3734 - val_loss: 0.5408 - val_mean_absolute_error: 0.4010\n",
      "Epoch 132/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4923 - mean_absolute_error: 0.3783\n",
      "Epoch 00132: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4928 - mean_absolute_error: 0.3785 - val_loss: 0.5629 - val_mean_absolute_error: 0.4181\n",
      "Epoch 133/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4939 - mean_absolute_error: 0.3828\n",
      "Epoch 00133: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4951 - mean_absolute_error: 0.3836 - val_loss: 0.7502 - val_mean_absolute_error: 0.5700\n",
      "Epoch 134/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4966 - mean_absolute_error: 0.3795\n",
      "Epoch 00134: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4966 - mean_absolute_error: 0.3797 - val_loss: 0.5684 - val_mean_absolute_error: 0.4146\n",
      "Epoch 135/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4987 - mean_absolute_error: 0.3811\n",
      "Epoch 00135: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4988 - mean_absolute_error: 0.3812 - val_loss: 0.5720 - val_mean_absolute_error: 0.4247\n",
      "Epoch 136/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4753 - mean_absolute_error: 0.3693\n",
      "Epoch 00136: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4753 - mean_absolute_error: 0.3693 - val_loss: 0.5618 - val_mean_absolute_error: 0.4120\n",
      "Epoch 137/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4901 - mean_absolute_error: 0.3781\n",
      "Epoch 00137: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4905 - mean_absolute_error: 0.3782 - val_loss: 0.5911 - val_mean_absolute_error: 0.4394\n",
      "Epoch 138/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5026 - mean_absolute_error: 0.3804\n",
      "Epoch 00138: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 0.5020 - mean_absolute_error: 0.3800 - val_loss: 0.5519 - val_mean_absolute_error: 0.4102\n",
      "Epoch 139/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4920 - mean_absolute_error: 0.3754\n",
      "Epoch 00139: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4923 - mean_absolute_error: 0.3757 - val_loss: 0.5574 - val_mean_absolute_error: 0.4117\n",
      "Epoch 140/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4831 - mean_absolute_error: 0.3711\n",
      "Epoch 00140: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4835 - mean_absolute_error: 0.3713 - val_loss: 0.5477 - val_mean_absolute_error: 0.4125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5001 - mean_absolute_error: 0.3781\n",
      "Epoch 00141: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.5006 - mean_absolute_error: 0.3784 - val_loss: 0.5545 - val_mean_absolute_error: 0.4136\n",
      "Epoch 142/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.4842 - mean_absolute_error: 0.3713\n",
      "Epoch 00142: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 204us/step - loss: 0.4849 - mean_absolute_error: 0.3716 - val_loss: 0.6401 - val_mean_absolute_error: 0.4753\n",
      "Epoch 143/200\n",
      "24064/24339 [============================>.] - ETA: 0s - loss: 0.4855 - mean_absolute_error: 0.3751\n",
      "Epoch 00143: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 205us/step - loss: 0.4857 - mean_absolute_error: 0.3751 - val_loss: 0.5448 - val_mean_absolute_error: 0.4152\n",
      "Epoch 144/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4848 - mean_absolute_error: 0.3734\n",
      "Epoch 00144: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 209us/step - loss: 0.4852 - mean_absolute_error: 0.3736 - val_loss: 0.5581 - val_mean_absolute_error: 0.4194\n",
      "Epoch 145/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4809 - mean_absolute_error: 0.3724\n",
      "Epoch 00145: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 207us/step - loss: 0.4810 - mean_absolute_error: 0.3724 - val_loss: 0.5641 - val_mean_absolute_error: 0.4184\n",
      "Epoch 146/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4791 - mean_absolute_error: 0.3743\n",
      "Epoch 00146: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 210us/step - loss: 0.4794 - mean_absolute_error: 0.3746 - val_loss: 0.5577 - val_mean_absolute_error: 0.4286\n",
      "Epoch 147/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4960 - mean_absolute_error: 0.3790\n",
      "Epoch 00147: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 214us/step - loss: 0.4960 - mean_absolute_error: 0.3790 - val_loss: 0.6223 - val_mean_absolute_error: 0.4712\n",
      "Epoch 148/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4878 - mean_absolute_error: 0.3792\n",
      "Epoch 00148: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.4877 - mean_absolute_error: 0.3792 - val_loss: 0.5358 - val_mean_absolute_error: 0.4038\n",
      "Epoch 149/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4737 - mean_absolute_error: 0.3726\n",
      "Epoch 00149: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 243us/step - loss: 0.4736 - mean_absolute_error: 0.3725 - val_loss: 0.5726 - val_mean_absolute_error: 0.4209\n",
      "Epoch 150/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4877 - mean_absolute_error: 0.3797\n",
      "Epoch 00150: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 244us/step - loss: 0.4878 - mean_absolute_error: 0.3799 - val_loss: 0.5811 - val_mean_absolute_error: 0.4437\n",
      "Epoch 151/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4841 - mean_absolute_error: 0.3744\n",
      "Epoch 00151: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 244us/step - loss: 0.4840 - mean_absolute_error: 0.3742 - val_loss: 0.5652 - val_mean_absolute_error: 0.4156\n",
      "Epoch 152/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4888 - mean_absolute_error: 0.3758\n",
      "Epoch 00152: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 250us/step - loss: 0.4889 - mean_absolute_error: 0.3759 - val_loss: 0.5697 - val_mean_absolute_error: 0.4290\n",
      "Epoch 153/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4787 - mean_absolute_error: 0.3676\n",
      "Epoch 00153: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.4797 - mean_absolute_error: 0.3682 - val_loss: 0.5549 - val_mean_absolute_error: 0.4214\n",
      "Epoch 154/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4827 - mean_absolute_error: 0.3765\n",
      "Epoch 00154: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.4827 - mean_absolute_error: 0.3766 - val_loss: 0.5684 - val_mean_absolute_error: 0.4300\n",
      "Epoch 155/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4807 - mean_absolute_error: 0.3746\n",
      "Epoch 00155: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.4806 - mean_absolute_error: 0.3744 - val_loss: 0.5620 - val_mean_absolute_error: 0.4203\n",
      "Epoch 156/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4895 - mean_absolute_error: 0.3749\n",
      "Epoch 00156: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.4895 - mean_absolute_error: 0.3751 - val_loss: 0.5869 - val_mean_absolute_error: 0.4300\n",
      "Epoch 157/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4798 - mean_absolute_error: 0.3744\n",
      "Epoch 00157: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.4801 - mean_absolute_error: 0.3747 - val_loss: 0.5774 - val_mean_absolute_error: 0.4218\n",
      "Epoch 158/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4778 - mean_absolute_error: 0.3765\n",
      "Epoch 00158: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.4777 - mean_absolute_error: 0.3764 - val_loss: 0.5818 - val_mean_absolute_error: 0.4388\n",
      "Epoch 159/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4813 - mean_absolute_error: 0.3773\n",
      "Epoch 00159: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.4814 - mean_absolute_error: 0.3774 - val_loss: 0.5094 - val_mean_absolute_error: 0.3937\n",
      "Epoch 160/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4790 - mean_absolute_error: 0.3743\n",
      "Epoch 00160: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.4788 - mean_absolute_error: 0.3743 - val_loss: 0.5960 - val_mean_absolute_error: 0.4434\n",
      "Epoch 161/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4903 - mean_absolute_error: 0.3782\n",
      "Epoch 00161: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.4901 - mean_absolute_error: 0.3781 - val_loss: 0.5868 - val_mean_absolute_error: 0.4269\n",
      "Epoch 162/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.4887 - mean_absolute_error: 0.3759\n",
      "Epoch 00162: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.4897 - mean_absolute_error: 0.3768 - val_loss: 0.5779 - val_mean_absolute_error: 0.4476\n",
      "Epoch 163/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4735 - mean_absolute_error: 0.3716\n",
      "Epoch 00163: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.4746 - mean_absolute_error: 0.3722 - val_loss: 0.5284 - val_mean_absolute_error: 0.4066\n",
      "Epoch 164/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4589 - mean_absolute_error: 0.3667\n",
      "Epoch 00164: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.4591 - mean_absolute_error: 0.3669 - val_loss: 0.5240 - val_mean_absolute_error: 0.4046\n",
      "Epoch 165/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4794 - mean_absolute_error: 0.3784\n",
      "Epoch 00165: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.4795 - mean_absolute_error: 0.3786 - val_loss: 0.5590 - val_mean_absolute_error: 0.4144\n",
      "Epoch 166/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.4843 - mean_absolute_error: 0.3777\n",
      "Epoch 00166: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.4843 - mean_absolute_error: 0.3778 - val_loss: 0.6374 - val_mean_absolute_error: 0.4451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4884 - mean_absolute_error: 0.3764\n",
      "Epoch 00167: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 219us/step - loss: 0.4885 - mean_absolute_error: 0.3765 - val_loss: 0.5624 - val_mean_absolute_error: 0.4240\n",
      "Epoch 168/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4715 - mean_absolute_error: 0.3689\n",
      "Epoch 00168: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 221us/step - loss: 0.4714 - mean_absolute_error: 0.3688 - val_loss: 0.5448 - val_mean_absolute_error: 0.4123\n",
      "Epoch 169/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4660 - mean_absolute_error: 0.3708\n",
      "Epoch 00169: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 221us/step - loss: 0.4660 - mean_absolute_error: 0.3708 - val_loss: 0.5371 - val_mean_absolute_error: 0.4143\n",
      "Epoch 170/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4726 - mean_absolute_error: 0.3719\n",
      "Epoch 00170: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 221us/step - loss: 0.4727 - mean_absolute_error: 0.3721 - val_loss: 0.6103 - val_mean_absolute_error: 0.4484\n",
      "Epoch 171/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4850 - mean_absolute_error: 0.3752\n",
      "Epoch 00171: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 222us/step - loss: 0.4848 - mean_absolute_error: 0.3752 - val_loss: 0.5853 - val_mean_absolute_error: 0.4473\n",
      "Epoch 172/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.4761 - mean_absolute_error: 0.3725\n",
      "Epoch 00172: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 222us/step - loss: 0.4760 - mean_absolute_error: 0.3725 - val_loss: 0.5335 - val_mean_absolute_error: 0.4098\n",
      "Epoch 173/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4848 - mean_absolute_error: 0.3768\n",
      "Epoch 00173: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 221us/step - loss: 0.4847 - mean_absolute_error: 0.3768 - val_loss: 0.5275 - val_mean_absolute_error: 0.4078\n",
      "Epoch 174/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4664 - mean_absolute_error: 0.3693\n",
      "Epoch 00174: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 223us/step - loss: 0.4662 - mean_absolute_error: 0.3692 - val_loss: 0.5574 - val_mean_absolute_error: 0.4158\n",
      "Epoch 175/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4699 - mean_absolute_error: 0.3713\n",
      "Epoch 00175: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 224us/step - loss: 0.4705 - mean_absolute_error: 0.3714 - val_loss: 0.5568 - val_mean_absolute_error: 0.4215\n",
      "Epoch 176/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4809 - mean_absolute_error: 0.3801\n",
      "Epoch 00176: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 224us/step - loss: 0.4812 - mean_absolute_error: 0.3803 - val_loss: 0.5376 - val_mean_absolute_error: 0.4077\n",
      "Epoch 177/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4818 - mean_absolute_error: 0.3720\n",
      "Epoch 00177: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 223us/step - loss: 0.4819 - mean_absolute_error: 0.3721 - val_loss: 0.5358 - val_mean_absolute_error: 0.4100\n",
      "Epoch 178/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4630 - mean_absolute_error: 0.3676\n",
      "Epoch 00178: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 225us/step - loss: 0.4634 - mean_absolute_error: 0.3679 - val_loss: 0.5366 - val_mean_absolute_error: 0.4150\n",
      "Epoch 179/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4699 - mean_absolute_error: 0.3730\n",
      "Epoch 00179: saving model to session/Crowd01/17\n",
      "24339/24339 [==============================] - 5s 225us/step - loss: 0.4699 - mean_absolute_error: 0.3730 - val_loss: 0.5832 - val_mean_absolute_error: 0.4399\n",
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 28.2140 - mean_absolute_error: 2.7900\n",
      "Epoch 00001: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 8s 338us/step - loss: 28.0914 - mean_absolute_error: 2.7827 - val_loss: 15.5852 - val_mean_absolute_error: 2.2955\n",
      "Epoch 2/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 10.5211 - mean_absolute_error: 1.4024\n",
      "Epoch 00002: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 10.5051 - mean_absolute_error: 1.3998 - val_loss: 7.5228 - val_mean_absolute_error: 0.9468\n",
      "Epoch 3/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 6.0045 - mean_absolute_error: 0.6562\n",
      "Epoch 00003: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 6.0016 - mean_absolute_error: 0.6564 - val_loss: 5.6987 - val_mean_absolute_error: 0.8969\n",
      "Epoch 4/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 4.4198 - mean_absolute_error: 0.5506\n",
      "Epoch 00004: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 4.4173 - mean_absolute_error: 0.5504 - val_loss: 4.1163 - val_mean_absolute_error: 0.6692\n",
      "Epoch 5/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 3.4231 - mean_absolute_error: 0.5546\n",
      "Epoch 00005: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 3.4217 - mean_absolute_error: 0.5546 - val_loss: 3.1114 - val_mean_absolute_error: 0.5822\n",
      "Epoch 6/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 2.6916 - mean_absolute_error: 0.5442\n",
      "Epoch 00006: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 2.6901 - mean_absolute_error: 0.5443 - val_loss: 2.3824 - val_mean_absolute_error: 0.5378\n",
      "Epoch 7/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 2.1668 - mean_absolute_error: 0.5492\n",
      "Epoch 00007: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 2.1664 - mean_absolute_error: 0.5493 - val_loss: 1.9608 - val_mean_absolute_error: 0.5505\n",
      "Epoch 8/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 1.7135 - mean_absolute_error: 0.5053\n",
      "Epoch 00008: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 1.7129 - mean_absolute_error: 0.5051 - val_loss: 1.5639 - val_mean_absolute_error: 0.4969\n",
      "Epoch 9/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 1.5316 - mean_absolute_error: 0.5424\n",
      "Epoch 00009: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 1.5321 - mean_absolute_error: 0.5425 - val_loss: 1.8085 - val_mean_absolute_error: 0.7395\n",
      "Epoch 10/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 1.3531 - mean_absolute_error: 0.5230\n",
      "Epoch 00010: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 1.3530 - mean_absolute_error: 0.5234 - val_loss: 1.3599 - val_mean_absolute_error: 0.5316\n",
      "Epoch 11/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 1.2938 - mean_absolute_error: 0.5330\n",
      "Epoch 00011: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 1.2935 - mean_absolute_error: 0.5328 - val_loss: 1.3865 - val_mean_absolute_error: 0.6161\n",
      "Epoch 12/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 1.1945 - mean_absolute_error: 0.5180\n",
      "Epoch 00012: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 1.1948 - mean_absolute_error: 0.5181 - val_loss: 1.2191 - val_mean_absolute_error: 0.5227\n",
      "Epoch 13/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 1.0878 - mean_absolute_error: 0.4900\n",
      "Epoch 00013: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 1.0877 - mean_absolute_error: 0.4900 - val_loss: 1.0773 - val_mean_absolute_error: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 1.1106 - mean_absolute_error: 0.5235\n",
      "Epoch 00014: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 1.1105 - mean_absolute_error: 0.5235 - val_loss: 1.2407 - val_mean_absolute_error: 0.6002\n",
      "Epoch 15/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 1.0208 - mean_absolute_error: 0.4895\n",
      "Epoch 00015: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 226us/step - loss: 1.0214 - mean_absolute_error: 0.4896 - val_loss: 1.0386 - val_mean_absolute_error: 0.4717\n",
      "Epoch 16/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.9794 - mean_absolute_error: 0.4784\n",
      "Epoch 00016: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 5s 226us/step - loss: 0.9795 - mean_absolute_error: 0.4786 - val_loss: 0.9525 - val_mean_absolute_error: 0.4677\n",
      "Epoch 17/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.8778 - mean_absolute_error: 0.4552\n",
      "Epoch 00017: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.8801 - mean_absolute_error: 0.4558 - val_loss: 0.9717 - val_mean_absolute_error: 0.4802\n",
      "Epoch 18/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.8553 - mean_absolute_error: 0.4511\n",
      "Epoch 00018: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 5s 226us/step - loss: 0.8559 - mean_absolute_error: 0.4514 - val_loss: 0.9535 - val_mean_absolute_error: 0.4828\n",
      "Epoch 19/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.8552 - mean_absolute_error: 0.4532\n",
      "Epoch 00019: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.8555 - mean_absolute_error: 0.4536 - val_loss: 0.9417 - val_mean_absolute_error: 0.5198\n",
      "Epoch 20/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.7881 - mean_absolute_error: 0.4322\n",
      "Epoch 00020: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.7881 - mean_absolute_error: 0.4322 - val_loss: 0.8507 - val_mean_absolute_error: 0.4717\n",
      "Epoch 21/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.7510 - mean_absolute_error: 0.4334\n",
      "Epoch 00021: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.7532 - mean_absolute_error: 0.4350 - val_loss: 0.8166 - val_mean_absolute_error: 0.4492\n",
      "Epoch 22/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.7470 - mean_absolute_error: 0.4333\n",
      "Epoch 00022: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.7472 - mean_absolute_error: 0.4334 - val_loss: 0.8356 - val_mean_absolute_error: 0.4691\n",
      "Epoch 23/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.7170 - mean_absolute_error: 0.4343\n",
      "Epoch 00023: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.7171 - mean_absolute_error: 0.4343 - val_loss: 0.8285 - val_mean_absolute_error: 0.4707\n",
      "Epoch 24/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.6920 - mean_absolute_error: 0.4280\n",
      "Epoch 00024: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.6925 - mean_absolute_error: 0.4286 - val_loss: 0.8488 - val_mean_absolute_error: 0.5443\n",
      "Epoch 25/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6678 - mean_absolute_error: 0.4266\n",
      "Epoch 00025: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.6679 - mean_absolute_error: 0.4265 - val_loss: 0.7827 - val_mean_absolute_error: 0.4629\n",
      "Epoch 26/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.7050 - mean_absolute_error: 0.4352\n",
      "Epoch 00026: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.7043 - mean_absolute_error: 0.4348 - val_loss: 0.7301 - val_mean_absolute_error: 0.4401\n",
      "Epoch 27/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.6488 - mean_absolute_error: 0.4171\n",
      "Epoch 00027: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.6487 - mean_absolute_error: 0.4170 - val_loss: 0.6799 - val_mean_absolute_error: 0.4315\n",
      "Epoch 28/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.6394 - mean_absolute_error: 0.4247\n",
      "Epoch 00028: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.6404 - mean_absolute_error: 0.4252 - val_loss: 0.7896 - val_mean_absolute_error: 0.5052\n",
      "Epoch 29/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6282 - mean_absolute_error: 0.4135\n",
      "Epoch 00029: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.6282 - mean_absolute_error: 0.4135 - val_loss: 0.6758 - val_mean_absolute_error: 0.4261\n",
      "Epoch 30/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.6172 - mean_absolute_error: 0.4107\n",
      "Epoch 00030: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.6170 - mean_absolute_error: 0.4107 - val_loss: 0.8344 - val_mean_absolute_error: 0.5637\n",
      "Epoch 31/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6427 - mean_absolute_error: 0.4226\n",
      "Epoch 00031: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.6428 - mean_absolute_error: 0.4228 - val_loss: 0.7579 - val_mean_absolute_error: 0.5068\n",
      "Epoch 32/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.6012 - mean_absolute_error: 0.4089\n",
      "Epoch 00032: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.6011 - mean_absolute_error: 0.4088 - val_loss: 0.7355 - val_mean_absolute_error: 0.4970\n",
      "Epoch 33/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5939 - mean_absolute_error: 0.4080\n",
      "Epoch 00033: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5939 - mean_absolute_error: 0.4080 - val_loss: 0.6534 - val_mean_absolute_error: 0.4248\n",
      "Epoch 34/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5880 - mean_absolute_error: 0.3980\n",
      "Epoch 00034: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5880 - mean_absolute_error: 0.3980 - val_loss: 0.6592 - val_mean_absolute_error: 0.4250\n",
      "Epoch 35/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.6139 - mean_absolute_error: 0.4211\n",
      "Epoch 00035: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.6139 - mean_absolute_error: 0.4212 - val_loss: 0.7466 - val_mean_absolute_error: 0.4963\n",
      "Epoch 36/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5813 - mean_absolute_error: 0.4049\n",
      "Epoch 00036: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5814 - mean_absolute_error: 0.4050 - val_loss: 0.6380 - val_mean_absolute_error: 0.4326\n",
      "Epoch 37/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5785 - mean_absolute_error: 0.4047\n",
      "Epoch 00037: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5785 - mean_absolute_error: 0.4048 - val_loss: 0.6946 - val_mean_absolute_error: 0.4447\n",
      "Epoch 38/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5872 - mean_absolute_error: 0.4024\n",
      "Epoch 00038: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5870 - mean_absolute_error: 0.4022 - val_loss: 0.6242 - val_mean_absolute_error: 0.4221\n",
      "Epoch 39/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5861 - mean_absolute_error: 0.4129\n",
      "Epoch 00039: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5861 - mean_absolute_error: 0.4129 - val_loss: 0.6524 - val_mean_absolute_error: 0.4385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5828 - mean_absolute_error: 0.4052\n",
      "Epoch 00040: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 5s 226us/step - loss: 0.5830 - mean_absolute_error: 0.4054 - val_loss: 0.6468 - val_mean_absolute_error: 0.4253\n",
      "Epoch 41/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5755 - mean_absolute_error: 0.4014\n",
      "Epoch 00041: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5755 - mean_absolute_error: 0.4014 - val_loss: 0.6561 - val_mean_absolute_error: 0.4314\n",
      "Epoch 42/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5787 - mean_absolute_error: 0.4066\n",
      "Epoch 00042: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5785 - mean_absolute_error: 0.4064 - val_loss: 0.6484 - val_mean_absolute_error: 0.4264\n",
      "Epoch 43/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5664 - mean_absolute_error: 0.3991\n",
      "Epoch 00043: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5676 - mean_absolute_error: 0.3996 - val_loss: 0.6637 - val_mean_absolute_error: 0.4420\n",
      "Epoch 44/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5857 - mean_absolute_error: 0.3988\n",
      "Epoch 00044: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5859 - mean_absolute_error: 0.3989 - val_loss: 0.7951 - val_mean_absolute_error: 0.5471\n",
      "Epoch 45/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5803 - mean_absolute_error: 0.4038\n",
      "Epoch 00045: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5803 - mean_absolute_error: 0.4038 - val_loss: 0.6006 - val_mean_absolute_error: 0.4144\n",
      "Epoch 46/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5778 - mean_absolute_error: 0.4080\n",
      "Epoch 00046: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5784 - mean_absolute_error: 0.4083 - val_loss: 0.6587 - val_mean_absolute_error: 0.4523\n",
      "Epoch 47/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5750 - mean_absolute_error: 0.4088\n",
      "Epoch 00047: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5756 - mean_absolute_error: 0.4089 - val_loss: 0.6236 - val_mean_absolute_error: 0.4268\n",
      "Epoch 48/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5629 - mean_absolute_error: 0.3995\n",
      "Epoch 00048: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5629 - mean_absolute_error: 0.3997 - val_loss: 0.6307 - val_mean_absolute_error: 0.4406\n",
      "Epoch 49/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5663 - mean_absolute_error: 0.4013\n",
      "Epoch 00049: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5662 - mean_absolute_error: 0.4013 - val_loss: 0.6231 - val_mean_absolute_error: 0.4436\n",
      "Epoch 50/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5521 - mean_absolute_error: 0.3937\n",
      "Epoch 00050: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5524 - mean_absolute_error: 0.3940 - val_loss: 0.6096 - val_mean_absolute_error: 0.4242\n",
      "Epoch 51/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5578 - mean_absolute_error: 0.3947\n",
      "Epoch 00051: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5580 - mean_absolute_error: 0.3948 - val_loss: 0.6088 - val_mean_absolute_error: 0.4224\n",
      "Epoch 52/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5550 - mean_absolute_error: 0.3984\n",
      "Epoch 00052: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5552 - mean_absolute_error: 0.3986 - val_loss: 0.6453 - val_mean_absolute_error: 0.4363\n",
      "Epoch 53/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5735 - mean_absolute_error: 0.4058\n",
      "Epoch 00053: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5732 - mean_absolute_error: 0.4055 - val_loss: 0.6416 - val_mean_absolute_error: 0.4452\n",
      "Epoch 54/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5523 - mean_absolute_error: 0.3904\n",
      "Epoch 00054: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5526 - mean_absolute_error: 0.3907 - val_loss: 0.6360 - val_mean_absolute_error: 0.4441\n",
      "Epoch 55/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5563 - mean_absolute_error: 0.3903\n",
      "Epoch 00055: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5565 - mean_absolute_error: 0.3904 - val_loss: 0.6234 - val_mean_absolute_error: 0.4262\n",
      "Epoch 56/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5568 - mean_absolute_error: 0.3948\n",
      "Epoch 00056: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5567 - mean_absolute_error: 0.3947 - val_loss: 0.6626 - val_mean_absolute_error: 0.4602\n",
      "Epoch 57/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5526 - mean_absolute_error: 0.3946\n",
      "Epoch 00057: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5525 - mean_absolute_error: 0.3945 - val_loss: 0.5908 - val_mean_absolute_error: 0.4106\n",
      "Epoch 58/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5562 - mean_absolute_error: 0.3977\n",
      "Epoch 00058: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5555 - mean_absolute_error: 0.3973 - val_loss: 0.6305 - val_mean_absolute_error: 0.4370\n",
      "Epoch 59/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5432 - mean_absolute_error: 0.3871\n",
      "Epoch 00059: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5435 - mean_absolute_error: 0.3873 - val_loss: 0.6940 - val_mean_absolute_error: 0.4898\n",
      "Epoch 60/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5398 - mean_absolute_error: 0.3870\n",
      "Epoch 00060: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5397 - mean_absolute_error: 0.3870 - val_loss: 0.6145 - val_mean_absolute_error: 0.4308\n",
      "Epoch 61/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5610 - mean_absolute_error: 0.4018\n",
      "Epoch 00061: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5614 - mean_absolute_error: 0.4021 - val_loss: 0.8001 - val_mean_absolute_error: 0.5662\n",
      "Epoch 62/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5503 - mean_absolute_error: 0.3947\n",
      "Epoch 00062: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5507 - mean_absolute_error: 0.3951 - val_loss: 0.6975 - val_mean_absolute_error: 0.4787\n",
      "Epoch 63/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5508 - mean_absolute_error: 0.3961\n",
      "Epoch 00063: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5511 - mean_absolute_error: 0.3962 - val_loss: 0.5822 - val_mean_absolute_error: 0.4091\n",
      "Epoch 64/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5390 - mean_absolute_error: 0.3827\n",
      "Epoch 00064: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5390 - mean_absolute_error: 0.3827 - val_loss: 0.6869 - val_mean_absolute_error: 0.4743\n",
      "Epoch 65/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5424 - mean_absolute_error: 0.3873\n",
      "Epoch 00065: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5427 - mean_absolute_error: 0.3874 - val_loss: 0.6182 - val_mean_absolute_error: 0.4354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5367 - mean_absolute_error: 0.3886\n",
      "Epoch 00066: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 5s 224us/step - loss: 0.5371 - mean_absolute_error: 0.3887 - val_loss: 0.6251 - val_mean_absolute_error: 0.4368\n",
      "Epoch 67/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5567 - mean_absolute_error: 0.4015\n",
      "Epoch 00067: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5570 - mean_absolute_error: 0.4017 - val_loss: 0.6024 - val_mean_absolute_error: 0.4155\n",
      "Epoch 68/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5393 - mean_absolute_error: 0.3840\n",
      "Epoch 00068: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 5s 226us/step - loss: 0.5394 - mean_absolute_error: 0.3842 - val_loss: 0.6322 - val_mean_absolute_error: 0.4330\n",
      "Epoch 69/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5324 - mean_absolute_error: 0.3853\n",
      "Epoch 00069: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5324 - mean_absolute_error: 0.3853 - val_loss: 0.5814 - val_mean_absolute_error: 0.4086\n",
      "Epoch 70/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5297 - mean_absolute_error: 0.3871\n",
      "Epoch 00070: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 5s 226us/step - loss: 0.5297 - mean_absolute_error: 0.3871 - val_loss: 0.5918 - val_mean_absolute_error: 0.4147\n",
      "Epoch 71/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5215 - mean_absolute_error: 0.3823\n",
      "Epoch 00071: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5216 - mean_absolute_error: 0.3824 - val_loss: 0.6195 - val_mean_absolute_error: 0.4274\n",
      "Epoch 72/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5448 - mean_absolute_error: 0.3922\n",
      "Epoch 00072: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5445 - mean_absolute_error: 0.3921 - val_loss: 0.5918 - val_mean_absolute_error: 0.4101\n",
      "Epoch 73/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5226 - mean_absolute_error: 0.3786\n",
      "Epoch 00073: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5226 - mean_absolute_error: 0.3786 - val_loss: 0.6240 - val_mean_absolute_error: 0.4454\n",
      "Epoch 74/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5275 - mean_absolute_error: 0.3860\n",
      "Epoch 00074: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5278 - mean_absolute_error: 0.3861 - val_loss: 0.6199 - val_mean_absolute_error: 0.4464\n",
      "Epoch 75/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5177 - mean_absolute_error: 0.3833\n",
      "Epoch 00075: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5184 - mean_absolute_error: 0.3836 - val_loss: 0.6259 - val_mean_absolute_error: 0.4412\n",
      "Epoch 76/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5301 - mean_absolute_error: 0.3876\n",
      "Epoch 00076: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5300 - mean_absolute_error: 0.3876 - val_loss: 0.5768 - val_mean_absolute_error: 0.4064\n",
      "Epoch 77/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5275 - mean_absolute_error: 0.3861\n",
      "Epoch 00077: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5275 - mean_absolute_error: 0.3860 - val_loss: 0.6246 - val_mean_absolute_error: 0.4411\n",
      "Epoch 78/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5343 - mean_absolute_error: 0.3901\n",
      "Epoch 00078: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5342 - mean_absolute_error: 0.3900 - val_loss: 0.6001 - val_mean_absolute_error: 0.4278\n",
      "Epoch 79/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5461 - mean_absolute_error: 0.3981\n",
      "Epoch 00079: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5461 - mean_absolute_error: 0.3980 - val_loss: 0.6595 - val_mean_absolute_error: 0.4336\n",
      "Epoch 80/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5339 - mean_absolute_error: 0.3817\n",
      "Epoch 00080: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5347 - mean_absolute_error: 0.3823 - val_loss: 0.5823 - val_mean_absolute_error: 0.4204\n",
      "Epoch 81/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5102 - mean_absolute_error: 0.3758\n",
      "Epoch 00081: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5104 - mean_absolute_error: 0.3761 - val_loss: 0.5818 - val_mean_absolute_error: 0.4133\n",
      "Epoch 82/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5125 - mean_absolute_error: 0.3810\n",
      "Epoch 00082: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5125 - mean_absolute_error: 0.3810 - val_loss: 0.6057 - val_mean_absolute_error: 0.4244\n",
      "Epoch 83/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5380 - mean_absolute_error: 0.3918\n",
      "Epoch 00083: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5385 - mean_absolute_error: 0.3920 - val_loss: 0.6420 - val_mean_absolute_error: 0.4537\n",
      "Epoch 84/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5270 - mean_absolute_error: 0.3845\n",
      "Epoch 00084: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5268 - mean_absolute_error: 0.3844 - val_loss: 0.5747 - val_mean_absolute_error: 0.4131\n",
      "Epoch 85/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5147 - mean_absolute_error: 0.3809\n",
      "Epoch 00085: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5149 - mean_absolute_error: 0.3812 - val_loss: 0.6330 - val_mean_absolute_error: 0.4611\n",
      "Epoch 86/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5173 - mean_absolute_error: 0.3792\n",
      "Epoch 00086: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5179 - mean_absolute_error: 0.3798 - val_loss: 0.5764 - val_mean_absolute_error: 0.4144\n",
      "Epoch 87/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5247 - mean_absolute_error: 0.3872\n",
      "Epoch 00087: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5246 - mean_absolute_error: 0.3872 - val_loss: 0.5830 - val_mean_absolute_error: 0.4178\n",
      "Epoch 88/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5088 - mean_absolute_error: 0.3771\n",
      "Epoch 00088: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5099 - mean_absolute_error: 0.3778 - val_loss: 0.6102 - val_mean_absolute_error: 0.4398\n",
      "Epoch 89/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5090 - mean_absolute_error: 0.3770\n",
      "Epoch 00089: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5094 - mean_absolute_error: 0.3773 - val_loss: 0.5778 - val_mean_absolute_error: 0.4133\n",
      "Epoch 90/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5254 - mean_absolute_error: 0.3881\n",
      "Epoch 00090: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5269 - mean_absolute_error: 0.3889 - val_loss: 0.6287 - val_mean_absolute_error: 0.4532\n",
      "Epoch 91/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5247 - mean_absolute_error: 0.3875\n",
      "Epoch 00091: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5248 - mean_absolute_error: 0.3876 - val_loss: 0.5841 - val_mean_absolute_error: 0.4119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5206 - mean_absolute_error: 0.3867\n",
      "Epoch 00092: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 5s 225us/step - loss: 0.5206 - mean_absolute_error: 0.3867 - val_loss: 0.6553 - val_mean_absolute_error: 0.4829\n",
      "Epoch 93/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5100 - mean_absolute_error: 0.3759\n",
      "Epoch 00093: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 226us/step - loss: 0.5100 - mean_absolute_error: 0.3759 - val_loss: 0.6086 - val_mean_absolute_error: 0.4426\n",
      "Epoch 94/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5007 - mean_absolute_error: 0.3768\n",
      "Epoch 00094: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5012 - mean_absolute_error: 0.3769 - val_loss: 0.5805 - val_mean_absolute_error: 0.4125\n",
      "Epoch 95/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5046 - mean_absolute_error: 0.3747\n",
      "Epoch 00095: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 226us/step - loss: 0.5046 - mean_absolute_error: 0.3748 - val_loss: 0.5734 - val_mean_absolute_error: 0.4239\n",
      "Epoch 96/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5347 - mean_absolute_error: 0.3993\n",
      "Epoch 00096: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5349 - mean_absolute_error: 0.3993 - val_loss: 0.5896 - val_mean_absolute_error: 0.4117\n",
      "Epoch 97/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5064 - mean_absolute_error: 0.3760\n",
      "Epoch 00097: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5063 - mean_absolute_error: 0.3761 - val_loss: 0.5733 - val_mean_absolute_error: 0.4186\n",
      "Epoch 98/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5042 - mean_absolute_error: 0.3731\n",
      "Epoch 00098: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5043 - mean_absolute_error: 0.3732 - val_loss: 0.5894 - val_mean_absolute_error: 0.4214\n",
      "Epoch 99/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5122 - mean_absolute_error: 0.3828\n",
      "Epoch 00099: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5125 - mean_absolute_error: 0.3829 - val_loss: 0.5727 - val_mean_absolute_error: 0.4124\n",
      "Epoch 100/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5258 - mean_absolute_error: 0.3863\n",
      "Epoch 00100: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5258 - mean_absolute_error: 0.3863 - val_loss: 0.5808 - val_mean_absolute_error: 0.4310\n",
      "Epoch 101/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5102 - mean_absolute_error: 0.3804\n",
      "Epoch 00101: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5102 - mean_absolute_error: 0.3804 - val_loss: 0.5833 - val_mean_absolute_error: 0.4130\n",
      "Epoch 102/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5094 - mean_absolute_error: 0.3780\n",
      "Epoch 00102: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5094 - mean_absolute_error: 0.3781 - val_loss: 0.5688 - val_mean_absolute_error: 0.4093\n",
      "Epoch 103/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5033 - mean_absolute_error: 0.3772\n",
      "Epoch 00103: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5045 - mean_absolute_error: 0.3777 - val_loss: 0.6002 - val_mean_absolute_error: 0.4410\n",
      "Epoch 104/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5195 - mean_absolute_error: 0.3852\n",
      "Epoch 00104: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.5195 - mean_absolute_error: 0.3853 - val_loss: 0.5562 - val_mean_absolute_error: 0.4060\n",
      "Epoch 105/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5034 - mean_absolute_error: 0.3781\n",
      "Epoch 00105: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5037 - mean_absolute_error: 0.3784 - val_loss: 0.5692 - val_mean_absolute_error: 0.4122\n",
      "Epoch 106/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5094 - mean_absolute_error: 0.3808\n",
      "Epoch 00106: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5093 - mean_absolute_error: 0.3808 - val_loss: 0.5670 - val_mean_absolute_error: 0.4218\n",
      "Epoch 107/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5078 - mean_absolute_error: 0.3809\n",
      "Epoch 00107: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5076 - mean_absolute_error: 0.3806 - val_loss: 0.6446 - val_mean_absolute_error: 0.4600\n",
      "Epoch 108/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5106 - mean_absolute_error: 0.3810\n",
      "Epoch 00108: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5107 - mean_absolute_error: 0.3811 - val_loss: 0.5732 - val_mean_absolute_error: 0.4166\n",
      "Epoch 109/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4992 - mean_absolute_error: 0.3785\n",
      "Epoch 00109: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.4996 - mean_absolute_error: 0.3787 - val_loss: 0.6148 - val_mean_absolute_error: 0.4400\n",
      "Epoch 110/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5169 - mean_absolute_error: 0.3804\n",
      "Epoch 00110: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5169 - mean_absolute_error: 0.3804 - val_loss: 0.5972 - val_mean_absolute_error: 0.4304\n",
      "Epoch 111/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4925 - mean_absolute_error: 0.3703\n",
      "Epoch 00111: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.4927 - mean_absolute_error: 0.3704 - val_loss: 0.6217 - val_mean_absolute_error: 0.4733\n",
      "Epoch 112/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5056 - mean_absolute_error: 0.3834\n",
      "Epoch 00112: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.5054 - mean_absolute_error: 0.3833 - val_loss: 0.5596 - val_mean_absolute_error: 0.3958\n",
      "Epoch 113/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5090 - mean_absolute_error: 0.3799\n",
      "Epoch 00113: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5089 - mean_absolute_error: 0.3798 - val_loss: 0.7983 - val_mean_absolute_error: 0.5772\n",
      "Epoch 114/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5140 - mean_absolute_error: 0.3833\n",
      "Epoch 00114: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5141 - mean_absolute_error: 0.3834 - val_loss: 0.6005 - val_mean_absolute_error: 0.4355\n",
      "Epoch 115/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4972 - mean_absolute_error: 0.3737\n",
      "Epoch 00115: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.4974 - mean_absolute_error: 0.3739 - val_loss: 0.5739 - val_mean_absolute_error: 0.4205\n",
      "Epoch 116/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4945 - mean_absolute_error: 0.3732\n",
      "Epoch 00116: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.4945 - mean_absolute_error: 0.3731 - val_loss: 0.5690 - val_mean_absolute_error: 0.4215\n",
      "Epoch 117/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5039 - mean_absolute_error: 0.3818\n",
      "Epoch 00117: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5039 - mean_absolute_error: 0.3818 - val_loss: 0.5722 - val_mean_absolute_error: 0.4169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5004 - mean_absolute_error: 0.3763\n",
      "Epoch 00118: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 226us/step - loss: 0.5008 - mean_absolute_error: 0.3765 - val_loss: 0.5604 - val_mean_absolute_error: 0.4118\n",
      "Epoch 119/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.4948 - mean_absolute_error: 0.3706\n",
      "Epoch 00119: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.4947 - mean_absolute_error: 0.3704 - val_loss: 0.5436 - val_mean_absolute_error: 0.3986\n",
      "Epoch 120/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4971 - mean_absolute_error: 0.3751\n",
      "Epoch 00120: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 226us/step - loss: 0.4978 - mean_absolute_error: 0.3755 - val_loss: 0.6859 - val_mean_absolute_error: 0.5163\n",
      "Epoch 121/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4978 - mean_absolute_error: 0.3745\n",
      "Epoch 00121: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.4980 - mean_absolute_error: 0.3747 - val_loss: 0.6152 - val_mean_absolute_error: 0.4540\n",
      "Epoch 122/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4973 - mean_absolute_error: 0.3801\n",
      "Epoch 00122: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.4971 - mean_absolute_error: 0.3799 - val_loss: 0.5862 - val_mean_absolute_error: 0.4206\n",
      "Epoch 123/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5065 - mean_absolute_error: 0.3786\n",
      "Epoch 00123: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.5066 - mean_absolute_error: 0.3788 - val_loss: 0.5918 - val_mean_absolute_error: 0.4427\n",
      "Epoch 124/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4887 - mean_absolute_error: 0.3704\n",
      "Epoch 00124: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 227us/step - loss: 0.4888 - mean_absolute_error: 0.3706 - val_loss: 0.5878 - val_mean_absolute_error: 0.4214\n",
      "Epoch 125/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5010 - mean_absolute_error: 0.3769\n",
      "Epoch 00125: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5020 - mean_absolute_error: 0.3773 - val_loss: 0.5759 - val_mean_absolute_error: 0.4244\n",
      "Epoch 126/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4958 - mean_absolute_error: 0.3754\n",
      "Epoch 00126: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.4961 - mean_absolute_error: 0.3756 - val_loss: 0.5503 - val_mean_absolute_error: 0.4141\n",
      "Epoch 127/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5069 - mean_absolute_error: 0.3836\n",
      "Epoch 00127: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 228us/step - loss: 0.5073 - mean_absolute_error: 0.3838 - val_loss: 0.5824 - val_mean_absolute_error: 0.4382\n",
      "Epoch 128/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4875 - mean_absolute_error: 0.3734\n",
      "Epoch 00128: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 229us/step - loss: 0.4876 - mean_absolute_error: 0.3734 - val_loss: 0.5699 - val_mean_absolute_error: 0.4336\n",
      "Epoch 129/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4956 - mean_absolute_error: 0.3758\n",
      "Epoch 00129: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.4963 - mean_absolute_error: 0.3761 - val_loss: 0.5500 - val_mean_absolute_error: 0.4049\n",
      "Epoch 130/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4856 - mean_absolute_error: 0.3678\n",
      "Epoch 00130: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.4857 - mean_absolute_error: 0.3679 - val_loss: 0.5508 - val_mean_absolute_error: 0.4064\n",
      "Epoch 131/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4939 - mean_absolute_error: 0.3788\n",
      "Epoch 00131: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.4937 - mean_absolute_error: 0.3786 - val_loss: 0.5620 - val_mean_absolute_error: 0.4188\n",
      "Epoch 132/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5043 - mean_absolute_error: 0.3810\n",
      "Epoch 00132: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5044 - mean_absolute_error: 0.3810 - val_loss: 0.5876 - val_mean_absolute_error: 0.4373\n",
      "Epoch 133/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4949 - mean_absolute_error: 0.3764\n",
      "Epoch 00133: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.4953 - mean_absolute_error: 0.3765 - val_loss: 0.5624 - val_mean_absolute_error: 0.4197\n",
      "Epoch 134/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5012 - mean_absolute_error: 0.3792\n",
      "Epoch 00134: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5010 - mean_absolute_error: 0.3791 - val_loss: 0.5654 - val_mean_absolute_error: 0.4224\n",
      "Epoch 135/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4912 - mean_absolute_error: 0.3738\n",
      "Epoch 00135: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.4912 - mean_absolute_error: 0.3737 - val_loss: 0.5783 - val_mean_absolute_error: 0.4234\n",
      "Epoch 136/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4925 - mean_absolute_error: 0.3768\n",
      "Epoch 00136: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.4925 - mean_absolute_error: 0.3769 - val_loss: 0.5576 - val_mean_absolute_error: 0.4339\n",
      "Epoch 137/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.4795 - mean_absolute_error: 0.3725\n",
      "Epoch 00137: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.4798 - mean_absolute_error: 0.3727 - val_loss: 0.5681 - val_mean_absolute_error: 0.4184\n",
      "Epoch 138/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.4890 - mean_absolute_error: 0.3736\n",
      "Epoch 00138: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.4890 - mean_absolute_error: 0.3736 - val_loss: 0.5554 - val_mean_absolute_error: 0.4138\n",
      "Epoch 139/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4882 - mean_absolute_error: 0.3701\n",
      "Epoch 00139: saving model to session/Crowd01/18\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.4881 - mean_absolute_error: 0.3701 - val_loss: 0.5771 - val_mean_absolute_error: 0.4276\n",
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 30.2380 - mean_absolute_error: 2.8656\n",
      "Epoch 00001: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 9s 356us/step - loss: 30.1122 - mean_absolute_error: 2.8576 - val_loss: 12.8005 - val_mean_absolute_error: 1.7061\n",
      "Epoch 2/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 11.4229 - mean_absolute_error: 1.5389\n",
      "Epoch 00002: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 11.4027 - mean_absolute_error: 1.5363 - val_loss: 9.1699 - val_mean_absolute_error: 1.2513\n",
      "Epoch 3/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 6.9050 - mean_absolute_error: 0.8092\n",
      "Epoch 00003: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 239us/step - loss: 6.9008 - mean_absolute_error: 0.8087 - val_loss: 5.7314 - val_mean_absolute_error: 0.6488\n",
      "Epoch 4/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 4.8658 - mean_absolute_error: 0.5349\n",
      "Epoch 00004: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 239us/step - loss: 4.8646 - mean_absolute_error: 0.5350 - val_loss: 4.5088 - val_mean_absolute_error: 0.6047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 3.9242 - mean_absolute_error: 0.5627\n",
      "Epoch 00005: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 3.9201 - mean_absolute_error: 0.5625 - val_loss: 3.5432 - val_mean_absolute_error: 0.5624\n",
      "Epoch 6/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 3.0442 - mean_absolute_error: 0.5143\n",
      "Epoch 00006: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 3.0428 - mean_absolute_error: 0.5143 - val_loss: 2.7840 - val_mean_absolute_error: 0.5578\n",
      "Epoch 7/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 2.4050 - mean_absolute_error: 0.5143\n",
      "Epoch 00007: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 2.4058 - mean_absolute_error: 0.5150 - val_loss: 2.3214 - val_mean_absolute_error: 0.6273\n",
      "Epoch 8/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 1.9967 - mean_absolute_error: 0.5418\n",
      "Epoch 00008: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 1.9958 - mean_absolute_error: 0.5417 - val_loss: 1.7938 - val_mean_absolute_error: 0.5217\n",
      "Epoch 9/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 1.6309 - mean_absolute_error: 0.5142\n",
      "Epoch 00009: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 1.6320 - mean_absolute_error: 0.5148 - val_loss: 1.6175 - val_mean_absolute_error: 0.5776\n",
      "Epoch 10/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 1.4576 - mean_absolute_error: 0.5362\n",
      "Epoch 00010: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 1.4577 - mean_absolute_error: 0.5363 - val_loss: 1.3999 - val_mean_absolute_error: 0.5227\n",
      "Epoch 11/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 1.3051 - mean_absolute_error: 0.5238\n",
      "Epoch 00011: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 1.3045 - mean_absolute_error: 0.5238 - val_loss: 1.3307 - val_mean_absolute_error: 0.5781\n",
      "Epoch 12/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 1.2293 - mean_absolute_error: 0.5153\n",
      "Epoch 00012: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 1.2289 - mean_absolute_error: 0.5152 - val_loss: 1.2887 - val_mean_absolute_error: 0.5571\n",
      "Epoch 13/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 1.1624 - mean_absolute_error: 0.5194\n",
      "Epoch 00013: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 1.1626 - mean_absolute_error: 0.5195 - val_loss: 1.3308 - val_mean_absolute_error: 0.6430\n",
      "Epoch 14/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 1.0780 - mean_absolute_error: 0.5030\n",
      "Epoch 00014: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 1.0777 - mean_absolute_error: 0.5029 - val_loss: 1.0883 - val_mean_absolute_error: 0.5045\n",
      "Epoch 15/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 1.0120 - mean_absolute_error: 0.4787\n",
      "Epoch 00015: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 1.0125 - mean_absolute_error: 0.4791 - val_loss: 1.0598 - val_mean_absolute_error: 0.5213\n",
      "Epoch 16/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.9686 - mean_absolute_error: 0.4801\n",
      "Epoch 00016: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.9685 - mean_absolute_error: 0.4801 - val_loss: 1.0628 - val_mean_absolute_error: 0.5344\n",
      "Epoch 17/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.9108 - mean_absolute_error: 0.4743\n",
      "Epoch 00017: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.9112 - mean_absolute_error: 0.4745 - val_loss: 1.0336 - val_mean_absolute_error: 0.5696\n",
      "Epoch 18/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.8760 - mean_absolute_error: 0.4568\n",
      "Epoch 00018: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.8767 - mean_absolute_error: 0.4572 - val_loss: 1.1606 - val_mean_absolute_error: 0.6216\n",
      "Epoch 19/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.8138 - mean_absolute_error: 0.4473\n",
      "Epoch 00019: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.8139 - mean_absolute_error: 0.4471 - val_loss: 0.8865 - val_mean_absolute_error: 0.4738\n",
      "Epoch 20/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.8464 - mean_absolute_error: 0.4601\n",
      "Epoch 00020: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 239us/step - loss: 0.8473 - mean_absolute_error: 0.4603 - val_loss: 1.1766 - val_mean_absolute_error: 0.6514\n",
      "Epoch 21/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.7523 - mean_absolute_error: 0.4407\n",
      "Epoch 00021: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.7524 - mean_absolute_error: 0.4407 - val_loss: 0.8370 - val_mean_absolute_error: 0.4777\n",
      "Epoch 22/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.7219 - mean_absolute_error: 0.4293\n",
      "Epoch 00022: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.7220 - mean_absolute_error: 0.4294 - val_loss: 0.7890 - val_mean_absolute_error: 0.4723\n",
      "Epoch 23/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.7457 - mean_absolute_error: 0.4467\n",
      "Epoch 00023: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.7462 - mean_absolute_error: 0.4469 - val_loss: 0.7681 - val_mean_absolute_error: 0.4449\n",
      "Epoch 24/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.7095 - mean_absolute_error: 0.4289\n",
      "Epoch 00024: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 240us/step - loss: 0.7095 - mean_absolute_error: 0.4289 - val_loss: 0.7275 - val_mean_absolute_error: 0.4371\n",
      "Epoch 25/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.6948 - mean_absolute_error: 0.4357\n",
      "Epoch 00025: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.6952 - mean_absolute_error: 0.4357 - val_loss: 0.7161 - val_mean_absolute_error: 0.4552\n",
      "Epoch 26/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.6604 - mean_absolute_error: 0.4198\n",
      "Epoch 00026: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 240us/step - loss: 0.6601 - mean_absolute_error: 0.4196 - val_loss: 0.6983 - val_mean_absolute_error: 0.4388\n",
      "Epoch 27/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.6553 - mean_absolute_error: 0.4210\n",
      "Epoch 00027: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.6556 - mean_absolute_error: 0.4210 - val_loss: 0.6837 - val_mean_absolute_error: 0.4227\n",
      "Epoch 28/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.6372 - mean_absolute_error: 0.4207\n",
      "Epoch 00028: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.6373 - mean_absolute_error: 0.4209 - val_loss: 0.6841 - val_mean_absolute_error: 0.4407\n",
      "Epoch 29/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.6266 - mean_absolute_error: 0.4140\n",
      "Epoch 00029: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.6266 - mean_absolute_error: 0.4140 - val_loss: 0.7787 - val_mean_absolute_error: 0.5153\n",
      "Epoch 30/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.6054 - mean_absolute_error: 0.4070\n",
      "Epoch 00030: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.6053 - mean_absolute_error: 0.4070 - val_loss: 0.6536 - val_mean_absolute_error: 0.4286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.6278 - mean_absolute_error: 0.4176\n",
      "Epoch 00031: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.6277 - mean_absolute_error: 0.4175 - val_loss: 0.6916 - val_mean_absolute_error: 0.4429\n",
      "Epoch 32/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.6022 - mean_absolute_error: 0.4076\n",
      "Epoch 00032: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 230us/step - loss: 0.6028 - mean_absolute_error: 0.4081 - val_loss: 0.6474 - val_mean_absolute_error: 0.4222\n",
      "Epoch 33/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.6032 - mean_absolute_error: 0.4078\n",
      "Epoch 00033: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.6031 - mean_absolute_error: 0.4078 - val_loss: 0.6979 - val_mean_absolute_error: 0.4799\n",
      "Epoch 34/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5978 - mean_absolute_error: 0.4150\n",
      "Epoch 00034: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.5978 - mean_absolute_error: 0.4149 - val_loss: 0.6398 - val_mean_absolute_error: 0.4249\n",
      "Epoch 35/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5677 - mean_absolute_error: 0.3978\n",
      "Epoch 00035: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5676 - mean_absolute_error: 0.3977 - val_loss: 0.6120 - val_mean_absolute_error: 0.4153\n",
      "Epoch 36/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5967 - mean_absolute_error: 0.4178\n",
      "Epoch 00036: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5970 - mean_absolute_error: 0.4181 - val_loss: 0.6819 - val_mean_absolute_error: 0.4411\n",
      "Epoch 37/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5820 - mean_absolute_error: 0.4061\n",
      "Epoch 00037: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5820 - mean_absolute_error: 0.4061 - val_loss: 0.6600 - val_mean_absolute_error: 0.4446\n",
      "Epoch 38/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5864 - mean_absolute_error: 0.4110\n",
      "Epoch 00038: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5863 - mean_absolute_error: 0.4111 - val_loss: 0.6452 - val_mean_absolute_error: 0.4434\n",
      "Epoch 39/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5741 - mean_absolute_error: 0.3968\n",
      "Epoch 00039: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5743 - mean_absolute_error: 0.3969 - val_loss: 0.7525 - val_mean_absolute_error: 0.5250\n",
      "Epoch 40/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5732 - mean_absolute_error: 0.4018\n",
      "Epoch 00040: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5733 - mean_absolute_error: 0.4018 - val_loss: 0.6376 - val_mean_absolute_error: 0.4367\n",
      "Epoch 41/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5651 - mean_absolute_error: 0.4005\n",
      "Epoch 00041: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5654 - mean_absolute_error: 0.4004 - val_loss: 0.6663 - val_mean_absolute_error: 0.4618\n",
      "Epoch 42/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5671 - mean_absolute_error: 0.4053\n",
      "Epoch 00042: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5670 - mean_absolute_error: 0.4053 - val_loss: 0.6117 - val_mean_absolute_error: 0.4229\n",
      "Epoch 43/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5707 - mean_absolute_error: 0.4069\n",
      "Epoch 00043: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5709 - mean_absolute_error: 0.4072 - val_loss: 0.6626 - val_mean_absolute_error: 0.4554\n",
      "Epoch 44/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5728 - mean_absolute_error: 0.4055\n",
      "Epoch 00044: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 240us/step - loss: 0.5728 - mean_absolute_error: 0.4056 - val_loss: 0.6858 - val_mean_absolute_error: 0.4770\n",
      "Epoch 45/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5581 - mean_absolute_error: 0.3997\n",
      "Epoch 00045: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5585 - mean_absolute_error: 0.4000 - val_loss: 0.6491 - val_mean_absolute_error: 0.4445\n",
      "Epoch 46/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5748 - mean_absolute_error: 0.4113\n",
      "Epoch 00046: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5748 - mean_absolute_error: 0.4113 - val_loss: 0.6147 - val_mean_absolute_error: 0.4198\n",
      "Epoch 47/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5541 - mean_absolute_error: 0.4001\n",
      "Epoch 00047: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5541 - mean_absolute_error: 0.4001 - val_loss: 0.6384 - val_mean_absolute_error: 0.4414\n",
      "Epoch 48/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5603 - mean_absolute_error: 0.4018\n",
      "Epoch 00048: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5607 - mean_absolute_error: 0.4021 - val_loss: 0.8141 - val_mean_absolute_error: 0.5879\n",
      "Epoch 49/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5568 - mean_absolute_error: 0.3985\n",
      "Epoch 00049: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5568 - mean_absolute_error: 0.3986 - val_loss: 0.6415 - val_mean_absolute_error: 0.4499\n",
      "Epoch 50/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5438 - mean_absolute_error: 0.3946\n",
      "Epoch 00050: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5439 - mean_absolute_error: 0.3947 - val_loss: 0.6035 - val_mean_absolute_error: 0.4289\n",
      "Epoch 51/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5751 - mean_absolute_error: 0.4121\n",
      "Epoch 00051: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5756 - mean_absolute_error: 0.4123 - val_loss: 0.6118 - val_mean_absolute_error: 0.4274\n",
      "Epoch 52/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5396 - mean_absolute_error: 0.3901\n",
      "Epoch 00052: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5394 - mean_absolute_error: 0.3901 - val_loss: 0.6099 - val_mean_absolute_error: 0.4379\n",
      "Epoch 53/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5440 - mean_absolute_error: 0.3989\n",
      "Epoch 00053: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5441 - mean_absolute_error: 0.3990 - val_loss: 0.6155 - val_mean_absolute_error: 0.4293\n",
      "Epoch 54/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5725 - mean_absolute_error: 0.4136\n",
      "Epoch 00054: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5722 - mean_absolute_error: 0.4134 - val_loss: 0.6593 - val_mean_absolute_error: 0.4492\n",
      "Epoch 55/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5409 - mean_absolute_error: 0.3940\n",
      "Epoch 00055: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5409 - mean_absolute_error: 0.3941 - val_loss: 0.5971 - val_mean_absolute_error: 0.4182\n",
      "Epoch 56/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5424 - mean_absolute_error: 0.3915\n",
      "Epoch 00056: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5430 - mean_absolute_error: 0.3918 - val_loss: 0.6348 - val_mean_absolute_error: 0.4414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5459 - mean_absolute_error: 0.3960\n",
      "Epoch 00057: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5458 - mean_absolute_error: 0.3960 - val_loss: 0.5627 - val_mean_absolute_error: 0.3988\n",
      "Epoch 58/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5511 - mean_absolute_error: 0.4033\n",
      "Epoch 00058: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5505 - mean_absolute_error: 0.4029 - val_loss: 0.6091 - val_mean_absolute_error: 0.4286\n",
      "Epoch 59/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5481 - mean_absolute_error: 0.4008\n",
      "Epoch 00059: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5487 - mean_absolute_error: 0.4010 - val_loss: 0.6818 - val_mean_absolute_error: 0.4888\n",
      "Epoch 60/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5405 - mean_absolute_error: 0.3915\n",
      "Epoch 00060: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5406 - mean_absolute_error: 0.3916 - val_loss: 0.6360 - val_mean_absolute_error: 0.4464\n",
      "Epoch 61/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5502 - mean_absolute_error: 0.4018\n",
      "Epoch 00061: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5501 - mean_absolute_error: 0.4017 - val_loss: 0.6825 - val_mean_absolute_error: 0.4683\n",
      "Epoch 62/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5470 - mean_absolute_error: 0.4015\n",
      "Epoch 00062: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5470 - mean_absolute_error: 0.4016 - val_loss: 0.5919 - val_mean_absolute_error: 0.4205\n",
      "Epoch 63/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5240 - mean_absolute_error: 0.3878\n",
      "Epoch 00063: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5250 - mean_absolute_error: 0.3882 - val_loss: 0.6122 - val_mean_absolute_error: 0.4196\n",
      "Epoch 64/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5457 - mean_absolute_error: 0.3973\n",
      "Epoch 00064: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5456 - mean_absolute_error: 0.3973 - val_loss: 0.5955 - val_mean_absolute_error: 0.4323\n",
      "Epoch 65/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5306 - mean_absolute_error: 0.3913\n",
      "Epoch 00065: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5306 - mean_absolute_error: 0.3914 - val_loss: 0.5944 - val_mean_absolute_error: 0.4311\n",
      "Epoch 66/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5387 - mean_absolute_error: 0.3987\n",
      "Epoch 00066: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5390 - mean_absolute_error: 0.3989 - val_loss: 0.7043 - val_mean_absolute_error: 0.4990\n",
      "Epoch 67/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5326 - mean_absolute_error: 0.3956\n",
      "Epoch 00067: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5332 - mean_absolute_error: 0.3959 - val_loss: 0.5966 - val_mean_absolute_error: 0.4357\n",
      "Epoch 68/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5331 - mean_absolute_error: 0.3935\n",
      "Epoch 00068: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5331 - mean_absolute_error: 0.3935 - val_loss: 0.6031 - val_mean_absolute_error: 0.4365\n",
      "Epoch 69/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5326 - mean_absolute_error: 0.3935\n",
      "Epoch 00069: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5324 - mean_absolute_error: 0.3935 - val_loss: 0.6691 - val_mean_absolute_error: 0.4818\n",
      "Epoch 70/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5406 - mean_absolute_error: 0.3951\n",
      "Epoch 00070: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5407 - mean_absolute_error: 0.3954 - val_loss: 0.6223 - val_mean_absolute_error: 0.4419\n",
      "Epoch 71/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5273 - mean_absolute_error: 0.3909\n",
      "Epoch 00071: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5275 - mean_absolute_error: 0.3911 - val_loss: 0.6839 - val_mean_absolute_error: 0.5000\n",
      "Epoch 72/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5362 - mean_absolute_error: 0.3945\n",
      "Epoch 00072: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5358 - mean_absolute_error: 0.3942 - val_loss: 0.6262 - val_mean_absolute_error: 0.4552\n",
      "Epoch 73/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5209 - mean_absolute_error: 0.3877\n",
      "Epoch 00073: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5212 - mean_absolute_error: 0.3879 - val_loss: 0.6335 - val_mean_absolute_error: 0.4614\n",
      "Epoch 74/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5360 - mean_absolute_error: 0.3986\n",
      "Epoch 00074: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5360 - mean_absolute_error: 0.3986 - val_loss: 0.5934 - val_mean_absolute_error: 0.4222\n",
      "Epoch 75/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5257 - mean_absolute_error: 0.3928\n",
      "Epoch 00075: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5256 - mean_absolute_error: 0.3927 - val_loss: 0.6559 - val_mean_absolute_error: 0.4766\n",
      "Epoch 76/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5302 - mean_absolute_error: 0.3953\n",
      "Epoch 00076: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5301 - mean_absolute_error: 0.3953 - val_loss: 0.5623 - val_mean_absolute_error: 0.4105\n",
      "Epoch 77/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5149 - mean_absolute_error: 0.3850\n",
      "Epoch 00077: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5151 - mean_absolute_error: 0.3852 - val_loss: 0.6462 - val_mean_absolute_error: 0.4827\n",
      "Epoch 78/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5204 - mean_absolute_error: 0.3895\n",
      "Epoch 00078: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5206 - mean_absolute_error: 0.3896 - val_loss: 0.5955 - val_mean_absolute_error: 0.4256\n",
      "Epoch 79/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5332 - mean_absolute_error: 0.3986\n",
      "Epoch 00079: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5335 - mean_absolute_error: 0.3988 - val_loss: 0.5873 - val_mean_absolute_error: 0.4347\n",
      "Epoch 80/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5232 - mean_absolute_error: 0.3934\n",
      "Epoch 00080: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5232 - mean_absolute_error: 0.3933 - val_loss: 0.5858 - val_mean_absolute_error: 0.4231\n",
      "Epoch 81/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5328 - mean_absolute_error: 0.3975\n",
      "Epoch 00081: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5328 - mean_absolute_error: 0.3975 - val_loss: 0.6111 - val_mean_absolute_error: 0.4361\n",
      "Epoch 82/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5263 - mean_absolute_error: 0.3922\n",
      "Epoch 00082: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 239us/step - loss: 0.5263 - mean_absolute_error: 0.3923 - val_loss: 0.5664 - val_mean_absolute_error: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5075 - mean_absolute_error: 0.3823\n",
      "Epoch 00083: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5074 - mean_absolute_error: 0.3823 - val_loss: 0.5626 - val_mean_absolute_error: 0.4147\n",
      "Epoch 84/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5203 - mean_absolute_error: 0.3911\n",
      "Epoch 00084: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5208 - mean_absolute_error: 0.3911 - val_loss: 0.5981 - val_mean_absolute_error: 0.4430\n",
      "Epoch 85/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5176 - mean_absolute_error: 0.3893\n",
      "Epoch 00085: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5177 - mean_absolute_error: 0.3894 - val_loss: 0.5766 - val_mean_absolute_error: 0.4236\n",
      "Epoch 86/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5260 - mean_absolute_error: 0.3924\n",
      "Epoch 00086: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5260 - mean_absolute_error: 0.3923 - val_loss: 0.5758 - val_mean_absolute_error: 0.4129\n",
      "Epoch 87/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5131 - mean_absolute_error: 0.3886\n",
      "Epoch 00087: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5131 - mean_absolute_error: 0.3887 - val_loss: 0.5723 - val_mean_absolute_error: 0.4211\n",
      "Epoch 88/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5150 - mean_absolute_error: 0.3895\n",
      "Epoch 00088: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5151 - mean_absolute_error: 0.3896 - val_loss: 0.5901 - val_mean_absolute_error: 0.4408\n",
      "Epoch 89/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5267 - mean_absolute_error: 0.3985\n",
      "Epoch 00089: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5265 - mean_absolute_error: 0.3983 - val_loss: 0.5729 - val_mean_absolute_error: 0.4170\n",
      "Epoch 90/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5139 - mean_absolute_error: 0.3864\n",
      "Epoch 00090: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 235us/step - loss: 0.5140 - mean_absolute_error: 0.3864 - val_loss: 0.6074 - val_mean_absolute_error: 0.4476\n",
      "Epoch 91/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5135 - mean_absolute_error: 0.3856\n",
      "Epoch 00091: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5133 - mean_absolute_error: 0.3854 - val_loss: 0.5655 - val_mean_absolute_error: 0.4101\n",
      "Epoch 92/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5105 - mean_absolute_error: 0.3833\n",
      "Epoch 00092: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.5104 - mean_absolute_error: 0.3833 - val_loss: 0.6343 - val_mean_absolute_error: 0.4789\n",
      "Epoch 93/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5197 - mean_absolute_error: 0.3917\n",
      "Epoch 00093: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5195 - mean_absolute_error: 0.3915 - val_loss: 0.5932 - val_mean_absolute_error: 0.4387\n",
      "Epoch 94/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5129 - mean_absolute_error: 0.3879\n",
      "Epoch 00094: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5129 - mean_absolute_error: 0.3880 - val_loss: 0.5389 - val_mean_absolute_error: 0.4040\n",
      "Epoch 95/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.4993 - mean_absolute_error: 0.3789\n",
      "Epoch 00095: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.4998 - mean_absolute_error: 0.3792 - val_loss: 0.5822 - val_mean_absolute_error: 0.4343\n",
      "Epoch 96/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.5195 - mean_absolute_error: 0.3860\n",
      "Epoch 00096: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 239us/step - loss: 0.5193 - mean_absolute_error: 0.3859 - val_loss: 0.5600 - val_mean_absolute_error: 0.4144\n",
      "Epoch 97/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5191 - mean_absolute_error: 0.3915\n",
      "Epoch 00097: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5191 - mean_absolute_error: 0.3915 - val_loss: 0.5761 - val_mean_absolute_error: 0.4232\n",
      "Epoch 98/200\n",
      "24192/24339 [============================>.] - ETA: 0s - loss: 0.5127 - mean_absolute_error: 0.3853\n",
      "Epoch 00098: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 239us/step - loss: 0.5125 - mean_absolute_error: 0.3851 - val_loss: 0.5591 - val_mean_absolute_error: 0.4082\n",
      "Epoch 99/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.5071 - mean_absolute_error: 0.3873\n",
      "Epoch 00099: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5073 - mean_absolute_error: 0.3873 - val_loss: 0.5906 - val_mean_absolute_error: 0.4350\n",
      "Epoch 100/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5076 - mean_absolute_error: 0.3837\n",
      "Epoch 00100: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5076 - mean_absolute_error: 0.3837 - val_loss: 0.5920 - val_mean_absolute_error: 0.4438\n",
      "Epoch 101/200\n",
      "24160/24339 [============================>.] - ETA: 0s - loss: 0.5153 - mean_absolute_error: 0.3861\n",
      "Epoch 00101: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5157 - mean_absolute_error: 0.3864 - val_loss: 0.5499 - val_mean_absolute_error: 0.4076\n",
      "Epoch 102/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.5011 - mean_absolute_error: 0.3797\n",
      "Epoch 00102: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 236us/step - loss: 0.5019 - mean_absolute_error: 0.3802 - val_loss: 0.5970 - val_mean_absolute_error: 0.4395\n",
      "Epoch 103/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5067 - mean_absolute_error: 0.3834\n",
      "Epoch 00103: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 237us/step - loss: 0.5067 - mean_absolute_error: 0.3834 - val_loss: 0.7224 - val_mean_absolute_error: 0.5455\n",
      "Epoch 104/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5042 - mean_absolute_error: 0.3849\n",
      "Epoch 00104: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5042 - mean_absolute_error: 0.3849 - val_loss: 0.5757 - val_mean_absolute_error: 0.4273\n",
      "Epoch 105/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4973 - mean_absolute_error: 0.3819\n",
      "Epoch 00105: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 240us/step - loss: 0.4975 - mean_absolute_error: 0.3821 - val_loss: 0.5572 - val_mean_absolute_error: 0.4046\n",
      "Epoch 106/200\n",
      "24288/24339 [============================>.] - ETA: 0s - loss: 0.4978 - mean_absolute_error: 0.3785\n",
      "Epoch 00106: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.4980 - mean_absolute_error: 0.3786 - val_loss: 0.6242 - val_mean_absolute_error: 0.4687\n",
      "Epoch 107/200\n",
      "24128/24339 [============================>.] - ETA: 0s - loss: 0.5143 - mean_absolute_error: 0.3935\n",
      "Epoch 00107: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 238us/step - loss: 0.5145 - mean_absolute_error: 0.3935 - val_loss: 0.5562 - val_mean_absolute_error: 0.4152\n",
      "Epoch 108/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4987 - mean_absolute_error: 0.3794\n",
      "Epoch 00108: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 240us/step - loss: 0.4988 - mean_absolute_error: 0.3795 - val_loss: 0.5468 - val_mean_absolute_error: 0.3994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.4976 - mean_absolute_error: 0.3807\n",
      "Epoch 00109: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 231us/step - loss: 0.4976 - mean_absolute_error: 0.3808 - val_loss: 0.5911 - val_mean_absolute_error: 0.4491\n",
      "Epoch 110/200\n",
      "24224/24339 [============================>.] - ETA: 0s - loss: 0.5005 - mean_absolute_error: 0.3843\n",
      "Epoch 00110: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 233us/step - loss: 0.5003 - mean_absolute_error: 0.3841 - val_loss: 0.5604 - val_mean_absolute_error: 0.4144\n",
      "Epoch 111/200\n",
      "24320/24339 [============================>.] - ETA: 0s - loss: 0.5142 - mean_absolute_error: 0.3908\n",
      "Epoch 00111: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.5142 - mean_absolute_error: 0.3908 - val_loss: 0.5500 - val_mean_absolute_error: 0.4055\n",
      "Epoch 112/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4965 - mean_absolute_error: 0.3796\n",
      "Epoch 00112: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.4964 - mean_absolute_error: 0.3796 - val_loss: 0.5786 - val_mean_absolute_error: 0.4442\n",
      "Epoch 113/200\n",
      "24096/24339 [============================>.] - ETA: 0s - loss: 0.4949 - mean_absolute_error: 0.3815\n",
      "Epoch 00113: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 232us/step - loss: 0.4947 - mean_absolute_error: 0.3815 - val_loss: 0.5407 - val_mean_absolute_error: 0.4089\n",
      "Epoch 114/200\n",
      "24256/24339 [============================>.] - ETA: 0s - loss: 0.4963 - mean_absolute_error: 0.3797\n",
      "Epoch 00114: saving model to session/Crowd01/19\n",
      "24339/24339 [==============================] - 6s 234us/step - loss: 0.4966 - mean_absolute_error: 0.3798 - val_loss: 0.5674 - val_mean_absolute_error: 0.4198\n"
     ]
    }
   ],
   "source": [
    "crowd01.train_new_entities(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl8HXW9//HXJ1uTJk2bNuma7rRAW/ayCFJRFAtoUQRFxcuiIipuV0RQLxe5XhXX6/2JogIi6GURUIugIMqmbG2BFkrpytK0tE23pGnTNMvn98d8005PT3JO2pycJOf9fDzOI7PPZ75nMp8z35nvjLk7IiIincnLdgAiItL7KVmIiEhKShYiIpKSkoWIiKSkZCEiIikpWYiISEpKFpIVZjbBzNzMCrK0/pPMbLmZNZjZ+zK8rnFhPfmdTNNgZpMyGUcmmNmFZvbPTsa/38xWh+07qidj2x9mdo2Z/TZ0p/zeOlnO18zsxu6PMHuULPaDmb1mZo1hR2r//DTbcUmXXAv81N3L3P2P3bngsH+8s73f3d8I62kN4x81s0/E5wnjV3VnHL3ED4DLwvY9n+1guiLxe+uImZ1iZjUJ837b3T/R0Tx9UVZ+1fUT73X3h1NNZGYF7t6SalhXlyF77Gf5jAcWZyIe2ct+l7OZ5ac6UKeYX/833UhnFt0snJb/y8x+bGabgGs6GJZnZt8ws9fNbIOZ3Wpmg8My2qtoPm5mbwD/SLKeJWb2nlh/gZnVmtnRZlZsZr81s01mttXM5pnZiDRib1/vBWb2hpltNLOvx8bfYmbfivXv9Ysq/KL+ipktMrPtZnaTmY0ws7+Y2TYze9jMKhJWe7GZrTWzN83s8tiy8szsSjNbGbbjLjMbmm75hOk+aWYrzGyzmc01s9Fh+EpgEnBfOCsckGTe0WZ2TyjTV83s87Fx14R4bg3btdjMZoZxtwHjYsu+Il7lZmb/DZwM/DR+RhrGHxS6B5jZD8J3sN7MbjCzkjCu0sz+HL7XzWb2hJnt839sSar54mc0ZnaQmT1mZnXhe74zNt0hZva3sPylZvbB2LhhoSzrzexZYHIHZT/AzBqAfGBhKHPM7NAQx9ZQbnNi89xiZj83swfMbDvw9iTLfdTMvmNmz4YY/pRqvzCzE8zsybDOhWZ2Smx5E0M5bDOzvwGVHZWhmQ01s1+H/XWLmf3RzEqBvwCjbU8tw2iLVWeFeeeE7d0atuHQ2LjXzOxyi/5v6szsTjMrTlauWeXu+nTxA7wGvLODcRcCLcDniM7cSjoYdjGwguigVQbcC9wWljEBcOBWoBQoSbKeq4HfxfrPBJaE7k8B9wEDif5ZjwHK09iu9vX+KsR4BNAEHBrG3wJ8Kzb9KUBNQrk8DYwAxgAbgOeAo4Bion/e/0xY1+1hGw8DatvLFfhCWFY1MAD4BXB7F8rnHcBG4Ogw//8DHk/zO8wDFoQyLgrf0Srg3WH8NcBO4IxQvt8Bnu5o2bF4C0L/o8AnEtbpwEGh+8fAXGAoMCh8l98J474D3AAUhs/JgHXyXRbEhu1ebyj3r4dtLQbeGoaXAquBi4j21aNCOU4L4+8A7grTzQDWAP/sZJ+Kb1ch0T7/tVCu7wC2AQfH9q864KT2uJIs79GwzhkhhnuA33a0XxDth5vCd5UHvCv0V4V5ngJ+FPaRWSGexOW1f2/3A3cCFWFb3pbs/yC2j7QvZyqwPay7ELgilENRbH95FhgdvvMlwKXZPs7tU/bZDqAvfsKX2wBsjX0+GcZdCLyRMH2yYX8HPhPrPxhoDv+g7TvppE5iOCjs2AND/++Aq0P3xcCTwOFd3K729VbHhj0LnBe6byF1svhorP8e4Oex/s8Bf0xY1yGx8d8DbgrdS4BTY+NGdbF8bgK+F+svC/NPiMXaUbI4Psn3dRXw69B9DfBwbNw0oDGhHPYrWQBGdGCZHBv3FuDV0H0t8CfCATiN77KjZHEr8Mv4dx2Gfwh4ImHYL4D/JEqMzQnf2bdJP1mcDKwD8mLjbweuie1ft6bYrkeB7yaU/a4Q2z77BfBVwo+w2LAHgQuIzgBbgNLYuP8jSbII+18bUJEkplPoPFn8B3BXbFweUcI7Jba/nJ/wf3BDV/53e+Kjaqj99z53HxL7/Co2bnWS6ROHjQZej/W/TrRTxquLki0HAHdfQXRAfa+ZDQTmEO3oALcR/UPcEU6Zv2dmhWltVWRdrHsH0YE2Xetj3Y1J+hOXFd/G14nKBaK67j+E0/atRNvaSprlQ0L5unsD0S/KMWlsw3iiaoWtsfV/LWHdiWVUbN1zZ1cV0Rnhgti6/xqGA3yf6FfpQ2a2ysyu3M/1XEGUmJ4N1SMXh+HjgeMTtv2jwMgQQwH7fmfpGg2sdve2hPnj30ln32myaV4n+rVe2cH48cC5CdvzVqKD/2hgi7tvT1heMmOBze6+JY34EiXui20hxvh2H8j/XI/QBe7MSPYo38Rha4l25Hbtv3LWE1W9dLScuNuBDxP9Unk5JBDcvRn4JvBNM5sAPAAsJfq1fSC2Ex3I2o08wOVB9E/4SugeR1QuEP0zXezu/0qcIWwTdF4+e5VvqFseRvSLLpXVRL/kp6QxbTKpvrfOxm8kSqrT3X2fWN19G/Bl4MtmNgP4h5nNc/e/J0zafgAcCNSH7t3fl7uvAz4JYGZvBR42s8eJtv0xd39X4rotuoW0hX2/s3StBcaaWV4sYYwDlsU3MY3ljI11jyM629kYGx5fxmqiM4tPJi7EzMYDFWZWGksY4zqIYTUw1MyGuPvWhHGpYl5LVM3avl4LsaazL/YaOrPIntuBL4ULbGVEp/N3etfu3rgDOA34NHvOKjCzt5vZYeGfu57on6kt+SK65AXgjHChbyTwxW5Y5n+Y2UAzm05UT95+ofUG4L/DPzRmVmVmZ3VhubcDF5nZkRZdwP428Iy7v5bGvM8C28zsq2ZWYmb5ZjbDzI5Nc93ria5zdHl8OIj+CvixmQ0HMLMxZvbu0P0eiy5OG1H9fitJvlt3ryU6GJ0f4r+Y2MVoMzvXzNp/lGwhOuC1AX8GpprZx8ysMHyONbNDPboz6V6iGzQGmtk0ouqcdD1D9Kv5irDcU4D3Eu3HXXG+mU0LZ9TXAnd7x3dN/Zbo7PvdoRyKLboxo9rdXwfmE/2oKgpJ873JFuLubxJdyP6ZmVWE+GeF0euBYRZuUEniLuBMMzs1nOF/meha4JNd3O6sUrLYf+13u7R//tDF+W8mqi56HHiV6ILp57qygLADPwWcyJ6DLES/IO8mShRLgMfCurDozpobuhhru9uAhUR1rA8lrHN/PUZUrfJ34Afu/lAY/hOii7wPmdk2oovdx6e7UI9ua/4PousmbxIdKM9Lc95W4D3AkUTfzUbgRqCjg0Gi7wDfCNUelycZ/xPgnHBHzf8mGf9VojJ52szqgYeJrmkBTAn9DUTf/c/c/ZEO4vgk8BWi6rfp7H1wOhZ4xqI7luYCX3D3VeHM5TSislpLVD1yHdEFYIDLiKpI1hFdY/h1ZwUR5+67iA7GpxOV6c+Af3P3VzqdcV+3hXWvI7o4//mOJnT31cBZRNWItURnCF9hz7HvI0T71Wai6zK3drLejxH98HqF6OaNL4Z1vEL042RV+M5Hx2dy96XA+UQ3WWwkKoP3hvLoMyxcUBER6fXM7FGiC8f9qnV0X6AzCxERSUnJQkREUlI1lIiIpKQzCxERSanftLOorKz0CRMmZDsMEZE+ZcGCBRvdvSrVdP0mWUyYMIH58+dnOwwRkT7FzNJqha9qKBERSUnJQkREUlKyEBGRlJQsREQkJSULERFJSclCRERSUrIQEZGUcj5Z1DU285OHl7NwdeL7TEREpF3OJwuAHz+8jGde3ZTtMEREeq2cTxaDSwopLy6gZktjtkMREem1cj5ZAFRXDFSyEBHphJIFUF1RQs2WHdkOQ0Sk11KyYM+Zhd7tISKSnJIF0ZnFjl2tbNnRnO1QRER6JSULomQBqCpKRKQDShZE1VCALnKLiHRAyQIYozMLEZFOKVmgthYiIqkoWQRqayEi0rGMJgszm21mS81shZldmWT8hWZWa2YvhM8nYuNaY8PnZjJOUFsLEZHOFGRqwWaWD1wPvAuoAeaZ2Vx3fzlh0jvd/bIki2h09yMzFV+i6oqB/HPFRtwdM+up1YqI9AmZPLM4Dljh7qvcfRdwB3BWBtd3QNTWQkSkY5lMFmOA1bH+mjAs0QfMbJGZ3W1mY2PDi81svpk9bWbvS7YCM7skTDO/trb2gIJVWwsRkY5l+wL3fcAEdz8c+Bvwm9i48e4+E/gI8D9mNjlxZnf/pbvPdPeZVVVVBxSI2lqIiHQsk8liDRA/U6gOw3Zz903u3hR6bwSOiY1bE/6uAh4FjspgrGprISLSiUwmi3nAFDObaGZFwHnAXnc1mdmoWO8cYEkYXmFmA0J3JXASkHhhvFuprYWISMcydjeUu7eY2WXAg0A+cLO7Lzaza4H57j4X+LyZzQFagM3AhWH2Q4FfmFkbUUL7bpK7qLqd2lqIiCSXsWQB4O4PAA8kDLs61n0VcFWS+Z4EDstkbMlUV5Tw2qbtPb1aEZFeL9sXuHsVvddCRCQ5JYsYtbUQEUlOySJGbS1ERJJTsohRWwsRkeSULGLU1kJEJDklixi1tRARSU7JIoHaWoiI7EvJIoHeayEisi8liwRqayEisi8liwRqayEisi8liwRqayEisi8liwRqayEisi8liwRqayEisi8liwRqayEisi8liyTU1kJEZG9KFkmorYWIyN6ULJJQWwsRkb0pWSShthYiIntTskhCbS1ERPamZJGE2lqIiOxNySIJtbUQEdmbkkUSamshIrI3JYsOqK2FiMgeShYdUFsLEZE9lCw6oLYWIiJ7KFl0QG0tRET2ULLogNpaiIjsoWTRAbW1EBHZQ8miA2prISKyh5JFB9TWQkRkDyWLTqithYhIRMmiE2prISISUbLohNpaiIhElCw6obYWIiIRJYtOqK2FiEgko8nCzGab2VIzW2FmVyYZf6GZ1ZrZC+Hzidi4C8xsefhckMk4O6K2FiIikYJMLdjM8oHrgXcBNcA8M5vr7i8nTHqnu1+WMO9Q4D+BmYADC8K8WzIVbzJqayEiEsnkmcVxwAp3X+Xuu4A7gLPSnPfdwN/cfXNIEH8DZmcozg6prYWISCSTyWIMsDrWXxOGJfqAmS0ys7vNbGxX5jWzS8xsvpnNr62t7a6496K2FiIi2b/AfR8wwd0PJzp7+E1XZnb3X7r7THefWVVVlZEA1dZCRCSzyWINMDbWXx2G7ebum9y9KfTeCByT7rw9ZUxFidpaiEjOy2SymAdMMbOJZlYEnAfMjU9gZqNivXOAJaH7QeA0M6swswrgtDCsx1VXDFRbCxHJeRm7G8rdW8zsMqKDfD5ws7svNrNrgfnuPhf4vJnNAVqAzcCFYd7NZvZfRAkH4Fp335ypWDsTb2sxtLQoGyGIiGRdxpIFgLs/ADyQMOzqWPdVwFUdzHszcHMm40vHnmTRyOHVQ7IcjYhIdmT7Anevt6dhni5yi0juUrJIYXBJIYPU1kJEcpySRRrU1kJEcp2SRRrU1kJEcp2SRRqq1dZCRHKckkUa1NZCRHKdkkUa9F4LEcl1ShZpiLe1EBHJRUoWaVBbCxHJdUoWaVBbCxHJdUoWaVJbCxHJZUoWaVJbCxHJZUoWaVJbCxHJZUoWaVJbCxHJZUoWaWq/fXaNrluISA5SskiTGuaJSC5TskjTnrYWOrMQkdyjZJGmPW0tdGYhIrlHyaIL1NZCRHKVkkUXtN8+KyKSa5QsuqC9YZ7aWohIrlGy6ILqioFs39XKVrW1EJEco2TRBXpUuYjkKiWLLlBbCxHJVUoWXaC2FiKSq1ImCzPLN7Mf9EQwvZ3aWohIrkqZLNy9FXhrD8TSJ6ithYjkooI0p3vezOYCvwe2tw9093szElUvVl1RwhubdGYhIrkl3WRRDGwC3hEb5kBOJosnV2zE3TGzbIcjItIj0koW7n5RpgPpK+JtLSpKi7IdjohIj0jrbigzqzazP5jZhvC5x8yqMx1cb6S2FiKSi9K9dfbXwFxgdPjcF4blHLW1EJFclG6yqHL3X7t7S/jcAlRlMK5eS20tRCQXpZssNpnZ+aHNRb6ZnU90wTvnqK2FiOSidJPFxcAHgXXAm8A5QM5e9FZbCxHJNSnvhjKzfOBsd5/TA/H0CWprISK5Jt0W3B/en4Wb2WwzW2pmK8zsyk6m+4CZuZnNDP0TzKzRzF4Inxv2Z/2ZovdaiEiuSbdR3r/M7KfAnezdgvu5jmYIZyTXA+8CaoB5ZjbX3V9OmG4Q8AXgmYRFrHT3I9OMr0eprYWI5Jp0k0X7Qfva2DBn7xbdiY4DVrj7KgAzuwM4C3g5Ybr/Aq4DvpJmLFkXb2uhZCEiuSCdp87mAT9397cnfDpLFABjgNWx/powLL7so4Gx7n5/kvknmtnzZvaYmZ3cQWyXmNl8M5tfW1ubalO6jdpaiEiuSeeaRRtwRXevOCShHwFfTjL6TWCcux8F/Dvwf2ZWniS2X7r7THefWVXVc80+1NZCRHJNurfOPmxml5vZWDMb2v5JMc8aYGysvzoMazcImAE8amavAScAc81sprs3ufsmAHdfAKwEpqYZa8aprYWI5Jp0r1l8KPz9bGyYA5M6mWceMMXMJhIlifOAj+ye2b0OqGzvN7NHgcvdfb6ZVQGb3b3VzCYBU4BVacbaI9TWQkRySbpPnZ3Y1QW7e4uZXQY8COQDN7v7YjO7Fpjv7nM7mX0WcK2ZNQNtwKXuvrmrMWSS2lqISC7pNFmY2RXu/r3Qfa67/z427tvu/rXO5nf3B4AHEoZd3cG0p8S67wHuSRl9Fum9FiKSS1Jdszgv1n1VwrjZ3RxLnxJvayEi0t+lShbWQXey/pyi91qISC5JlSy8g+5k/TlFbS1EJJekusB9hJnVE51FlIRuQn9xRiPr5dTWQkRySafJwt3zeyqQvkZtLUQkl6TbKE+SUFsLEckVShYHIHpUuZKFiPR/ShYHQO+1EJFcoWRxANTWQkRyhZLFAVBbCxHJFUoWB0BtLUQkVyhZHIDqIWprISK5QcniAJSXFDBogNpaiEj/p2RxAMyMMbp9VkRygJLFAVLDPBHJBUoWB0htLUQkFyhZHKDqihK1tRCRfk/J4gDp6bMikguULA6Q2lqISC5QsjhAY3VmISI5QMniAKmthYjkAiWLA6S2FiKSC5QsuoHaWohIf6dk0Q3U1kJE+jsli26gthYi0t8pWXQDtbUQkf5OyaIbTKiMksVTqzZmORIRkcxQsugGB48YxNumVvHjvy1n9WbdQisi/Y+SRTcwM7599mHk5xlX3rtIF7pFpN9RsugmY4aUcOXph/CvFZu4c97qbIcjItKtlCy60UeOG8fxE4fy3/cvYV3dzmyHIyLSbZQsulFennHdBw6nua2Nr//hRVVHiUi/oWTRzSZUlnL5aQfz91c2MHfh2myHIyLSLZQsMuCikyZy5NghXDN3MRsbmrIdjojIAVOyyID8POP75xzO9qZWrpm7ONvhiIgcsIwmCzObbWZLzWyFmV3ZyXQfMDM3s5mxYVeF+Zaa2bszGWcmTBkxiM+94yD+vOhNHly8LtvhiIgckIwlCzPLB64HTgemAR82s2lJphsEfAF4JjZsGnAeMB2YDfwsLK9PufSUyUwbVc43/vgSdXpulIj0YZk8szgOWOHuq9x9F3AHcFaS6f4LuA6I32t6FnCHuze5+6vAirC8PqUwP4/vnXM4m7fv4r/ufznb4YiI7LdMJosxQLx1Wk0YtpuZHQ2Mdff7uzpvmP8SM5tvZvNra2u7J+puNmPMYC592yTuXlDDY8t6Z4wiIqlk7QK3meUBPwK+vL/LcPdfuvtMd59ZVVXVfcF1s8+9YwqTq0r52r0v0tDUku1wRES6LJPJYg0wNtZfHYa1GwTMAB41s9eAE4C54SJ3qnn7lOLCfL53zhGsrWvkur+8ku1wRES6LJPJYh4wxcwmmlkR0QXrue0j3b3O3SvdfYK7TwCeBua4+/ww3XlmNsDMJgJTgGczGGvGHTO+gotOnMhtT7/OM6s2ZTscEZEuyViycPcW4DLgQWAJcJe7Lzaza81sTop5FwN3AS8DfwU+6+6tmYq1p1z+7qmMGzqQr96ziMZdfX5zRCSHWH95ftHMmTN9/vz52Q4jpSdXbOQjNz7DJbMm8bUzDs12OCKS48xsgbvPTDWdWnD3sBMPquTDx43jxidWsXD11myHIyKSFiWLLLjqjEMYPqiYr9y9kKYWVUeJSO+nZJEF5cWFfPvsGSxb38D1j6zMdjgiIikpWWTJOw4ZwfuPGsPPHlnBkjfrsx2OiPRRO3a1sHZrY8bXU5DxNUiHrn7PNJ5YXssVdy/iD585kYJ85W4R2Ze7s2n7LlZuaGBFbQMrN2wPfxtYs7WRY8ZXcM+nT8xoDEoWWVRRWsS1Z83gM797jl898SqfPmVytkMSkSxqbXNqtuxgZW0DKzbEkkJtA1tjDyMtLsxjclUZx4yv4EPHjmXaqPKMx6ZkkWVnHDaK02eM5McPL+O06SOYXFWW7ZBEJMPcnTc272Dx2nqWrtu2+yzh1Y3baWpp2z3dsNIiJg8v4/QZozhoeBmTq0o5aHgZoweXkJdnPRqzkkUv8M2zpvPkyk1ccfci7rjkBApVHSXSbzS3trGytoHFa+pZvLael9bWsWRtPdvCc+LMYGzFQCZXlXLylEomV5WFxFBGRWlRlqPfQ8miFxg+qJhr5kzjS3cu5IyfPMHV753GyVN674MRRSS5xl2tLFkXJYWX19axeG09r6zbxq5wtlBcmMchI8uZc+Ropo8ezPTR5Rw8chDFhb3/dT1KFr3E+4+qpmxAId+6/2U+dtOzvGvaCL5x5qGMH1aa7dBEJMGuljY2bNvJG5t27D5bWLy2nlW1DbSFh2KUFxcwffRg/u2E8cwYEyWGiZWlffZGFj3uo5dpamnlpn++yk//sYKWVufjJ0/ksrcfROkA5XWRTHN36hqbWVe/k3V1O1lfv5N1dU2s37aT9XU7WVcfDdvYsGuv+UaWFzN9dDnTR5czLZwxVFeUYNaz1xX2R7qP+1Cy6KXW1+/kur++wr3PrWH4oAFcefohvO/IMT1+UUukP2lpbWP1lkZW1Tbw2qYdrKtrZF19E+vr2xPDzr0uMLcbWlrEiPJiRpQPYGR5MSPKixk5uJjqihIOHVVOZdmALGxN91Cy6Ceee2ML37zvZRau3spR44bwn++dzpFjh2Q7LJFebdvOZlbVbmdluO105Yao+7VN22lu3XPMKyrIY2R5cZQABhczsnzA7kQwIgwfXj6AAQW9/5rC/lKy6Efa2px7n1/DdX99hdptTZxzTDVXvPtghpcXZzs0kaxpa3PerN/Jyg1RQognh/X1Tbuny88zxg8byOSqsvApZVJVGRMrS6kYWNgnqooyScmiH9q2s5mfPrKCm//5KkX5eXzu1ClcdNKEfv2rR3qXnc2tFOXn9Vh16LadzdRsaWTNlkZqtuyIurc28sbmHayq3U5j854HcQ4qLth9y+nkqjImVZUyuaqMcUMHUlTQNy8q9wQli37s1Y3b+e/7X+bhJRuYMGwg//GeabzjkOE5/wtJul9rm7OwZiuPvrKBR5fVsqimjjyDioFFDC2NPsPK2rsHMKx9WGkRQ9uHDyzq8A6gusZmarbsCMmg/bODNVuj7rrG5r2mLy7Mo7piINUVJUyqLGPy8NLdyaGyrEj/A/tBySIHPLaslmvvW8zK2u3MmlrF1e+ZxkHD1QJcDsymhiYeX17LI6/U8sTyWrbsaCbP4KhxFZw0eRgObNq+i80Nu9i8fRebtjexefsutjY209HhZHBJ4e5EUlZcwPr6Jmq27GDbzpa9pispzKe6oiR8oqQwJtY9rFQJobspWeSI5tY2bn3qdf7n4WU07mrlwhMncMXsQ3TaLWlrbXMW1WzlkaW1PLZ0A4vW1OEOlWVFzJpaxSkHD2fWlEqGDOy8NXFLaxtbG5ujBBISyebtTVFi2b6LTdt3samhiYamFkYMKt4nEVRXDNQ1hCxQssgxGxua+OFDS7n92dW8bWoVN5x/DCVFupYhyW3evovHl9XyyNINPL4sOnswg6PGDuGUg4dzysFVzBg9WLdq54B0k4VaevUTlWUD+M7Zh3PU2AquvHcRH7vpGW668FgGlxRmOzTJoqaWVuobW6hrbGZTQxNPrdrEI0trWVSzFffoQXVvP3g4bzu4illTqnrVs4ikd1Gy6Gc+eOxYyooL+MIdz/PhXz7NrR8/rk83GJLIpoYm1m7dSV1jM/U7m6lvbI51t1C/M/Q3NlO/s2V3d2IDMzM4cuwQvnjqVE45uIrDxujsQdKjZNEPnXHYKEoHFPCp2+bzwRue4rZPHM+YISXZDkv2Q1NLKz97ZCU/f3Qlu1r3bVmcn2eUFxdQXlLI4JJCyosLGTm4eHd3eUnhXuMPrx7CUJ09yH7QNYt+bP5rm7nolnkMGlDAbZ84Xu/K6GOeWbWJr/3hRVbWbmfOEaOZc8To6OBfUkB5cXTwH1iUrwvCckB0gVsAWLy2jgtufhZ3+M3FxzFjzOBshyQp1O1o5jt/WcId81ZTXVHCt943g1MOHp7tsKSfSjdZ6P7Kfm766MHc9am3MKAgjw//8mnmvbY52yFJB9yduQvXcuqPHuP3C2r41KxJPPSlWUoU0isoWeSASVVl3P3pE6kqH8DHbnqGR5duyHZIkmD15h1cdMs8Pn/784weUszcy07iqjMOZWCRLitK76BkkSNGDynhrk+9hclVZXzy1vncv+jNbIckRA3ZfvX4Kk778eM8++pmrn7PNP7wmZOYPlrVhdK76GdLDqksG8Dtl5zAx2+Zx+duf45tOw/jvOPGZTusnPViTR1X3ruIxWvreeehw/nmWTN015r0WkoWOaa8uJBbLz6eS3+7gCvvfZH6nc1cMmtytsPKKdubWvjhQ8u45clXqSwbwM8/ejSzZ4zUXU3SqylZ5KCSonx+9W8z+dJdL/DtB16hrrGZy087WAerHvD3Jeu5+k+LWbO1kfPwvLOZAAAPuElEQVRPGMcVsw+hvFit7KX3U7LIUUUFefzveUdRXlzA9Y+spL6xhW/Oma7WvBmyoX4n37zvZe5/8U2mjijjnk+/hWPGD812WCJpU7LIYfl5xrfffxjlxYX84vFVNDS18L1zDqewg3cPSNfVNTZzz4IafvzwMppa2rj8tKlcMmuyngosfY6SRY4zM648/RDKSwr5/oNLo7fxfeRoigv1xNr91dbmPLlyE79fsJq/vrSOppY2Tpw8jG+9bwaT1Ipe+iglC8HM+OzbD6K8pJCr//QSH/zFU5x6yAimjihjyohBTBg2sMM3nckeqzfv4PcLarhnQQ1rtjZSXlzAB2eO5dyZ1Rw2ZrCuCUmfpmQhu33shPEMLinkhw8t5X/+vmz3W8+K8vOYVFXKlBGDmDo8SiBTR5Qxflgp+Tl+jaNxVyt/eelNfj+/hqdWbcIM3npQJV89/RBOmzZCZ2jSb+jZUJJU465WVmxoYNn6bSzbsI3l66Pumi2Nu6cpKshjclUZU0eUMXXEIKYMj/6OHTqwXycRd+e5N7Zy94LV3LfwTRqaWhg3dCDnHlPN2cdUq62E9Cm94uVHZjYb+AmQD9zo7t9NGH8p8FmgFWgALnH3l81sArAEWBomfdrdL81krLK3kqJ8DqsezGHVe7ck3t7UsjuJLA9/57+2hT+9sHb3NAMK8jh0VDlvPaiSk6dUctS4in5xQXdD/U7ufX4Nv5+/mpW12ykpzOeMw0Zx7sxqjpswVHeSSb+WsTMLM8sHlgHvAmqAecCH3f3l2DTl7l4fuucAn3H32SFZ/NndZ6S7Pp1ZZFdDUwvL1+85A3l+9VZeWL2V1jantCift0yuZNbUSk6eUsWEYQP7TP39rpY2/vHKen4/v4ZHl9XS2ubMHF/BuTOrOfPw0ZQNUE2u9G294cziOGCFu68KAd0BnAXsThbtiSIoBfpHnVgOKhtQwFHjKjhqXMXuYXWNzTy1chNPLK/l8eW1PLxkPQDVFSWcPKWKWVMqOfGgyl736ld358U1ddyzoIa5C9eyZUczI8oHcMmsSZxzTLXeCyI5KZPJYgywOtZfAxyfOJGZfRb4d6AIeEds1EQzex6oB77h7k8kmfcS4BKAceP0jKPeZnBJIbNnjGT2jJEAvL5pO48v38jjy2q5b+Fabn/2DfLCaz5PnlLFrKmVHFE9JGt3Xq3d2sgfX1jDvc+tYcWGBooK8njXtBGcc3Q1J0+p1B1hktMyWQ11DjDb3T8R+j8GHO/ul3Uw/UeAd7v7BWY2AChz901mdgzwR2B6wpnIXlQN1bc0t7bxwuqtPLGslseXb2RRzVbaHAYVF3Di5GHMmlrFWyYNY8Kw0oxeC9je1MJfX1rHvc/X8OTKTbjDsRMqOPvoas44bFSvO+sR6W69oRpqDTA21l8dhnXkDuDnAO7eBDSF7gVmthKYCigb9BOF+XkcO2Eox04Yyr+fdjBbd+ziXytCldWyWh5cHFVZDRpQwPQx5Rw2ZjAzxgzmsDGDDziBtLY5T6/axD3P1fDXl9axY1cr44YO5AunTuH9R41h/LDS7tpMkX4jk8liHjDFzCYSJYnzgI/EJzCzKe6+PPSeCSwPw6uAze7eamaTgCnAqgzGKlk2ZGARZx4+ijMPH4W7s7J2Owte38yLa+p4cU09v3nqdXa1tAFRApk2Okogh1VHSWRiGglkxYZt3PPcGv74/BrerNvJoOICzjpyNGcfXc3M8RV95qK7SDZkLFm4e4uZXQY8SHTr7M3uvtjMrgXmu/tc4DIzeyfQDGwBLgizzwKuNbNmoA241N31PtAcYWYcNLyMg4aX8aFjo2HNrW0sX9/AS2vqQgKp47anX6cpJJCyeAIJZyGTKkvZsmMX9y1cy73Pr2FRTR35ecbbplbx9TMP5Z2HqtGcSLrUKE/6rObWNlZsaODFNXW7k8jLa+t3J5DSonyaWtpoaXOmjy7n7KOrmXPEaKoGDchy5CK9R2+4ZiGSUYX5UeO/Q0eV88GZ0eWxltY2VtQ28GJNlEBKigp431GjOWRkeZajFenblCykXynIz+OQkeUcMrKcc2eOTT2DiKRFN46LiEhKShYiIpKSkoWIiKSkZCEiIikpWYiISEpKFiIikpKShYiIpKRkISIiKfWbx32YWS3w+gEsohLY2E3hZJLi7F59JU7oO7Eqzu6XyVjHu3tVqon6TbI4UGY2P53no2Sb4uxefSVO6DuxKs7u1xtiVTWUiIikpGQhIiIpKVns8ctsB5Amxdm9+kqc0HdiVZzdL+ux6pqFiIikpDMLERFJSclCRERSyqlkYWazzWypma0wsyuTjB9gZneG8c+Y2YSejxLMbKyZPWJmL5vZYjP7QpJpTjGzOjN7IXyuzlKsr5nZiyGGfd5ra5H/DWW6yMyOzkKMB8fK6QUzqzezLyZMk7XyNLObzWyDmb0UGzbUzP5mZsvD34oO5r0gTLPczC5INk2G4/y+mb0Svts/mNmQDubtdD/pgTivMbM1se/3jA7m7fQY0UOx3hmL8zUze6GDeXusTAFw95z4APnASmASUAQsBKYlTPMZ4IbQfR5wZ5ZiHQUcHboHAcuSxHoK8OdeUK6vAZWdjD8D+AtgwAnAM71gP1hH1BCpV5QnMAs4GngpNux7wJWh+0rguiTzDQVWhb8Vobuih+M8DSgI3dclizOd/aQH4rwGuDyNfaPTY0RPxJow/ofA1dkuU3fPqTOL44AV7r7K3XcBdwBnJUxzFvCb0H03cKqZWQ/GCIC7v+nuz4XubcASYExPx9FNzgJu9cjTwBAzG5XFeE4FVrr7gbT271bu/jiwOWFwfF/8DfC+JLO+G/ibu2929y3A34DZPRmnuz/k7i2h92mgOlPrT1cH5ZmOdI4R3aqzWMOx54PA7ZmMIV25lCzGAKtj/TXsewDePU34B6gDhvVIdB0IVWFHAc8kGf0WM1toZn8xs+k9GtgeDjxkZgvM7JIk49Mp9550Hh3/8/WG8mw3wt3fDN3rgBFJpultZXsx0VlkMqn2k55wWaguu7mDar3eVp4nA+vdfXkH43u0THMpWfQ5ZlYG3AN80d3rE0Y/R1SVcgTw/4A/9nR8wVvd/WjgdOCzZjYrS3GkZGZFwBzg90lG95by3IdHdQ69+h53M/s60AL8roNJsr2f/ByYDBwJvElUvdPbfZjOzyp6tExzKVmsAcbG+qvDsKTTmFkBMBjY1CPRJTCzQqJE8Tt3vzdxvLvXu3tD6H4AKDSzyh4OE3dfE/5uAP5AdCofl06595TTgefcfX3iiN5SnjHr26vrwt8NSabpFWVrZhcC7wE+GhLbPtLYTzLK3de7e6u7twG/6mD9vaI8Yffx52zgzo6m6ekyzaVkMQ+YYmYTwy/M84C5CdPMBdrvKDkH+EdHO38mhbrKm4Al7v6jDqYZ2X49xcyOI/ouezSxmVmpmQ1q7ya62PlSwmRzgX8Ld0WdANTFqld6Woe/1HpDeSaI74sXAH9KMs2DwGlmVhGqVU4Lw3qMmc0GrgDmuPuODqZJZz/JqITrZO/vYP3pHCN6yjuBV9y9JtnIrJRpT11J7w0fojtzlhHd8fD1MOxaoh0doJioimIF8CwwKUtxvpWo2mER8EL4nAFcClwaprkMWEx0x8bTwIlZiHNSWP/CEEt7mcbjNOD6UOYvAjOzVKalRAf/wbFhvaI8iRLYm0AzUT35x4mulf0dWA48DAwN084EbozNe3HYX1cAF2UhzhVE9fzt+2n73YSjgQc62096OM7bwv63iCgBjEqMM/Tvc4zo6VjD8Fva983YtFkrU3fX4z5ERCS1XKqGEhGR/aRkISIiKSlZiIhISkoWIiKSkpKFiIikpGQhWWNmbmY/jPVfbmbXdNOybzGzc7pjWSnWc66ZLTGzR7phWRea2ehY/41mNi10fy1h2icPdH2ZELbhp9mOQ7qfkoVkUxNwdpZbSu8jtJ5N18eBT7r727th1RcS3UsPgLt/wt1fDr17JQt3P7Eb1ieSNiULyaYWoncLfylxROKZgZk1hL+nmNljZvYnM1tlZt81s4+a2bPh2f6TY4t5p5nNN7NlZvaeMH++Re9gmBceKvep2HKfMLO5wMskMLMPh+W/ZGbXhWFXEzWgvMnMvp9knq/E1vPNMGxCOBP5lUXvKnnIzErCts4EfmfR+wlKzOxRM5tpZt8FSsLw38XLo5P1lJrZ/RY9GPElM/tQkvgeNbOZobvSzF4L3dNDeb4QljklDD8/NvwXZpYfhl8UyvhZ4KSk37T0eUoWkm3XAx81s8FdmOcIotbXhwIfA6a6+3HAjcDnYtNNIHpezpnADWZWTHQmUOfuxwLHAp80s4lh+qOBL7j71PjKQtXQdcA7iB5Ed6yZvc/drwXmEz0T6SsJ85wGTAnrPxI4xvY86G0KcL27Twe2Ah9w97tjyzrS3Rvbl+XuVwKNYfhH01zPbGCtux/h7jOAv6ZVspFLgZ+4+5FECazGzA4FPgScFIa3En1vo4BvEiWJtwLTurAe6UO6crot0u3cvd7MbgU+DzSmmj6Y5+H5Uma2EngoDH8RiFcH3eXRg+OWm9kq4BCiZ+gcHjtrGUx0sN0FPOvuryZZ37HAo+5eG9b5O6KX1nT2ZNrTwuf50F8W1vMG8Kq7t7/9bAFRUttfHa3nCeCH4Szoz+7+RBeW+RTwdTOrBu519+VmdipwDDDPokdolRA93PB49i6bO4GpyRcrfZmShfQG/0P0iPBfx4a1EM58zSyP6M1l7Zpi3W2x/jb23qcTn2XjRM+q+py77/XAPTM7Bdi+f+EnZcB33P0XCeuZwN7xtxIdeLt1PWFdRxM96+hbZvb3cCYUt7uMiZ6LBoC7/5+ZPUN0RvZAqKoz4DfuflXCOpK9lEn6IVVDSda5+2bgLqIqonavEf2ShegdFIX7sehzzSwvXMeYBCwleirrpy16BDxmNtWip3Z25lngbaFeP5/o6bWPpZjnQeBii95JgpmNMbPhKebZRvQa3WSa22NOZz2h6myHu/8W+D5RFVui19hTxvHrQ5OAVe7+v0RPuz2c6KGG57Rvg0XvCB9P9FKut5nZsBDfuSm2UfoonVlIb/FDoie/tvsV8CczW0hU374/v/rfIDrQlxM9wXOnmd1IVO3znEX1KbUkf2Xpbu7+ppldCTxC9Av7fndP9sjw+DwPhXr+p0K1TQNwPtGZREduIbq20gi8JWHcL4FFZvZc/LpFJ+s5CPi+mbURPdH000nW9wPgLovesnZ/bPgHgY+ZWTPRW/q+7e6bzewbRG9mywvL/Ky7P23R7c5PEV1/eQHpl/TUWRERSUnVUCIikpKShYiIpKRkISIiKSlZiIhISkoWIiKSkpKFiIikpGQhIiIp/X+LjNCBLD9t8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crowd01.plot_crowd_error(X_test_red, y_test, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDUAAAJ4CAYAAAB1ZthpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3XmcLHV97//XGw7IKkQ5UVkOR4zxStwwRxOjcUFNUBHvL9ErRlQWRY3XmMR7FXeNJqImPjQ3UcQNlygqBoMxRiWKxKgoKDFsRoTDepBNZFFB4PP7o2qkGHrO9PR0z0z1vJ6PRz9OdVV1fT/1reqez/n0t6pTVUiSJEmSJPXNFssdgCRJkiRJ0igsakiSJEmSpF6yqCFJkiRJknrJooYkSZIkSeolixqSJEmSJKmXLGpIkiRJkqResqixiiU5KslrxrStdUmuT7Jl+/ykJM8dx7bb7X0+yXPGtb0FtPumJFcmuWyp217tkmxM8rgh1lufpJKsWeD2k+SDSX6c5FujRzpUW2M5f0fd15UiyaOTXLzccUiaHuYyQ7VrLrNMzGUGbsdcRmPXy5NJ80uyEbgbcDNwC3AW8GHg6Kq6FaCqXrCAbT23qk6ca52quhDYYXFR/7K91wO/VlUHdbb/hHFse4FxrANeCuxZVZcvdfuauEcAjwd2r6obJtnQcpy/ktR35jJjicNcZrqZy0g4UmPaPbmqdgT2BI4EXg68f9yN9LXSOoR1wFXjSAIG9dEo/Tbz7dFSm9JjvCewcZQkYEr7Q5JWInOZxTGXua3daTzG5jISFjVWhar6SVWdADwdeE6S+wEkOSbJm9rpXZL8c5Jrklyd5N+TbJHkIzR/ED/bDsl8WWfY2GFJLgS+PMdQsnsl+VaSa5P8U5K7tG3dYdjWzPC8JPsBrwSe3rb3n+3yXw4BbeN6dZILklye5MNJdmqXzcTxnCQXtsMtXzVX3yTZqX39Fe32Xt1u/3HAl4Bd2ziOmeP1+yc5ve23ryd5wKx9enmS7wE3JFkzx7z7tvt3TZIzkxzQ2cYxSd6d5F+S3AA8ZkAMuyY5oT1u5yZ5Xmf+z2b6vZ23T9snW7XPD01ydjts8QtJ9uysW0lelOQHwA8GtDvT14ckuajdxguSPCTJ99r9+bvO+nMet3b5s9plV80+Zu1rj0jyw3b5J7v7NWvdg5Ocl+S6JOcneeaAdQ4D3gc8rD2+b2jnP6/tw6vbPt11Af2xTZKPtvFdk+TbSe7WLuuevwcn+VqSv2777PwkT+hs555JTm7jPzHJ3yf56Bz7ulOS9yfZlOSSNEOMByaLSR6a5NQ078cfJXl7Z9mnklyW5Cdt27/RWXZMknelGXZ6fZL/SHL3JO9o4z8nyT6d9TcmeUWSs9rlH0yyzRwx7Zrk02nef+cn+ZNB60mSuYy5TGddcxnMZWIuo66q8jGFD2Aj8LgB8y8EXthOHwO8qZ1+M3AUsFX7+F0gg7YFrAeKZgjo9sC2nXlr2nVOAi4B7teu82ngo+2yRwMXzxUv8PqZdTvLT6IZNgpwKHAusBfNMNF/BD4yK7b3tnE9ELgRuO8c/fRh4J+AHdvX/jdw2FxxznrtPsDlwG8BWwLPaffjTp19Oh3YA9h20Ly2r8+lSX62BvYFrgPu0zlGPwEeTlOE3GZAHCcD7wK2AR4EXAHs2y77MvC8zrpvA45qp5/Stn1fmkvRXg18vbNu0SRDd5mJf1a7M319VNv27wE/Bz4D/CqwW9s/jxriuO0NXA88ErgT8Haa4cYz58RLgG8Cu7fL3wN8fFYca2jOtWs7/XcP4DfmOH4HA1/rPN8XuBJ4cNvG/wNOXkB/PB/4LLBdez78JnDnAefvwcAvgOe1670QuJTb3m/fAP66PR8e0e7PR2fva/v8+LYvtm/7/FvA8+fY328Az2qndwB+u7PsUJr3wJ2AdwCnd5Yd0/bLb7bH+cvA+cCz2/jfBHxl1nv5DJpz/C7Af3Db58yjad9TNOfzacBr233dCzgP+P3l/vz04cPHynhgLmMuU+YymMt04zOX8TH4s2y5A/AxoQM7dyLwTeBV7fQxnTfoX9D8Qfy1+bbV+TDaa8C8biJwZGf53sBN7QfHLz8MBrXB/InAvwF/3Fl2n/aDdU0njt07y78FHDhgv7ZsY9q7M+/5wEnt9B3inPX6dwNvnDXv+9z2h28jcOiA/Ty08/x3gcuALTrzPg68vnOMPryZGPaguc54x868NwPHtNPPBb7cTge4CHhk+/zztElP+3wL4Kc0193S9uO+m2l7pq9368y7Cnh65/mngT8d4ri9Fji2s2z79tjMnBNnA4/tLL/HgGM+kwhcA/whA/5Yz4r/YG6fCLwfeGvn+Q5tG+uH7I9Dga8DDxiw7CRunwic21m2Xbvtu9N8k3gzsF1n+UcZkAjQXGd+Y3c/gWfQ+aM8K4aTgTcAu8zTLzu3bezUOQff21n+YuDszvP7A9fMOsdf0Hn+ROCHs99TNAn0hbPafgXwwc3F58OHj9XzwFzGXKbMZeZ5jxyMucyg9cxlVtnDy09Wn92AqwfMfxtN5fmL7XC3I4bY1kULWH4BTSV/l6Gi3Lxd2+11tz3zwTije4fvnzL4xl+7tDHN3tZuQ8axJ/DSdnjeNUmuofnDvGtnnUF91J23K3BRtTc8myOGzfXzrsDVVXXdHK//NM2wxHvQfHNwK/Dvnfjf2Yn9appkYdi2Z/yoM/2zAc9n+n5zx23XblvVXBt6VWfdPYHjO7GeTZMAdY/5zOueDrwA2JTkc0n+xxD7cIf4qur6NoZh++MjwBeAY5NcmuStM0NjB/jl+VlVP20nd+C24/nTzrpztbknzfm7qdMv76H5lmOQw4BfB85ph5PuD821zUmObIfDXkvzhxxu/14d9hgPivkCbv+e6Ma/66z3zyuZdUwlaQBzmduYy5jLdJnLmMusShY1VpEkD6H5UPva7GVVdV1VvbSq9gIOAP48yWNnFs+xybnmz9ijM72OplJ8JXADTUV3Jq4tgbUL2O6lNB8i3W3fzO0/nIZxZRvT7G1dMuTrLwL+sqp27jy2q6qPd9YZtC/deZcCeyTpvhdnx7C5/rgUuEuSHQe9vqp+DHyR5o/jH9F8gzCzvYtohvd149+2qr4+ZNsLtbnjtonO+ZJkO+CunXUvAp4wK9ZtquoOx6qqvlBVj6f5BuQcmuG7C44vyfZtDEMdi6r6RVW9oar2Bn4H2J9mWONCbKI5ntt15u0xx7oX0Xy7sUunT+5cVb8xaOWq+kFVPYMmUXgLcFy7j39EM3z3ccBONN+gQJMUjmr2e//SOeI/f9Yx3bGqnriIdiVNOXOZOzCXMZeZMz5zGXOZ1cKixiqQ5M5tJfNYmqFf/zVgnf2T/FqS0Fz3eAtNJRyaD+q9Rmj6oCR7tx9qfwEcV1W30FzruU2SJ7XV31fTXP8240fA+ll/HLs+DvxZexOiHYC/Aj5RVTcvJLg2lk8Cf5lkxzQ3lvpzmiFyw3gv8IIkv5XG9u0+7TjvK29zCs23Ly9LslWSRwNPpjlWw+zDRTTDBN+c5uZOD6CpYnf34WM0f5Ce2k7POAp4xcyNlNLcqOlpC4h9oTZ33I4D9k/yiCRb05wv3eN/FM1x2rONdW2Sp8xuIMndkjyl/QN3I821rbfOXm8z8R2S5EFJ7tTGd0pVbRzmxUkek+T+bWJ7LU2SOWzbAFTVBcCpwOuTbJ3kYTTnw6B1N9EkeX/Tvse3SHKvJI+aI76Dkqxtv0m7pp19K831pzfSfJOzHc1+L9aLkuye5gZorwI+MWCdbwHXpbnZ3Lbttyz3a//DIkm3Yy4zmLmMucyA+MxlzGVWHYsa0+2zSa6jqSK+iuaGRYfMse69gRNpPji/Abyrqr7SLnsz8Oo0w6r+zwLa/wjNNWyX0dyU50+guYM58Mc0d2y+hObbju4dxD/V/ntVku8M2O4H2m2fTHOTn5/TXBs3ihe37Z9H863Px9rtz6uqTqW5QdLfAT+mGfJ68EIar6qbaD7on0Dzbcu7gGdX1TkL2MwzaCrSl9LcbOl1VXViZ/kJNMf3sqr6z07bx9NUuY9NM1TvjDaOSZnzuFXVmcCLaPp/E01/ds+Jd7b78cX2nP4mzXWMs21Bk8xdSjME9VE0N6+aV9tnr6EZ5roJuBdw4AL27+40Cc21NENKv0qzvwv1TOBhNH+Y30TzR/TGOdZ9Ns2Nqc6i6bPjaL7VGWQ/4Mwk19P054FV9TOaG8xdQPNePIumbxfrYzRJynnAD9v9uJ02Ed+f5oZw59Oc/++j+YZFkmaYy8zPXMZchjYGcxlzmVVp5g61kqQVKMkngHOq6nXLHcswkmykuZHYifOtK0mSpp+5jCbNkRqStIIkeUg79HKLJPvRXCP6meWOS5IkaRjmMlpqa5Y7AEnS7dyd5nfv70ozbPWFVfXd5Q1JkiRpaOYyWlJefiJJkiRJknrJy08kSZIkSVIvWdSQJEmSJEm9tKLuqbHLLrvU+vXrlzsMSZJ677TTTruyqtYudxyrjbmMJEnjMWwus6KKGuvXr+fUU09d7jAkSeq9JBcsdwyrkbmMJEnjMWwu4+UnkiRJkiSplyxqSJIkSZKkXrKoIUmSJEmSesmihiRJkiRJ6iWLGpIkSZIkqZcsakiSJEmSpF6yqCFJkiRJknppzSQ3nmQjcB1wC3BzVW2YZHuSJEnjlGRn4H3A/YACDq2qbyxvVJIkacZEixqtx1TVlUvQjiRJ0ri9E/jXqnpqkq2B7ZY7IEmSdJulKGpIkiT1TpKdgEcCBwNU1U3ATcsZkyRJur1JFzUK+GKSAt5TVUfPXiHJ4cDhAOvWrRt7AOuP+NzYt7nabTzyScsdwlTyXB0/z1VJi3RP4Argg0keCJwGvKSqbuiuNOlcRuoLc5nxM5cZP8/TyVjOc3XSNwp9RFU9GHgC8KIkj5y9QlUdXVUbqmrD2rVrJxyOJEnS0NYADwbeXVX7ADcAR8xeyVxGkqTlM9GiRlVd0v57OXA88NBJtidJkjRGFwMXV9Up7fPjaIockiRphZhYUSPJ9kl2nJkGfg84Y1LtSZIkjVNVXQZclOQ+7azHAmctY0iSJGmWSd5T427A8Ulm2vlYVf3rBNuTJEkatxcD/9D+8sl5wCHLHI8kSeqYWFGjqs4DHjip7UuSJE1aVZ0ObFjuOCRJ0mCTvlGoJEmSJEnSRFjUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLFjUkSZIkSVIvWdSQJEmSJEm9ZFFDkiRJkiT1kkUNSZIkSZLUSxY1JEmSJElSL1nUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLFjUkSZIkSVIvWdSQJEmSJEm9ZFFDkiRJkiT1kkUNSZIkSZLUSxY1JEmSJElSL1nUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLa5Y7AEmSpJUqyUbgOuAW4Oaq2rC8EUmSpC6LGpIkSZv3mKq6crmDkCRJd+TlJ5IkSZIkqZcsakiSJM2tgC8mOS3J4csdjCRJuj0vP5EkSZrbI6rqkiS/CnwpyTlVdXJ3hbbYcTjAunXrliNGSZJWLUdqSJIkzaGqLmn/vRw4HnjogHWOrqoNVbVh7dq1Sx2iJEmrmkUNSZKkAZJsn2THmWng94AzljcqSZLU5eUnkiRJg90NOD4JNDnTx6rqX5c3JEmS1DXxokaSLYFTgUuqav9JtydJkjQOVXUe8MDljkOSJM1tKS4/eQlw9hK0I0mSJEmSVpGJFjWS7A48CXjfJNuRJEmSJEmrz6RHarwDeBlw64TbkSRJkiRJq8zE7qmRZH/g8qo6LcmjN7Oev+0uaSLWH/G55Q5h6mw88knLHYIkSZL0S5McqfFw4IAkG4FjgX2TfHT2Sv62uyRJkiRJGsXEihpV9Yqq2r2q1gMHAl+uqoMm1Z4kSZIkSVpdluLXTyRJkiRJksZuYvfU6Kqqk4CTlqItSZIkSZK0OjhSQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLFjUkSZIkSVIvWdSQJEmSJEm9ZFFDkiRJkiT1kkUNSZIkSZLUSxY1JEmSJElSL1nUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRL8xY1kjw8yfbt9EFJ3p5kz8mHJkmStHjmMpIkTa9hRmq8G/hpkgcCLwV+CHx4olFJkiSNj7mMJElTapiixs1VVcBTgL+rqr8HdpxsWJIkSWNjLiNJ0pRaM8Q61yV5BXAQ8MgkWwBbTTYsSZKksTGXkSRpSg0zUuPpwI3AYVV1GbA78LaJRiVJkjQ+5jKSJE2peUdqtH/83955fiFehypJknrCXEaSpOk1Z1EjyXVADVoEVFXdeWJRSZIkLdK4cpkkWwKnApdU1f5jDFGSJC3SnEWNqvIGWpIkqbfGmMu8BDgb8AsdSZJWmGHuqUGSRyQ5pJ3eJck9JxuWJEnS+IyayyTZHXgS8L5JxidJkkYzb1EjyeuAlwOvaGdtDXx0kkFJkiSNyyJzmXcALwNunUBokiRpkYb5Sdf/D9gH+A5AVV2axEtTJElSX4yUyyTZH7i8qk5L8ujNrHc4cDjAunXrxhKwJAGsP+Jzyx2CtOINc/nJTVVVtDfaSrL9ZEOSJEkaq1FzmYcDByTZCBwL7JvkDiM8quroqtpQVRvWrl07rpglSdIQhilqfDLJe4CdkzwPOBF472TDkiRJGpuRcpmqekVV7V5V64EDgS9X1UGTDVWSJC3EvJefVNVfJ3k8cC1wH+C1VfWliUcmSZI0BuYykiRNr2HuqUH7h98//pIkqZcWm8tU1UnASeOKR5IkjcecRY0k19FeezpIVflb7ZIkacUyl5EkafrNWdSoqh0BkrwR2AR8BAjwTOAeSxKdJEnSiMxlJEmafsPcKPSAqnpXVV1XVddW1buBp0w6MEmSpDExl5EkaUoNU9S4Ickzk2yZZIskzwRumHRgkiRJY2IuI0nSlBqmqPFHwP8CfgRcDjytnSdJktQH5jKSJE2pYX7SdSMO0ZQkST1lLiNJ0vSad6RGkt2THJ/k8vbx6SS7L0VwkiRJi2UuI0nS9Brm8pMPAicAu7aPz7bzNivJNkm+leQ/k5yZ5A2LC1WSJGkkI+UykiRp5RumqLG2qj5YVTe3j2OAtUO87kZg36p6IPAgYL8kv72IWCVJkkYxai4jSZJWuGGKGlclOai9Y/iWSQ4CrprvRdW4vn26VfuoRcQqSZI0ipFyGUmStPINU9Q4lOaO4ZcBm4CnAocMs/E2cTid5k7jX6qqU0YNVJIkaUQj5zKSJGllG+bXTy4ADhhl41V1C/CgJDsDxye5X1Wd0V0nyeHA4QDr1q0bpRktsfVHfG65Q5C0THz/j9/GI5+03CFMvcXkMpIkaWWbt6iR5J7Ai4H13fWraujkoKquSfIVYD/gjFnLjgaOBtiwYYOXp0iSpLEaRy4jSZJWpnmLGsBngPfT3Cn81mE3nGQt8Iu2oLEt8HjgLSNFKUmSNLqRchlJkrTyDVPU+HlV/e0I274H8KEkW9Lcu+OTVfXPI2xHkiRpMUbNZSRJ0go3TFHjnUleB3yR5mdaAaiq72zuRVX1PWCfxYUnSZK0aCPlMpIkaeUbpqhxf+BZwL7cNmSz2ueSJEkrnbmMJElTapiixtOAvarqpkkHI0mSNAHmMpIkTakthljnDGDnSQciSZI0IeYykiRNqWFGauwMnJPk29z+OlR/Bk2SJPWBuYwkSVNqmKLG6yYehSRJ0uSYy0iSNKXmLWpU1VeXIhBJkqRJMJeRJGl6DXNPDUmSJEmSpBXHooYkSZIkSeqlOYsaSf6t/fctSxeOJEnSeJjLSJI0/TZ3T417JPkd4IAkxwLpLqyq70w0MkmSpMUxl5EkacptrqjxWuA1wO7A22ctK2DfSQUlSZI0BuYykiRNuTmLGlV1HHBcktdU1RuXMCZJkqRFM5eRJGn6DfOTrm9McgDwyHbWSVX1z5MNS5IkaTzMZSRJml7z/vpJkjcDLwHOah8vSfJXkw5MkiRpHMxlJEmaXvOO1ACeBDyoqm4FSPIh4LvAKycZmCRJ0piYy0iSNKXmHanR2rkzvdMkApEkSZogcxlJkqbQMCM13gx8N8lXaH4K7ZHAERONSpIkaXxGymWSbAOcDNyJJmc6rqpeN8lAJUnSwgxzo9CPJzkJeEg76+VVddlEo5IkSRqTReQyNwL7VtX1SbYCvpbk81X1zUnFKkmSFmaYkRpU1SbghAnHIkmSNBGj5DJVVcD17dOt2keNOTRJkrQIw95TQ5IkadVJsmWS04HLgS9V1SnLHZMkSbrNUCM1JEmSVqOqugV4UJKdgeOT3K+qzuiuk+Rw4HCAdevWjT2G9Ud8buzbXO02Hvmk5Q5BkjQmmx2p0X47cc5SBSNJkjRO48plquoa4CvAfgOWHV1VG6pqw9q1axfblCRJWoDNFjXabye+n2T8XztIkiRN2GJymSRr2xEaJNkWeDzglz2SJK0gw1x+8ivAmUm+BdwwM7OqDphYVJIkSeMzai5zD+BDSbak+SLok1X1z5MLU5IkLdQwRY3XTDwKSZKkyRkpl6mq7wH7jDkWSZI0RvMWNarqq0n2BO5dVScm2Q7YcvKhSZIkLZ65jCRJ02ven3RN8jzgOOA97azdgM9MMihJkqRxMZeRJGl6zVvUAF4EPBy4FqCqfgD86iSDkiRJGiNzGUmSptQwRY0bq+qmmSdJ1gA1uZAkSZLGylxGkqQpNUxR46tJXglsm+TxwKeAz042LEmSpLExl5EkaUoNU9Q4ArgC+C/g+cC/AK+eZFCSJEljZC4jSdKUGubXT25N8iHgFJqhmt+vKodsSpKkXjCXkSRpes1b1EjyJOAo4IdAgHsmeX5VfX7SwUmSJC2WuYwkSdNr3qIG8DfAY6rqXIAk9wI+B5gISJKkPjCXkSRpSg1zT43rZpKA1nnAdROKR5IkadzMZSRJmlJzjtRI8gft5KlJ/gX4JM11qE8Dvr0EsUmSJI3MXEaSpOm3uctPntyZ/hHwqHb6CmDbiUUkSZI0HuYykiRNuTmLGlV1yFIGIkmSNE7mMpIkTb9hfv3knsCLgfXd9avqgMmFJUmSNB7mMpIkTa9hfv3kM8D7gc8Ct042HEmSpLEzl5EkaUoNU9T4eVX97cQjkSRJmgxzGUmSptQwRY13Jnkd8EXgxpmZVfWdzb0oyR7Ah4G70dxp/OiqeuciYpUkSRrFSLmMJEla+YYpatwfeBawL7cN2az2+ebcDLy0qr6TZEfgtCRfqqqzRo5WkiRp4UbNZSRJ0go3TFHjacBeVXXTQjZcVZuATe30dUnOBnYDLGpIkqSlNFIuI0mSVr4thljnDGDnxTSSZD2wD3DKYrYjSZI0gkXnMpIkaWUaZqTGzsA5Sb7N7a9DHepn0JLsAHwa+NOqunbA8sOBwwHWrVs3zCYlSZIWYlG5jCRJWrmGKWq8btSNJ9mKpqDxD1X1j4PWqaqjgaMBNmzYUKO2JUmSNIeRcxlJkrSyzVvUqKqvjrLhJKH5Tfizq+rto2xDkiRpsUbNZSRJ0so3b1EjyXU0dwgH2BrYCrihqu48z0sfTnOn8f9Kcno775VV9S+jBitJkrRQi8hlJEnSCjfMSI0dZ6bb0RdPAX57iNd9DciiopMkSVqkUXMZSZK08g3z6ye/VI3PAL8/oXgkSZImxlxGkqTpMszlJ3/QeboFsAH4+cQikiRJGiNzGUmSptcwv37y5M70zcBGmmGbkiRJfWAuI0nSlBrmnhqHLEUgkiRJk2AuI0nS9JqzqJHktZt5XVXVGycQjyRJ0liYy0iSNP02N1LjhgHztgcOA+4KmAhIkqSVzFxGkqQpN2dRo6r+ZmY6yY7AS4BDgGOBv5nrdZIkSSuBuYwkSdNvsz/pmuQuSd4EfI+mAPLgqnp5VV2+JNFJkiQtwmJymSR7JPlKkrOSnJnkJRMPWJIkLcjm7qnxNuAPgKOB+1fV9UsWlSRJ0iKNIZe5GXhpVX2nHelxWpIvVdVZ445VkiSNZnMjNV4K7Aq8Grg0ybXt47ok1y5NeJIkSSNbVC5TVZuq6jvt9HXA2cBuE41YkiQtyObuqbHZS1MkSZJWsnHmMknWA/sAp4xrm5IkafEsXEiSJG1Gkh2ATwN/WlV3GOGR5PAkpyY59Yorrlj6ACVJWsUsakiSJM0hyVY0BY1/qKp/HLROVR1dVRuqasPatWuXNkBJklY5ixqSJEkDJAnwfuDsqnr7cscjSZLuyKKGJEnSYA8HngXsm+T09vHE5Q5KkiTdZs4bhUqSJK1mVfU1IMsdhyRJmpsjNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLFjUkSZIkSVIvWdSQJEmSJEm9ZFFDkiRJkiT1kkUNSZIkSZLUSxY1JEmSJElSL1nUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLFjUkSZIkSVIvWdSQJEmSJEm9ZFFDkiRJkiT1kkUNSZIkSZLUSxY1JEmSJElSL1nUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsTK2ok+UCSy5OcMak2JEmSJEnS6jXJkRrHAPtNcPuSJEmSJGkVm1hRo6pOBq6e1PYlSZIkSdLq5j01JEmSJElSLy17USPJ4UlOTXLqFVdcsdzhSJIkSZKknlj2okZVHV1VG6pqw9q1a5c7HEmSJEmS1BPLXtSQJEmSJEkaxSR/0vXjwDeA+yS5OMlhk2pLkiRJkiStPmsmteGqesakti1JkjRpST4A7A9cXlX3W+54JEnSHXn5iSRJ0mDHAPstdxCSJGlzCuB6AAAgAElEQVRuFjUkSZIGqKqTgauXOw5JkjQ3ixqSJEmSJKmXJnZPDUmSpNUgyeHA4QDr1q1b5mg0jPVHfG65Q5AkjYkjNSRJkhahqo6uqg1VtWHt2rXLHY4kSauKRQ1JkiRJktRLFjUkSZIGSPJx4BvAfZJcnOSw5Y5JkiTdnvfUkCRJGqCqnrHcMUiSpM1zpIYkSZIkSeolixqSJEmSJKmXLGpIkiRJkqResqghSZIkSZJ6yaKGJEmSJEnqJYsakiRJkiSplyxqSJIkSZKkXrKoIUmSJEmSesmihiRJkiRJ6iWLGpIkSZIkqZcsakiSJEmSpF6yqCFJkiRJknrJooYkSZIkSeolixqSJEmSJKmXLGpIkiRJkqResqghSZIkSZJ6yaKGJEmSJEnqJYsakiRJkiSplyxqSJIkSZKkXrKoIUmSJEmSesmihiRJkiRJ6iWLGpIkSZIkqZcsakiSJEmSpF6yqCFJkiRJknrJooYkSZIkSeolixqSJEmSJKmXLGpIkiRJkqResqghSZIkSZJ6yaKGJEmSJEnqJYsakiRJkiSplyxqSJIkSZKkXrKoIUmSJEmSesmihiRJkiRJ6qWJFjWS7Jfk+0nOTXLEJNuSJEkaN3MZSZJWtokVNZJsCfw98ARgb+AZSfaeVHuSJEnjZC4jSdLKN8mRGg8Fzq2q86rqJuBY4CkTbE+SJGmczGUkSVrh1kxw27sBF3WeXwz81uyVkhwOHN4+vT7J98cYwy7AlWPcXl/ZDw37wT6YYT807IfGsvZD3jKxTe85sS2vHishl1kqfh6Mxn4bjf02OvtuNPbbaIbutwnlM0PlMpMsagylqo4Gjp7EtpOcWlUbJrHtPrEfGvaDfTDDfmjYDw37QYs1yVxmqfg+GI39Nhr7bXT23Wjst9H0pd8mefnJJcAenee7t/MkSZL6wFxGkqQVbpJFjW8D905yzyRbAwcCJ0ywPUmSpHEyl5EkaYWb2OUnVXVzkv8NfAHYEvhAVZ05qfbm0OuhoGNkPzTsB/tghv3QsB8a9oMGWiG5zFLxfTAa+2009tvo7LvR2G+j6UW/paqWOwZJkiRJkqQFm+TlJ5IkSZIkSRNjUUOSJEmSJPXSVBU1ktwlyZeS/KD991cGrPOgJN9IcmaS7yV5+nLEOglJ9kvy/STnJjliwPI7JflEu/yUJOuXPsrJGqIP/jzJWe2x/7ckQ/32cd/M1w+d9f4wSSVZ8T/VNIph+iHJ/2rPiTOTfGypY1wKQ7wv1iX5SpLvtu+NJy5HnJOU5ANJLk9yxhzLk+Rv2z76XpIHL3WM0qSZJ4zO/GI05iOjMX8ZnTnPaHqfJ1XV1DyAtwJHtNNHAG8ZsM6vA/dup3cFNgE7L3fsY9j3LYEfAnsBWwP/Cew9a50/Bo5qpw8EPrHccS9DHzwG2K6dfuG09cGw/dCutyNwMvBNYMNyx71M58O9ge8Cv9I+/9XljnuZ+uFo4IXt9N7AxuWOewL98EjgwcAZcyx/IvB5IMBvA6csd8w+fIzzYZ4w8b6b+vxiEv3WrjfV+cgk+m015C8T7Lupz3lG7Lte50lTNVIDeArwoXb6Q8D/nL1CVf13Vf2gnb4UuBxYu2QRTs5DgXOr6ryqugk4lqY/urr9cxzw2CRZwhgnbd4+qKqvVNVP26ffBHZf4hiXwjDnAsAbgbcAP1/K4JbQMP3wPODvq+rHAFV1+RLHuBSG6YcC7txO7wRcuoTxLYmqOhm4ejOrPAX4cDW+Ceyc5B5LE520JMwTRmd+MRrzkdGYv4zOnGdEfc+Tpq2ocbeq2tROXwbcbXMrJ3koTRXvh5MObAnsBlzUeX5xO2/gOlV1M/AT4K5LEt3SGKYPug6jqThOm3n7oR0ytkdVfW4pA1tiw5wPvw78epL/SPLNJPstWXRLZ5h+eD1wUJKLgX8BXrw0oa0oC/38kPrGPGF05hejMR8ZjfnL6Mx5JmdF50lrljuAhUpyInD3AYte1X1SVZVkzt+rbStLHwGeU1W3jjdKrXRJDgI2AI9a7liWWpItgLcDBy9zKCvBGpohnI+m+Vbt5CT3r6prljWqpfcM4Jiq+pskDwM+kuR+fjZK0sKs5vxiocxHFsX8ZXTmPFOod0WNqnrcXMuS/CjJPapqU1u0GDgUK8mdgc8Br2qHz0yDS4A9Os93b+cNWufiJGtohlxdtTThLYlh+oAkj6Mpgj2qqm5cotiW0nz9sCNwP+CkdlTx3YETkhxQVacuWZSTN8z5cDHNNYG/AM5P8t80ScK3lybEJTFMPxwG7AdQVd9Isg2wC3N8hk6poT4/pB4zTxid+cVozEdGY/4yOnOeyVnRedK0XX5yAvCcdvo5wD/NXiHJ1sDxNNcEHbeEsU3at4F7J7lnu48H0vRHV7d/ngp8udo7v0yJefsgyT7Ae4ADpvj6w832Q1X9pKp2qar1VbWe5trfaUwghnlPfIbmWw6S7EIznPO8pQxyCQzTDxcCjwVIcl9gG+CKJY1y+Z0APLu9u/dvAz/pXM4oTQPzhNGZX4zGfGQ05i+jM+eZnBWdJ/VupMY8jgQ+meQw4ALgfwG0Pw/1gqp6bjvvkcBdkxzcvu7gqjp9GeIdm6q6Ocn/Br5Ac+ffD1TVmUn+Aji1qk4A3k8zxOpcmhvBHLh8EY/fkH3wNmAH4FPttwIXVtUByxb0BAzZD1NvyH74AvB7Sc4CbgH+b1VN1beSQ/bDS4H3JvkzmhtoHTxt/5FJ8nGaBHCX9jra1wFbAVTVUTTX1T4ROBf4KXDI8kQqTYZ5wujML0ZjPjIa85fRmfOMru95UjyGkiRJkiSpj6bt8hNJkiRJkrRKWNSQJEmSJEm9ZFFDkiRJkiT1kkUNSZIkSZLUSxY1JEmSJElSL03bT7pKGkGSW4D/6sw6tqqOXK54JEmSFsJcRlq9/ElXSSS5vqp2mGedLavqls7zNVV18xDbHmo9SZKkUZnLSKuXl59ImlOSjUnekuQ7wNOSnJTkHUlOBV6SZH2SLyf5XpJ/S7Kufd0xSY5Kcgrw1mXdCUmStGqZy0jTz8tPJAFsm+T0zvM3V9Un2umrqurBAEleAGxdVRva558FPlRVH0pyKPC3wP9sX7c78Dvdb0QkSZImxFxGWqUsakgC+FlVPWiOZZ/YzPOHAX/QTn+E23+T8SmTAEmStETMZaRVystPJM3nhnmeD/s6SZKk5WAuI00xixqSFuPrwIHt9DOBf1/GWCRJkhbKXEbqOS8/kQR3vA71X6vqiCFe92Lgg0n+L3AFcMhEopMkSdo8cxlplfInXSVJkiRJUi95+YkkSZIkSeolixqSJEmSJKmXLGpIkiRJkqResqghSZIkSZJ6yaKGJEmSJEnqJYsakiRJkiSplyxqrGJJjkrymjFta12S65Ns2T4/Kclzx7HtdnufT/KccW1vAe2+KcmVSS5b6rZXuyQbkzxuiPXWJ6kkaxa4/ST5YJIfJ/nW6JEO1dZYzt9R93WlSPLoJBcvdxySpoe5zFDtmsssE3OZgdsxl9HY9fJk0vySbATuBtwM3AKcBXwYOLqqbgWoqhcsYFvPraoT51qnqi4Edlhc1L9s7/XAr1XVQZ3tP2Ec215gHOuAlwJ7VtXlS92+Ju4RwOOB3avqhkk2tBznryT1nbnMWOIwl5lu5jISjtSYdk+uqh2BPYEjgZcD7x93I32ttA5hHXDVOJKAQX00Sr/NfHu01Kb0GO8JbBwlCZjS/pCklchcZnHMZW5rdxqPsbmMhEWNVaGqflJVJwBPB56T5H4ASY5J8qZ2epck/5zkmiRXJ/n3JFsk+QjNH8TPtkMyX9YZNnZYkguBL88xlOxeSb6V5Nok/5TkLm1bdxi2NTM8L8l+wCuBp7ft/We7/JdDQNu4Xp3kgiSXJ/lwkp3aZTNxPCfJhe1wy1fN1TdJdmpff0W7vVe3238c8CVg1zaOY+Z4/f5JTm/77etJHjBrn16e5HvADUnWzDHvvu3+XZPkzCQHdLZxTJJ3J/mXJDcAjxkQw65JTmiP27lJnteZ/7OZfm/n7dP2yVbt80OTnN0OW/xCkj0761aSFyX5AfCDAe3O9PUhSS5qt/GCJA9J8r12f/6us/6cx61d/qx22VWzj1n72iOS/LBd/snufs1a9+Ak5yW5Lsn5SZ45YJ3DgPcBD2uP7xva+c9r+/Dqtk93XUB/bJPko2181yT5dpK7tcu65+/BSb6W5K/bPjs/yRM627lnkpPb+E9M8vdJPjrHvu6U5P1JNiW5JM0Q44HJYpKHJjk1zfvxR0ne3ln2qSSXJflJ2/ZvdJYdk+RdaYadXp/kP5LcPck72vjPSbJPZ/2NSV6R5Kx2+QeTbDNHTLsm+XSa99/5Sf5k0HqSZC5jLtNZ11wGc5mYy6irqnxM4QPYCDxuwPwLgRe208cAb2qn3wwcBWzVPn4XyKBtAeuBohkCuj2wbWfemnadk4BLgPu163wa+Gi77NHAxXPFC7x+Zt3O8pNoho0CHAqcC+xFM0z0H4GPzIrtvW1cDwRuBO47Rz99GPgnYMf2tf8NHDZXnLNeuw9wOfBbwJbAc9r9uFNnn04H9gC2HTSv7etzaZKfrYF9geuA+3SO0U+Ah9MUIbcZEMfJwLuAbYAHAVcA+7bLvgw8r7Pu24Cj2umntG3fl+ZStFcDX++sWzTJ0F1m4p/V7kxfH9W2/XvAz4HPAL8K7Nb2z6OGOG57A9cDjwTuBLydZrjxzDnxEuCbwO7t8vcAH58Vxxqac+3aTv/dA/iNOY7fwcDXOs/3Ba4EHty28f+AkxfQH88HPgts154PvwncecD5ezDwC+B57XovBC7ltvfbN4C/bs+HR7T789HZ+9o+P77ti+3bPv8W8Pw59vcbwLPa6R2A3+4sO5TmPXAn4B3A6Z1lx7T98pvtcf4ycD7w7Db+NwFfmfVePoPmHL8L8B/c9jnzaNr3FM35fBrw2nZf9wLOA35/uT8/ffjwsTIemMuYy5S5DOYy3fjMZXwM/ixb7gB8TOjAzp0IfBN4VTt9TOcN+hc0fxB/bb5tdT6M9howr5sIHNlZvjdwU/vB8csPg0FtMH8i8G/AH3eW3af9YF3TiWP3zvJvAQcO2K8t25j27sx7PnBSO32HOGe9/t3AG2fN+z63/eHbCBw6YD8P7Tz/XeAyYIvOvI8Dr+8cow9vJoY9aK4z3rEz783AMe30c4Evt9MBLgIe2T7/PG3S0z7fAvgpzXW3tP2472banunr3TrzrgKe3nn+aeBPhzhurwWO7Szbvj02M+fE2cBjO8vvMeCYzyQC1wB/yIA/1rPiP5jbJwLvB97aeb5D28b6IfvjUODrwAMGLDuJ2ycC53aWbddu++403yTeDGzXWf5RBiQCNNeZ39jdT+AZdP4oz4rhZOANwC7z9MvObRs7dc7B93aWvxg4u/P8/sA1s87xF3SePxH44ez3FE0CfeGstl8BfHBz8fnw4WP1PDCXMZcpc5l53iMHYy4zaD1zmVX28PKT1Wc34OoB899GU3n+Yjvc7YghtnXRApZfQFPJ32WoKDdv13Z73W3PfDDO6N7h+6cMvvHXLm1Ms7e125Bx7Am8tB2ed02Sa2j+MO/aWWdQH3Xn7QpcVO0Nz+aIYXP9vCtwdVVdN8frP00zLPEeNN8c3Ar8eyf+d3Ziv5omWRi27Rk/6kz/bMDzmb7f3HHbtdtWNdeGXtVZd0/g+E6sZ9MkQN1jPvO6pwMvADYl+VyS/zHEPtwhvqq6vo1h2P74CPAF4NgklyZ568zQ2AF+eX5W1U/byR247Xj+tLPuXG3uSXP+bur0y3tovuUY5DDg14Fz2uGk+0NzbXOSI9vhsNfS/CGH279Xhz3Gg2K+gNu/J7rx7zrr/fNKZh1TSRrAXOY25jLmMl3mMuYyq5JFjVUkyUNoPtS+NntZVV1XVS+tqr2AA4A/T/LYmcVzbHKu+TP26Eyvo6kUXwncQFPRnYlrS2DtArZ7Kc2HSHfbN3P7D6dhXNnGNHtblwz5+ouAv6yqnTuP7arq4511Bu1Ld96lwB5Juu/F2TFsrj8uBe6SZMdBr6+qHwNfpPnj+Ec03yDMbO8imuF93fi3raqvD9n2Qm3uuG2ic74k2Q64a2fdi4AnzIp1m6q6w7Gqqi9U1eNpvgE5h2b47oLjS7J9G8NQx6KqflFVb6iqvYHfAfanGda4EJtojud2nXl7zLHuRTTfbuzS6ZM7V9VvDFq5qn5QVc+gSRTeAhzX7uMf0QzffRywE803KNAkhaOa/d6/dI74z591THesqicuol1JU85c5g7MZcxl5ozPXMZcZrWwqLEKJLlzW8k8lmbo138NWGf/JL+WJDTXPd5CUwmH5oN6rxGaPijJ3u2H2l8Ax1XVLTTXem6T5Elt9ffVNNe/zfgRsH7WH8eujwN/1t6EaAfgr4BPVNXNCwmujeWTwF8m2THNjaX+nGaI3DDeC7wgyW+lsX27TzvO+8rbnELz7cvLkmyV5NHAk2mO1TD7cBHNMME3p7m50wNoqtjdffgYzR+kp7bTM44CXjFzI6U0N2p62gJiX6jNHbfjgP2TPCLJ1jTnS/f4H0VznPZsY12b5CmzG0hytyRPaf/A3Uhzbeuts9fbTHyHJHlQkju18Z1SVRuHeXGSxyS5f5vYXkuTZA7bNgBVdQFwKvD6JFsneRjN+TBo3U00Sd7ftO/xLZLcK8mj5ojvoCRr22/Srmln30pz/emNNN/kbEez34v1oiS7p7kB2quATwxY51vAdWluNrdt+y3L/dr/sEjS7ZjLDGYuYy4zID5zGXOZVceixnT7bJLraKqIr6K5YdEhc6x7b+BEmg/ObwDvqqqvtMveDLw6zbCq/7OA9j9Ccw3bZTQ35fkTaO5gDvwxzR2bL6H5tqN7B/FPtf9eleQ7A7b7gXbbJ9Pc5OfnNNfGjeLFbfvn0Xzr87F2+/OqqlNpbpD0d8CPaYa8HryQxqvqJpoP+ifQfNvyLuDZVXXOAjbzDJqK9KU0N1t6XVWd2Fl+As3xvayq/rPT9vE0Ve5j0wzVO6ONY1LmPG5VdSbwIpr+30TTn91z4p3tfnyxPae/SXMd42xb0CRzl9IMQX0Uzc2r5tX22WtohrluAu4FHLiA/bs7TUJzLc2Q0q/S7O9CPRN4GM0f5jfR/BG9cY51n01zY6qzaPrsOJpvdQbZDzgzyfU0/XlgVf2M5gZzF9C8F8+i6dvF+hhNknIe8MN2P26nTcT3p7kh3Pk05//7aL5hkaQZ5jLzM5cxl6GNwVzGXGZVmrlDrSRpBUryCeCcqnrdcscyjCQbaW4kduJ860qSpOlnLqNJc6SGJK0gSR7SDr3cIsl+NNeIfma545IkSRqGuYyW2prlDkCSdDt3p/nd+7vSDFt9YVV9d3lDkiRJGpq5jJaUl59IkiRJkqRe8vITSZIkSZLUSyvq8pNddtml1q9fv9xhSJLUe6eddtqVVbV2ueNYbcxlJEkaj2FzmRVV1Fi/fj2nnnrqcochSVLvJblguWNYjcxlJEkaj2FzGS8/kSRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLEy1qJNk5yXFJzklydpKHTbI9SZIkSZK0eqyZ8PbfCfxrVT01ydbAdhNuT5IkSZIkrRITK2ok2Ql4JHAwQFXdBNw0qfYkSZIkSdLqMsnLT+4JXAF8MMl3k7wvyfYTbE+SJEmSJK0ik7z8ZA3wYODFVXVKkncCRwCv6a6U5HDgcIB169ZNMBxpZVt/xOeWO4Sps/HIJy13CJIkrRrmMuNnLiPNb5IjNS4GLq6qU9rnx9EUOW6nqo6uqg1VtWHt2rUTDEeSJEmSJE2TiRU1quoy4KIk92lnPRY4a1LtSZIkSZKk1WXSv37yYuAf2l8+OQ84ZMLtSZIkSZKkVWKiRY2qOh3YMMk2JEmSJEnS6jTJe2pIkiRJkiRNjEUNSZIkSZLUSxY1JEmSJElSL1nUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkiRJUi9Z1JAkSZIkSb1kUUOSJEmSJPWSRQ1JkiRJktRLFjUkSZIkSVIvWdSQJEmSJEm9ZFFDkiRJkiT1kkUNSZIkSZLUSxY1JEmSJElSL1nUkCRJkiRJvWRRQ5IkSZIk9ZJFDUmSJEmS1EsWNSRJkuaQ5M+SnJnkjPz/7d19tGV3WR/w75MMkbfEqFwVCePEFl1SqITestAoaoAWAYO1olBCNbKYdqk0LvFlUDGuslYBEQSWaIlEiKi8GIGCQQUxgdpCmhBSIAlIjCkGghmpSMBCDDz9456YezN35p659+xz7j7381nrrtnnnH32fua37pz9zPf89t5Vr6mquy+6JgDgTkINAIBNVNX9kvynJKvd/aAkJyZ50mKrAgDWE2oAABzdviT3qKp9Se6Z5OMLrgcAWEeoAQCwie7+WJJfTvLRJDcn+bvufttiqwIA1hNqAABsoqq+LMkTkpye5GuS3KuqztlkvYNVdWVVXXn48OF5lwkAe5pQAwBgc49K8pfdfbi7/yHJG5J8y11X6u4Lunu1u1dXVlbmXiQA7GVCDQCAzX00ycOr6p5VVUkemeS6BdcEAKwj1AAA2ER3X57k4iRXJflA1vqmCxZaFACwwb5FFwAAsFt19/lJzl90HQDA5szUAAAAAEZJqAEAAACMklADAAAAGCWhBgAAADBKQg0AAABglAa9+0lV3Zjk1iRfSHJ7d68OuT8AAABg75jHLV2/s7v/Zg77AQAAAPYQp58AAAAAozR0qNFJ3lZV762qgwPvCwAAANhDhj795Fu7+2NV9ZVJ3l5VH+rud61fYRJ2HEyS/fv3D1wOADtx4NAliy5h6dz4vMctugQAgNEadKZGd39s8uctSd6Y5GGbrHNBd6929+rKysqQ5QAAAABLZLBQo6ruVVUn37Gc5F8l+eBQ+wMAAAD2liFPP/mqJG+sqjv287vd/UcD7g8AAADYQwYLNbr7hiTfNNT2AQAAgL3NLV0BAACAURJqAAAAAKMk1AAAAABGSagBAAAAjJJQAwAAABgloQYAAAAwSkINAAAAYJSEGgAAAMAoCTUAAACAURJqAAAAAKMk1AAAAABGSagBAAAAjJJQAwAAABgloQYAAAAwSkINAAAAYJSEGgAAAMAoCTUAAACAURJqAAAAAKMk1AAAAABGSagBAAAAjJJQAwAAABgloQYAAAAwSkINAAAAYJSEGgAAAMAoCTUAAACAURJqAAAAAKO0ZahRVWdW1b0my+dU1Yuq6muHLw0AYOf0MgCwvKaZqfHrSf6+qr4pyTOT/EWS3xq0KgCA2dHLAMCSmibUuL27O8kTkvxqd78sycnDlgUAMDN6GQBYUvumWOfWqnpWknOSPKKqTkhyt2HLAgCYGb0MACypaWZq/ECSzyd5Wnd/IslpSV4waFUAALOjlwGAJbXlTI3Jwf9F6x5/NM5DBQBGQi8DAMvrqKFGVd2apDd7KUl39ynT7KCqTkxyZZKPdffjt1UlAMBxmkUvU1WnJnlFkgdNtvXD3f3umRYKAGzbUUON7p7VBbTOS3JdkqlCEACAWZhRL/OSJH/U3d9XVScluecMtgkAzMg019RIVX1rVZ07Wb5PVZ0+5ftOS/K4rH3DAQCwENvpZarqS5M8IsmFSdLdt3X3p4atFAA4HluGGlV1fpKfSfKsyVMnJfntKbf/4iQ/neSL26oOAGCHdtDLnJ7kcJJXVtX7quoVVXWvgcoEALZhmlu6/pskZyS5Kkm6++NVteV0zqp6fJJbuvu9VfUdx1jvYJKDSbJ///5pambBDhy6ZNElAMDx2FYvk7U+6aFJntHdl1fVS5IcSvLs9SvpZQBgcaY5/eS27u5MLrR1HN9QnJnk7Kq6Mclrk5xVVUd8K9LdF3T3anevrqysTLlpAICpbbeXuSnJTd19+eTxxVkLOTbQywDA4kwTary+ql6e5NSqenqSP0nyG1u9qbuf1d2ndfeBJE9K8qfdfc6OqgUAOH7b7WU+keSvquobJk89Msm1w5UJAByvLU8/6e5frqpHJ/l0km9I8gvd/fbBKwMAmIEd9jLPSPI7kzuf3JDk3IHKBAC2YZpramRy4N92kNHdlyW5bLvvBwDYie32Mt19dZLV2VcEAMzCUUONqro1k3NPN9PdpwxSEQDADOhlAGD5HTXU6O6Tk6SqnpPk5iSvTlJJnpLkvnOpDgBgm/QyALD8prlQ6Nnd/WvdfWt3f7q7fz3JE4YuDABgRvQyALCkpgk1PltVT6mqE6vqhKp6SpLPDl0YAMCM6GUAYElNE2r8uyTfn+Svk9yS5ImT5wAAxkAvAwBLappbut4YUzQBgJHSywDA8tpypkZVnVZVb6yqWyY/v19Vp82jOACAndLLAMDymub0k1cmeXOSr5n8vGXyHADAGOhlAGBJTRNqrHT3K7v79snPq5KsDFwXAMCs6GUAYElNE2p8sqrOmVwx/MSqOifJJ4cuDABgRvQyALCkpgk1fjhrVwz/RJKbk3xfknOHLAoAYIb0MgCwpKa5+8n/SXL2HGoBAJg5vQwALK8tQ42qOj3JM5IcWL9+d2sOAIBdTy8DAMtry1AjyZuSXJi1K4V/cdhyAABmTi8DAEtqmlDjc9390sErAQAYhl4GAJbUNKHGS6rq/CRvS/L5O57s7qsGqwoAYHb0MgCwpKYJNR6c5KlJzsqdUzZ78hgAYLfTywDAkpom1Hhikq/r7tuGLgYAYAB6GQBYUidMsc4Hk5w6dCEAAAPRywDAkppmpsapST5UVVdk43moboMGAIyBXgYAltQ0ocb5g1cBADAcvQwALKktQ43ufuc8CgEAGIJeBgCW1zTX1AAAAADYdYQaAAAAwCgdNdSoqndM/nz+/MoBAJgNvQwALL9jXVPjvlX1LUnOrqrXJlg1/2gAABL8SURBVKn1L3b3VYNWBgCwM3oZAFhyxwo1fiHJs5OcluRFd3mtk5w1VFEAADOglwGAJXfUUKO7L05ycVU9u7ufM8eaAAB2TC8DAMtvmlu6Pqeqzk7yiMlTl3X3HwxbFgDAbOhlAGB5bXn3k6p6bpLzklw7+Tmvqv7L0IUBAMyCXgYAlteWMzWSPC7JQ7r7i0lSVRcleV+Snx2yMACAGdHLAMCS2nKmxsSp65a/dIhCAAAGpJcBgCU0zUyN5yZ5X1VdmrVboT0iyaGt3lRVd0/yriRfMtnPxd19/g5qBQDYjm31MgDA7jfNhUJfU1WXJfmXk6d+prs/McW2P5/krO7+TFXdLcmfVdUfdvd7tl8uAMDx2UEvAwDsctPM1Eh335zkzcez4e7uJJ+ZPLzb5KePqzoAgBnYTi8DAOx+015TY1uq6sSqujrJLUne3t2XD7k/AAAAYO+YaqbGdnX3F5I8pKpOTfLGqnpQd39w/TpVdTDJwSTZv3//zGs4cOiSmW8TAAAAWLxjztSYzLT40E530t2fSnJpksds8toF3b3a3asrKys73RUAwD+aVS8DAOxOxww1JjMtPlxVxz2FoqpWJjM0UlX3SPLoJJoKAGBudtLLAAC73zSnn3xZkmuq6n8l+ewdT3b32Vu8775JLqqqE7MWnry+u/9g25UCAGzPdnsZAGCXmybUePZ2Ntzd709yxnbeCwAwQ9vqZQCA3W/LUKO731lVX5vkAd39J1V1zyQnDl8aAMDO6WUAYHlteUvXqnp6kouTvHzy1P2SvGnIogAAZkUvAwDLa8tQI8mPJjkzyaeTpLs/kuQrhywKAGCG9DIAsKSmCTU+39233fGgqvYl6eFKAgCYKb0MACypaUKNd1bVzya5R1U9OsnvJXnLsGUBAMyMXgYAltQ0ocahJIeTfCDJf0jy1iQ/P2RRAAAztKNepqpOrKr3VZVb0wPALjPN3U++WFUXJbk8a1M1P9zdpmwCAKMwg17mvCTXJTlliPoAgO2b5u4nj0vyF0lemuRXk1xfVd81dGEAALOwk16mqk5L8rgkrxiuQgBgu7acqZHkhUm+s7uvT5Kq+idJLknyh0MWBgAwIzvpZV6c5KeTnDxceQDAdk0Tatx6RxMwcUOSWweqBwBg1rbVy1TV45Pc0t3vrarvOMZ6B5McTJL9+/fvsFTm4cChSxZdAgAzctRQo6q+d7J4ZVW9Ncnrs3Ye6hOTXDGH2gAAtm0GvcyZSc6uqscmuXuSU6rqt7v7nPUrdfcFSS5IktXVVdcdA4A5OtZMje9et/zXSb59snw4yT0GqwgAYDZ21Mt097OSPCtJJjM1fvKugQYAsFhHDTW6+9x5FgIAMEt6GQBYflteU6OqTk/yjCQH1q/f3WcPVxYAwGzMopfp7suSXDbj0gCAHZrmQqFvSnJhkrck+eKw5QAAzJxeBgCW1DShxue6+6WDVwIAMAy9DAAsqWlCjZdU1flJ3pbk83c82d1XDVYVAMDs6GUAYElNE2o8OMlTk5yVO6ds9uQxAMBup5cBgCU1TajxxCRf1923DV0MAMAA9DIAsKROmGKdDyY5dehCAAAGopcBgCU1zUyNU5N8qKquyMbzUN3SFQAYA70MACypaUKN8wevAgBgOHoZAFhSW4Ya3f3OeRQCADAEvQwALK8tQ42qujVrVwhPkpOS3C3JZ7v7lCELAwCYBb0MACyvaWZqnHzHclVVkickefiQRQEAzIpeBgCW1zR3P/lHveZNSf71QPUAAAxGLwMAy2Wa00++d93DE5KsJvncYBUBAMyQXgYAltc0dz/57nXLtye5MWvTNgEAxkAvAwBLapprapw7j0IAAIaglwGA5XXUUKOqfuEY7+vufs4A9QAAzIReBgCW37Fmanx2k+fuleRpSb4iiUYAANjN9DIAsOSOGmp09wvvWK6qk5Ocl+TcJK9N8sKjvQ8AYDfQywDA8jvmNTWq6suT/ESSpyS5KMlDu/tv51EYAMBO6WUAYLmdcLQXquoFSa5IcmuSB3f3Lx5PE1BV96+qS6vq2qq6pqrOm0G9AABT2WkvAwDsfkcNNZI8M8nXJPn5JB+vqk9Pfm6tqk9Pse3bkzyzux+Y5OFJfrSqHrjzkgEAprLTXgYA2OWOdU2NYwUeW+rum5PcPFm+taquS3K/JNfuZLsAANPYaS8DAOx+x7ymxqxU1YEkZyS5fJPXDiY5mCT79++fRznAHnHg0CWLLgFgx3yWAcyOz9Rh3Pi8xy1s34N/g1FV907y+0l+vLuPmOrZ3Rd092p3r66srAxdDgAAALAkBg01qupuWQs0fqe73zDkvgAAAIC9ZbBQo6oqyYVJruvuFw21HwAAAGBvGnKmxplJnprkrKq6evLz2AH3BwAAAOwhg10otLv/LEkNtX0AAABgb3OrMwAAAGCUhBoAAADAKAk1AAAAgFESagAAAACjJNQAAAAARkmoAQAAAIySUAMAAAAYJaEGAAAAMEpCDQAAAGCUhBoAAADAKAk1AAAAgFESagAAAACjJNQAAAAARkmoAQAAAIySUAMAAAAYJaEGAAAAMEpCDQAAAGCUhBoAAADAKAk1AAA2UVX3r6pLq+raqrqmqs5bdE0AwEb7Fl0AAMAudXuSZ3b3VVV1cpL3VtXbu/vaRRcGAKwxUwMAYBPdfXN3XzVZvjXJdUnut9iqAID1hBoAAFuoqgNJzkhy+WIrAQDWE2oAABxDVd07ye8n+fHu/vQmrx+sqiur6srDhw/Pv0AA2MOEGgAAR1FVd8taoPE73f2Gzdbp7gu6e7W7V1dWVuZbIADscUINAIBNVFUluTDJdd39okXXAwAcSagBALC5M5M8NclZVXX15Oexiy4KALiTW7oCAGyiu/8sSS26DgDg6MzUAAAAAEZJqAEAAACMklADAAAAGCWhBgAAADBKQg0AAABglAYLNarqN6vqlqr64FD7AAAAAPauIWdqvCrJYwbcPgAAALCHDRZqdPe7kvzfobYPAAAA7G2uqQEAAACM0sJDjao6WFVXVtWVhw8fXnQ5AAAAwEgsPNTo7gu6e7W7V1dWVhZdDgAAADASCw81AAAAALZjyFu6vibJu5N8Q1XdVFVPG2pfAAAAwN6zb6gNd/eTh9o2AAAAgNNPAAAAgFESagAAAACjJNQAAAAARkmoAQAAAIySUAMAAAAYJaEGAAAAMEpCDQAAAGCUhBoAAADAKO1bdAEAAAAc6cChSxZdAux6ZmoAAAAAoyTUAAAAAEZJqAEAAACMklADAAAAGCWhBgAAADBKQg0AAABglIQaAAAAwCgJNQAAAIBREmoAAAAAoyTUAAAAAEZJqAEAAACMklADAAAAGCWhBgAAADBKQg0AAABglIQaAAAAwCgJNQAAAIBREmoAAAAAoyTUAAAAAEZJqAEAAACMklADAAAAGCWhBgAAADBKQg0AAABglIQaAAAAwCgNGmpU1WOq6sNVdX1VHRpyXwAAs6aXAYDdbbBQo6pOTPKyJN+V5IFJnlxVDxxqfwAAs6SXAYDdb8iZGg9Lcn1339DdtyV5bZInDLg/AIBZ0ssAwC43ZKhxvyR/te7xTZPnAADGQC8DALvcvkUXUFUHkxycPPxMVX14kfWsc58kf7PoIpaUsR2GcR2OsR2GcU1Szx9ks/dJ8rWDbJkjbNLLfDJ+t9fzb/1IxmQj47GR8TiSMdlo143HQP3MVL3MkKHGx5Lcf93j0ybPbdDdFyS5YMA6tqWqruzu1UXXsYyM7TCM63CM7TCM63AmY3tg0XUsgW31Mn63NzIeRzImGxmPjYzHkYzJRsZjoyFPP7kiyQOq6vSqOinJk5K8ecD9AQDMkl4GAHa5wWZqdPftVfVjSf44yYlJfrO7rxlqfwAAs6SXAYDdb9BranT3W5O8dch9DGjXnRKzRIztMIzrcIztMIzrcIztjGyzlzH+GxmPIxmTjYzHRsbjSMZkI+OxTnX3omsAAAAAOG5DXlMDAAAAYDBCjYmq+vKqentVfWTy55cdZb39VfW2qrquqq6tqgPzrXR8ph3bybqnVNVNVfWr86xxjKYZ16p6SFW9u6quqar3V9UPLKLWsaiqx1TVh6vq+qo6tMnrX1JVr5u8frl//9OZYlx/YvJ5+v6qekdVuRXplLYa23Xr/duq6qpypfQBOM5t5Pi0xjHlSI4HG/kM32ia8aiq75/8jlxTVb877xrnbYp/M/ur6tKqet/k381jF1Hnogk17nQoyTu6+wFJ3jF5vJnfSvKC7v7GJA9Lcsuc6huzacc2SZ6T5F1zqWr8phnXv0/y77v7nyV5TJIXV9Wpc6xxNKrqxCQvS/JdSR6Y5MlV9cC7rPa0JH/b3f80ya8kGeaO3EtkynF9X5LV7v7nSS5O8kvzrXKcphzbVNXJSc5Lcvl8K9xTHOc22vPHJ8eUIzkebOQzfKNpxqOqHpDkWUnOnHx2/PjcC52jKX9Hfj7J67v7jKzdoevX5lvl7iDUuNMTklw0Wb4oyffcdYXJL9G+7n57knT3Z7r77+dX4mhtObZJUlX/IslXJXnbnOoauy3Htbv/vLs/Mln+eNZCuJW5VTguD0tyfXff0N23JXlt1sZ4vfVjfnGSR1ZVzbHGMdpyXLv70nWfpe9JctqcaxyraX5nk7X/RD8/yefmWdwe4zi3keOTY8pmHA828hm+0TTj8fQkL+vuv02S7l72L5enGZNOcspk+UuTfHyO9e0aQo07fVV33zxZ/kTWmo67+vokn6qqN0ym+LxgkqBxbFuObVWdkOSFSX5ynoWN3DS/s/+oqh6W5KQkfzF0YSN1vyR/te7xTZPnNl2nu29P8ndJvmIu1Y3XNOO63tOS/OGgFS2PLce2qh6a5P7dfck8C9uDHOc2cnxyTNmM48FGPsM3mub34+uTfH1V/Y+qek9VPWZu1S3GNGPyi0nOqaqbsnanrmfMp7TdZdBbuu42VfUnSb56k5d+bv2D7u6q2uy2MPuSfFuSM5J8NMnrkvxQkgtnW+n4zGBsfyTJW7v7puX+kuL4zGBc79jOfZO8OskPdvcXZ1slzEZVnZNkNcm3L7qWZTD5T/SLsnacYocc5zZyfGJIjgc+w49iX5IHJPmOrM3ieVdVPbi7P7XQqhbryUle1d0vrKpvTvLqqnrQXvs83VOhRnc/6mivVdVfV9V9u/vmyQF2s+lMNyW5urtvmLznTUkeHqHGLMb2m5N8W1X9SJJ7Jzmpqj7T3cc6L3npzWBcU1WnJLkkyc9193sGKnUZfCzJ/dc9Pm3y3Gbr3FRV+7I2ze+T8ylvtKYZ11TVo7L2n6Fv7+7Pz6m2sdtqbE9O8qAkl03+E/3VSd5cVWd395Vzq3JJOM5t5Pi0JceUIzkebOQzfKNpfj9uSnJ5d/9Dkr+sqj/PWshxxXxKnLtpxuRpWbsuUbr73VV19yT3yR677qPTT+705iQ/OFn+wST/bZN1rkhyalXdcc7nWUmunUNtY7fl2Hb3U7p7f3cfyNrU3N8aa6M3R1uOa1WdlOSNWRvPi+dY2xhdkeQBVXX6ZNyelLUxXm/9mH9fkj/t7qN+A0mSKca1qs5I8vIkZ++B82Nn6Zhj291/19336e4Dk8/W92RtjJexGV40x7mNHJ8cUzbjeLCRz/CNpvk386aszdJIVd0na6ej3DDPIudsmjH5aJJHJklVfWOSuyc5PNcqdwGhxp2el+TRVfWRJI+aPE5VrVbVK5Kku7+QtUbkHVX1gSSV5DcWVO+YbDm2bMs04/r9SR6R5Ieq6urJz0MWU+7uNjmf+ceS/HGS67J2Jelrquo/V9XZk9UuTPIVVXV9kp/Ise9wQKYe1xdk7Zvr35v8jt71gM0mphxb5sNxbqM9f3xyTDmS48FGPsM3mnI8/jjJJ6vq2iSXJvmp7l7a2U1Tjskzkzy9qv53ktck+aElD0c3VXvw7wwAAAAsATM1AAAAgFESagAAAACjJNQAAAAARkmoAQAAAIySUAMAAAAYpX2LLgBYvKr6QpIPrHvqtd39vEXVAwBwPPQysHe5pSuQqvpMd997i3VO7O4vrHu8b3L/7K22PdV6AADbpZeBvcvpJ8BRVdWNVfX8qroqyROr6rKqenFVXZnkvKo6UFV/WlXvr6p3VNX+yfteVVX/taouT/JLC/1LAAB7ll4Glp/TT4AkuUdVXb3u8XO7+3WT5U9290OTpKr+Y5KTunt18vgtSS7q7ouq6oeTvDTJ90zed1qSb1n/jQgAwED0MrBHCTWAJPl/3f2Qo7z2umM8/uYk3ztZfnU2fpPxe5oAAGBO9DKwRzn9BNjKZ7d4PO37AAAWQS8DS0yoAezE/0zypMnyU5L89wXWAgBwvPQyMHJOPwGSI89D/aPuPjTF+56R5JVV9VNJDic5d5DqAACOTS8De5RbugIAAACj5PQTAAAAYJSEGgAAAMAoCTUAAACAURJqAAAAAKMk1AAAAABGSagBAAAAjJJQAwAAABgloQYAAAAwSv8fkz29Aw++tjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1332x756 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.subplot(221)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[0], y_test[0], basic_error, show = False)\n",
    "plt.subplot(222)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[1], y_test[1], basic_error, show = False)\n",
    "plt.subplot(223)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[2], y_test[2], basic_error, show = False)\n",
    "plt.subplot(224)\n",
    "crowd01.plot_error_dist_on_sample(X_test_red[3], y_test[3], basic_error, show = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3197507002101804"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(crowd01.predict(X_test_red), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The results are good, however we remark a bias which has to be corrected using other networks in the crowd (of other type maybe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Dropout layers\n",
    "Dropout layers have been reported in the litterature to bring good results to avoid overfitting in combination with L2 regularizers http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf (Srivastava et al.). It will train the model while keeping only a neuron active with probability p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dropout() got an unexpected keyword argument 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-89512d890d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model = tf.keras.Sequential([\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Assuming each layer represent a link between particules, we begin with 4 layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dropout() got an unexpected keyword argument 'activation'"
     ]
    }
   ],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Assuming each layer represent a link between particules, we begin with 4 layers\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    tf.layers.dropout(64, rate=0.1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train the model on our data\n",
    "# Number of epochs the network should run through\n",
    "EPOCHS = 100\n",
    "# Size of the batch for optimization\n",
    "BATCH_SIZE = 32\n",
    "# Set up validation split\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "# This will avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature selection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 3004)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized_red.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")\n",
    "X_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(X_red) * TRAIN_SET_PERC)\n",
    "X_train_red = X_red[: train_set_size]\n",
    "X_test_red = X_red[train_set_size:]\n",
    "y_train = y[: train_set_size]\n",
    "y_test = y[train_set_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_red: (30049, 3004)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_red: \" + str(X_red.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Number of layers and neurons doesn't really matter, we need as much as possible.\n",
    "    # We well take care of overfitting with regularizers.\n",
    "    # We chose relu activation (relative usual choice when working on regression)\n",
    "    # We add L2 regularizers on hidden layers to avoid overfitting the data. Threshold should be tuned.\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24339/24339 [==============================] - 21s 882us/step - loss: 16.2423 - mean_absolute_error: 2.7712 - val_loss: 11.7952 - val_mean_absolute_error: 2.7973\n",
      "Epoch 2/200\n",
      "24339/24339 [==============================] - 20s 823us/step - loss: 2.7857 - mean_absolute_error: 1.0994 - val_loss: 2.2373 - val_mean_absolute_error: 0.9991\n",
      "Epoch 3/200\n",
      "24339/24339 [==============================] - 20s 836us/step - loss: 0.8024 - mean_absolute_error: 0.4852 - val_loss: 1.8001 - val_mean_absolute_error: 0.8622\n",
      "Epoch 4/200\n",
      "24339/24339 [==============================] - 21s 855us/step - loss: 0.6898 - mean_absolute_error: 0.4331 - val_loss: 1.5499 - val_mean_absolute_error: 0.7983\n",
      "Epoch 5/200\n",
      "24339/24339 [==============================] - 20s 808us/step - loss: 0.7234 - mean_absolute_error: 0.4703 - val_loss: 1.5848 - val_mean_absolute_error: 0.8310\n",
      "Epoch 6/200\n",
      "24339/24339 [==============================] - 19s 799us/step - loss: 0.7371 - mean_absolute_error: 0.4794 - val_loss: 1.2641 - val_mean_absolute_error: 0.7065\n",
      "Epoch 7/200\n",
      "24339/24339 [==============================] - 19s 790us/step - loss: 0.6793 - mean_absolute_error: 0.4450 - val_loss: 1.2880 - val_mean_absolute_error: 0.7394\n",
      "Epoch 8/200\n",
      "24339/24339 [==============================] - 20s 823us/step - loss: 0.7408 - mean_absolute_error: 0.4802 - val_loss: 1.2129 - val_mean_absolute_error: 0.7189\n",
      "Epoch 9/200\n",
      "24339/24339 [==============================] - 20s 840us/step - loss: 0.7020 - mean_absolute_error: 0.4618 - val_loss: 1.1131 - val_mean_absolute_error: 0.6642\n",
      "Epoch 10/200\n",
      "24339/24339 [==============================] - 19s 799us/step - loss: 0.6423 - mean_absolute_error: 0.4366 - val_loss: 1.0270 - val_mean_absolute_error: 0.6376\n",
      "Epoch 11/200\n",
      "24339/24339 [==============================] - 20s 823us/step - loss: 0.5638 - mean_absolute_error: 0.3984 - val_loss: 1.0245 - val_mean_absolute_error: 0.6241\n",
      "Epoch 12/200\n",
      "24339/24339 [==============================] - 20s 811us/step - loss: 0.5283 - mean_absolute_error: 0.4005 - val_loss: 0.9990 - val_mean_absolute_error: 0.6395\n",
      "Epoch 13/200\n",
      "24339/24339 [==============================] - 19s 773us/step - loss: 0.4806 - mean_absolute_error: 0.3786 - val_loss: 0.8085 - val_mean_absolute_error: 0.5569\n",
      "Epoch 14/200\n",
      "24339/24339 [==============================] - 19s 799us/step - loss: 0.4715 - mean_absolute_error: 0.3770 - val_loss: 0.8427 - val_mean_absolute_error: 0.5616\n",
      "Epoch 15/200\n",
      "24339/24339 [==============================] - 19s 797us/step - loss: 0.4305 - mean_absolute_error: 0.3601 - val_loss: 0.8673 - val_mean_absolute_error: 0.6014\n",
      "Epoch 16/200\n",
      "24339/24339 [==============================] - 20s 802us/step - loss: 0.4215 - mean_absolute_error: 0.3613 - val_loss: 0.7645 - val_mean_absolute_error: 0.5379\n",
      "Epoch 17/200\n",
      "24339/24339 [==============================] - 19s 777us/step - loss: 0.4063 - mean_absolute_error: 0.3540 - val_loss: 1.4885 - val_mean_absolute_error: 0.9263\n",
      "Epoch 18/200\n",
      "24339/24339 [==============================] - 23s 931us/step - loss: 0.4090 - mean_absolute_error: 0.3639 - val_loss: 0.7458 - val_mean_absolute_error: 0.5332\n",
      "Epoch 19/200\n",
      "24339/24339 [==============================] - 23s 953us/step - loss: 0.3557 - mean_absolute_error: 0.3266 - val_loss: 0.8022 - val_mean_absolute_error: 0.5676\n",
      "Epoch 20/200\n",
      "24339/24339 [==============================] - 20s 840us/step - loss: 0.3305 - mean_absolute_error: 0.3058 - val_loss: 0.8590 - val_mean_absolute_error: 0.6080\n",
      "Epoch 21/200\n",
      "24339/24339 [==============================] - 20s 812us/step - loss: 0.3199 - mean_absolute_error: 0.3069 - val_loss: 0.7241 - val_mean_absolute_error: 0.5287\n",
      "Epoch 22/200\n",
      "24339/24339 [==============================] - 23s 937us/step - loss: 0.3112 - mean_absolute_error: 0.3044 - val_loss: 0.7433 - val_mean_absolute_error: 0.5512\n",
      "Epoch 23/200\n",
      "24339/24339 [==============================] - 23s 933us/step - loss: 0.2952 - mean_absolute_error: 0.2894 - val_loss: 0.6752 - val_mean_absolute_error: 0.5300\n",
      "Epoch 24/200\n",
      "24339/24339 [==============================] - 23s 928us/step - loss: 0.2855 - mean_absolute_error: 0.2936 - val_loss: 0.6530 - val_mean_absolute_error: 0.5126\n",
      "Epoch 25/200\n",
      "24339/24339 [==============================] - 23s 941us/step - loss: 0.2668 - mean_absolute_error: 0.2820 - val_loss: 0.6783 - val_mean_absolute_error: 0.5221\n",
      "Epoch 26/200\n",
      "24339/24339 [==============================] - 20s 825us/step - loss: 0.2892 - mean_absolute_error: 0.2930 - val_loss: 0.7017 - val_mean_absolute_error: 0.5235\n",
      "Epoch 27/200\n",
      "24339/24339 [==============================] - 20s 841us/step - loss: 0.2647 - mean_absolute_error: 0.2690 - val_loss: 0.7243 - val_mean_absolute_error: 0.5336\n",
      "Epoch 28/200\n",
      "24339/24339 [==============================] - 20s 841us/step - loss: 0.2390 - mean_absolute_error: 0.2575 - val_loss: 0.6537 - val_mean_absolute_error: 0.5297\n",
      "Epoch 29/200\n",
      "24339/24339 [==============================] - 19s 789us/step - loss: 0.2182 - mean_absolute_error: 0.2490 - val_loss: 0.6120 - val_mean_absolute_error: 0.4993\n",
      "Epoch 30/200\n",
      "24339/24339 [==============================] - 20s 826us/step - loss: 0.2359 - mean_absolute_error: 0.2596 - val_loss: 0.6368 - val_mean_absolute_error: 0.5054\n",
      "Epoch 31/200\n",
      "24339/24339 [==============================] - 19s 785us/step - loss: 0.2197 - mean_absolute_error: 0.2545 - val_loss: 0.6418 - val_mean_absolute_error: 0.5116\n",
      "Epoch 32/200\n",
      "24339/24339 [==============================] - 20s 810us/step - loss: 0.2394 - mean_absolute_error: 0.2635 - val_loss: 0.6511 - val_mean_absolute_error: 0.5039\n",
      "Epoch 33/200\n",
      "24339/24339 [==============================] - 22s 916us/step - loss: 0.2427 - mean_absolute_error: 0.2601 - val_loss: 0.7265 - val_mean_absolute_error: 0.5330\n",
      "Epoch 34/200\n",
      "24339/24339 [==============================] - 22s 911us/step - loss: 0.2086 - mean_absolute_error: 0.2293 - val_loss: 0.6749 - val_mean_absolute_error: 0.5096\n",
      "Epoch 35/200\n",
      "24339/24339 [==============================] - 23s 944us/step - loss: 0.2037 - mean_absolute_error: 0.2382 - val_loss: 0.6290 - val_mean_absolute_error: 0.5074\n",
      "Epoch 36/200\n",
      "24339/24339 [==============================] - 23s 954us/step - loss: 0.1883 - mean_absolute_error: 0.2320 - val_loss: 0.7271 - val_mean_absolute_error: 0.5856\n",
      "Epoch 37/200\n",
      "24339/24339 [==============================] - 23s 929us/step - loss: 0.1802 - mean_absolute_error: 0.2271 - val_loss: 0.6096 - val_mean_absolute_error: 0.5055\n",
      "Epoch 38/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.2456 - mean_absolute_error: 0.2600 - val_loss: 0.6939 - val_mean_absolute_error: 0.5281\n",
      "Epoch 39/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.2102 - mean_absolute_error: 0.2284 - val_loss: 0.6167 - val_mean_absolute_error: 0.5061\n",
      "Epoch 40/200\n",
      "24339/24339 [==============================] - 23s 933us/step - loss: 0.1808 - mean_absolute_error: 0.2239 - val_loss: 0.6464 - val_mean_absolute_error: 0.5053\n",
      "Epoch 41/200\n",
      "24339/24339 [==============================] - 23s 937us/step - loss: 0.1664 - mean_absolute_error: 0.2146 - val_loss: 0.6742 - val_mean_absolute_error: 0.5446\n",
      "Epoch 42/200\n",
      "24339/24339 [==============================] - 24s 973us/step - loss: 0.1646 - mean_absolute_error: 0.2185 - val_loss: 0.6145 - val_mean_absolute_error: 0.5169\n",
      "Epoch 43/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1732 - mean_absolute_error: 0.2273 - val_loss: 0.6063 - val_mean_absolute_error: 0.4985\n",
      "Epoch 44/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1905 - mean_absolute_error: 0.2318 - val_loss: 0.6006 - val_mean_absolute_error: 0.4967\n",
      "Epoch 45/200\n",
      "24339/24339 [==============================] - 23s 929us/step - loss: 0.1677 - mean_absolute_error: 0.2173 - val_loss: 0.6333 - val_mean_absolute_error: 0.5065\n",
      "Epoch 46/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1485 - mean_absolute_error: 0.2049 - val_loss: 0.6053 - val_mean_absolute_error: 0.5040\n",
      "Epoch 47/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1506 - mean_absolute_error: 0.2077 - val_loss: 0.6334 - val_mean_absolute_error: 0.5152\n",
      "Epoch 48/200\n",
      "24339/24339 [==============================] - 21s 849us/step - loss: 0.1800 - mean_absolute_error: 0.2255 - val_loss: 0.7606 - val_mean_absolute_error: 0.5862\n",
      "Epoch 49/200\n",
      "24339/24339 [==============================] - 20s 839us/step - loss: 0.1715 - mean_absolute_error: 0.2152 - val_loss: 0.6018 - val_mean_absolute_error: 0.4932\n",
      "Epoch 50/200\n",
      "24339/24339 [==============================] - 21s 847us/step - loss: 0.1471 - mean_absolute_error: 0.1995 - val_loss: 0.6093 - val_mean_absolute_error: 0.5032\n",
      "Epoch 51/200\n",
      "24339/24339 [==============================] - 21s 853us/step - loss: 0.1470 - mean_absolute_error: 0.2052 - val_loss: 0.7892 - val_mean_absolute_error: 0.6186\n",
      "Epoch 52/200\n",
      "24339/24339 [==============================] - 21s 848us/step - loss: 0.1377 - mean_absolute_error: 0.1978 - val_loss: 0.6148 - val_mean_absolute_error: 0.5033\n",
      "Epoch 53/200\n",
      "24339/24339 [==============================] - 21s 850us/step - loss: 0.1454 - mean_absolute_error: 0.2076 - val_loss: 0.6417 - val_mean_absolute_error: 0.5099\n",
      "Epoch 54/200\n",
      "24339/24339 [==============================] - 21s 846us/step - loss: 0.1496 - mean_absolute_error: 0.2062 - val_loss: 0.6763 - val_mean_absolute_error: 0.5237\n",
      "Epoch 55/200\n",
      "24339/24339 [==============================] - 21s 851us/step - loss: 0.1593 - mean_absolute_error: 0.2119 - val_loss: 0.6438 - val_mean_absolute_error: 0.5134\n",
      "Epoch 56/200\n",
      "24339/24339 [==============================] - 21s 855us/step - loss: 0.1354 - mean_absolute_error: 0.1942 - val_loss: 0.6616 - val_mean_absolute_error: 0.5347\n",
      "Epoch 57/200\n",
      "24339/24339 [==============================] - 21s 850us/step - loss: 0.1306 - mean_absolute_error: 0.1938 - val_loss: 0.6340 - val_mean_absolute_error: 0.5216\n",
      "Epoch 58/200\n",
      "24339/24339 [==============================] - 22s 896us/step - loss: 0.1341 - mean_absolute_error: 0.2000 - val_loss: 0.6204 - val_mean_absolute_error: 0.5107\n",
      "Epoch 59/200\n",
      "24339/24339 [==============================] - 22s 901us/step - loss: 0.1411 - mean_absolute_error: 0.2084 - val_loss: 0.6909 - val_mean_absolute_error: 0.5418\n",
      "Epoch 60/200\n",
      "24339/24339 [==============================] - 22s 897us/step - loss: 0.1452 - mean_absolute_error: 0.2076 - val_loss: 0.6232 - val_mean_absolute_error: 0.5106\n",
      "Epoch 61/200\n",
      "24339/24339 [==============================] - 22s 899us/step - loss: 0.1310 - mean_absolute_error: 0.1935 - val_loss: 0.5990 - val_mean_absolute_error: 0.5041\n",
      "Epoch 62/200\n",
      "24339/24339 [==============================] - 22s 901us/step - loss: 0.1302 - mean_absolute_error: 0.1952 - val_loss: 0.6449 - val_mean_absolute_error: 0.5356\n",
      "Epoch 63/200\n",
      "24339/24339 [==============================] - 22s 907us/step - loss: 0.1372 - mean_absolute_error: 0.2017 - val_loss: 0.6185 - val_mean_absolute_error: 0.5046\n",
      "Epoch 64/200\n",
      "24339/24339 [==============================] - 22s 907us/step - loss: 0.1312 - mean_absolute_error: 0.1951 - val_loss: 0.6098 - val_mean_absolute_error: 0.5072\n",
      "Epoch 65/200\n",
      "24339/24339 [==============================] - 22s 898us/step - loss: 0.1250 - mean_absolute_error: 0.1919 - val_loss: 0.5898 - val_mean_absolute_error: 0.5003\n",
      "Epoch 66/200\n",
      "24339/24339 [==============================] - 22s 907us/step - loss: 0.1355 - mean_absolute_error: 0.2012 - val_loss: 0.6412 - val_mean_absolute_error: 0.5416\n",
      "Epoch 67/200\n",
      "24339/24339 [==============================] - 22s 909us/step - loss: 0.1308 - mean_absolute_error: 0.1983 - val_loss: 0.6126 - val_mean_absolute_error: 0.5030\n",
      "Epoch 68/200\n",
      "24339/24339 [==============================] - 23s 961us/step - loss: 0.1226 - mean_absolute_error: 0.1887 - val_loss: 0.5786 - val_mean_absolute_error: 0.4958\n",
      "Epoch 69/200\n",
      "24339/24339 [==============================] - 22s 913us/step - loss: 0.1266 - mean_absolute_error: 0.1952 - val_loss: 0.5816 - val_mean_absolute_error: 0.4979\n",
      "Epoch 70/200\n",
      "24339/24339 [==============================] - 23s 925us/step - loss: 0.1257 - mean_absolute_error: 0.1919 - val_loss: 0.6068 - val_mean_absolute_error: 0.5106\n",
      "Epoch 71/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1278 - mean_absolute_error: 0.1955 - val_loss: 0.6461 - val_mean_absolute_error: 0.5298\n",
      "Epoch 72/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1219 - mean_absolute_error: 0.1923 - val_loss: 0.6258 - val_mean_absolute_error: 0.5110\n",
      "Epoch 73/200\n",
      "24339/24339 [==============================] - 23s 925us/step - loss: 0.1284 - mean_absolute_error: 0.2005 - val_loss: 0.6229 - val_mean_absolute_error: 0.5189\n",
      "Epoch 74/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1216 - mean_absolute_error: 0.1907 - val_loss: 0.6717 - val_mean_absolute_error: 0.5375\n",
      "Epoch 75/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1152 - mean_absolute_error: 0.1857 - val_loss: 0.6278 - val_mean_absolute_error: 0.5089\n",
      "Epoch 76/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1181 - mean_absolute_error: 0.1922 - val_loss: 0.6200 - val_mean_absolute_error: 0.5128\n",
      "Epoch 77/200\n",
      "24339/24339 [==============================] - 22s 924us/step - loss: 0.1290 - mean_absolute_error: 0.2062 - val_loss: 0.6251 - val_mean_absolute_error: 0.5172\n",
      "Epoch 78/200\n",
      "24339/24339 [==============================] - 22s 918us/step - loss: 0.1158 - mean_absolute_error: 0.1838 - val_loss: 0.6042 - val_mean_absolute_error: 0.5040\n",
      "Epoch 79/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1142 - mean_absolute_error: 0.1850 - val_loss: 0.5741 - val_mean_absolute_error: 0.4919\n",
      "Epoch 80/200\n",
      "24339/24339 [==============================] - 22s 918us/step - loss: 0.1277 - mean_absolute_error: 0.1991 - val_loss: 0.6381 - val_mean_absolute_error: 0.5103\n",
      "Epoch 81/200\n",
      "24339/24339 [==============================] - 22s 921us/step - loss: 0.1309 - mean_absolute_error: 0.1953 - val_loss: 0.6366 - val_mean_absolute_error: 0.5025\n",
      "Epoch 82/200\n",
      "24339/24339 [==============================] - 22s 915us/step - loss: 0.1137 - mean_absolute_error: 0.1777 - val_loss: 0.6158 - val_mean_absolute_error: 0.5008\n",
      "Epoch 83/200\n",
      "24339/24339 [==============================] - 23s 926us/step - loss: 0.1119 - mean_absolute_error: 0.1805 - val_loss: 0.5786 - val_mean_absolute_error: 0.4972\n",
      "Epoch 84/200\n",
      "24339/24339 [==============================] - 22s 920us/step - loss: 0.1180 - mean_absolute_error: 0.1902 - val_loss: 0.6017 - val_mean_absolute_error: 0.4994\n",
      "Epoch 85/200\n",
      "24339/24339 [==============================] - 22s 917us/step - loss: 0.1243 - mean_absolute_error: 0.1952 - val_loss: 0.6333 - val_mean_absolute_error: 0.5171\n",
      "Epoch 86/200\n",
      "24339/24339 [==============================] - 22s 924us/step - loss: 0.1151 - mean_absolute_error: 0.1823 - val_loss: 0.6074 - val_mean_absolute_error: 0.5019\n",
      "Epoch 87/200\n",
      "24339/24339 [==============================] - 23s 928us/step - loss: 0.1120 - mean_absolute_error: 0.1824 - val_loss: 0.6273 - val_mean_absolute_error: 0.5156\n",
      "Epoch 88/200\n",
      "24339/24339 [==============================] - 22s 916us/step - loss: 0.1131 - mean_absolute_error: 0.1853 - val_loss: 0.6407 - val_mean_absolute_error: 0.5204\n",
      "Epoch 89/200\n",
      "24339/24339 [==============================] - 22s 922us/step - loss: 0.1284 - mean_absolute_error: 0.1996 - val_loss: 0.5835 - val_mean_absolute_error: 0.5040\n",
      "Epoch 90/200\n",
      "24339/24339 [==============================] - 23s 935us/step - loss: 0.1199 - mean_absolute_error: 0.1893 - val_loss: 0.6028 - val_mean_absolute_error: 0.4999\n",
      "Epoch 91/200\n",
      "24339/24339 [==============================] - 23s 928us/step - loss: 0.1162 - mean_absolute_error: 0.1815 - val_loss: 0.6563 - val_mean_absolute_error: 0.5336\n",
      "Epoch 92/200\n",
      "24339/24339 [==============================] - 23s 937us/step - loss: 0.1119 - mean_absolute_error: 0.1781 - val_loss: 0.6062 - val_mean_absolute_error: 0.5050\n",
      "Epoch 93/200\n",
      "24339/24339 [==============================] - 23s 940us/step - loss: 0.1161 - mean_absolute_error: 0.1871 - val_loss: 0.6555 - val_mean_absolute_error: 0.5338\n",
      "Epoch 94/200\n",
      "24339/24339 [==============================] - 23s 938us/step - loss: 0.1189 - mean_absolute_error: 0.1909 - val_loss: 0.5772 - val_mean_absolute_error: 0.4925\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24339/24339 [==============================] - 21s 851us/step - loss: 0.1102 - mean_absolute_error: 0.1804 - val_loss: 0.6129 - val_mean_absolute_error: 0.5024\n",
      "Epoch 96/200\n",
      "24339/24339 [==============================] - 20s 839us/step - loss: 0.1113 - mean_absolute_error: 0.1835 - val_loss: 0.6052 - val_mean_absolute_error: 0.4992\n",
      "Epoch 97/200\n",
      "24339/24339 [==============================] - 21s 848us/step - loss: 0.1150 - mean_absolute_error: 0.1902 - val_loss: 0.6312 - val_mean_absolute_error: 0.5190\n",
      "Epoch 98/200\n",
      "24339/24339 [==============================] - 21s 849us/step - loss: 0.1101 - mean_absolute_error: 0.1823 - val_loss: 0.6291 - val_mean_absolute_error: 0.5101\n",
      "Epoch 99/200\n",
      "24339/24339 [==============================] - 21s 849us/step - loss: 0.1202 - mean_absolute_error: 0.1958 - val_loss: 0.6232 - val_mean_absolute_error: 0.5087\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  1538560   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  513       \n",
      "=================================================================\n",
      "Total params: 3,377,665\n",
      "Trainable params: 3,377,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.1\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(X_train_red, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6834309411311952"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_test_red, batch_size=32)\n",
    "rmse(result, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of feature selection matrix - polynomial expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized_red.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 3004)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = build_poly(X_red, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30049, 6008)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(X_red) * TRAIN_SET_PERC)\n",
    "X_poly_train_red = X_poly[: train_set_size]\n",
    "X_poly_test_red = X_poly[train_set_size:]\n",
    "y_train = y[: train_set_size]\n",
    "y_test = y[train_set_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_poly_red: (30049, 6008)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_poly_red: \" + str(X_poly.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up as much memory as possible before starting\n",
    "garbage_collection()\n",
    "\n",
    "# Prepare model \n",
    "model = tf.keras.Sequential([\n",
    "    # Number of layers and neurons doesn't really matter, we need as much as possible.\n",
    "    # We well take care of overfitting with regularizers.\n",
    "    # We chose relu activation (relative usual choice when working on regression)\n",
    "    # We add L2 regularizers on hidden layers to avoid overfitting the data. Threshold should be tuned.\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)),\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    layers.Dense(1, activation='relu')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24339 samples, validate on 2705 samples\n",
      "Epoch 1/200\n",
      "24339/24339 [==============================] - 15s 609us/step - loss: 68.8399 - mean_absolute_error: 5.7557 - val_loss: 27.8898 - val_mean_absolute_error: 3.7220\n",
      "Epoch 2/200\n",
      "24339/24339 [==============================] - 12s 498us/step - loss: 6.5372 - mean_absolute_error: 1.8642 - val_loss: 18.6232 - val_mean_absolute_error: 2.6665\n",
      "Epoch 3/200\n",
      "24339/24339 [==============================] - 12s 502us/step - loss: 2.9390 - mean_absolute_error: 1.2613 - val_loss: 13.8524 - val_mean_absolute_error: 2.5427\n",
      "Epoch 4/200\n",
      "24339/24339 [==============================] - 12s 504us/step - loss: 2.3184 - mean_absolute_error: 1.1061 - val_loss: 16.8185 - val_mean_absolute_error: 2.3774\n",
      "Epoch 5/200\n",
      "24339/24339 [==============================] - 12s 508us/step - loss: 2.9168 - mean_absolute_error: 1.1900 - val_loss: 16.8111 - val_mean_absolute_error: 3.0914\n",
      "Epoch 6/200\n",
      "24339/24339 [==============================] - 12s 512us/step - loss: 4.4732 - mean_absolute_error: 1.3325 - val_loss: 9.7703 - val_mean_absolute_error: 1.8556\n",
      "Epoch 7/200\n",
      "24339/24339 [==============================] - 13s 516us/step - loss: 1.1854 - mean_absolute_error: 0.8141 - val_loss: 7.0981 - val_mean_absolute_error: 1.6146\n",
      "Epoch 8/200\n",
      "24339/24339 [==============================] - 12s 512us/step - loss: 0.8139 - mean_absolute_error: 0.6580 - val_loss: 6.5084 - val_mean_absolute_error: 1.5337\n",
      "Epoch 9/200\n",
      "24339/24339 [==============================] - 13s 521us/step - loss: 0.7479 - mean_absolute_error: 0.6342 - val_loss: 5.2058 - val_mean_absolute_error: 1.5439\n",
      "Epoch 10/200\n",
      "24339/24339 [==============================] - 13s 516us/step - loss: 0.7438 - mean_absolute_error: 0.6332 - val_loss: 3.6742 - val_mean_absolute_error: 1.1958\n",
      "Epoch 11/200\n",
      "24339/24339 [==============================] - 13s 522us/step - loss: 0.5379 - mean_absolute_error: 0.5337 - val_loss: 2.9012 - val_mean_absolute_error: 1.1089\n",
      "Epoch 12/200\n",
      "24339/24339 [==============================] - 13s 527us/step - loss: 0.5180 - mean_absolute_error: 0.5134 - val_loss: 3.3346 - val_mean_absolute_error: 1.1598\n",
      "Epoch 13/200\n",
      "24339/24339 [==============================] - 13s 528us/step - loss: 0.6059 - mean_absolute_error: 0.5599 - val_loss: 2.2220 - val_mean_absolute_error: 0.9951\n",
      "Epoch 14/200\n",
      "24339/24339 [==============================] - 13s 532us/step - loss: 0.5314 - mean_absolute_error: 0.5017 - val_loss: 2.0240 - val_mean_absolute_error: 0.9474\n",
      "Epoch 15/200\n",
      "24339/24339 [==============================] - 13s 531us/step - loss: 2.2644 - mean_absolute_error: 0.7110 - val_loss: 2.7938 - val_mean_absolute_error: 1.1779\n",
      "Epoch 16/200\n",
      "24339/24339 [==============================] - 13s 533us/step - loss: 0.8219 - mean_absolute_error: 0.5439 - val_loss: 1.8506 - val_mean_absolute_error: 0.8835\n",
      "Epoch 17/200\n",
      "24339/24339 [==============================] - 13s 526us/step - loss: 0.3273 - mean_absolute_error: 0.3787 - val_loss: 1.6629 - val_mean_absolute_error: 0.8276\n",
      "Epoch 18/200\n",
      "24339/24339 [==============================] - 12s 502us/step - loss: 0.2710 - mean_absolute_error: 0.3419 - val_loss: 1.7931 - val_mean_absolute_error: 0.8653\n",
      "Epoch 19/200\n",
      "24339/24339 [==============================] - 12s 492us/step - loss: 0.2916 - mean_absolute_error: 0.3579 - val_loss: 1.5916 - val_mean_absolute_error: 0.8690\n",
      "Epoch 20/200\n",
      "24339/24339 [==============================] - 16s 667us/step - loss: 0.2920 - mean_absolute_error: 0.3528 - val_loss: 1.6668 - val_mean_absolute_error: 0.8014\n",
      "Epoch 21/200\n",
      "24339/24339 [==============================] - 12s 474us/step - loss: 0.4287 - mean_absolute_error: 0.4046 - val_loss: 1.8885 - val_mean_absolute_error: 1.0049\n",
      "Epoch 22/200\n",
      "24339/24339 [==============================] - 12s 486us/step - loss: 0.3567 - mean_absolute_error: 0.3822 - val_loss: 1.4134 - val_mean_absolute_error: 0.7727\n",
      "Epoch 23/200\n",
      "24339/24339 [==============================] - 12s 473us/step - loss: 0.2337 - mean_absolute_error: 0.3088 - val_loss: 1.3867 - val_mean_absolute_error: 0.7517\n",
      "Epoch 24/200\n",
      "24339/24339 [==============================] - 11s 472us/step - loss: 0.2565 - mean_absolute_error: 0.3309 - val_loss: 1.3309 - val_mean_absolute_error: 0.7459\n",
      "Epoch 25/200\n",
      "24339/24339 [==============================] - 12s 474us/step - loss: 0.2705 - mean_absolute_error: 0.3324 - val_loss: 1.3334 - val_mean_absolute_error: 0.7598\n",
      "Epoch 26/200\n",
      "24339/24339 [==============================] - 12s 473us/step - loss: 0.3887 - mean_absolute_error: 0.3723 - val_loss: 1.4272 - val_mean_absolute_error: 0.7705\n",
      "Epoch 27/200\n",
      "24339/24339 [==============================] - 13s 517us/step - loss: 0.2545 - mean_absolute_error: 0.3153 - val_loss: 1.3307 - val_mean_absolute_error: 0.7335\n",
      "Epoch 28/200\n",
      "24339/24339 [==============================] - 12s 496us/step - loss: 0.6821 - mean_absolute_error: 0.4172 - val_loss: 1.3574 - val_mean_absolute_error: 0.7251\n",
      "Epoch 29/200\n",
      "24339/24339 [==============================] - 12s 480us/step - loss: 0.3379 - mean_absolute_error: 0.3088 - val_loss: 1.3126 - val_mean_absolute_error: 0.7270\n",
      "Epoch 30/200\n",
      "24339/24339 [==============================] - 13s 521us/step - loss: 0.4225 - mean_absolute_error: 0.3220 - val_loss: 1.3091 - val_mean_absolute_error: 0.7328\n",
      "Epoch 31/200\n",
      "24339/24339 [==============================] - 13s 519us/step - loss: 0.2132 - mean_absolute_error: 0.2818 - val_loss: 1.3056 - val_mean_absolute_error: 0.7237\n",
      "Epoch 32/200\n",
      "24339/24339 [==============================] - 13s 548us/step - loss: 0.1777 - mean_absolute_error: 0.2564 - val_loss: 1.2970 - val_mean_absolute_error: 0.7180\n",
      "Epoch 33/200\n",
      "24339/24339 [==============================] - 14s 555us/step - loss: 0.2007 - mean_absolute_error: 0.2740 - val_loss: 1.2958 - val_mean_absolute_error: 0.7564\n",
      "Epoch 34/200\n",
      "24339/24339 [==============================] - 13s 552us/step - loss: 0.2050 - mean_absolute_error: 0.2827 - val_loss: 1.2785 - val_mean_absolute_error: 0.7185\n",
      "Epoch 35/200\n",
      "24339/24339 [==============================] - 13s 554us/step - loss: 0.1758 - mean_absolute_error: 0.2545 - val_loss: 1.2339 - val_mean_absolute_error: 0.7032\n",
      "Epoch 36/200\n",
      "24339/24339 [==============================] - 13s 528us/step - loss: 0.1981 - mean_absolute_error: 0.2731 - val_loss: 1.3682 - val_mean_absolute_error: 0.7372\n",
      "Epoch 37/200\n",
      "24339/24339 [==============================] - 13s 527us/step - loss: 0.2034 - mean_absolute_error: 0.2777 - val_loss: 1.3166 - val_mean_absolute_error: 0.7328\n",
      "Epoch 38/200\n",
      "24339/24339 [==============================] - 13s 529us/step - loss: 0.1709 - mean_absolute_error: 0.2543 - val_loss: 1.3938 - val_mean_absolute_error: 0.8046\n",
      "Epoch 39/200\n",
      "24339/24339 [==============================] - 13s 525us/step - loss: 0.1632 - mean_absolute_error: 0.2478 - val_loss: 1.4540 - val_mean_absolute_error: 0.7540\n",
      "Epoch 40/200\n",
      "24339/24339 [==============================] - 13s 524us/step - loss: 0.1881 - mean_absolute_error: 0.2718 - val_loss: 1.3903 - val_mean_absolute_error: 0.7322\n",
      "Epoch 41/200\n",
      "24339/24339 [==============================] - 13s 526us/step - loss: 0.1699 - mean_absolute_error: 0.2463 - val_loss: 1.3020 - val_mean_absolute_error: 0.7335\n",
      "Epoch 42/200\n",
      "24339/24339 [==============================] - 13s 522us/step - loss: 0.2055 - mean_absolute_error: 0.2639 - val_loss: 1.4099 - val_mean_absolute_error: 0.7578\n",
      "Epoch 43/200\n",
      "24339/24339 [==============================] - 13s 529us/step - loss: 0.1512 - mean_absolute_error: 0.2337 - val_loss: 1.3557 - val_mean_absolute_error: 0.7119\n",
      "Epoch 44/200\n",
      "24339/24339 [==============================] - 13s 530us/step - loss: 0.1430 - mean_absolute_error: 0.2267 - val_loss: 1.3583 - val_mean_absolute_error: 0.7134\n",
      "Epoch 45/200\n",
      "24339/24339 [==============================] - 13s 530us/step - loss: 0.1501 - mean_absolute_error: 0.2354 - val_loss: 1.4310 - val_mean_absolute_error: 0.7364\n",
      "Epoch 46/200\n",
      "24339/24339 [==============================] - 13s 530us/step - loss: 0.1623 - mean_absolute_error: 0.2478 - val_loss: 1.3734 - val_mean_absolute_error: 0.7279\n",
      "Epoch 47/200\n",
      "24339/24339 [==============================] - 13s 536us/step - loss: 0.1393 - mean_absolute_error: 0.2235 - val_loss: 1.2579 - val_mean_absolute_error: 0.6938\n",
      "Epoch 48/200\n",
      "24339/24339 [==============================] - 12s 502us/step - loss: 0.1374 - mean_absolute_error: 0.2193 - val_loss: 1.3505 - val_mean_absolute_error: 0.7038\n",
      "Epoch 49/200\n",
      "24339/24339 [==============================] - 12s 504us/step - loss: 0.1371 - mean_absolute_error: 0.2251 - val_loss: 1.3210 - val_mean_absolute_error: 0.7144\n",
      "Epoch 50/200\n",
      "24339/24339 [==============================] - 12s 511us/step - loss: 0.8432 - mean_absolute_error: 0.2880 - val_loss: 1.5669 - val_mean_absolute_error: 0.7369\n",
      "Epoch 51/200\n",
      "24339/24339 [==============================] - 12s 508us/step - loss: 0.1758 - mean_absolute_error: 0.2401 - val_loss: 1.3623 - val_mean_absolute_error: 0.7159\n",
      "Epoch 52/200\n",
      "24339/24339 [==============================] - 12s 508us/step - loss: 0.1293 - mean_absolute_error: 0.1938 - val_loss: 1.3155 - val_mean_absolute_error: 0.7173\n",
      "Epoch 53/200\n",
      "24339/24339 [==============================] - 12s 505us/step - loss: 0.1244 - mean_absolute_error: 0.1959 - val_loss: 1.5086 - val_mean_absolute_error: 0.7373\n",
      "Epoch 54/200\n",
      "24339/24339 [==============================] - 12s 499us/step - loss: 0.1338 - mean_absolute_error: 0.2142 - val_loss: 1.4460 - val_mean_absolute_error: 0.7117\n",
      "Epoch 55/200\n",
      "24339/24339 [==============================] - 12s 492us/step - loss: 0.1461 - mean_absolute_error: 0.2244 - val_loss: 1.4769 - val_mean_absolute_error: 0.7251\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              multiple                  1538304   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  257       \n",
      "=================================================================\n",
      "Total params: 1,999,105\n",
      "Trainable params: 1,999,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.1\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(X_poly_train_red, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "          callbacks=[early_stop])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0123385147545783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_poly_test_red, batch_size=32)\n",
    "rmse(result, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
