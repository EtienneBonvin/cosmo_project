{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating electromagnetic shielding using deep learning\n",
    "\n",
    "Here we are digging the deep learning part of the automated learning. We wish to see by ourselves to which extends this is appliable to our case and if it gives better results than standard machine learning.\n",
    "\n",
    "When designing algorithms, we always have to wonder what are the requirements in terms of time / performance trade-off. In our case, the performance is the most important. Computation time should of course stay reasonable but considering the time taken to construct the matrix on which we train, as long as our algorithms don't take several minutes to run they will not take the major part of the overall time.\n",
    "\n",
    "Note that deep-learning algorithms rely a lot on data. The more you have, the better your predictions will be. Hence we highly recommand that whenever more data are available to rerun the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Clean up the memory\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "\n",
    "import crowd\n",
    "import experts\n",
    "import supercrowd as sc\n",
    "import collaborative_crowd as cc\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import timeit\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "SESSION_FOLDER = \"session/\"\n",
    "\n",
    "TRAIN_SET_PERC = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, real, loop = True):\n",
    "    '''\n",
    "    Computes RMSE between predictions and real values\n",
    "    :param : float[]\n",
    "    :param : float[]\n",
    "    :return : float\n",
    "    '''\n",
    "    if len(pred) != len(real):\n",
    "        print(\"RMSE Error : Predictions and real values arrays do not have the same length, aborting.\")\n",
    "        return None\n",
    "    \n",
    "    if loop:\n",
    "        mse = 0\n",
    "        for i in range(len(pred)):\n",
    "            mse += (pred[i] - real[i])**2\n",
    "        return math.sqrt(mse/len(pred))\n",
    "    else:\n",
    "        # The creation of the array may produce memory error\n",
    "        err = pred - real\n",
    "        mse = err.T @ err\n",
    "        return math.sqrt(2 * mse / len(pred))\n",
    "    \n",
    "    \n",
    "def basic_error(pred, real):\n",
    "    '''\n",
    "    Compute basic error. Used to notify bias.\n",
    "    :param : float[]\n",
    "    :param : float[]\n",
    "    :return : float\n",
    "    '''\n",
    "    err = 0\n",
    "    for i in range(len(pred)):\n",
    "        err += (pred[i][0][0] - real[i])\n",
    "    return err\n",
    "\n",
    "\n",
    "def garbage_collection():\n",
    "    '''\n",
    "    Calls garbage collection to clean unused memory\n",
    "    '''\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    '''\n",
    "    Plots the history of the training error\n",
    "    '''\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "First, we need to prepare the data in a train / test split. The test part is required to have good approximation of the error on unseen data. The lab asked for a $75$ / $25$ train / test split, we select the samples at random to avoid training only on a subset of the data (note that this is overkill since the lab revealed us that the samples were already randomized).\n",
    "\n",
    "And the last, but not the least, detail : we add a random seed in our random selection to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_red: (30049, 3004)\n",
      "y: (30049,)\n"
     ]
    }
   ],
   "source": [
    "X_red = np.load(DATA_FOLDER + \"feature_mat_radial_compression_normalized_red.npy\")\n",
    "y = np.load(DATA_FOLDER + \"CSD500-r_train-H_total.npy\")\n",
    "\n",
    "train_set_size = int(len(X_red) * TRAIN_SET_PERC)\n",
    "# Select random rows of the matrix for train / test set\n",
    "# Random seed for reproducibility \n",
    "np.random.seed(100)\n",
    "train_idx = np.random.choice(len(X_red), size=train_set_size, replace = False)\n",
    "test_idx = [i for i in range(len(X_red)) if i not in train_idx]\n",
    "X_train_red = X_red[train_idx, :]\n",
    "X_test_red = X_red[test_idx, :]\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "print(\"X_red: \" + str(X_red.shape))\n",
    "print(\"y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single neural network model approach \n",
    "\n",
    "First, we want to see how well a single neural network can perform on the data we have at our disposal. Highly influenced by tensorflow's tutorials and Standford University CS231n Convolutional Neural Networks for Visual Recognition lecture (http://cs231n.github.io/), we build our first neural network.\n",
    "\n",
    "We also execute cross-validations on the relevant parameters to get the best RMSE out of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_pred(nb_layers, nb_neurons, regularizer_fac, optimizer_fac):\n",
    "    # Prepare model \n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(nb_layers):\n",
    "        model.add(layers.Dense(nb_neurons, activation='relu', \\\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(regularizer_fac)))\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(optimizer_fac),\n",
    "                  loss='mse',\n",
    "                  # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "                  metrics=['mae'])\n",
    "    EPOCHS = 200\n",
    "    BATCH_SIZE = 32\n",
    "    VALIDATION_SPLIT = 0.1\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = model.fit(X_train_red, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "              callbacks=[early_stop])\n",
    "    plot_history(history)\n",
    "    \n",
    "    result = model.predict(X_test_red, batch_size=32)\n",
    "    error = rmse(result, y_test)\n",
    "    print(\"Error : {}\".format(error))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd703e74f60>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = [0.7416394267991249, 0.6443409956831526, 0.4930030937745785, \\\n",
    "         0.453638706377575, 0.41453323956187177, 0.4311010863788413, 0.4254569121978898]\n",
    "\n",
    "x = np.logspace(-1, -9, 7)\n",
    "\n",
    "plt.semilogx(x, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will train the neural network and print its error on the test set.\n",
    "# Since tensorflow is very talkative when training a network, we remove the output for the comfort of the reader.\n",
    "error = train_and_pred(8, 156, 1e-6, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of cross validation over regularization factor\n",
    "\n",
    "For the sake of sanity, we only display the results we obtained to avoid recomputing them. The previous graph shows evolution of the RMSE for a single neural network versus the L2 regularization factor.\n",
    "\n",
    "The number of layers and neurons by layers was chosen such that the model is powerful enough to capture most of the complexity of the model, overfitting being taken care with the L2-regularization. \n",
    "\n",
    "As for the optimizer factor, it will not influence the accuracy of our predictions but rather the convergence times. Hence we chose a factor that allowed us to converge while keeping a decent amount of epochs.\n",
    "\n",
    "## Final optimized structure :\n",
    "\n",
    "- Train / test split : $75$ / $25$.\n",
    "- Number of hidden layers : $8$.\n",
    "- Number of neuron / layers : $156$.\n",
    "- Activations : Rectified Linear Unit (relu).\n",
    "- Regularizer : L2 regularizer with factor $10^{-6}$.\n",
    "- Optimizer : Adam Optimizer with factor $10^{-3}$.\n",
    "- Single network error : 0.43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowd of Neural Networks Approach\n",
    "\n",
    "Now we try a new approach based on the *Wisdom Of Crowds* principle which states that the average of the predictions of a crowd is almost always better than the prediction of a single expert.\n",
    "\n",
    "Hence we will create a Crowd composed of a multitude of networks, train them all on the same training set and then ask them all to predict the test data. We will then average their predictions to give the final answer of the crowd, counting on the randomness of the neural network algorithm to give different answers for each individual, needed assumption for the principle to hold.\n",
    "\n",
    "Note that most of the code for this part is located in the Crowd class, itself defined in the file crowd.py.\n",
    "\n",
    "The structure of each networks we use is the optimized one we found in the previous part. Note also that the crowds are pretty long to train, to have good approximations, the more networks they have, the better. However this training should be done only once and each network is saved in the directory of its crowd in the folder '/session'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 16 entities from session/Crowd_opt_2_8_156_relu_1e-06_0.001_mse/16\n"
     ]
    }
   ],
   "source": [
    "crowd_opt2 = crowd.Crowd(X_train_red, y_train, \"Crowd_opt_2\", nb_layers = 8, \\\n",
    "                      nb_neurons=156, regularization_factor=1e-6, validation_split = 0)\n",
    "# Recover the crowd from file.\n",
    "# The file should be located in the 'session' folder\n",
    "crowd_opt2.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will add new networks to the crowd. Note that this is a long operation (up to 2 hours for 8 entities).\n",
    "crowd_opt2.train_new_entities(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time for 7513 samples : 185.83958538400475 seconds\n",
      "RMSE : 0.35298389679256353 \n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set and compute RMSE\n",
    "start = timeit.default_timer()\n",
    "pred = crowd_opt2.predict(X_test_red)\n",
    "stop = timeit.default_timer()\n",
    "error_rmse = rmse(pred, y_test)\n",
    "print('Prediction time for {} samples : {} seconds\\nRMSE : {} '.format(len(X_test_red), stop - start, error_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the crowd error vs the number of networks used for prediction\n",
    "crowd_opt2.plot_crowd_error(X_test_red, y_test, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the prediction time vs the number of networks used\n",
    "crowd_opt2.plot_crowd_pred_time(X_test_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of the error of the different networks over a single sample\n",
    "nb_bins = 8\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.subplot(221)\n",
    "crowd_opt2.plot_error_dist_on_sample(X_test_red[0], y_test[0], basic_error, show = False, bins = nb_bins)\n",
    "plt.subplot(222)\n",
    "crowd_opt2.plot_error_dist_on_sample(X_test_red[1], y_test[1], basic_error, show = False, bins = nb_bins)\n",
    "plt.subplot(223)\n",
    "crowd_opt2.plot_error_dist_on_sample(X_test_red[2], y_test[2], basic_error, show = False, bins = nb_bins)\n",
    "plt.subplot(224)\n",
    "crowd_opt2.plot_error_dist_on_sample(X_test_red[3], y_test[3], basic_error, show = False, bins = nb_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A wild idea : use a neural network stacked above the crowd for the prediction\n",
    "\n",
    "This idea is not detailed in the report because it doesn't bring better results than the ones we already have. And because we are limited to 4 pages for the report we had to make choices.\n",
    "\n",
    "This type of predictions adds a neural network on top of the crowd to make the prediction. This network will train on the whole training matrix but also on all the predictions of the other networks of the crowd. Doing so should learn him how the other networks did and it may ameliorate its predictions with this knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using a stacker at the end of the crowd\n",
    "# Again output is removed because of tensorflow verbosity.\n",
    "print(\"RMSE using stacker : {}\".format(rmse(crowd_opt2.predict_stacked(X_test_red), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Looking at the error versus the number of networks used for prediction, the results is undeniable : the crowd definetely reduce our error in an impressive way.\n",
    "\n",
    "We can clearly see that the error follows an exponential decay when compared to the number of networks used for a linear increase of the computation time. From the plot of the distribution of the error over a single sample, we can see that it is more or less gaussianly distributed. However we observe that this gaussian distribution is not centered around 0 which means that adding more and more networks will not necessarly brought us to a RMSE of $0$. \n",
    "\n",
    "Consequently, we have to find better ways of ameliorate the error.\n",
    "\n",
    "As a side note, please consider the error obtained with the stacked_prediction. Although it is not as good as the average of the predictions of the crowd (around $0.35$) it is better than the single network error (around $0.43$). Keep this in mind since it will be the starting point of our collaborative crowds.\n",
    "\n",
    "## Final structure :\n",
    "\n",
    "- Each network composing the crowd is an instance of the optimized version found in the first part.\n",
    "- 16 entities (more will bring better results but also increase the prediction time).\n",
    "- Crowd error : $0.353$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture of experts\n",
    "\n",
    "Finally we want to test a last method : instead of assigning the same weight to the prediction of each individual of the Crowd, we will try to assign different weights based on ressemblance between the sample to predict and the samples on which the individual performed best. \n",
    "\n",
    "If the data is categorizable, this method may give very good results. The core code is located in the file experts.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No directory with name session/Experts_opt1_8_156_relu_1e-06_0.001_mse\n"
     ]
    }
   ],
   "source": [
    "experts01 = experts.Experts(X_train_red, y_train, \"Experts_opt1\", nb_layers = 8, \\\n",
    "                      nb_neurons=156, regularization_factor=1e-6, validation_split = 0)\n",
    "experts01.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 34.2623 - mean_absolute_error: 3.3461\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 7s 290us/step - loss: 34.2507 - mean_absolute_error: 3.3453\n",
      "Epoch 2/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 4.2818 - mean_absolute_error: 1.4643\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 4.2735 - mean_absolute_error: 1.4623\n",
      "Epoch 3/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 1.0801 - mean_absolute_error: 0.7410\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 1.0807 - mean_absolute_error: 0.7412\n",
      "Epoch 4/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.5109 - mean_absolute_error: 0.5296\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.5110 - mean_absolute_error: 0.5298\n",
      "Epoch 5/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.4194 - mean_absolute_error: 0.4821\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.4197 - mean_absolute_error: 0.4823\n",
      "Epoch 6/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.3707 - mean_absolute_error: 0.4517\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.3711 - mean_absolute_error: 0.4518\n",
      "Epoch 7/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.4265 - mean_absolute_error: 0.4843\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.4275 - mean_absolute_error: 0.4849\n",
      "Epoch 8/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.4535 - mean_absolute_error: 0.4996\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.4565 - mean_absolute_error: 0.5015\n",
      "Epoch 9/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.3747 - mean_absolute_error: 0.4552\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.3734 - mean_absolute_error: 0.4543\n",
      "Epoch 10/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.4074 - mean_absolute_error: 0.4460\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.4070 - mean_absolute_error: 0.4461\n",
      "Epoch 11/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.3266 - mean_absolute_error: 0.4081\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.3266 - mean_absolute_error: 0.4081\n",
      "Epoch 12/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.2641 - mean_absolute_error: 0.3766\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.2639 - mean_absolute_error: 0.3765\n",
      "Epoch 13/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.2500 - mean_absolute_error: 0.3675\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.2502 - mean_absolute_error: 0.3676\n",
      "Epoch 14/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2563 - mean_absolute_error: 0.3731\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 193us/step - loss: 0.2560 - mean_absolute_error: 0.3730\n",
      "Epoch 15/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.4315 - mean_absolute_error: 0.4206\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.4311 - mean_absolute_error: 0.4209\n",
      "Epoch 16/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1898 - mean_absolute_error: 0.3169\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.1896 - mean_absolute_error: 0.3167\n",
      "Epoch 17/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2305 - mean_absolute_error: 0.3464\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.2314 - mean_absolute_error: 0.3474\n",
      "Epoch 18/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.1980 - mean_absolute_error: 0.3301\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 193us/step - loss: 0.1979 - mean_absolute_error: 0.3300\n",
      "Epoch 19/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1450 - mean_absolute_error: 0.2799\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 194us/step - loss: 0.1446 - mean_absolute_error: 0.2796\n",
      "Epoch 20/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1522 - mean_absolute_error: 0.2851\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.1518 - mean_absolute_error: 0.2848\n",
      "Epoch 21/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1771 - mean_absolute_error: 0.2945\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.1773 - mean_absolute_error: 0.2946\n",
      "Epoch 22/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1650 - mean_absolute_error: 0.2961\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 194us/step - loss: 0.1654 - mean_absolute_error: 0.2967\n",
      "Epoch 23/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.1299 - mean_absolute_error: 0.2610\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 193us/step - loss: 0.1296 - mean_absolute_error: 0.2607\n",
      "Epoch 24/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.1236 - mean_absolute_error: 0.2535\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 194us/step - loss: 0.1253 - mean_absolute_error: 0.2551\n",
      "Epoch 25/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1503 - mean_absolute_error: 0.2696\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 194us/step - loss: 0.1503 - mean_absolute_error: 0.2698\n",
      "Epoch 26/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2552\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 195us/step - loss: 0.1228 - mean_absolute_error: 0.2554\n",
      "Epoch 27/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1030 - mean_absolute_error: 0.2328\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.1029 - mean_absolute_error: 0.2328\n",
      "Epoch 28/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0921 - mean_absolute_error: 0.2222\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 187us/step - loss: 0.0920 - mean_absolute_error: 0.2222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.7842 - mean_absolute_error: 0.2823\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.8219 - mean_absolute_error: 0.2976\n",
      "Epoch 30/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.2277 - mean_absolute_error: 0.3198\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.2265 - mean_absolute_error: 0.3191\n",
      "Epoch 31/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0738 - mean_absolute_error: 0.1757\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0739 - mean_absolute_error: 0.1760\n",
      "Epoch 32/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.1569\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 187us/step - loss: 0.0517 - mean_absolute_error: 0.1569\n",
      "Epoch 33/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0566 - mean_absolute_error: 0.1640\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0567 - mean_absolute_error: 0.1641\n",
      "Epoch 34/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0779 - mean_absolute_error: 0.2037\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0779 - mean_absolute_error: 0.2037\n",
      "Epoch 35/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0728 - mean_absolute_error: 0.1969\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0726 - mean_absolute_error: 0.1966\n",
      "Epoch 36/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.1899\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0689 - mean_absolute_error: 0.1898\n",
      "Epoch 37/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0748 - mean_absolute_error: 0.1960\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0749 - mean_absolute_error: 0.1959\n",
      "Epoch 38/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0836 - mean_absolute_error: 0.2038\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0836 - mean_absolute_error: 0.2040\n",
      "Epoch 39/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0700 - mean_absolute_error: 0.1894\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0698 - mean_absolute_error: 0.1891\n",
      "Epoch 40/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.1890\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0699 - mean_absolute_error: 0.1887\n",
      "Epoch 41/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0764 - mean_absolute_error: 0.1979\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0765 - mean_absolute_error: 0.1981\n",
      "Epoch 42/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0759 - mean_absolute_error: 0.1986\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0760 - mean_absolute_error: 0.1986\n",
      "Epoch 43/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0620 - mean_absolute_error: 0.1775\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0619 - mean_absolute_error: 0.1773\n",
      "Epoch 44/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0697 - mean_absolute_error: 0.1845\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0698 - mean_absolute_error: 0.1846\n",
      "Epoch 45/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0616 - mean_absolute_error: 0.1743\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0615 - mean_absolute_error: 0.1742\n",
      "Epoch 46/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0633 - mean_absolute_error: 0.1768\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0646 - mean_absolute_error: 0.1770\n",
      "Epoch 47/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0740 - mean_absolute_error: 0.1898\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0749 - mean_absolute_error: 0.1902\n",
      "Epoch 48/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0534 - mean_absolute_error: 0.1609\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0538 - mean_absolute_error: 0.1618\n",
      "Epoch 49/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.1599\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0531 - mean_absolute_error: 0.1604\n",
      "Epoch 50/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0561 - mean_absolute_error: 0.1648\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0563 - mean_absolute_error: 0.1651\n",
      "Epoch 51/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0553 - mean_absolute_error: 0.1647\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 186us/step - loss: 0.0553 - mean_absolute_error: 0.1647\n",
      "Epoch 52/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0541 - mean_absolute_error: 0.1632\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/0\n",
      "22536/22536 [==============================] - 4s 185us/step - loss: 0.0540 - mean_absolute_error: 0.1631\n",
      "Epoch 1/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 20.4067 - mean_absolute_error: 2.8743\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 6s 273us/step - loss: 20.3799 - mean_absolute_error: 2.8726\n",
      "Epoch 2/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 4.6871 - mean_absolute_error: 1.5529\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 4.6686 - mean_absolute_error: 1.5506\n",
      "Epoch 3/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 1.4897 - mean_absolute_error: 0.8731\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 1.4882 - mean_absolute_error: 0.8727\n",
      "Epoch 4/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.4874 - mean_absolute_error: 0.5201\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.4860 - mean_absolute_error: 0.5194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.4259 - mean_absolute_error: 0.4904\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.4256 - mean_absolute_error: 0.4905\n",
      "Epoch 6/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.3563 - mean_absolute_error: 0.4461\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.3568 - mean_absolute_error: 0.4464\n",
      "Epoch 7/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.4028 - mean_absolute_error: 0.4682\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.4032 - mean_absolute_error: 0.4685\n",
      "Epoch 8/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.3406 - mean_absolute_error: 0.4269\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.3399 - mean_absolute_error: 0.4263\n",
      "Epoch 9/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.3919 - mean_absolute_error: 0.4507\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.3919 - mean_absolute_error: 0.4507\n",
      "Epoch 10/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.3243 - mean_absolute_error: 0.4138\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.3255 - mean_absolute_error: 0.4146\n",
      "Epoch 11/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.3122 - mean_absolute_error: 0.4075\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.3122 - mean_absolute_error: 0.4075\n",
      "Epoch 12/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.2935 - mean_absolute_error: 0.3958\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.2938 - mean_absolute_error: 0.3962\n",
      "Epoch 13/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.2713 - mean_absolute_error: 0.3813\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.2711 - mean_absolute_error: 0.3812\n",
      "Epoch 14/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.2367 - mean_absolute_error: 0.3501\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.2367 - mean_absolute_error: 0.3501\n",
      "Epoch 15/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.2440 - mean_absolute_error: 0.3592\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.2444 - mean_absolute_error: 0.3595\n",
      "Epoch 16/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.2313 - mean_absolute_error: 0.3476\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.2316 - mean_absolute_error: 0.3482\n",
      "Epoch 17/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.2268 - mean_absolute_error: 0.3308\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.2265 - mean_absolute_error: 0.3307\n",
      "Epoch 18/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.1688 - mean_absolute_error: 0.3019\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.1688 - mean_absolute_error: 0.3020\n",
      "Epoch 19/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.1529 - mean_absolute_error: 0.2867\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.1533 - mean_absolute_error: 0.2872\n",
      "Epoch 20/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1391 - mean_absolute_error: 0.2743\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.1390 - mean_absolute_error: 0.2743\n",
      "Epoch 21/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1541 - mean_absolute_error: 0.2921\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.1540 - mean_absolute_error: 0.2921\n",
      "Epoch 22/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1339 - mean_absolute_error: 0.2687\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.1347 - mean_absolute_error: 0.2695\n",
      "Epoch 23/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.1326 - mean_absolute_error: 0.2669\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.1329 - mean_absolute_error: 0.2674\n",
      "Epoch 24/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1323 - mean_absolute_error: 0.2642\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.1325 - mean_absolute_error: 0.2645\n",
      "Epoch 25/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.1107 - mean_absolute_error: 0.2409\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.1107 - mean_absolute_error: 0.2409\n",
      "Epoch 26/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0972 - mean_absolute_error: 0.2287\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0971 - mean_absolute_error: 0.2284\n",
      "Epoch 27/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1112 - mean_absolute_error: 0.2453\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.1115 - mean_absolute_error: 0.2459\n",
      "Epoch 28/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1057 - mean_absolute_error: 0.2404\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.1056 - mean_absolute_error: 0.2402\n",
      "Epoch 29/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.1044 - mean_absolute_error: 0.2361\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.1041 - mean_absolute_error: 0.2357\n",
      "Epoch 30/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0816 - mean_absolute_error: 0.2076\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0816 - mean_absolute_error: 0.2076\n",
      "Epoch 31/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0832 - mean_absolute_error: 0.2076\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0831 - mean_absolute_error: 0.2075\n",
      "Epoch 32/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0845 - mean_absolute_error: 0.2084\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0845 - mean_absolute_error: 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0757 - mean_absolute_error: 0.1970\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.0756 - mean_absolute_error: 0.1967\n",
      "Epoch 34/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0734 - mean_absolute_error: 0.1966\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0734 - mean_absolute_error: 0.1967\n",
      "Epoch 35/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0716 - mean_absolute_error: 0.1929\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0716 - mean_absolute_error: 0.1929\n",
      "Epoch 36/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0777 - mean_absolute_error: 0.2021\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0775 - mean_absolute_error: 0.2018\n",
      "Epoch 37/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0624 - mean_absolute_error: 0.1769\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0623 - mean_absolute_error: 0.1767\n",
      "Epoch 38/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0649 - mean_absolute_error: 0.1841\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0649 - mean_absolute_error: 0.1841\n",
      "Epoch 39/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0617 - mean_absolute_error: 0.1765\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0617 - mean_absolute_error: 0.1765\n",
      "Epoch 40/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0624 - mean_absolute_error: 0.1773\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0623 - mean_absolute_error: 0.1773\n",
      "Epoch 41/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0592 - mean_absolute_error: 0.1716\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0591 - mean_absolute_error: 0.1716\n",
      "Epoch 42/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0601 - mean_absolute_error: 0.1745\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0600 - mean_absolute_error: 0.1745\n",
      "Epoch 43/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0559 - mean_absolute_error: 0.1676\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0559 - mean_absolute_error: 0.1676\n",
      "Epoch 44/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0574 - mean_absolute_error: 0.1703\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0573 - mean_absolute_error: 0.1701\n",
      "Epoch 45/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0532 - mean_absolute_error: 0.1621\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0532 - mean_absolute_error: 0.1620\n",
      "Epoch 46/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0578 - mean_absolute_error: 0.1681\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0577 - mean_absolute_error: 0.1680\n",
      "Epoch 47/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0497 - mean_absolute_error: 0.1540\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0497 - mean_absolute_error: 0.1540\n",
      "Epoch 48/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0553 - mean_absolute_error: 0.1649\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0553 - mean_absolute_error: 0.1649\n",
      "Epoch 49/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.1587\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.0516 - mean_absolute_error: 0.1586\n",
      "Epoch 50/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0495 - mean_absolute_error: 0.1529\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0495 - mean_absolute_error: 0.1529\n",
      "Epoch 51/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0518 - mean_absolute_error: 0.1583\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0518 - mean_absolute_error: 0.1582\n",
      "Epoch 52/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.1474\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0458 - mean_absolute_error: 0.1475\n",
      "Epoch 53/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0438 - mean_absolute_error: 0.1444\n",
      "Epoch 00053: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0438 - mean_absolute_error: 0.1444\n",
      "Epoch 54/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0479 - mean_absolute_error: 0.1506\n",
      "Epoch 00054: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0478 - mean_absolute_error: 0.1504\n",
      "Epoch 55/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0508 - mean_absolute_error: 0.1549\n",
      "Epoch 00055: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0507 - mean_absolute_error: 0.1549\n",
      "Epoch 56/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0494 - mean_absolute_error: 0.1514\n",
      "Epoch 00056: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0494 - mean_absolute_error: 0.1514\n",
      "Epoch 57/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0425 - mean_absolute_error: 0.1378\n",
      "Epoch 00057: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0425 - mean_absolute_error: 0.1378\n",
      "Epoch 58/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0402 - mean_absolute_error: 0.1353\n",
      "Epoch 00058: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0403 - mean_absolute_error: 0.1353\n",
      "Epoch 59/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0471 - mean_absolute_error: 0.1493\n",
      "Epoch 00059: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0471 - mean_absolute_error: 0.1493\n",
      "Epoch 60/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0468 - mean_absolute_error: 0.1478\n",
      "Epoch 00060: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0468 - mean_absolute_error: 0.1478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0403 - mean_absolute_error: 0.1330\n",
      "Epoch 00061: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0403 - mean_absolute_error: 0.1329\n",
      "Epoch 62/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0385 - mean_absolute_error: 0.1297\n",
      "Epoch 00062: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0385 - mean_absolute_error: 0.1298\n",
      "Epoch 63/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0431 - mean_absolute_error: 0.1406\n",
      "Epoch 00063: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0431 - mean_absolute_error: 0.1405\n",
      "Epoch 64/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0449 - mean_absolute_error: 0.1438\n",
      "Epoch 00064: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.0450 - mean_absolute_error: 0.1442\n",
      "Epoch 65/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0441 - mean_absolute_error: 0.1413\n",
      "Epoch 00065: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0441 - mean_absolute_error: 0.1413\n",
      "Epoch 66/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1287\n",
      "Epoch 00066: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0383 - mean_absolute_error: 0.1287\n",
      "Epoch 67/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1317\n",
      "Epoch 00067: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0398 - mean_absolute_error: 0.1318\n",
      "Epoch 68/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1307\n",
      "Epoch 00068: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0396 - mean_absolute_error: 0.1305\n",
      "Epoch 69/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0420 - mean_absolute_error: 0.1369\n",
      "Epoch 00069: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0420 - mean_absolute_error: 0.1371\n",
      "Epoch 70/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0381 - mean_absolute_error: 0.1277\n",
      "Epoch 00070: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0382 - mean_absolute_error: 0.1278\n",
      "Epoch 71/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0389 - mean_absolute_error: 0.1313\n",
      "Epoch 00071: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0389 - mean_absolute_error: 0.1314\n",
      "Epoch 72/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1204\n",
      "Epoch 00072: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0350 - mean_absolute_error: 0.1206\n",
      "Epoch 73/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1290\n",
      "Epoch 00073: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0385 - mean_absolute_error: 0.1290\n",
      "Epoch 74/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0408 - mean_absolute_error: 0.1324\n",
      "Epoch 00074: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0408 - mean_absolute_error: 0.1324\n",
      "Epoch 75/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1300\n",
      "Epoch 00075: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0399 - mean_absolute_error: 0.1298\n",
      "Epoch 76/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1153\n",
      "Epoch 00076: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0334 - mean_absolute_error: 0.1152\n",
      "Epoch 77/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1188\n",
      "Epoch 00077: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0348 - mean_absolute_error: 0.1188\n",
      "Epoch 78/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1317\n",
      "Epoch 00078: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0396 - mean_absolute_error: 0.1316\n",
      "Epoch 79/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1231\n",
      "Epoch 00079: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0361 - mean_absolute_error: 0.1231\n",
      "Epoch 80/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1198\n",
      "Epoch 00080: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0345 - mean_absolute_error: 0.1197\n",
      "Epoch 81/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0376 - mean_absolute_error: 0.1250\n",
      "Epoch 00081: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0377 - mean_absolute_error: 0.1252\n",
      "Epoch 82/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0371 - mean_absolute_error: 0.1240\n",
      "Epoch 00082: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.0371 - mean_absolute_error: 0.1240\n",
      "Epoch 83/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1121\n",
      "Epoch 00083: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.0327 - mean_absolute_error: 0.1123\n",
      "Epoch 84/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1204\n",
      "Epoch 00084: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.0353 - mean_absolute_error: 0.1202\n",
      "Epoch 85/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1184\n",
      "Epoch 00085: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0347 - mean_absolute_error: 0.1185\n",
      "Epoch 86/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0363 - mean_absolute_error: 0.1222\n",
      "Epoch 00086: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0364 - mean_absolute_error: 0.1223\n",
      "Epoch 87/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1201\n",
      "Epoch 00087: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.0355 - mean_absolute_error: 0.1199\n",
      "Epoch 88/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1139\n",
      "Epoch 00088: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0325 - mean_absolute_error: 0.1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1170\n",
      "Epoch 00089: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0342 - mean_absolute_error: 0.1170\n",
      "Epoch 90/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1187\n",
      "Epoch 00090: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0347 - mean_absolute_error: 0.1187\n",
      "Epoch 91/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1223\n",
      "Epoch 00091: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0359 - mean_absolute_error: 0.1223\n",
      "Epoch 92/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1167\n",
      "Epoch 00092: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0337 - mean_absolute_error: 0.1167\n",
      "Epoch 93/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1178\n",
      "Epoch 00093: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0347 - mean_absolute_error: 0.1176\n",
      "Epoch 94/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1121\n",
      "Epoch 00094: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0321 - mean_absolute_error: 0.1125\n",
      "Epoch 95/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1071\n",
      "Epoch 00095: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0302 - mean_absolute_error: 0.1072\n",
      "Epoch 96/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1159\n",
      "Epoch 00096: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0333 - mean_absolute_error: 0.1159\n",
      "Epoch 97/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1098\n",
      "Epoch 00097: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0311 - mean_absolute_error: 0.1098\n",
      "Epoch 98/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1144\n",
      "Epoch 00098: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0329 - mean_absolute_error: 0.1149\n",
      "Epoch 99/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1213\n",
      "Epoch 00099: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0356 - mean_absolute_error: 0.1213\n",
      "Epoch 100/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1136\n",
      "Epoch 00100: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0325 - mean_absolute_error: 0.1135\n",
      "Epoch 101/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1120\n",
      "Epoch 00101: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0328 - mean_absolute_error: 0.1121\n",
      "Epoch 102/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1142\n",
      "Epoch 00102: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0326 - mean_absolute_error: 0.1143\n",
      "Epoch 103/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1127\n",
      "Epoch 00103: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0325 - mean_absolute_error: 0.1127\n",
      "Epoch 104/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1121\n",
      "Epoch 00104: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0318 - mean_absolute_error: 0.1121\n",
      "Epoch 105/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1108\n",
      "Epoch 00105: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0318 - mean_absolute_error: 0.1108\n",
      "Epoch 106/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1061\n",
      "Epoch 00106: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0301 - mean_absolute_error: 0.1061\n",
      "Epoch 107/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1095\n",
      "Epoch 00107: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0312 - mean_absolute_error: 0.1096\n",
      "Epoch 108/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1103\n",
      "Epoch 00108: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0311 - mean_absolute_error: 0.1103\n",
      "Epoch 109/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1104\n",
      "Epoch 00109: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0312 - mean_absolute_error: 0.1103\n",
      "Epoch 110/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1088\n",
      "Epoch 00110: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.0305 - mean_absolute_error: 0.1090\n",
      "Epoch 111/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1149\n",
      "Epoch 00111: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0327 - mean_absolute_error: 0.1148\n",
      "Epoch 112/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1146\n",
      "Epoch 00112: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0330 - mean_absolute_error: 0.1146\n",
      "Epoch 113/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1001\n",
      "Epoch 00113: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0280 - mean_absolute_error: 0.1003\n",
      "Epoch 114/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1148\n",
      "Epoch 00114: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0336 - mean_absolute_error: 0.1148\n",
      "Epoch 115/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1100\n",
      "Epoch 00115: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0319 - mean_absolute_error: 0.1100\n",
      "Epoch 116/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1109\n",
      "Epoch 00116: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0325 - mean_absolute_error: 0.1109\n",
      "Epoch 117/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.0999\n",
      "Epoch 00117: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0278 - mean_absolute_error: 0.0998\n",
      "Epoch 118/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1001\n",
      "Epoch 00118: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0279 - mean_absolute_error: 0.1001\n",
      "Epoch 119/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0280 - mean_absolute_error: 0.1023\n",
      "Epoch 00119: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0280 - mean_absolute_error: 0.1023\n",
      "Epoch 120/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1105\n",
      "Epoch 00120: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0317 - mean_absolute_error: 0.1107\n",
      "Epoch 121/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1113\n",
      "Epoch 00121: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0322 - mean_absolute_error: 0.1115\n",
      "Epoch 122/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1097\n",
      "Epoch 00122: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0311 - mean_absolute_error: 0.1097\n",
      "Epoch 123/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1027\n",
      "Epoch 00123: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0283 - mean_absolute_error: 0.1025\n",
      "Epoch 124/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1042\n",
      "Epoch 00124: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0293 - mean_absolute_error: 0.1043\n",
      "Epoch 125/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1071\n",
      "Epoch 00125: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0303 - mean_absolute_error: 0.1071\n",
      "Epoch 126/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1043\n",
      "Epoch 00126: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0289 - mean_absolute_error: 0.1044\n",
      "Epoch 127/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1038\n",
      "Epoch 00127: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0284 - mean_absolute_error: 0.1037\n",
      "Epoch 128/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1040\n",
      "Epoch 00128: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.0286 - mean_absolute_error: 0.1040\n",
      "Epoch 129/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1044\n",
      "Epoch 00129: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0297 - mean_absolute_error: 0.1044\n",
      "Epoch 130/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1034\n",
      "Epoch 00130: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0286 - mean_absolute_error: 0.1034\n",
      "Epoch 131/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.1005\n",
      "Epoch 00131: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0277 - mean_absolute_error: 0.1006\n",
      "Epoch 132/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.0994\n",
      "Epoch 00132: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0286 - mean_absolute_error: 0.0994\n",
      "Epoch 133/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.1006\n",
      "Epoch 00133: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0276 - mean_absolute_error: 0.1005\n",
      "Epoch 134/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.1001\n",
      "Epoch 00134: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0275 - mean_absolute_error: 0.1002\n",
      "Epoch 135/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1039\n",
      "Epoch 00135: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0284 - mean_absolute_error: 0.1040\n",
      "Epoch 136/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0983\n",
      "Epoch 00136: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0265 - mean_absolute_error: 0.0983\n",
      "Epoch 137/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0268 - mean_absolute_error: 0.0992\n",
      "Epoch 00137: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0268 - mean_absolute_error: 0.0990\n",
      "Epoch 138/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0282 - mean_absolute_error: 0.1027\n",
      "Epoch 00138: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0281 - mean_absolute_error: 0.1026\n",
      "Epoch 139/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.0983\n",
      "Epoch 00139: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0269 - mean_absolute_error: 0.0983\n",
      "Epoch 140/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.1058\n",
      "Epoch 00140: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0293 - mean_absolute_error: 0.1058\n",
      "Epoch 141/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1056\n",
      "Epoch 00141: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0292 - mean_absolute_error: 0.1056\n",
      "Epoch 142/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0260 - mean_absolute_error: 0.0960\n",
      "Epoch 00142: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0261 - mean_absolute_error: 0.0963\n",
      "Epoch 143/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1030\n",
      "Epoch 00143: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0283 - mean_absolute_error: 0.1030\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0278 - mean_absolute_error: 0.1010\n",
      "Epoch 00144: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0278 - mean_absolute_error: 0.1010\n",
      "Epoch 145/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0946\n",
      "Epoch 00145: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0259 - mean_absolute_error: 0.0950\n",
      "Epoch 146/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.1018\n",
      "Epoch 00146: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0276 - mean_absolute_error: 0.1018\n",
      "Epoch 147/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0972\n",
      "Epoch 00147: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0261 - mean_absolute_error: 0.0972\n",
      "Epoch 148/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0260 - mean_absolute_error: 0.0967\n",
      "Epoch 00148: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0260 - mean_absolute_error: 0.0968\n",
      "Epoch 149/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0278 - mean_absolute_error: 0.1021\n",
      "Epoch 00149: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 188us/step - loss: 0.0277 - mean_absolute_error: 0.1020\n",
      "Epoch 150/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1077\n",
      "Epoch 00150: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.0299 - mean_absolute_error: 0.1076\n",
      "Epoch 151/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.0990\n",
      "Epoch 00151: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0274 - mean_absolute_error: 0.0991\n",
      "Epoch 152/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0979\n",
      "Epoch 00152: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0267 - mean_absolute_error: 0.0982\n",
      "Epoch 153/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.0913\n",
      "Epoch 00153: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0245 - mean_absolute_error: 0.0919\n",
      "Epoch 154/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.0952\n",
      "Epoch 00154: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0255 - mean_absolute_error: 0.0953\n",
      "Epoch 155/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1016\n",
      "Epoch 00155: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0287 - mean_absolute_error: 0.1016\n",
      "Epoch 156/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0272 - mean_absolute_error: 0.0989\n",
      "Epoch 00156: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0272 - mean_absolute_error: 0.0989\n",
      "Epoch 157/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0256 - mean_absolute_error: 0.0944\n",
      "Epoch 00157: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0256 - mean_absolute_error: 0.0943\n",
      "Epoch 158/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.0948\n",
      "Epoch 00158: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0254 - mean_absolute_error: 0.0951\n",
      "Epoch 159/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0988\n",
      "Epoch 00159: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0266 - mean_absolute_error: 0.0988\n",
      "Epoch 160/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.0882\n",
      "Epoch 00160: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 191us/step - loss: 0.0232 - mean_absolute_error: 0.0882\n",
      "Epoch 161/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.0968\n",
      "Epoch 00161: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0263 - mean_absolute_error: 0.0967\n",
      "Epoch 162/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0256 - mean_absolute_error: 0.0957\n",
      "Epoch 00162: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0256 - mean_absolute_error: 0.0956\n",
      "Epoch 163/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0268 - mean_absolute_error: 0.0982\n",
      "Epoch 00163: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0269 - mean_absolute_error: 0.0984\n",
      "Epoch 164/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0246 - mean_absolute_error: 0.0915\n",
      "Epoch 00164: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0245 - mean_absolute_error: 0.0914\n",
      "Epoch 165/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0262 - mean_absolute_error: 0.0975\n",
      "Epoch 00165: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0262 - mean_absolute_error: 0.0975\n",
      "Epoch 166/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0993\n",
      "Epoch 00166: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0270 - mean_absolute_error: 0.0993\n",
      "Epoch 167/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.0930\n",
      "Epoch 00167: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0248 - mean_absolute_error: 0.0930\n",
      "Epoch 168/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.0912\n",
      "Epoch 00168: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0241 - mean_absolute_error: 0.0913\n",
      "Epoch 169/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.0906\n",
      "Epoch 00169: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0237 - mean_absolute_error: 0.0907\n",
      "Epoch 170/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0260 - mean_absolute_error: 0.0979\n",
      "Epoch 00170: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0260 - mean_absolute_error: 0.0978\n",
      "Epoch 171/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0998\n",
      "Epoch 00171: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0266 - mean_absolute_error: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.0917\n",
      "Epoch 00172: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0244 - mean_absolute_error: 0.0917\n",
      "Epoch 173/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0955\n",
      "Epoch 00173: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0249 - mean_absolute_error: 0.0955\n",
      "Epoch 174/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1040\n",
      "Epoch 00174: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0285 - mean_absolute_error: 0.1038\n",
      "Epoch 175/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.0924\n",
      "Epoch 00175: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0256 - mean_absolute_error: 0.0926\n",
      "Epoch 176/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.0944\n",
      "Epoch 00176: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 192us/step - loss: 0.0248 - mean_absolute_error: 0.0944\n",
      "Epoch 177/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.0907\n",
      "Epoch 00177: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0243 - mean_absolute_error: 0.0908\n",
      "Epoch 178/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.0922\n",
      "Epoch 00178: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0241 - mean_absolute_error: 0.0922\n",
      "Epoch 179/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.0962\n",
      "Epoch 00179: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 190us/step - loss: 0.0251 - mean_absolute_error: 0.0962\n",
      "Epoch 180/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0943\n",
      "Epoch 00180: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/1\n",
      "22536/22536 [==============================] - 4s 189us/step - loss: 0.0257 - mean_absolute_error: 0.0943\n",
      "Epoch 1/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 18.7256 - mean_absolute_error: 2.8500\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 7s 302us/step - loss: 18.6991 - mean_absolute_error: 2.8478\n",
      "Epoch 2/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 3.5234 - mean_absolute_error: 1.3363\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 239us/step - loss: 3.5121 - mean_absolute_error: 1.3340\n",
      "Epoch 3/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.9176 - mean_absolute_error: 0.7014\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 237us/step - loss: 0.9163 - mean_absolute_error: 0.7004\n",
      "Epoch 4/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.4728 - mean_absolute_error: 0.5078\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 233us/step - loss: 0.4755 - mean_absolute_error: 0.5095\n",
      "Epoch 5/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.4668 - mean_absolute_error: 0.5088\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 232us/step - loss: 0.4667 - mean_absolute_error: 0.5088\n",
      "Epoch 6/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.4587 - mean_absolute_error: 0.4944\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 234us/step - loss: 0.4587 - mean_absolute_error: 0.4942\n",
      "Epoch 7/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.4166 - mean_absolute_error: 0.4646\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 236us/step - loss: 0.4174 - mean_absolute_error: 0.4651\n",
      "Epoch 8/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.4224 - mean_absolute_error: 0.4728\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 235us/step - loss: 0.4228 - mean_absolute_error: 0.4730\n",
      "Epoch 9/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.4868 - mean_absolute_error: 0.4802\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 231us/step - loss: 0.4849 - mean_absolute_error: 0.4791\n",
      "Epoch 10/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.3797 - mean_absolute_error: 0.4312\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 248us/step - loss: 0.3788 - mean_absolute_error: 0.4309\n",
      "Epoch 11/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.3729 - mean_absolute_error: 0.4251\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 258us/step - loss: 0.3728 - mean_absolute_error: 0.4250\n",
      "Epoch 12/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.3225 - mean_absolute_error: 0.4018\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 237us/step - loss: 0.3224 - mean_absolute_error: 0.4017\n",
      "Epoch 13/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.3356 - mean_absolute_error: 0.4085\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 241us/step - loss: 0.3347 - mean_absolute_error: 0.4080\n",
      "Epoch 14/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.2899 - mean_absolute_error: 0.3745\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 239us/step - loss: 0.2896 - mean_absolute_error: 0.3744\n",
      "Epoch 15/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.3241 - mean_absolute_error: 0.3906\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 237us/step - loss: 0.3240 - mean_absolute_error: 0.3908\n",
      "Epoch 16/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.2429 - mean_absolute_error: 0.3500\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 240us/step - loss: 0.2429 - mean_absolute_error: 0.3500\n",
      "Epoch 17/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.2193 - mean_absolute_error: 0.3287\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 236us/step - loss: 0.2190 - mean_absolute_error: 0.3284\n",
      "Epoch 18/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2448 - mean_absolute_error: 0.3413\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 238us/step - loss: 0.2463 - mean_absolute_error: 0.3416\n",
      "Epoch 19/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.2107 - mean_absolute_error: 0.3136\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 240us/step - loss: 0.2107 - mean_absolute_error: 0.3136\n",
      "Epoch 20/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.2114 - mean_absolute_error: 0.3116\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.2112 - mean_absolute_error: 0.3114\n",
      "Epoch 21/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1779 - mean_absolute_error: 0.3030\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.1776 - mean_absolute_error: 0.3028\n",
      "Epoch 22/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1599 - mean_absolute_error: 0.2799\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.1594 - mean_absolute_error: 0.2796\n",
      "Epoch 23/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.1635 - mean_absolute_error: 0.2717\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.1634 - mean_absolute_error: 0.2718\n",
      "Epoch 24/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1561 - mean_absolute_error: 0.2769\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.1562 - mean_absolute_error: 0.2769\n",
      "Epoch 25/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2328 - mean_absolute_error: 0.3199\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.2318 - mean_absolute_error: 0.3193\n",
      "Epoch 26/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.1455 - mean_absolute_error: 0.2436\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.1455 - mean_absolute_error: 0.2436\n",
      "Epoch 27/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1281 - mean_absolute_error: 0.2303\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.1281 - mean_absolute_error: 0.2306\n",
      "Epoch 28/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1109 - mean_absolute_error: 0.2338\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.1108 - mean_absolute_error: 0.2337\n",
      "Epoch 29/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1127 - mean_absolute_error: 0.2339\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.1132 - mean_absolute_error: 0.2341\n",
      "Epoch 30/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1231 - mean_absolute_error: 0.2434\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.1231 - mean_absolute_error: 0.2434\n",
      "Epoch 31/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1342 - mean_absolute_error: 0.2498\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.1342 - mean_absolute_error: 0.2499\n",
      "Epoch 32/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1259 - mean_absolute_error: 0.2375\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.1256 - mean_absolute_error: 0.2374\n",
      "Epoch 33/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2271\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.1173 - mean_absolute_error: 0.2270\n",
      "Epoch 34/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1027 - mean_absolute_error: 0.2200\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.1029 - mean_absolute_error: 0.2203\n",
      "Epoch 35/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.2070\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0911 - mean_absolute_error: 0.2072\n",
      "Epoch 36/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0900 - mean_absolute_error: 0.2061\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0900 - mean_absolute_error: 0.2061\n",
      "Epoch 37/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0911 - mean_absolute_error: 0.2061\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0911 - mean_absolute_error: 0.2062\n",
      "Epoch 38/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0937 - mean_absolute_error: 0.2057\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0938 - mean_absolute_error: 0.2060\n",
      "Epoch 39/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0793 - mean_absolute_error: 0.1916\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0792 - mean_absolute_error: 0.1916\n",
      "Epoch 40/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0847 - mean_absolute_error: 0.2048\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0854 - mean_absolute_error: 0.2056\n",
      "Epoch 41/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0841 - mean_absolute_error: 0.1933\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0843 - mean_absolute_error: 0.1937\n",
      "Epoch 42/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0833 - mean_absolute_error: 0.1920\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 226us/step - loss: 0.0832 - mean_absolute_error: 0.1920\n",
      "Epoch 43/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.1822\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 227us/step - loss: 0.0718 - mean_absolute_error: 0.1822\n",
      "Epoch 44/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0639 - mean_absolute_error: 0.1719\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 227us/step - loss: 0.0639 - mean_absolute_error: 0.1718\n",
      "Epoch 45/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0762 - mean_absolute_error: 0.1809\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0761 - mean_absolute_error: 0.1808\n",
      "Epoch 46/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0652 - mean_absolute_error: 0.1685\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 226us/step - loss: 0.0652 - mean_absolute_error: 0.1685\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0758 - mean_absolute_error: 0.1846\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0758 - mean_absolute_error: 0.1847\n",
      "Epoch 48/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.1717\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0672 - mean_absolute_error: 0.1718\n",
      "Epoch 49/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0589 - mean_absolute_error: 0.1609\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0589 - mean_absolute_error: 0.1609\n",
      "Epoch 50/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0615 - mean_absolute_error: 0.1667\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0615 - mean_absolute_error: 0.1668\n",
      "Epoch 51/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0662 - mean_absolute_error: 0.1740\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0661 - mean_absolute_error: 0.1738\n",
      "Epoch 52/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0617 - mean_absolute_error: 0.1615\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0618 - mean_absolute_error: 0.1615\n",
      "Epoch 53/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0647 - mean_absolute_error: 0.1728\n",
      "Epoch 00053: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0646 - mean_absolute_error: 0.1726\n",
      "Epoch 54/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0536 - mean_absolute_error: 0.1522\n",
      "Epoch 00054: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0537 - mean_absolute_error: 0.1524\n",
      "Epoch 55/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0571 - mean_absolute_error: 0.1628\n",
      "Epoch 00055: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0571 - mean_absolute_error: 0.1628\n",
      "Epoch 56/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0549 - mean_absolute_error: 0.1568\n",
      "Epoch 00056: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0549 - mean_absolute_error: 0.1570\n",
      "Epoch 57/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0569 - mean_absolute_error: 0.1593\n",
      "Epoch 00057: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0569 - mean_absolute_error: 0.1594\n",
      "Epoch 58/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0530 - mean_absolute_error: 0.1544\n",
      "Epoch 00058: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0530 - mean_absolute_error: 0.1544\n",
      "Epoch 59/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0602 - mean_absolute_error: 0.1638\n",
      "Epoch 00059: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0601 - mean_absolute_error: 0.1638\n",
      "Epoch 60/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0565 - mean_absolute_error: 0.1588\n",
      "Epoch 00060: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0564 - mean_absolute_error: 0.1587\n",
      "Epoch 61/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0550 - mean_absolute_error: 0.1539\n",
      "Epoch 00061: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0552 - mean_absolute_error: 0.1540\n",
      "Epoch 62/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0511 - mean_absolute_error: 0.1485\n",
      "Epoch 00062: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0511 - mean_absolute_error: 0.1487\n",
      "Epoch 63/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0527 - mean_absolute_error: 0.1526\n",
      "Epoch 00063: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0528 - mean_absolute_error: 0.1526\n",
      "Epoch 64/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0474 - mean_absolute_error: 0.1433\n",
      "Epoch 00064: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0473 - mean_absolute_error: 0.1432\n",
      "Epoch 65/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0498 - mean_absolute_error: 0.1455\n",
      "Epoch 00065: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 226us/step - loss: 0.0498 - mean_absolute_error: 0.1455\n",
      "Epoch 66/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0500 - mean_absolute_error: 0.1450\n",
      "Epoch 00066: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0499 - mean_absolute_error: 0.1448\n",
      "Epoch 67/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0495 - mean_absolute_error: 0.1464\n",
      "Epoch 00067: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0495 - mean_absolute_error: 0.1464\n",
      "Epoch 68/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0480 - mean_absolute_error: 0.1414\n",
      "Epoch 00068: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0481 - mean_absolute_error: 0.1415\n",
      "Epoch 69/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0462 - mean_absolute_error: 0.1370\n",
      "Epoch 00069: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0462 - mean_absolute_error: 0.1370\n",
      "Epoch 70/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0448 - mean_absolute_error: 0.1347\n",
      "Epoch 00070: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0449 - mean_absolute_error: 0.1349\n",
      "Epoch 71/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.1329\n",
      "Epoch 00071: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0452 - mean_absolute_error: 0.1329\n",
      "Epoch 72/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0485 - mean_absolute_error: 0.1422\n",
      "Epoch 00072: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0485 - mean_absolute_error: 0.1422\n",
      "Epoch 73/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0479 - mean_absolute_error: 0.1409\n",
      "Epoch 00073: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0478 - mean_absolute_error: 0.1409\n",
      "Epoch 74/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0447 - mean_absolute_error: 0.1338\n",
      "Epoch 00074: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0447 - mean_absolute_error: 0.1338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0418 - mean_absolute_error: 0.1295\n",
      "Epoch 00075: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0418 - mean_absolute_error: 0.1294\n",
      "Epoch 76/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0497 - mean_absolute_error: 0.1448\n",
      "Epoch 00076: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0496 - mean_absolute_error: 0.1447\n",
      "Epoch 77/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0441 - mean_absolute_error: 0.1369\n",
      "Epoch 00077: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0441 - mean_absolute_error: 0.1370\n",
      "Epoch 78/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0451 - mean_absolute_error: 0.1355\n",
      "Epoch 00078: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0452 - mean_absolute_error: 0.1355\n",
      "Epoch 79/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.1316\n",
      "Epoch 00079: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0453 - mean_absolute_error: 0.1317\n",
      "Epoch 80/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1238\n",
      "Epoch 00080: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0385 - mean_absolute_error: 0.1239\n",
      "Epoch 81/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1228\n",
      "Epoch 00081: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0382 - mean_absolute_error: 0.1227\n",
      "Epoch 82/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0402 - mean_absolute_error: 0.1264\n",
      "Epoch 00082: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0402 - mean_absolute_error: 0.1265\n",
      "Epoch 83/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0407 - mean_absolute_error: 0.1268\n",
      "Epoch 00083: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0406 - mean_absolute_error: 0.1267\n",
      "Epoch 84/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0386 - mean_absolute_error: 0.1243\n",
      "Epoch 00084: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0387 - mean_absolute_error: 0.1244\n",
      "Epoch 85/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0432 - mean_absolute_error: 0.1343\n",
      "Epoch 00085: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0432 - mean_absolute_error: 0.1344\n",
      "Epoch 86/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0488 - mean_absolute_error: 0.1413\n",
      "Epoch 00086: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0487 - mean_absolute_error: 0.1412\n",
      "Epoch 87/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0404 - mean_absolute_error: 0.1273\n",
      "Epoch 00087: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0403 - mean_absolute_error: 0.1273\n",
      "Epoch 88/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0363 - mean_absolute_error: 0.1182\n",
      "Epoch 00088: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0362 - mean_absolute_error: 0.1182\n",
      "Epoch 89/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0371 - mean_absolute_error: 0.1198\n",
      "Epoch 00089: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0371 - mean_absolute_error: 0.1198\n",
      "Epoch 90/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0393 - mean_absolute_error: 0.1247\n",
      "Epoch 00090: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0394 - mean_absolute_error: 0.1249\n",
      "Epoch 91/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0410 - mean_absolute_error: 0.1298\n",
      "Epoch 00091: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0410 - mean_absolute_error: 0.1298\n",
      "Epoch 92/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0407 - mean_absolute_error: 0.1299\n",
      "Epoch 00092: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0407 - mean_absolute_error: 0.1300\n",
      "Epoch 93/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0459 - mean_absolute_error: 0.1331\n",
      "Epoch 00093: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0459 - mean_absolute_error: 0.1330\n",
      "Epoch 94/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1161\n",
      "Epoch 00094: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0350 - mean_absolute_error: 0.1163\n",
      "Epoch 95/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0390 - mean_absolute_error: 0.1271\n",
      "Epoch 00095: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0390 - mean_absolute_error: 0.1271\n",
      "Epoch 96/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0399 - mean_absolute_error: 0.1243\n",
      "Epoch 00096: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0398 - mean_absolute_error: 0.1242\n",
      "Epoch 97/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1147\n",
      "Epoch 00097: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0361 - mean_absolute_error: 0.1147\n",
      "Epoch 98/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1180\n",
      "Epoch 00098: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0359 - mean_absolute_error: 0.1180\n",
      "Epoch 99/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1209\n",
      "Epoch 00099: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 226us/step - loss: 0.0406 - mean_absolute_error: 0.1209\n",
      "Epoch 100/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0408 - mean_absolute_error: 0.1249\n",
      "Epoch 00100: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0408 - mean_absolute_error: 0.1249\n",
      "Epoch 101/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1162\n",
      "Epoch 00101: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0355 - mean_absolute_error: 0.1160\n",
      "Epoch 102/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0351 - mean_absolute_error: 0.1165\n",
      "Epoch 00102: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0352 - mean_absolute_error: 0.1167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0389 - mean_absolute_error: 0.1256\n",
      "Epoch 00103: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0389 - mean_absolute_error: 0.1256\n",
      "Epoch 104/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0365 - mean_absolute_error: 0.1184\n",
      "Epoch 00104: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0365 - mean_absolute_error: 0.1182\n",
      "Epoch 105/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1148\n",
      "Epoch 00105: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0357 - mean_absolute_error: 0.1148\n",
      "Epoch 106/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1207\n",
      "Epoch 00106: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0367 - mean_absolute_error: 0.1206\n",
      "Epoch 107/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0369 - mean_absolute_error: 0.1210\n",
      "Epoch 00107: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0369 - mean_absolute_error: 0.1210\n",
      "Epoch 108/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1115\n",
      "Epoch 00108: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0332 - mean_absolute_error: 0.1115\n",
      "Epoch 109/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1126\n",
      "Epoch 00109: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0341 - mean_absolute_error: 0.1126\n",
      "Epoch 110/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1200\n",
      "Epoch 00110: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0389 - mean_absolute_error: 0.1201\n",
      "Epoch 111/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1205\n",
      "Epoch 00111: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0381 - mean_absolute_error: 0.1205\n",
      "Epoch 112/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1094\n",
      "Epoch 00112: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0329 - mean_absolute_error: 0.1095\n",
      "Epoch 113/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1078\n",
      "Epoch 00113: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0329 - mean_absolute_error: 0.1078\n",
      "Epoch 114/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1206\n",
      "Epoch 00114: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0373 - mean_absolute_error: 0.1206\n",
      "Epoch 115/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1150\n",
      "Epoch 00115: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0346 - mean_absolute_error: 0.1150\n",
      "Epoch 116/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1101\n",
      "Epoch 00116: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0329 - mean_absolute_error: 0.1101\n",
      "Epoch 117/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1084\n",
      "Epoch 00117: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0321 - mean_absolute_error: 0.1083\n",
      "Epoch 118/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1209\n",
      "Epoch 00118: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0367 - mean_absolute_error: 0.1208\n",
      "Epoch 119/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1164\n",
      "Epoch 00119: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0356 - mean_absolute_error: 0.1162\n",
      "Epoch 120/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1067\n",
      "Epoch 00120: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0318 - mean_absolute_error: 0.1067\n",
      "Epoch 121/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1198\n",
      "Epoch 00121: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0362 - mean_absolute_error: 0.1201\n",
      "Epoch 122/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1092\n",
      "Epoch 00122: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0329 - mean_absolute_error: 0.1093\n",
      "Epoch 123/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1041\n",
      "Epoch 00123: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0304 - mean_absolute_error: 0.1041\n",
      "Epoch 124/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1102\n",
      "Epoch 00124: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0324 - mean_absolute_error: 0.1102\n",
      "Epoch 125/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1111\n",
      "Epoch 00125: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0330 - mean_absolute_error: 0.1114\n",
      "Epoch 126/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1150\n",
      "Epoch 00126: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0341 - mean_absolute_error: 0.1150\n",
      "Epoch 127/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1081\n",
      "Epoch 00127: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0320 - mean_absolute_error: 0.1082\n",
      "Epoch 128/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1047\n",
      "Epoch 00128: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0309 - mean_absolute_error: 0.1047\n",
      "Epoch 129/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1071\n",
      "Epoch 00129: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0312 - mean_absolute_error: 0.1071\n",
      "Epoch 130/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1055\n",
      "Epoch 00130: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0309 - mean_absolute_error: 0.1055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1137\n",
      "Epoch 00131: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0340 - mean_absolute_error: 0.1137\n",
      "Epoch 132/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1109\n",
      "Epoch 00132: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0329 - mean_absolute_error: 0.1109\n",
      "Epoch 133/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1035\n",
      "Epoch 00133: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0299 - mean_absolute_error: 0.1039\n",
      "Epoch 134/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1044\n",
      "Epoch 00134: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0299 - mean_absolute_error: 0.1044\n",
      "Epoch 135/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1085\n",
      "Epoch 00135: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0324 - mean_absolute_error: 0.1086\n",
      "Epoch 136/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1091\n",
      "Epoch 00136: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0327 - mean_absolute_error: 0.1095\n",
      "Epoch 137/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1126\n",
      "Epoch 00137: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0337 - mean_absolute_error: 0.1126\n",
      "Epoch 138/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1035\n",
      "Epoch 00138: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0301 - mean_absolute_error: 0.1036\n",
      "Epoch 139/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1057\n",
      "Epoch 00139: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0313 - mean_absolute_error: 0.1057\n",
      "Epoch 140/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1069\n",
      "Epoch 00140: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0311 - mean_absolute_error: 0.1068\n",
      "Epoch 141/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1001\n",
      "Epoch 00141: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0283 - mean_absolute_error: 0.1001\n",
      "Epoch 142/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.0977\n",
      "Epoch 00142: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0279 - mean_absolute_error: 0.0978\n",
      "Epoch 143/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1082\n",
      "Epoch 00143: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0314 - mean_absolute_error: 0.1083\n",
      "Epoch 144/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1142\n",
      "Epoch 00144: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0335 - mean_absolute_error: 0.1142\n",
      "Epoch 145/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1103\n",
      "Epoch 00145: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0321 - mean_absolute_error: 0.1103\n",
      "Epoch 146/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.0994\n",
      "Epoch 00146: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0292 - mean_absolute_error: 0.0995\n",
      "Epoch 147/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.0969\n",
      "Epoch 00147: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0277 - mean_absolute_error: 0.0971\n",
      "Epoch 148/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1047\n",
      "Epoch 00148: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0308 - mean_absolute_error: 0.1047\n",
      "Epoch 149/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.0986\n",
      "Epoch 00149: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0284 - mean_absolute_error: 0.0986\n",
      "Epoch 150/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.0997\n",
      "Epoch 00150: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0290 - mean_absolute_error: 0.0997\n",
      "Epoch 151/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1025\n",
      "Epoch 00151: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0292 - mean_absolute_error: 0.1025\n",
      "Epoch 152/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1063\n",
      "Epoch 00152: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0301 - mean_absolute_error: 0.1063\n",
      "Epoch 153/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1059\n",
      "Epoch 00153: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0306 - mean_absolute_error: 0.1059\n",
      "Epoch 154/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0280 - mean_absolute_error: 0.0985\n",
      "Epoch 00154: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0280 - mean_absolute_error: 0.0986\n",
      "Epoch 155/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1073\n",
      "Epoch 00155: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0306 - mean_absolute_error: 0.1074\n",
      "Epoch 156/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1105\n",
      "Epoch 00156: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0330 - mean_absolute_error: 0.1106\n",
      "Epoch 157/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1036\n",
      "Epoch 00157: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0304 - mean_absolute_error: 0.1035\n",
      "Epoch 158/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0915\n",
      "Epoch 00158: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0270 - mean_absolute_error: 0.0915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0942\n",
      "Epoch 00159: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0270 - mean_absolute_error: 0.0942\n",
      "Epoch 160/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1061\n",
      "Epoch 00160: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0327 - mean_absolute_error: 0.1062\n",
      "Epoch 161/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.0998\n",
      "Epoch 00161: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0279 - mean_absolute_error: 0.0999\n",
      "Epoch 162/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0951\n",
      "Epoch 00162: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0265 - mean_absolute_error: 0.0950\n",
      "Epoch 163/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.0987\n",
      "Epoch 00163: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0274 - mean_absolute_error: 0.0987\n",
      "Epoch 164/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1051\n",
      "Epoch 00164: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0294 - mean_absolute_error: 0.1050\n",
      "Epoch 165/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.0968\n",
      "Epoch 00165: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0275 - mean_absolute_error: 0.0973\n",
      "Epoch 166/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1067\n",
      "Epoch 00166: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0315 - mean_absolute_error: 0.1067\n",
      "Epoch 167/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1064\n",
      "Epoch 00167: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0301 - mean_absolute_error: 0.1065\n",
      "Epoch 168/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0947\n",
      "Epoch 00168: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0265 - mean_absolute_error: 0.0947\n",
      "Epoch 169/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0951\n",
      "Epoch 00169: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0270 - mean_absolute_error: 0.0952\n",
      "Epoch 170/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.0998\n",
      "Epoch 00170: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0288 - mean_absolute_error: 0.0998\n",
      "Epoch 171/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1021\n",
      "Epoch 00171: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 236us/step - loss: 0.0291 - mean_absolute_error: 0.1021\n",
      "Epoch 172/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0940\n",
      "Epoch 00172: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0265 - mean_absolute_error: 0.0940\n",
      "Epoch 173/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.0952\n",
      "Epoch 00173: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 246us/step - loss: 0.0273 - mean_absolute_error: 0.0950\n",
      "Epoch 174/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.0992\n",
      "Epoch 00174: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 236us/step - loss: 0.0280 - mean_absolute_error: 0.0995\n",
      "Epoch 175/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.0962\n",
      "Epoch 00175: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 233us/step - loss: 0.0273 - mean_absolute_error: 0.0961\n",
      "Epoch 176/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0257 - mean_absolute_error: 0.0935\n",
      "Epoch 00176: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 233us/step - loss: 0.0257 - mean_absolute_error: 0.0934\n",
      "Epoch 177/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.0988\n",
      "Epoch 00177: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 235us/step - loss: 0.0276 - mean_absolute_error: 0.0988\n",
      "Epoch 178/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0955\n",
      "Epoch 00178: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 250us/step - loss: 0.0266 - mean_absolute_error: 0.0955\n",
      "Epoch 179/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0946\n",
      "Epoch 00179: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 274us/step - loss: 0.0258 - mean_absolute_error: 0.0947\n",
      "Epoch 180/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.0986\n",
      "Epoch 00180: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 268us/step - loss: 0.0274 - mean_absolute_error: 0.0986\n",
      "Epoch 181/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0959\n",
      "Epoch 00181: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 264us/step - loss: 0.0265 - mean_absolute_error: 0.0959\n",
      "Epoch 182/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.0971\n",
      "Epoch 00182: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 242us/step - loss: 0.0270 - mean_absolute_error: 0.0973\n",
      "Epoch 183/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.0993\n",
      "Epoch 00183: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 247us/step - loss: 0.0277 - mean_absolute_error: 0.0992\n",
      "Epoch 184/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.0936\n",
      "Epoch 00184: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 247us/step - loss: 0.0254 - mean_absolute_error: 0.0937\n",
      "Epoch 185/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.0964\n",
      "Epoch 00185: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 6s 255us/step - loss: 0.0265 - mean_absolute_error: 0.0965\n",
      "Epoch 186/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.0936\n",
      "Epoch 00186: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 244us/step - loss: 0.0259 - mean_absolute_error: 0.0935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1000\n",
      "Epoch 00187: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 231us/step - loss: 0.0279 - mean_absolute_error: 0.0999\n",
      "Epoch 188/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0943\n",
      "Epoch 00188: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 226us/step - loss: 0.0265 - mean_absolute_error: 0.0942\n",
      "Epoch 189/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0262 - mean_absolute_error: 0.0916\n",
      "Epoch 00189: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0264 - mean_absolute_error: 0.0918\n",
      "Epoch 190/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0936\n",
      "Epoch 00190: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0260 - mean_absolute_error: 0.0936\n",
      "Epoch 191/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0254 - mean_absolute_error: 0.0931\n",
      "Epoch 00191: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0254 - mean_absolute_error: 0.0931\n",
      "Epoch 192/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0920\n",
      "Epoch 00192: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0249 - mean_absolute_error: 0.0920\n",
      "Epoch 193/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0272 - mean_absolute_error: 0.0979\n",
      "Epoch 00193: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0272 - mean_absolute_error: 0.0979\n",
      "Epoch 194/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0254 - mean_absolute_error: 0.0931\n",
      "Epoch 00194: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0254 - mean_absolute_error: 0.0931\n",
      "Epoch 195/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.0901\n",
      "Epoch 00195: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0244 - mean_absolute_error: 0.0903\n",
      "Epoch 196/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0964\n",
      "Epoch 00196: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0266 - mean_absolute_error: 0.0966\n",
      "Epoch 197/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0938\n",
      "Epoch 00197: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0261 - mean_absolute_error: 0.0938\n",
      "Epoch 198/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0254 - mean_absolute_error: 0.0922\n",
      "Epoch 00198: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0253 - mean_absolute_error: 0.0920\n",
      "Epoch 199/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.0901\n",
      "Epoch 00199: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0244 - mean_absolute_error: 0.0901\n",
      "Epoch 200/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0256 - mean_absolute_error: 0.0952\n",
      "Epoch 00200: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/2\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0256 - mean_absolute_error: 0.0953\n",
      "Epoch 1/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 18.3667 - mean_absolute_error: 2.8063\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 7s 319us/step - loss: 18.2446 - mean_absolute_error: 2.7957\n",
      "Epoch 2/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 3.2647 - mean_absolute_error: 1.2866\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 3.2641 - mean_absolute_error: 1.2862\n",
      "Epoch 3/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.9620 - mean_absolute_error: 0.6988\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.9620 - mean_absolute_error: 0.6989\n",
      "Epoch 4/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.5125 - mean_absolute_error: 0.5337\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.5156 - mean_absolute_error: 0.5356\n",
      "Epoch 5/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.4151 - mean_absolute_error: 0.4829\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.4171 - mean_absolute_error: 0.4841\n",
      "Epoch 6/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.3963 - mean_absolute_error: 0.4730\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.3959 - mean_absolute_error: 0.4729\n",
      "Epoch 7/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.3905 - mean_absolute_error: 0.4514\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.3904 - mean_absolute_error: 0.4516\n",
      "Epoch 8/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.3989 - mean_absolute_error: 0.4598\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.3988 - mean_absolute_error: 0.4597\n",
      "Epoch 9/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.3704 - mean_absolute_error: 0.4498\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.3704 - mean_absolute_error: 0.4499\n",
      "Epoch 10/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.3306 - mean_absolute_error: 0.4190\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.3308 - mean_absolute_error: 0.4191\n",
      "Epoch 11/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.3187 - mean_absolute_error: 0.4064\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.3185 - mean_absolute_error: 0.4064\n",
      "Epoch 12/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.3249 - mean_absolute_error: 0.4095\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.3246 - mean_absolute_error: 0.4089\n",
      "Epoch 13/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.2822 - mean_absolute_error: 0.3825\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.2821 - mean_absolute_error: 0.3826\n",
      "Epoch 14/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.2512 - mean_absolute_error: 0.3596\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.2513 - mean_absolute_error: 0.3596\n",
      "Epoch 15/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2323 - mean_absolute_error: 0.3502\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.2329 - mean_absolute_error: 0.3506\n",
      "Epoch 16/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.2206 - mean_absolute_error: 0.3449\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 6s 258us/step - loss: 0.2204 - mean_absolute_error: 0.3448\n",
      "Epoch 17/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.1832 - mean_absolute_error: 0.3150\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 241us/step - loss: 0.1827 - mean_absolute_error: 0.3145\n",
      "Epoch 18/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1681 - mean_absolute_error: 0.3016\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 228us/step - loss: 0.1683 - mean_absolute_error: 0.3018\n",
      "Epoch 19/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.1659 - mean_absolute_error: 0.2969\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.1659 - mean_absolute_error: 0.2969\n",
      "Epoch 20/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.1663 - mean_absolute_error: 0.2982\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.1663 - mean_absolute_error: 0.2983\n",
      "Epoch 21/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1439 - mean_absolute_error: 0.2798\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.1438 - mean_absolute_error: 0.2797\n",
      "Epoch 22/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1359 - mean_absolute_error: 0.2702\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.1361 - mean_absolute_error: 0.2704\n",
      "Epoch 23/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1317 - mean_absolute_error: 0.2714\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.1315 - mean_absolute_error: 0.2713\n",
      "Epoch 24/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1136 - mean_absolute_error: 0.2451\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.1137 - mean_absolute_error: 0.2452\n",
      "Epoch 25/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1129 - mean_absolute_error: 0.2455\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.1127 - mean_absolute_error: 0.2452\n",
      "Epoch 26/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1094 - mean_absolute_error: 0.2404\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.1093 - mean_absolute_error: 0.2404\n",
      "Epoch 27/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1091 - mean_absolute_error: 0.2430\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.1093 - mean_absolute_error: 0.2433\n",
      "Epoch 28/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.2190\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0917 - mean_absolute_error: 0.2191\n",
      "Epoch 29/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0899 - mean_absolute_error: 0.2171\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0903 - mean_absolute_error: 0.2173\n",
      "Epoch 30/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0835 - mean_absolute_error: 0.2071\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.0835 - mean_absolute_error: 0.2071\n",
      "Epoch 31/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0826 - mean_absolute_error: 0.2061\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0827 - mean_absolute_error: 0.2062\n",
      "Epoch 32/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0802 - mean_absolute_error: 0.2027\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0802 - mean_absolute_error: 0.2027\n",
      "Epoch 33/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0787 - mean_absolute_error: 0.2017\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.0787 - mean_absolute_error: 0.2017\n",
      "Epoch 34/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0805 - mean_absolute_error: 0.2066\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 225us/step - loss: 0.0804 - mean_absolute_error: 0.2066\n",
      "Epoch 35/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0688 - mean_absolute_error: 0.1849\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 242us/step - loss: 0.0688 - mean_absolute_error: 0.1850\n",
      "Epoch 36/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.6918 - mean_absolute_error: 0.2928\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 6s 247us/step - loss: 0.6916 - mean_absolute_error: 0.2927\n",
      "Epoch 37/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0525 - mean_absolute_error: 0.1556\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0525 - mean_absolute_error: 0.1556\n",
      "Epoch 38/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0415 - mean_absolute_error: 0.1399\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0416 - mean_absolute_error: 0.1400\n",
      "Epoch 39/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0438 - mean_absolute_error: 0.1375\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0438 - mean_absolute_error: 0.1377\n",
      "Epoch 40/200\n",
      "22272/22536 [============================>.] - ETA: 0s - loss: 0.0502 - mean_absolute_error: 0.1565\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 201us/step - loss: 0.0501 - mean_absolute_error: 0.1564\n",
      "Epoch 41/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0656 - mean_absolute_error: 0.1738\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 197us/step - loss: 0.0656 - mean_absolute_error: 0.1738\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0647 - mean_absolute_error: 0.1817\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 197us/step - loss: 0.0647 - mean_absolute_error: 0.1817\n",
      "Epoch 43/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0506 - mean_absolute_error: 0.1576\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.0506 - mean_absolute_error: 0.1574\n",
      "Epoch 44/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0564 - mean_absolute_error: 0.1684\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.0564 - mean_absolute_error: 0.1685\n",
      "Epoch 45/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0569 - mean_absolute_error: 0.1660\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0569 - mean_absolute_error: 0.1660\n",
      "Epoch 46/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0550 - mean_absolute_error: 0.1645\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 201us/step - loss: 0.0549 - mean_absolute_error: 0.1645\n",
      "Epoch 47/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0618 - mean_absolute_error: 0.1763\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.0617 - mean_absolute_error: 0.1761\n",
      "Epoch 48/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0463 - mean_absolute_error: 0.1481\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0464 - mean_absolute_error: 0.1482\n",
      "Epoch 49/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0539 - mean_absolute_error: 0.1632\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 198us/step - loss: 0.0539 - mean_absolute_error: 0.1631\n",
      "Epoch 50/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0570 - mean_absolute_error: 0.1628\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 198us/step - loss: 0.0573 - mean_absolute_error: 0.1635\n",
      "Epoch 51/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0575 - mean_absolute_error: 0.1630\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 196us/step - loss: 0.0574 - mean_absolute_error: 0.1629\n",
      "Epoch 52/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0459 - mean_absolute_error: 0.1459\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 196us/step - loss: 0.0459 - mean_absolute_error: 0.1459\n",
      "Epoch 53/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0462 - mean_absolute_error: 0.1457\n",
      "Epoch 00053: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.0461 - mean_absolute_error: 0.1458\n",
      "Epoch 54/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0480 - mean_absolute_error: 0.1495\n",
      "Epoch 00054: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 197us/step - loss: 0.0481 - mean_absolute_error: 0.1497\n",
      "Epoch 55/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0589 - mean_absolute_error: 0.1641\n",
      "Epoch 00055: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 4s 197us/step - loss: 0.0589 - mean_absolute_error: 0.1641\n",
      "Epoch 56/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0467 - mean_absolute_error: 0.1442\n",
      "Epoch 00056: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0468 - mean_absolute_error: 0.1444\n",
      "Epoch 57/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0434 - mean_absolute_error: 0.1374\n",
      "Epoch 00057: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0434 - mean_absolute_error: 0.1374\n",
      "Epoch 58/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0456 - mean_absolute_error: 0.1470\n",
      "Epoch 00058: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/3\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0458 - mean_absolute_error: 0.1473\n",
      "Epoch 1/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 20.3906 - mean_absolute_error: 2.8558\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 7s 319us/step - loss: 20.3740 - mean_absolute_error: 2.8554\n",
      "Epoch 2/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 4.7124 - mean_absolute_error: 1.5701\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 4.6914 - mean_absolute_error: 1.5668\n",
      "Epoch 3/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 1.3914 - mean_absolute_error: 0.8509\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 1.3864 - mean_absolute_error: 0.8494\n",
      "Epoch 4/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.5738 - mean_absolute_error: 0.5500\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.5736 - mean_absolute_error: 0.5499\n",
      "Epoch 5/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.4742 - mean_absolute_error: 0.5125\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.4741 - mean_absolute_error: 0.5125\n",
      "Epoch 6/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.3838 - mean_absolute_error: 0.4560\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.3843 - mean_absolute_error: 0.4562\n",
      "Epoch 7/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.4927 - mean_absolute_error: 0.5091\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.4921 - mean_absolute_error: 0.5089\n",
      "Epoch 8/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.4013 - mean_absolute_error: 0.4601\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.4011 - mean_absolute_error: 0.4599\n",
      "Epoch 9/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.3737 - mean_absolute_error: 0.4459\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.3736 - mean_absolute_error: 0.4460\n",
      "Epoch 10/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.3646 - mean_absolute_error: 0.4318\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.3645 - mean_absolute_error: 0.4319\n",
      "Epoch 11/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.3386 - mean_absolute_error: 0.4246\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.3390 - mean_absolute_error: 0.4250\n",
      "Epoch 12/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.3051 - mean_absolute_error: 0.4032\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.3051 - mean_absolute_error: 0.4033\n",
      "Epoch 13/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2661 - mean_absolute_error: 0.3746\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.2652 - mean_absolute_error: 0.3740\n",
      "Epoch 14/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.2405 - mean_absolute_error: 0.3556\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.2407 - mean_absolute_error: 0.3558\n",
      "Epoch 15/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.2255 - mean_absolute_error: 0.3519\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.2259 - mean_absolute_error: 0.3524\n",
      "Epoch 16/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.2270 - mean_absolute_error: 0.3364\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.2273 - mean_absolute_error: 0.3367\n",
      "Epoch 17/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2315 - mean_absolute_error: 0.3524\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.2308 - mean_absolute_error: 0.3518\n",
      "Epoch 18/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1506 - mean_absolute_error: 0.2859\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.1505 - mean_absolute_error: 0.2859\n",
      "Epoch 19/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1545 - mean_absolute_error: 0.2900\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.1547 - mean_absolute_error: 0.2903\n",
      "Epoch 20/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1900 - mean_absolute_error: 0.3167\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.1901 - mean_absolute_error: 0.3167\n",
      "Epoch 21/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1455 - mean_absolute_error: 0.2798\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.1451 - mean_absolute_error: 0.2794\n",
      "Epoch 22/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.1508 - mean_absolute_error: 0.2641\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.1507 - mean_absolute_error: 0.2641\n",
      "Epoch 23/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.1229 - mean_absolute_error: 0.2584\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.1228 - mean_absolute_error: 0.2584\n",
      "Epoch 24/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1305 - mean_absolute_error: 0.2514\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1304 - mean_absolute_error: 0.2513\n",
      "Epoch 25/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1076 - mean_absolute_error: 0.2386\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.1076 - mean_absolute_error: 0.2387\n",
      "Epoch 26/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1123 - mean_absolute_error: 0.2478\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.1128 - mean_absolute_error: 0.2481\n",
      "Epoch 27/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0968 - mean_absolute_error: 0.2292\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0967 - mean_absolute_error: 0.2291\n",
      "Epoch 28/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0921 - mean_absolute_error: 0.2227\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0921 - mean_absolute_error: 0.2226\n",
      "Epoch 29/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1078 - mean_absolute_error: 0.2305\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.1075 - mean_absolute_error: 0.2303\n",
      "Epoch 30/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0860 - mean_absolute_error: 0.2124\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0861 - mean_absolute_error: 0.2125\n",
      "Epoch 31/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0758 - mean_absolute_error: 0.1974\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0760 - mean_absolute_error: 0.1975\n",
      "Epoch 32/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0926 - mean_absolute_error: 0.2197\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.0926 - mean_absolute_error: 0.2196\n",
      "Epoch 33/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1062 - mean_absolute_error: 0.2185\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.1064 - mean_absolute_error: 0.2189\n",
      "Epoch 34/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0696 - mean_absolute_error: 0.1924\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0696 - mean_absolute_error: 0.1924\n",
      "Epoch 35/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.4645 - mean_absolute_error: 0.2686\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.4638 - mean_absolute_error: 0.2685\n",
      "Epoch 36/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0551 - mean_absolute_error: 0.1626\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 202us/step - loss: 0.0550 - mean_absolute_error: 0.1625\n",
      "Epoch 37/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0419 - mean_absolute_error: 0.1403\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0420 - mean_absolute_error: 0.1405\n",
      "Epoch 38/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0472 - mean_absolute_error: 0.1521\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0472 - mean_absolute_error: 0.1522\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0558 - mean_absolute_error: 0.1647\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 203us/step - loss: 0.0561 - mean_absolute_error: 0.1654\n",
      "Epoch 40/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0661 - mean_absolute_error: 0.1829\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0661 - mean_absolute_error: 0.1829\n",
      "Epoch 41/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0591 - mean_absolute_error: 0.1734\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0593 - mean_absolute_error: 0.1735\n",
      "Epoch 42/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0561 - mean_absolute_error: 0.1674\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0561 - mean_absolute_error: 0.1674\n",
      "Epoch 43/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0570 - mean_absolute_error: 0.1681\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0570 - mean_absolute_error: 0.1684\n",
      "Epoch 44/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0588 - mean_absolute_error: 0.1734\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0588 - mean_absolute_error: 0.1734\n",
      "Epoch 45/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0573 - mean_absolute_error: 0.1711\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0573 - mean_absolute_error: 0.1711\n",
      "Epoch 46/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0567 - mean_absolute_error: 0.1667\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0567 - mean_absolute_error: 0.1667\n",
      "Epoch 47/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0651 - mean_absolute_error: 0.1772\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0651 - mean_absolute_error: 0.1772\n",
      "Epoch 48/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0525 - mean_absolute_error: 0.1609\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0527 - mean_absolute_error: 0.1614\n",
      "Epoch 49/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0503 - mean_absolute_error: 0.1568\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0503 - mean_absolute_error: 0.1567\n",
      "Epoch 50/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0532 - mean_absolute_error: 0.1631\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 233us/step - loss: 0.0532 - mean_absolute_error: 0.1631\n",
      "Epoch 51/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0509 - mean_absolute_error: 0.1582\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0509 - mean_absolute_error: 0.1583\n",
      "Epoch 52/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0470 - mean_absolute_error: 0.1493\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.0470 - mean_absolute_error: 0.1494\n",
      "Epoch 53/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0543 - mean_absolute_error: 0.1612\n",
      "Epoch 00053: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0544 - mean_absolute_error: 0.1616\n",
      "Epoch 54/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0511 - mean_absolute_error: 0.1570\n",
      "Epoch 00054: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0511 - mean_absolute_error: 0.1570\n",
      "Epoch 55/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0482 - mean_absolute_error: 0.1510\n",
      "Epoch 00055: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0484 - mean_absolute_error: 0.1514\n",
      "Epoch 56/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0483 - mean_absolute_error: 0.1491\n",
      "Epoch 00056: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0482 - mean_absolute_error: 0.1490\n",
      "Epoch 57/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0420 - mean_absolute_error: 0.1388\n",
      "Epoch 00057: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/4\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0420 - mean_absolute_error: 0.1388\n",
      "Epoch 1/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 18.6635 - mean_absolute_error: 2.7869\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 8s 336us/step - loss: 18.6213 - mean_absolute_error: 2.7835\n",
      "Epoch 2/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 4.2147 - mean_absolute_error: 1.4537\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 4.1870 - mean_absolute_error: 1.4481\n",
      "Epoch 3/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.9461 - mean_absolute_error: 0.6955\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.9459 - mean_absolute_error: 0.6954\n",
      "Epoch 4/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.4541 - mean_absolute_error: 0.5020\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 227us/step - loss: 0.4536 - mean_absolute_error: 0.5017\n",
      "Epoch 5/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.4001 - mean_absolute_error: 0.4697\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 227us/step - loss: 0.4011 - mean_absolute_error: 0.4698\n",
      "Epoch 6/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.3503 - mean_absolute_error: 0.4384\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.3517 - mean_absolute_error: 0.4390\n",
      "Epoch 7/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.4166 - mean_absolute_error: 0.4830\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.4174 - mean_absolute_error: 0.4833\n",
      "Epoch 8/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.3946 - mean_absolute_error: 0.4570\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.3956 - mean_absolute_error: 0.4578\n",
      "Epoch 9/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.4276 - mean_absolute_error: 0.4760\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.4275 - mean_absolute_error: 0.4759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.3238 - mean_absolute_error: 0.4036\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.3234 - mean_absolute_error: 0.4037\n",
      "Epoch 11/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.3056 - mean_absolute_error: 0.3981\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.3061 - mean_absolute_error: 0.3983\n",
      "Epoch 12/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.2999 - mean_absolute_error: 0.4000\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.2997 - mean_absolute_error: 0.3997\n",
      "Epoch 13/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.2742 - mean_absolute_error: 0.3745\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.2737 - mean_absolute_error: 0.3741\n",
      "Epoch 14/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2605 - mean_absolute_error: 0.3659\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.2605 - mean_absolute_error: 0.3660\n",
      "Epoch 15/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.2571 - mean_absolute_error: 0.3703\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.2572 - mean_absolute_error: 0.3704\n",
      "Epoch 16/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.2451 - mean_absolute_error: 0.3559\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.2449 - mean_absolute_error: 0.3558\n",
      "Epoch 17/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1949 - mean_absolute_error: 0.3239\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 233us/step - loss: 0.1950 - mean_absolute_error: 0.3239\n",
      "Epoch 18/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.1953 - mean_absolute_error: 0.3167\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.1953 - mean_absolute_error: 0.3167\n",
      "Epoch 19/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1837 - mean_absolute_error: 0.3157\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.1834 - mean_absolute_error: 0.3155\n",
      "Epoch 20/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.1496 - mean_absolute_error: 0.2832\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 232us/step - loss: 0.1498 - mean_absolute_error: 0.2832\n",
      "Epoch 21/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1345 - mean_absolute_error: 0.2650\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 228us/step - loss: 0.1344 - mean_absolute_error: 0.2649\n",
      "Epoch 22/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1351 - mean_absolute_error: 0.2683\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.1353 - mean_absolute_error: 0.2685\n",
      "Epoch 23/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1262 - mean_absolute_error: 0.2606\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.1263 - mean_absolute_error: 0.2606\n",
      "Epoch 24/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1347 - mean_absolute_error: 0.2723\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.1345 - mean_absolute_error: 0.2722\n",
      "Epoch 25/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.2219 - mean_absolute_error: 0.2828\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.2218 - mean_absolute_error: 0.2828\n",
      "Epoch 26/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.1352 - mean_absolute_error: 0.2667\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1349 - mean_absolute_error: 0.2665\n",
      "Epoch 27/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0915 - mean_absolute_error: 0.2162\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.0915 - mean_absolute_error: 0.2162\n",
      "Epoch 28/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0896 - mean_absolute_error: 0.2199\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0895 - mean_absolute_error: 0.2198\n",
      "Epoch 29/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0866 - mean_absolute_error: 0.2134\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0865 - mean_absolute_error: 0.2132\n",
      "Epoch 30/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0867 - mean_absolute_error: 0.2137\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0865 - mean_absolute_error: 0.2134\n",
      "Epoch 31/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0892 - mean_absolute_error: 0.2175\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0892 - mean_absolute_error: 0.2175\n",
      "Epoch 32/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0868 - mean_absolute_error: 0.2079\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 240us/step - loss: 0.0869 - mean_absolute_error: 0.2080\n",
      "Epoch 33/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0841 - mean_absolute_error: 0.2113\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 234us/step - loss: 0.0841 - mean_absolute_error: 0.2113\n",
      "Epoch 34/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0807 - mean_absolute_error: 0.2078\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 6s 252us/step - loss: 0.0807 - mean_absolute_error: 0.2078\n",
      "Epoch 35/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0651 - mean_absolute_error: 0.1843\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 228us/step - loss: 0.0651 - mean_absolute_error: 0.1843\n",
      "Epoch 36/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0708 - mean_absolute_error: 0.1908\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0708 - mean_absolute_error: 0.1908\n",
      "Epoch 37/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0661 - mean_absolute_error: 0.1830\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0661 - mean_absolute_error: 0.1830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0784 - mean_absolute_error: 0.2037\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 6s 247us/step - loss: 0.0784 - mean_absolute_error: 0.2037\n",
      "Epoch 39/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.1888\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0682 - mean_absolute_error: 0.1893\n",
      "Epoch 40/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0637 - mean_absolute_error: 0.1794\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0638 - mean_absolute_error: 0.1796\n",
      "Epoch 41/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0601 - mean_absolute_error: 0.1727\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0600 - mean_absolute_error: 0.1726\n",
      "Epoch 42/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0583 - mean_absolute_error: 0.1719\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0582 - mean_absolute_error: 0.1719\n",
      "Epoch 43/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0589 - mean_absolute_error: 0.1728\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0593 - mean_absolute_error: 0.1735\n",
      "Epoch 44/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0564 - mean_absolute_error: 0.1699\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.0563 - mean_absolute_error: 0.1698\n",
      "Epoch 45/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0549 - mean_absolute_error: 0.1661\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0550 - mean_absolute_error: 0.1662\n",
      "Epoch 46/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0510 - mean_absolute_error: 0.1586\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0510 - mean_absolute_error: 0.1586\n",
      "Epoch 47/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0511 - mean_absolute_error: 0.1578\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0511 - mean_absolute_error: 0.1578\n",
      "Epoch 48/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0487 - mean_absolute_error: 0.1529\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0490 - mean_absolute_error: 0.1535\n",
      "Epoch 49/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0511 - mean_absolute_error: 0.1586\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.0510 - mean_absolute_error: 0.1586\n",
      "Epoch 50/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0497 - mean_absolute_error: 0.1554\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.0497 - mean_absolute_error: 0.1556\n",
      "Epoch 51/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0498 - mean_absolute_error: 0.1546\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0499 - mean_absolute_error: 0.1547\n",
      "Epoch 52/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0440 - mean_absolute_error: 0.1427\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0440 - mean_absolute_error: 0.1427\n",
      "Epoch 53/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0540 - mean_absolute_error: 0.1627\n",
      "Epoch 00053: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0540 - mean_absolute_error: 0.1627\n",
      "Epoch 54/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0464 - mean_absolute_error: 0.1471\n",
      "Epoch 00054: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0464 - mean_absolute_error: 0.1471\n",
      "Epoch 55/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0432 - mean_absolute_error: 0.1389\n",
      "Epoch 00055: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 233us/step - loss: 0.0431 - mean_absolute_error: 0.1387\n",
      "Epoch 56/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0459 - mean_absolute_error: 0.1456\n",
      "Epoch 00056: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 232us/step - loss: 0.0459 - mean_absolute_error: 0.1456\n",
      "Epoch 57/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0490 - mean_absolute_error: 0.1512\n",
      "Epoch 00057: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 6s 253us/step - loss: 0.0489 - mean_absolute_error: 0.1510\n",
      "Epoch 58/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0442 - mean_absolute_error: 0.1416\n",
      "Epoch 00058: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0442 - mean_absolute_error: 0.1416\n",
      "Epoch 59/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1347\n",
      "Epoch 00059: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 234us/step - loss: 0.0406 - mean_absolute_error: 0.1347\n",
      "Epoch 60/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1386\n",
      "Epoch 00060: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0421 - mean_absolute_error: 0.1387\n",
      "Epoch 61/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1338\n",
      "Epoch 00061: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0400 - mean_absolute_error: 0.1338\n",
      "Epoch 62/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0415 - mean_absolute_error: 0.1361\n",
      "Epoch 00062: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0415 - mean_absolute_error: 0.1361\n",
      "Epoch 63/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1330\n",
      "Epoch 00063: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0400 - mean_absolute_error: 0.1329\n",
      "Epoch 64/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0390 - mean_absolute_error: 0.1318\n",
      "Epoch 00064: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 223us/step - loss: 0.0390 - mean_absolute_error: 0.1318\n",
      "Epoch 65/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0393 - mean_absolute_error: 0.1332\n",
      "Epoch 00065: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 220us/step - loss: 0.0393 - mean_absolute_error: 0.1332\n",
      "Epoch 66/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0391 - mean_absolute_error: 0.1319\n",
      "Epoch 00066: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0390 - mean_absolute_error: 0.1318\n",
      "Epoch 67/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0442 - mean_absolute_error: 0.1398\n",
      "Epoch 00067: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 231us/step - loss: 0.0442 - mean_absolute_error: 0.1397\n",
      "Epoch 68/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0371 - mean_absolute_error: 0.1257\n",
      "Epoch 00068: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 234us/step - loss: 0.0370 - mean_absolute_error: 0.1256\n",
      "Epoch 69/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0386 - mean_absolute_error: 0.1280\n",
      "Epoch 00069: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.0386 - mean_absolute_error: 0.1281\n",
      "Epoch 70/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1222\n",
      "Epoch 00070: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0359 - mean_absolute_error: 0.1224\n",
      "Epoch 71/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0466 - mean_absolute_error: 0.1441\n",
      "Epoch 00071: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 226us/step - loss: 0.0465 - mean_absolute_error: 0.1440\n",
      "Epoch 72/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0371 - mean_absolute_error: 0.1227\n",
      "Epoch 00072: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0371 - mean_absolute_error: 0.1226\n",
      "Epoch 73/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1166\n",
      "Epoch 00073: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0335 - mean_absolute_error: 0.1166\n",
      "Epoch 74/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1179\n",
      "Epoch 00074: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0337 - mean_absolute_error: 0.1178\n",
      "Epoch 75/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1266\n",
      "Epoch 00075: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0373 - mean_absolute_error: 0.1266\n",
      "Epoch 76/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1216\n",
      "Epoch 00076: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0347 - mean_absolute_error: 0.1215\n",
      "Epoch 77/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1230\n",
      "Epoch 00077: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0360 - mean_absolute_error: 0.1230\n",
      "Epoch 78/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1233\n",
      "Epoch 00078: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 237us/step - loss: 0.0361 - mean_absolute_error: 0.1232\n",
      "Epoch 79/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1233\n",
      "Epoch 00079: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 224us/step - loss: 0.0361 - mean_absolute_error: 0.1233\n",
      "Epoch 80/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1181\n",
      "Epoch 00080: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0357 - mean_absolute_error: 0.1183\n",
      "Epoch 81/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1100\n",
      "Epoch 00081: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0309 - mean_absolute_error: 0.1099\n",
      "Epoch 82/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1139\n",
      "Epoch 00082: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0321 - mean_absolute_error: 0.1140\n",
      "Epoch 83/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0365 - mean_absolute_error: 0.1193\n",
      "Epoch 00083: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0365 - mean_absolute_error: 0.1194\n",
      "Epoch 84/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0353 - mean_absolute_error: 0.1212\n",
      "Epoch 00084: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 219us/step - loss: 0.0353 - mean_absolute_error: 0.1212\n",
      "Epoch 85/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1133\n",
      "Epoch 00085: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0330 - mean_absolute_error: 0.1133\n",
      "Epoch 86/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1113\n",
      "Epoch 00086: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0315 - mean_absolute_error: 0.1113\n",
      "Epoch 87/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1102\n",
      "Epoch 00087: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0306 - mean_absolute_error: 0.1102\n",
      "Epoch 88/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0375 - mean_absolute_error: 0.1269\n",
      "Epoch 00088: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0374 - mean_absolute_error: 0.1269\n",
      "Epoch 89/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1161\n",
      "Epoch 00089: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0336 - mean_absolute_error: 0.1161\n",
      "Epoch 90/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1120\n",
      "Epoch 00090: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0316 - mean_absolute_error: 0.1120\n",
      "Epoch 91/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1141\n",
      "Epoch 00091: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0323 - mean_absolute_error: 0.1141\n",
      "Epoch 92/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1036\n",
      "Epoch 00092: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0289 - mean_absolute_error: 0.1037\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1154\n",
      "Epoch 00093: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0346 - mean_absolute_error: 0.1155\n",
      "Epoch 94/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1175\n",
      "Epoch 00094: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0337 - mean_absolute_error: 0.1176\n",
      "Epoch 95/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1055\n",
      "Epoch 00095: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0300 - mean_absolute_error: 0.1056\n",
      "Epoch 96/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1052\n",
      "Epoch 00096: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0292 - mean_absolute_error: 0.1052\n",
      "Epoch 97/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1174\n",
      "Epoch 00097: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0341 - mean_absolute_error: 0.1175\n",
      "Epoch 98/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1142\n",
      "Epoch 00098: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0332 - mean_absolute_error: 0.1145\n",
      "Epoch 99/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1152\n",
      "Epoch 00099: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0327 - mean_absolute_error: 0.1152\n",
      "Epoch 100/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1025\n",
      "Epoch 00100: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0287 - mean_absolute_error: 0.1024\n",
      "Epoch 101/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1037\n",
      "Epoch 00101: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0289 - mean_absolute_error: 0.1037\n",
      "Epoch 102/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1026\n",
      "Epoch 00102: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0283 - mean_absolute_error: 0.1025\n",
      "Epoch 103/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1077\n",
      "Epoch 00103: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0303 - mean_absolute_error: 0.1078\n",
      "Epoch 104/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1107\n",
      "Epoch 00104: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0309 - mean_absolute_error: 0.1107\n",
      "Epoch 105/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1069\n",
      "Epoch 00105: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0297 - mean_absolute_error: 0.1070\n",
      "Epoch 106/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1052\n",
      "Epoch 00106: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0291 - mean_absolute_error: 0.1052\n",
      "Epoch 107/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.1053\n",
      "Epoch 00107: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0292 - mean_absolute_error: 0.1051\n",
      "Epoch 108/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1068\n",
      "Epoch 00108: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0297 - mean_absolute_error: 0.1070\n",
      "Epoch 109/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1088\n",
      "Epoch 00109: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0302 - mean_absolute_error: 0.1087\n",
      "Epoch 110/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1021\n",
      "Epoch 00110: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0285 - mean_absolute_error: 0.1022\n",
      "Epoch 111/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0280 - mean_absolute_error: 0.1022\n",
      "Epoch 00111: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0280 - mean_absolute_error: 0.1022\n",
      "Epoch 112/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1041\n",
      "Epoch 00112: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0285 - mean_absolute_error: 0.1042\n",
      "Epoch 113/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.1005\n",
      "Epoch 00113: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0269 - mean_absolute_error: 0.1005\n",
      "Epoch 114/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1040\n",
      "Epoch 00114: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0280 - mean_absolute_error: 0.1039\n",
      "Epoch 115/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1037\n",
      "Epoch 00115: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0283 - mean_absolute_error: 0.1038\n",
      "Epoch 116/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1037\n",
      "Epoch 00116: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0289 - mean_absolute_error: 0.1038\n",
      "Epoch 117/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1073\n",
      "Epoch 00117: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.0308 - mean_absolute_error: 0.1075\n",
      "Epoch 118/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1048\n",
      "Epoch 00118: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0284 - mean_absolute_error: 0.1047\n",
      "Epoch 119/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0972\n",
      "Epoch 00119: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0266 - mean_absolute_error: 0.0972\n",
      "Epoch 120/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.0971\n",
      "Epoch 00120: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0264 - mean_absolute_error: 0.0972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.1008\n",
      "Epoch 00121: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0271 - mean_absolute_error: 0.1007\n",
      "Epoch 122/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1004\n",
      "Epoch 00122: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0273 - mean_absolute_error: 0.1004\n",
      "Epoch 123/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1033\n",
      "Epoch 00123: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0286 - mean_absolute_error: 0.1033\n",
      "Epoch 124/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1053\n",
      "Epoch 00124: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0286 - mean_absolute_error: 0.1053\n",
      "Epoch 125/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.0978\n",
      "Epoch 00125: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0260 - mean_absolute_error: 0.0979\n",
      "Epoch 126/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0977\n",
      "Epoch 00126: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0261 - mean_absolute_error: 0.0976\n",
      "Epoch 127/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0992\n",
      "Epoch 00127: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0266 - mean_absolute_error: 0.0993\n",
      "Epoch 128/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0282 - mean_absolute_error: 0.1027\n",
      "Epoch 00128: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0282 - mean_absolute_error: 0.1027\n",
      "Epoch 129/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1030\n",
      "Epoch 00129: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0283 - mean_absolute_error: 0.1029\n",
      "Epoch 130/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0972\n",
      "Epoch 00130: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0257 - mean_absolute_error: 0.0972\n",
      "Epoch 131/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0976\n",
      "Epoch 00131: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0261 - mean_absolute_error: 0.0976\n",
      "Epoch 132/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1038\n",
      "Epoch 00132: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0280 - mean_absolute_error: 0.1037\n",
      "Epoch 133/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0978\n",
      "Epoch 00133: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0261 - mean_absolute_error: 0.0978\n",
      "Epoch 134/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.0953\n",
      "Epoch 00134: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0253 - mean_absolute_error: 0.0954\n",
      "Epoch 135/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.1028\n",
      "Epoch 00135: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0293 - mean_absolute_error: 0.1027\n",
      "Epoch 136/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.0921\n",
      "Epoch 00136: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0242 - mean_absolute_error: 0.0923\n",
      "Epoch 137/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.1001\n",
      "Epoch 00137: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0265 - mean_absolute_error: 0.1001\n",
      "Epoch 138/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.0952\n",
      "Epoch 00138: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0252 - mean_absolute_error: 0.0952\n",
      "Epoch 139/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0947\n",
      "Epoch 00139: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0249 - mean_absolute_error: 0.0947\n",
      "Epoch 140/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0970\n",
      "Epoch 00140: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0258 - mean_absolute_error: 0.0970\n",
      "Epoch 141/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0238 - mean_absolute_error: 0.0897\n",
      "Epoch 00141: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0238 - mean_absolute_error: 0.0898\n",
      "Epoch 142/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0260 - mean_absolute_error: 0.0969\n",
      "Epoch 00142: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0260 - mean_absolute_error: 0.0968\n",
      "Epoch 143/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.0954\n",
      "Epoch 00143: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0251 - mean_absolute_error: 0.0955\n",
      "Epoch 144/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.1045\n",
      "Epoch 00144: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0293 - mean_absolute_error: 0.1045\n",
      "Epoch 145/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0257 - mean_absolute_error: 0.0966\n",
      "Epoch 00145: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0257 - mean_absolute_error: 0.0966\n",
      "Epoch 146/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0245 - mean_absolute_error: 0.0938\n",
      "Epoch 00146: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0245 - mean_absolute_error: 0.0939\n",
      "Epoch 147/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0985\n",
      "Epoch 00147: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0262 - mean_absolute_error: 0.0987\n",
      "Epoch 148/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0996\n",
      "Epoch 00148: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0265 - mean_absolute_error: 0.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0928\n",
      "Epoch 00149: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0246 - mean_absolute_error: 0.0928\n",
      "Epoch 150/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0245 - mean_absolute_error: 0.0927\n",
      "Epoch 00150: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0245 - mean_absolute_error: 0.0927\n",
      "Epoch 151/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.0903\n",
      "Epoch 00151: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0237 - mean_absolute_error: 0.0903\n",
      "Epoch 152/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0282 - mean_absolute_error: 0.1036\n",
      "Epoch 00152: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0282 - mean_absolute_error: 0.1036\n",
      "Epoch 153/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1011\n",
      "Epoch 00153: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0279 - mean_absolute_error: 0.1013\n",
      "Epoch 154/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.0951\n",
      "Epoch 00154: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0253 - mean_absolute_error: 0.0951\n",
      "Epoch 155/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0240 - mean_absolute_error: 0.0911\n",
      "Epoch 00155: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0240 - mean_absolute_error: 0.0911\n",
      "Epoch 156/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0939\n",
      "Epoch 00156: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0247 - mean_absolute_error: 0.0938\n",
      "Epoch 157/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.0934\n",
      "Epoch 00157: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0243 - mean_absolute_error: 0.0934\n",
      "Epoch 158/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.0905\n",
      "Epoch 00158: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0237 - mean_absolute_error: 0.0905\n",
      "Epoch 159/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.0961\n",
      "Epoch 00159: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0252 - mean_absolute_error: 0.0961\n",
      "Epoch 160/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0964\n",
      "Epoch 00160: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0258 - mean_absolute_error: 0.0963\n",
      "Epoch 161/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0242 - mean_absolute_error: 0.0917\n",
      "Epoch 00161: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0241 - mean_absolute_error: 0.0917\n",
      "Epoch 162/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0227 - mean_absolute_error: 0.0894\n",
      "Epoch 00162: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0228 - mean_absolute_error: 0.0894\n",
      "Epoch 163/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0242 - mean_absolute_error: 0.0950\n",
      "Epoch 00163: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0242 - mean_absolute_error: 0.0950\n",
      "Epoch 164/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.0958\n",
      "Epoch 00164: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0247 - mean_absolute_error: 0.0957\n",
      "Epoch 165/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.0941\n",
      "Epoch 00165: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0243 - mean_absolute_error: 0.0942\n",
      "Epoch 166/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0935\n",
      "Epoch 00166: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0247 - mean_absolute_error: 0.0935\n",
      "Epoch 167/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0932\n",
      "Epoch 00167: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0249 - mean_absolute_error: 0.0932\n",
      "Epoch 168/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0230 - mean_absolute_error: 0.0890\n",
      "Epoch 00168: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0230 - mean_absolute_error: 0.0891\n",
      "Epoch 169/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.0903\n",
      "Epoch 00169: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0233 - mean_absolute_error: 0.0903\n",
      "Epoch 170/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.0897\n",
      "Epoch 00170: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0232 - mean_absolute_error: 0.0897\n",
      "Epoch 171/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.0922\n",
      "Epoch 00171: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0244 - mean_absolute_error: 0.0923\n",
      "Epoch 172/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0246 - mean_absolute_error: 0.0950\n",
      "Epoch 00172: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0245 - mean_absolute_error: 0.0948\n",
      "Epoch 173/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0236 - mean_absolute_error: 0.0898\n",
      "Epoch 00173: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0236 - mean_absolute_error: 0.0898\n",
      "Epoch 174/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.0974\n",
      "Epoch 00174: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0259 - mean_absolute_error: 0.0974\n",
      "Epoch 175/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0215 - mean_absolute_error: 0.0849\n",
      "Epoch 00175: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 204us/step - loss: 0.0215 - mean_absolute_error: 0.0849\n",
      "Epoch 176/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0231 - mean_absolute_error: 0.0897\n",
      "Epoch 00176: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0231 - mean_absolute_error: 0.0898\n",
      "Epoch 177/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0957\n",
      "Epoch 00177: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0249 - mean_absolute_error: 0.0957\n",
      "Epoch 178/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0234 - mean_absolute_error: 0.0907\n",
      "Epoch 00178: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0234 - mean_absolute_error: 0.0906\n",
      "Epoch 179/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0246 - mean_absolute_error: 0.0947\n",
      "Epoch 00179: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0246 - mean_absolute_error: 0.0947\n",
      "Epoch 180/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0242 - mean_absolute_error: 0.0918\n",
      "Epoch 00180: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0241 - mean_absolute_error: 0.0918\n",
      "Epoch 181/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0216 - mean_absolute_error: 0.0841\n",
      "Epoch 00181: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0216 - mean_absolute_error: 0.0841\n",
      "Epoch 182/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0246 - mean_absolute_error: 0.0938\n",
      "Epoch 00182: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0246 - mean_absolute_error: 0.0938\n",
      "Epoch 183/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.0910\n",
      "Epoch 00183: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0233 - mean_absolute_error: 0.0910\n",
      "Epoch 184/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0211 - mean_absolute_error: 0.0823\n",
      "Epoch 00184: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0212 - mean_absolute_error: 0.0824\n",
      "Epoch 185/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0226 - mean_absolute_error: 0.0884\n",
      "Epoch 00185: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0226 - mean_absolute_error: 0.0885\n",
      "Epoch 186/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0954\n",
      "Epoch 00186: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0248 - mean_absolute_error: 0.0954\n",
      "Epoch 187/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0228 - mean_absolute_error: 0.0896\n",
      "Epoch 00187: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0228 - mean_absolute_error: 0.0896\n",
      "Epoch 188/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0227 - mean_absolute_error: 0.0895\n",
      "Epoch 00188: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0227 - mean_absolute_error: 0.0895\n",
      "Epoch 189/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0222 - mean_absolute_error: 0.0874\n",
      "Epoch 00189: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0222 - mean_absolute_error: 0.0874\n",
      "Epoch 190/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0947\n",
      "Epoch 00190: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0247 - mean_absolute_error: 0.0947\n",
      "Epoch 191/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0220 - mean_absolute_error: 0.0867\n",
      "Epoch 00191: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0220 - mean_absolute_error: 0.0867\n",
      "Epoch 192/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0229 - mean_absolute_error: 0.0896\n",
      "Epoch 00192: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0229 - mean_absolute_error: 0.0896\n",
      "Epoch 193/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.0926\n",
      "Epoch 00193: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0237 - mean_absolute_error: 0.0926\n",
      "Epoch 194/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0227 - mean_absolute_error: 0.0885\n",
      "Epoch 00194: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 209us/step - loss: 0.0227 - mean_absolute_error: 0.0885\n",
      "Epoch 195/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0837\n",
      "Epoch 00195: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 206us/step - loss: 0.0209 - mean_absolute_error: 0.0837\n",
      "Epoch 196/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.0959\n",
      "Epoch 00196: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0248 - mean_absolute_error: 0.0959\n",
      "Epoch 197/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0224 - mean_absolute_error: 0.0881\n",
      "Epoch 00197: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 208us/step - loss: 0.0224 - mean_absolute_error: 0.0882\n",
      "Epoch 198/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0227 - mean_absolute_error: 0.0894\n",
      "Epoch 00198: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 205us/step - loss: 0.0227 - mean_absolute_error: 0.0894\n",
      "Epoch 199/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0210 - mean_absolute_error: 0.0837\n",
      "Epoch 00199: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0210 - mean_absolute_error: 0.0836\n",
      "Epoch 200/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0831\n",
      "Epoch 00200: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/5\n",
      "22536/22536 [==============================] - 5s 207us/step - loss: 0.0209 - mean_absolute_error: 0.0831\n",
      "Epoch 1/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 18.3438 - mean_absolute_error: 2.7969\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 8s 338us/step - loss: 18.3021 - mean_absolute_error: 2.7933\n",
      "Epoch 2/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 3.2794 - mean_absolute_error: 1.2928\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 3.2755 - mean_absolute_error: 1.2920\n",
      "Epoch 3/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.7673 - mean_absolute_error: 0.6306\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.7655 - mean_absolute_error: 0.6299\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.4474 - mean_absolute_error: 0.4978\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.4473 - mean_absolute_error: 0.4978\n",
      "Epoch 5/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.3910 - mean_absolute_error: 0.4673\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.3911 - mean_absolute_error: 0.4672\n",
      "Epoch 6/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.4002 - mean_absolute_error: 0.4646\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.4003 - mean_absolute_error: 0.4647\n",
      "Epoch 7/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.4325 - mean_absolute_error: 0.4799\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.4325 - mean_absolute_error: 0.4799\n",
      "Epoch 8/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.3637 - mean_absolute_error: 0.4298\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.3635 - mean_absolute_error: 0.4298\n",
      "Epoch 9/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.3909 - mean_absolute_error: 0.4583\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 221us/step - loss: 0.3919 - mean_absolute_error: 0.4589\n",
      "Epoch 10/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.3102 - mean_absolute_error: 0.4061\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.3106 - mean_absolute_error: 0.4065\n",
      "Epoch 11/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.3090 - mean_absolute_error: 0.4114\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.3088 - mean_absolute_error: 0.4111\n",
      "Epoch 12/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.2589 - mean_absolute_error: 0.3710\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.2588 - mean_absolute_error: 0.3711\n",
      "Epoch 13/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.2554 - mean_absolute_error: 0.3713\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.2551 - mean_absolute_error: 0.3712\n",
      "Epoch 14/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.2966 - mean_absolute_error: 0.3969\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.2963 - mean_absolute_error: 0.3966\n",
      "Epoch 15/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.2107 - mean_absolute_error: 0.3379\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.2110 - mean_absolute_error: 0.3379\n",
      "Epoch 16/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1991 - mean_absolute_error: 0.3223\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1996 - mean_absolute_error: 0.3225\n",
      "Epoch 17/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1836 - mean_absolute_error: 0.3148\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.1841 - mean_absolute_error: 0.3152\n",
      "Epoch 18/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.2406 - mean_absolute_error: 0.3273\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.2401 - mean_absolute_error: 0.3270\n",
      "Epoch 19/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1505 - mean_absolute_error: 0.2836\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1505 - mean_absolute_error: 0.2836\n",
      "Epoch 20/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1297 - mean_absolute_error: 0.2671\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1299 - mean_absolute_error: 0.2673\n",
      "Epoch 21/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2570\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.1195 - mean_absolute_error: 0.2570\n",
      "Epoch 22/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1449 - mean_absolute_error: 0.2709\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1447 - mean_absolute_error: 0.2707\n",
      "Epoch 23/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1131 - mean_absolute_error: 0.2465\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.1131 - mean_absolute_error: 0.2466\n",
      "Epoch 24/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1106 - mean_absolute_error: 0.2459\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.1107 - mean_absolute_error: 0.2459\n",
      "Epoch 25/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2477\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1144 - mean_absolute_error: 0.2478\n",
      "Epoch 26/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1030 - mean_absolute_error: 0.2392\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1027 - mean_absolute_error: 0.2389\n",
      "Epoch 27/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0980 - mean_absolute_error: 0.2324\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0979 - mean_absolute_error: 0.2322\n",
      "Epoch 28/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0955 - mean_absolute_error: 0.2282\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0954 - mean_absolute_error: 0.2281\n",
      "Epoch 29/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0781 - mean_absolute_error: 0.2037\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0781 - mean_absolute_error: 0.2037\n",
      "Epoch 30/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0990 - mean_absolute_error: 0.2188\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0990 - mean_absolute_error: 0.2188\n",
      "Epoch 31/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0817 - mean_absolute_error: 0.2086\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0817 - mean_absolute_error: 0.2086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0813 - mean_absolute_error: 0.2079\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0812 - mean_absolute_error: 0.2078\n",
      "Epoch 33/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.1954\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0727 - mean_absolute_error: 0.1954\n",
      "Epoch 34/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0655 - mean_absolute_error: 0.1842\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0654 - mean_absolute_error: 0.1842\n",
      "Epoch 35/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0709 - mean_absolute_error: 0.1920\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0709 - mean_absolute_error: 0.1920\n",
      "Epoch 36/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0634 - mean_absolute_error: 0.1776\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0633 - mean_absolute_error: 0.1775\n",
      "Epoch 37/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0634 - mean_absolute_error: 0.1816\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0634 - mean_absolute_error: 0.1816\n",
      "Epoch 38/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0649 - mean_absolute_error: 0.1790\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0649 - mean_absolute_error: 0.1790\n",
      "Epoch 39/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0619 - mean_absolute_error: 0.1778\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0619 - mean_absolute_error: 0.1778\n",
      "Epoch 40/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0567 - mean_absolute_error: 0.1678\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0566 - mean_absolute_error: 0.1677\n",
      "Epoch 41/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0570 - mean_absolute_error: 0.1689\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0569 - mean_absolute_error: 0.1688\n",
      "Epoch 42/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0564 - mean_absolute_error: 0.1688\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0564 - mean_absolute_error: 0.1687\n",
      "Epoch 43/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0523 - mean_absolute_error: 0.1608\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0523 - mean_absolute_error: 0.1608\n",
      "Epoch 44/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0505 - mean_absolute_error: 0.1566\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0505 - mean_absolute_error: 0.1567\n",
      "Epoch 45/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0579 - mean_absolute_error: 0.1709\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0578 - mean_absolute_error: 0.1708\n",
      "Epoch 46/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0493 - mean_absolute_error: 0.1521\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0493 - mean_absolute_error: 0.1521\n",
      "Epoch 47/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0463 - mean_absolute_error: 0.1476\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0462 - mean_absolute_error: 0.1475\n",
      "Epoch 48/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0521 - mean_absolute_error: 0.1606\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0521 - mean_absolute_error: 0.1605\n",
      "Epoch 49/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0460 - mean_absolute_error: 0.1480\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0460 - mean_absolute_error: 0.1480\n",
      "Epoch 50/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0483 - mean_absolute_error: 0.1526\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0483 - mean_absolute_error: 0.1526\n",
      "Epoch 51/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0506 - mean_absolute_error: 0.1559\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0505 - mean_absolute_error: 0.1558\n",
      "Epoch 52/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0404 - mean_absolute_error: 0.1353\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0404 - mean_absolute_error: 0.1353\n",
      "Epoch 53/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0511 - mean_absolute_error: 0.1551\n",
      "Epoch 00053: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0511 - mean_absolute_error: 0.1550\n",
      "Epoch 54/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0486 - mean_absolute_error: 0.1472\n",
      "Epoch 00054: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0496 - mean_absolute_error: 0.1473\n",
      "Epoch 55/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0484 - mean_absolute_error: 0.1461\n",
      "Epoch 00055: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0484 - mean_absolute_error: 0.1460\n",
      "Epoch 56/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0369 - mean_absolute_error: 0.1235\n",
      "Epoch 00056: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0369 - mean_absolute_error: 0.1235\n",
      "Epoch 57/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1331\n",
      "Epoch 00057: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0398 - mean_absolute_error: 0.1331\n",
      "Epoch 58/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0392 - mean_absolute_error: 0.1327\n",
      "Epoch 00058: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0392 - mean_absolute_error: 0.1328\n",
      "Epoch 59/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0472 - mean_absolute_error: 0.1495\n",
      "Epoch 00059: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0472 - mean_absolute_error: 0.1494\n",
      "Epoch 60/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0395 - mean_absolute_error: 0.1324\n",
      "Epoch 00060: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0395 - mean_absolute_error: 0.1323\n",
      "Epoch 61/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0392 - mean_absolute_error: 0.1316\n",
      "Epoch 00061: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0392 - mean_absolute_error: 0.1315\n",
      "Epoch 62/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0419 - mean_absolute_error: 0.1361\n",
      "Epoch 00062: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0419 - mean_absolute_error: 0.1359\n",
      "Epoch 63/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1308\n",
      "Epoch 00063: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0388 - mean_absolute_error: 0.1309\n",
      "Epoch 64/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0423 - mean_absolute_error: 0.1390\n",
      "Epoch 00064: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0422 - mean_absolute_error: 0.1389\n",
      "Epoch 65/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0390 - mean_absolute_error: 0.1312\n",
      "Epoch 00065: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0390 - mean_absolute_error: 0.1311\n",
      "Epoch 66/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1315\n",
      "Epoch 00066: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0388 - mean_absolute_error: 0.1315\n",
      "Epoch 67/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1283\n",
      "Epoch 00067: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0388 - mean_absolute_error: 0.1283\n",
      "Epoch 68/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0404 - mean_absolute_error: 0.1330\n",
      "Epoch 00068: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0405 - mean_absolute_error: 0.1331\n",
      "Epoch 69/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0399 - mean_absolute_error: 0.1313\n",
      "Epoch 00069: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0398 - mean_absolute_error: 0.1312\n",
      "Epoch 70/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1205\n",
      "Epoch 00070: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0353 - mean_absolute_error: 0.1204\n",
      "Epoch 71/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0370 - mean_absolute_error: 0.1269\n",
      "Epoch 00071: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0370 - mean_absolute_error: 0.1269\n",
      "Epoch 72/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1174\n",
      "Epoch 00072: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0344 - mean_absolute_error: 0.1174\n",
      "Epoch 73/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1138\n",
      "Epoch 00073: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0330 - mean_absolute_error: 0.1140\n",
      "Epoch 74/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1349\n",
      "Epoch 00074: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0406 - mean_absolute_error: 0.1349\n",
      "Epoch 75/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1273\n",
      "Epoch 00075: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0379 - mean_absolute_error: 0.1273\n",
      "Epoch 76/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1216\n",
      "Epoch 00076: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0365 - mean_absolute_error: 0.1215\n",
      "Epoch 77/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1133\n",
      "Epoch 00077: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0319 - mean_absolute_error: 0.1133\n",
      "Epoch 78/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1193\n",
      "Epoch 00078: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0348 - mean_absolute_error: 0.1192\n",
      "Epoch 79/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1200\n",
      "Epoch 00079: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0350 - mean_absolute_error: 0.1200\n",
      "Epoch 80/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1255\n",
      "Epoch 00080: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0373 - mean_absolute_error: 0.1255\n",
      "Epoch 81/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1201\n",
      "Epoch 00081: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0354 - mean_absolute_error: 0.1199\n",
      "Epoch 82/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1094\n",
      "Epoch 00082: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0314 - mean_absolute_error: 0.1097\n",
      "Epoch 83/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1224\n",
      "Epoch 00083: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0360 - mean_absolute_error: 0.1223\n",
      "Epoch 84/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1133\n",
      "Epoch 00084: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0330 - mean_absolute_error: 0.1133\n",
      "Epoch 85/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1156\n",
      "Epoch 00085: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0334 - mean_absolute_error: 0.1156\n",
      "Epoch 86/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1089\n",
      "Epoch 00086: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0306 - mean_absolute_error: 0.1089\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1162\n",
      "Epoch 00087: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0340 - mean_absolute_error: 0.1161\n",
      "Epoch 88/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1205\n",
      "Epoch 00088: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0354 - mean_absolute_error: 0.1205\n",
      "Epoch 89/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1128\n",
      "Epoch 00089: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0325 - mean_absolute_error: 0.1128\n",
      "Epoch 90/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1106\n",
      "Epoch 00090: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0308 - mean_absolute_error: 0.1106\n",
      "Epoch 91/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1098\n",
      "Epoch 00091: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0314 - mean_absolute_error: 0.1098\n",
      "Epoch 92/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1119\n",
      "Epoch 00092: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0323 - mean_absolute_error: 0.1120\n",
      "Epoch 93/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1159\n",
      "Epoch 00093: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0331 - mean_absolute_error: 0.1159\n",
      "Epoch 94/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1114\n",
      "Epoch 00094: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0313 - mean_absolute_error: 0.1114\n",
      "Epoch 95/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1156\n",
      "Epoch 00095: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0343 - mean_absolute_error: 0.1156\n",
      "Epoch 96/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1114\n",
      "Epoch 00096: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0319 - mean_absolute_error: 0.1114\n",
      "Epoch 97/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1086\n",
      "Epoch 00097: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0304 - mean_absolute_error: 0.1086\n",
      "Epoch 98/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1083\n",
      "Epoch 00098: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0322 - mean_absolute_error: 0.1085\n",
      "Epoch 99/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1091\n",
      "Epoch 00099: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0314 - mean_absolute_error: 0.1091\n",
      "Epoch 100/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1040\n",
      "Epoch 00100: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0290 - mean_absolute_error: 0.1040\n",
      "Epoch 101/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1192\n",
      "Epoch 00101: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0362 - mean_absolute_error: 0.1192\n",
      "Epoch 102/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1103\n",
      "Epoch 00102: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0314 - mean_absolute_error: 0.1102\n",
      "Epoch 103/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0272 - mean_absolute_error: 0.0992\n",
      "Epoch 00103: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0271 - mean_absolute_error: 0.0992\n",
      "Epoch 104/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1081\n",
      "Epoch 00104: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0305 - mean_absolute_error: 0.1081\n",
      "Epoch 105/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1147\n",
      "Epoch 00105: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0323 - mean_absolute_error: 0.1146\n",
      "Epoch 106/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1066\n",
      "Epoch 00106: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0303 - mean_absolute_error: 0.1065\n",
      "Epoch 107/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1023\n",
      "Epoch 00107: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0288 - mean_absolute_error: 0.1022\n",
      "Epoch 108/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1038\n",
      "Epoch 00108: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0292 - mean_absolute_error: 0.1039\n",
      "Epoch 109/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1144\n",
      "Epoch 00109: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0333 - mean_absolute_error: 0.1144\n",
      "Epoch 110/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1099\n",
      "Epoch 00110: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0312 - mean_absolute_error: 0.1098\n",
      "Epoch 111/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0985\n",
      "Epoch 00111: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0271 - mean_absolute_error: 0.0986\n",
      "Epoch 112/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0280 - mean_absolute_error: 0.1002\n",
      "Epoch 00112: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0280 - mean_absolute_error: 0.1002\n",
      "Epoch 113/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1057\n",
      "Epoch 00113: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0300 - mean_absolute_error: 0.1057\n",
      "Epoch 114/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1053\n",
      "Epoch 00114: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0297 - mean_absolute_error: 0.1052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1127\n",
      "Epoch 00115: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0320 - mean_absolute_error: 0.1128\n",
      "Epoch 116/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1011\n",
      "Epoch 00116: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0277 - mean_absolute_error: 0.1011\n",
      "Epoch 117/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0959\n",
      "Epoch 00117: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0261 - mean_absolute_error: 0.0960\n",
      "Epoch 118/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1045\n",
      "Epoch 00118: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0304 - mean_absolute_error: 0.1045\n",
      "Epoch 119/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1015\n",
      "Epoch 00119: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0287 - mean_absolute_error: 0.1015\n",
      "Epoch 120/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1049\n",
      "Epoch 00120: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0292 - mean_absolute_error: 0.1049\n",
      "Epoch 121/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1015\n",
      "Epoch 00121: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0278 - mean_absolute_error: 0.1017\n",
      "Epoch 122/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.0989\n",
      "Epoch 00122: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0271 - mean_absolute_error: 0.0990\n",
      "Epoch 123/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0990\n",
      "Epoch 00123: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0270 - mean_absolute_error: 0.0989\n",
      "Epoch 124/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1098\n",
      "Epoch 00124: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0309 - mean_absolute_error: 0.1098\n",
      "Epoch 125/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.0979\n",
      "Epoch 00125: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0268 - mean_absolute_error: 0.0978\n",
      "Epoch 126/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1094\n",
      "Epoch 00126: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0310 - mean_absolute_error: 0.1093\n",
      "Epoch 127/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0974\n",
      "Epoch 00127: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0265 - mean_absolute_error: 0.0974\n",
      "Epoch 128/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.1000\n",
      "Epoch 00128: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0271 - mean_absolute_error: 0.1000\n",
      "Epoch 129/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0926\n",
      "Epoch 00129: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0249 - mean_absolute_error: 0.0927\n",
      "Epoch 130/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1008\n",
      "Epoch 00130: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0287 - mean_absolute_error: 0.1008\n",
      "Epoch 131/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1051\n",
      "Epoch 00131: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0291 - mean_absolute_error: 0.1050\n",
      "Epoch 132/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0980\n",
      "Epoch 00132: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0261 - mean_absolute_error: 0.0980\n",
      "Epoch 133/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.0954\n",
      "Epoch 00133: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0255 - mean_absolute_error: 0.0954\n",
      "Epoch 134/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.0995\n",
      "Epoch 00134: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0272 - mean_absolute_error: 0.0994\n",
      "Epoch 135/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1052\n",
      "Epoch 00135: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0291 - mean_absolute_error: 0.1053\n",
      "Epoch 136/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0966\n",
      "Epoch 00136: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0261 - mean_absolute_error: 0.0965\n",
      "Epoch 137/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0231 - mean_absolute_error: 0.0878\n",
      "Epoch 00137: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0232 - mean_absolute_error: 0.0880\n",
      "Epoch 138/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.1002\n",
      "Epoch 00138: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0274 - mean_absolute_error: 0.1002\n",
      "Epoch 139/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0992\n",
      "Epoch 00139: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0270 - mean_absolute_error: 0.0992\n",
      "Epoch 140/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.1003\n",
      "Epoch 00140: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0276 - mean_absolute_error: 0.1003\n",
      "Epoch 141/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1010\n",
      "Epoch 00141: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0281 - mean_absolute_error: 0.1010\n",
      "Epoch 142/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.0908\n",
      "Epoch 00142: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0242 - mean_absolute_error: 0.0908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.0913\n",
      "Epoch 00143: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0241 - mean_absolute_error: 0.0913\n",
      "Epoch 144/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0987\n",
      "Epoch 00144: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0266 - mean_absolute_error: 0.0987\n",
      "Epoch 145/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.0994\n",
      "Epoch 00145: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0270 - mean_absolute_error: 0.0994\n",
      "Epoch 146/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1041\n",
      "Epoch 00146: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0285 - mean_absolute_error: 0.1041\n",
      "Epoch 147/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0242 - mean_absolute_error: 0.0915\n",
      "Epoch 00147: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0242 - mean_absolute_error: 0.0915\n",
      "Epoch 148/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0976\n",
      "Epoch 00148: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0261 - mean_absolute_error: 0.0976\n",
      "Epoch 149/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.0940\n",
      "Epoch 00149: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0252 - mean_absolute_error: 0.0939\n",
      "Epoch 150/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.0907\n",
      "Epoch 00150: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0241 - mean_absolute_error: 0.0911\n",
      "Epoch 151/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1056\n",
      "Epoch 00151: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0290 - mean_absolute_error: 0.1056\n",
      "Epoch 152/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.0917\n",
      "Epoch 00152: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 210us/step - loss: 0.0243 - mean_absolute_error: 0.0918\n",
      "Epoch 153/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0257 - mean_absolute_error: 0.0957\n",
      "Epoch 00153: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0257 - mean_absolute_error: 0.0957\n",
      "Epoch 154/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.0921\n",
      "Epoch 00154: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0251 - mean_absolute_error: 0.0921\n",
      "Epoch 155/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0930\n",
      "Epoch 00155: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0249 - mean_absolute_error: 0.0930\n",
      "Epoch 156/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0254 - mean_absolute_error: 0.0949\n",
      "Epoch 00156: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0253 - mean_absolute_error: 0.0948\n",
      "Epoch 157/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.0970\n",
      "Epoch 00157: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/6\n",
      "22536/22536 [==============================] - 5s 211us/step - loss: 0.0259 - mean_absolute_error: 0.0970\n",
      "Epoch 1/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 19.2407 - mean_absolute_error: 2.7978\n",
      "Epoch 00001: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 8s 348us/step - loss: 19.1234 - mean_absolute_error: 2.7894\n",
      "Epoch 2/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 4.3013 - mean_absolute_error: 1.4802\n",
      "Epoch 00002: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 4.2944 - mean_absolute_error: 1.4784\n",
      "Epoch 3/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 1.1307 - mean_absolute_error: 0.7598\n",
      "Epoch 00003: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 1.1294 - mean_absolute_error: 0.7593\n",
      "Epoch 4/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.4870 - mean_absolute_error: 0.5131\n",
      "Epoch 00004: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.4865 - mean_absolute_error: 0.5129\n",
      "Epoch 5/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.4060 - mean_absolute_error: 0.4769\n",
      "Epoch 00005: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.4060 - mean_absolute_error: 0.4769\n",
      "Epoch 6/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.4205 - mean_absolute_error: 0.4801\n",
      "Epoch 00006: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.4209 - mean_absolute_error: 0.4808\n",
      "Epoch 7/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.4308 - mean_absolute_error: 0.4798\n",
      "Epoch 00007: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.4310 - mean_absolute_error: 0.4800\n",
      "Epoch 8/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.3539 - mean_absolute_error: 0.4293\n",
      "Epoch 00008: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.3540 - mean_absolute_error: 0.4293\n",
      "Epoch 9/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.3391 - mean_absolute_error: 0.4225\n",
      "Epoch 00009: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.3396 - mean_absolute_error: 0.4229\n",
      "Epoch 10/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.3376 - mean_absolute_error: 0.4273\n",
      "Epoch 00010: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.3373 - mean_absolute_error: 0.4273\n",
      "Epoch 11/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.3377 - mean_absolute_error: 0.4140\n",
      "Epoch 00011: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.3376 - mean_absolute_error: 0.4141\n",
      "Epoch 12/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2932 - mean_absolute_error: 0.3916\n",
      "Epoch 00012: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.2934 - mean_absolute_error: 0.3915\n",
      "Epoch 13/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.2750 - mean_absolute_error: 0.3690\n",
      "Epoch 00013: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.2756 - mean_absolute_error: 0.3693\n",
      "Epoch 14/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.2859 - mean_absolute_error: 0.3859\n",
      "Epoch 00014: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.2867 - mean_absolute_error: 0.3861\n",
      "Epoch 15/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.2482 - mean_absolute_error: 0.3545\n",
      "Epoch 00015: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.2474 - mean_absolute_error: 0.3540\n",
      "Epoch 16/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.2047 - mean_absolute_error: 0.3286\n",
      "Epoch 00016: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.2046 - mean_absolute_error: 0.3285\n",
      "Epoch 17/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1909 - mean_absolute_error: 0.3217\n",
      "Epoch 00017: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1909 - mean_absolute_error: 0.3216\n",
      "Epoch 18/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1782 - mean_absolute_error: 0.3069\n",
      "Epoch 00018: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1787 - mean_absolute_error: 0.3074\n",
      "Epoch 19/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1637 - mean_absolute_error: 0.2921\n",
      "Epoch 00019: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1639 - mean_absolute_error: 0.2925\n",
      "Epoch 20/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1625 - mean_absolute_error: 0.2935\n",
      "Epoch 00020: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1622 - mean_absolute_error: 0.2933\n",
      "Epoch 21/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.1374 - mean_absolute_error: 0.2699\n",
      "Epoch 00021: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1371 - mean_absolute_error: 0.2695\n",
      "Epoch 22/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.1270 - mean_absolute_error: 0.2576\n",
      "Epoch 00022: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1268 - mean_absolute_error: 0.2575\n",
      "Epoch 23/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1281 - mean_absolute_error: 0.2623\n",
      "Epoch 00023: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.1280 - mean_absolute_error: 0.2622\n",
      "Epoch 24/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1292 - mean_absolute_error: 0.2587\n",
      "Epoch 00024: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.1291 - mean_absolute_error: 0.2586\n",
      "Epoch 25/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.1419 - mean_absolute_error: 0.2627\n",
      "Epoch 00025: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1415 - mean_absolute_error: 0.2623\n",
      "Epoch 26/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.1257 - mean_absolute_error: 0.2342\n",
      "Epoch 00026: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.1257 - mean_absolute_error: 0.2343\n",
      "Epoch 27/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.2226\n",
      "Epoch 00027: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0928 - mean_absolute_error: 0.2226\n",
      "Epoch 28/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.1018 - mean_absolute_error: 0.2278\n",
      "Epoch 00028: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.1017 - mean_absolute_error: 0.2277\n",
      "Epoch 29/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0822 - mean_absolute_error: 0.2065\n",
      "Epoch 00029: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0822 - mean_absolute_error: 0.2065\n",
      "Epoch 30/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0843 - mean_absolute_error: 0.2114\n",
      "Epoch 00030: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0843 - mean_absolute_error: 0.2114\n",
      "Epoch 31/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0862 - mean_absolute_error: 0.2114\n",
      "Epoch 00031: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0872 - mean_absolute_error: 0.2116\n",
      "Epoch 32/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0878 - mean_absolute_error: 0.2138\n",
      "Epoch 00032: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0879 - mean_absolute_error: 0.2139\n",
      "Epoch 33/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0858 - mean_absolute_error: 0.2107\n",
      "Epoch 00033: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0857 - mean_absolute_error: 0.2105\n",
      "Epoch 34/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0797 - mean_absolute_error: 0.2009\n",
      "Epoch 00034: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0797 - mean_absolute_error: 0.2008\n",
      "Epoch 35/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0733 - mean_absolute_error: 0.1903\n",
      "Epoch 00035: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0732 - mean_absolute_error: 0.1903\n",
      "Epoch 36/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0733 - mean_absolute_error: 0.1886\n",
      "Epoch 00036: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0733 - mean_absolute_error: 0.1886\n",
      "Epoch 37/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0769 - mean_absolute_error: 0.1974\n",
      "Epoch 00037: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0769 - mean_absolute_error: 0.1973\n",
      "Epoch 38/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0632 - mean_absolute_error: 0.1758\n",
      "Epoch 00038: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0633 - mean_absolute_error: 0.1761\n",
      "Epoch 39/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0624 - mean_absolute_error: 0.1737\n",
      "Epoch 00039: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0623 - mean_absolute_error: 0.1735\n",
      "Epoch 40/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0659 - mean_absolute_error: 0.1828\n",
      "Epoch 00040: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0662 - mean_absolute_error: 0.1831\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0647 - mean_absolute_error: 0.1812\n",
      "Epoch 00041: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0647 - mean_absolute_error: 0.1811\n",
      "Epoch 42/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0595 - mean_absolute_error: 0.1705\n",
      "Epoch 00042: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0594 - mean_absolute_error: 0.1704\n",
      "Epoch 43/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0587 - mean_absolute_error: 0.1678\n",
      "Epoch 00043: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0588 - mean_absolute_error: 0.1680\n",
      "Epoch 44/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0567 - mean_absolute_error: 0.1647\n",
      "Epoch 00044: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0566 - mean_absolute_error: 0.1646\n",
      "Epoch 45/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0543 - mean_absolute_error: 0.1627\n",
      "Epoch 00045: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0542 - mean_absolute_error: 0.1627\n",
      "Epoch 46/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0526 - mean_absolute_error: 0.1596\n",
      "Epoch 00046: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0527 - mean_absolute_error: 0.1598\n",
      "Epoch 47/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0549 - mean_absolute_error: 0.1623\n",
      "Epoch 00047: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0549 - mean_absolute_error: 0.1622\n",
      "Epoch 48/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0528 - mean_absolute_error: 0.1591\n",
      "Epoch 00048: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0528 - mean_absolute_error: 0.1590\n",
      "Epoch 49/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0540 - mean_absolute_error: 0.1608\n",
      "Epoch 00049: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0540 - mean_absolute_error: 0.1607\n",
      "Epoch 50/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0502 - mean_absolute_error: 0.1510\n",
      "Epoch 00050: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0501 - mean_absolute_error: 0.1509\n",
      "Epoch 51/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0494 - mean_absolute_error: 0.1501\n",
      "Epoch 00051: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0495 - mean_absolute_error: 0.1503\n",
      "Epoch 52/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.1483\n",
      "Epoch 00052: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0464 - mean_absolute_error: 0.1483\n",
      "Epoch 53/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0445 - mean_absolute_error: 0.1430\n",
      "Epoch 00053: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0447 - mean_absolute_error: 0.1432\n",
      "Epoch 54/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0536 - mean_absolute_error: 0.1594\n",
      "Epoch 00054: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0536 - mean_absolute_error: 0.1594\n",
      "Epoch 55/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.1449\n",
      "Epoch 00055: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0452 - mean_absolute_error: 0.1449\n",
      "Epoch 56/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.1468\n",
      "Epoch 00056: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0457 - mean_absolute_error: 0.1467\n",
      "Epoch 57/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0385 - mean_absolute_error: 0.1286\n",
      "Epoch 00057: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0385 - mean_absolute_error: 0.1286\n",
      "Epoch 58/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0438 - mean_absolute_error: 0.1416\n",
      "Epoch 00058: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0437 - mean_absolute_error: 0.1415\n",
      "Epoch 59/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.1456\n",
      "Epoch 00059: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0466 - mean_absolute_error: 0.1457\n",
      "Epoch 60/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0430 - mean_absolute_error: 0.1378\n",
      "Epoch 00060: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0430 - mean_absolute_error: 0.1378\n",
      "Epoch 61/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0386 - mean_absolute_error: 0.1291\n",
      "Epoch 00061: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0391 - mean_absolute_error: 0.1302\n",
      "Epoch 62/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0409 - mean_absolute_error: 0.1350\n",
      "Epoch 00062: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0408 - mean_absolute_error: 0.1349\n",
      "Epoch 63/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0404 - mean_absolute_error: 0.1315\n",
      "Epoch 00063: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0404 - mean_absolute_error: 0.1315\n",
      "Epoch 64/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1295\n",
      "Epoch 00064: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0398 - mean_absolute_error: 0.1295\n",
      "Epoch 65/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1321\n",
      "Epoch 00065: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0398 - mean_absolute_error: 0.1322\n",
      "Epoch 66/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1306\n",
      "Epoch 00066: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0388 - mean_absolute_error: 0.1306\n",
      "Epoch 67/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0396 - mean_absolute_error: 0.1322\n",
      "Epoch 00067: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0396 - mean_absolute_error: 0.1323\n",
      "Epoch 68/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1332\n",
      "Epoch 00068: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0406 - mean_absolute_error: 0.1331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0414 - mean_absolute_error: 0.1317\n",
      "Epoch 00069: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0416 - mean_absolute_error: 0.1320\n",
      "Epoch 70/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0381 - mean_absolute_error: 0.1273\n",
      "Epoch 00070: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0381 - mean_absolute_error: 0.1274\n",
      "Epoch 71/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1272\n",
      "Epoch 00071: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0378 - mean_absolute_error: 0.1271\n",
      "Epoch 72/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1164\n",
      "Epoch 00072: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0334 - mean_absolute_error: 0.1165\n",
      "Epoch 73/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0399 - mean_absolute_error: 0.1308\n",
      "Epoch 00073: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0399 - mean_absolute_error: 0.1308\n",
      "Epoch 74/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0442 - mean_absolute_error: 0.1405\n",
      "Epoch 00074: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0441 - mean_absolute_error: 0.1403\n",
      "Epoch 75/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1216\n",
      "Epoch 00075: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0363 - mean_absolute_error: 0.1217\n",
      "Epoch 76/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0351 - mean_absolute_error: 0.1171\n",
      "Epoch 00076: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0350 - mean_absolute_error: 0.1170\n",
      "Epoch 77/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1177\n",
      "Epoch 00077: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0342 - mean_absolute_error: 0.1177\n",
      "Epoch 78/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0383 - mean_absolute_error: 0.1261\n",
      "Epoch 00078: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 235us/step - loss: 0.0383 - mean_absolute_error: 0.1260\n",
      "Epoch 79/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0365 - mean_absolute_error: 0.1223\n",
      "Epoch 00079: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 250us/step - loss: 0.0365 - mean_absolute_error: 0.1224\n",
      "Epoch 80/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1208\n",
      "Epoch 00080: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0362 - mean_absolute_error: 0.1209\n",
      "Epoch 81/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1176\n",
      "Epoch 00081: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0348 - mean_absolute_error: 0.1177\n",
      "Epoch 82/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1159\n",
      "Epoch 00082: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0347 - mean_absolute_error: 0.1162\n",
      "Epoch 83/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1220\n",
      "Epoch 00083: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0366 - mean_absolute_error: 0.1222\n",
      "Epoch 84/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1112\n",
      "Epoch 00084: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0328 - mean_absolute_error: 0.1112\n",
      "Epoch 85/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1141\n",
      "Epoch 00085: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0330 - mean_absolute_error: 0.1141\n",
      "Epoch 86/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1179\n",
      "Epoch 00086: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0344 - mean_absolute_error: 0.1177\n",
      "Epoch 87/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1181\n",
      "Epoch 00087: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0345 - mean_absolute_error: 0.1181\n",
      "Epoch 88/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1169\n",
      "Epoch 00088: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0338 - mean_absolute_error: 0.1169\n",
      "Epoch 89/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1085\n",
      "Epoch 00089: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0312 - mean_absolute_error: 0.1086\n",
      "Epoch 90/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1087\n",
      "Epoch 00090: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0319 - mean_absolute_error: 0.1086\n",
      "Epoch 91/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1174\n",
      "Epoch 00091: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0348 - mean_absolute_error: 0.1173\n",
      "Epoch 92/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1165\n",
      "Epoch 00092: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0333 - mean_absolute_error: 0.1166\n",
      "Epoch 93/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1194\n",
      "Epoch 00093: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0345 - mean_absolute_error: 0.1194\n",
      "Epoch 94/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1069\n",
      "Epoch 00094: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0304 - mean_absolute_error: 0.1068\n",
      "Epoch 95/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1055\n",
      "Epoch 00095: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0304 - mean_absolute_error: 0.1055\n",
      "Epoch 96/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1135\n",
      "Epoch 00096: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0329 - mean_absolute_error: 0.1136\n",
      "Epoch 97/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1160\n",
      "Epoch 00097: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0347 - mean_absolute_error: 0.1160\n",
      "Epoch 98/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1129\n",
      "Epoch 00098: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0339 - mean_absolute_error: 0.1128\n",
      "Epoch 99/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1034\n",
      "Epoch 00099: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0287 - mean_absolute_error: 0.1034\n",
      "Epoch 100/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1077\n",
      "Epoch 00100: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0303 - mean_absolute_error: 0.1077\n",
      "Epoch 101/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1085\n",
      "Epoch 00101: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0312 - mean_absolute_error: 0.1084\n",
      "Epoch 102/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1068\n",
      "Epoch 00102: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0314 - mean_absolute_error: 0.1069\n",
      "Epoch 103/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1091\n",
      "Epoch 00103: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0310 - mean_absolute_error: 0.1091\n",
      "Epoch 104/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1103\n",
      "Epoch 00104: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0310 - mean_absolute_error: 0.1103\n",
      "Epoch 105/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1096\n",
      "Epoch 00105: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0306 - mean_absolute_error: 0.1095\n",
      "Epoch 106/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1077\n",
      "Epoch 00106: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0303 - mean_absolute_error: 0.1077\n",
      "Epoch 107/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1115\n",
      "Epoch 00107: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0318 - mean_absolute_error: 0.1114\n",
      "Epoch 108/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1061\n",
      "Epoch 00108: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0305 - mean_absolute_error: 0.1061\n",
      "Epoch 109/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1077\n",
      "Epoch 00109: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0302 - mean_absolute_error: 0.1075\n",
      "Epoch 110/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1101\n",
      "Epoch 00110: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0314 - mean_absolute_error: 0.1103\n",
      "Epoch 111/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1095\n",
      "Epoch 00111: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0313 - mean_absolute_error: 0.1095\n",
      "Epoch 112/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1085\n",
      "Epoch 00112: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0310 - mean_absolute_error: 0.1084\n",
      "Epoch 113/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1057\n",
      "Epoch 00113: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0299 - mean_absolute_error: 0.1057\n",
      "Epoch 114/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.0997\n",
      "Epoch 00114: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0271 - mean_absolute_error: 0.0996\n",
      "Epoch 115/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.1006\n",
      "Epoch 00115: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0275 - mean_absolute_error: 0.1008\n",
      "Epoch 116/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1043\n",
      "Epoch 00116: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0289 - mean_absolute_error: 0.1041\n",
      "Epoch 117/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1143\n",
      "Epoch 00117: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0330 - mean_absolute_error: 0.1142\n",
      "Epoch 118/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1066\n",
      "Epoch 00118: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0301 - mean_absolute_error: 0.1065\n",
      "Epoch 119/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0278 - mean_absolute_error: 0.1008\n",
      "Epoch 00119: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0278 - mean_absolute_error: 0.1008\n",
      "Epoch 120/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1045\n",
      "Epoch 00120: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0288 - mean_absolute_error: 0.1046\n",
      "Epoch 121/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1056\n",
      "Epoch 00121: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0296 - mean_absolute_error: 0.1057\n",
      "Epoch 122/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1029\n",
      "Epoch 00122: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0297 - mean_absolute_error: 0.1029\n",
      "Epoch 123/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.1009\n",
      "Epoch 00123: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0275 - mean_absolute_error: 0.1009\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1001\n",
      "Epoch 00124: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0273 - mean_absolute_error: 0.1001\n",
      "Epoch 125/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1035\n",
      "Epoch 00125: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0296 - mean_absolute_error: 0.1034\n",
      "Epoch 126/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.0955\n",
      "Epoch 00126: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0264 - mean_absolute_error: 0.0956\n",
      "Epoch 127/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0280 - mean_absolute_error: 0.1007\n",
      "Epoch 00127: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0280 - mean_absolute_error: 0.1007\n",
      "Epoch 128/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.0998\n",
      "Epoch 00128: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0284 - mean_absolute_error: 0.0998\n",
      "Epoch 129/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0278 - mean_absolute_error: 0.1000\n",
      "Epoch 00129: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0278 - mean_absolute_error: 0.1000\n",
      "Epoch 130/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1034\n",
      "Epoch 00130: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0299 - mean_absolute_error: 0.1035\n",
      "Epoch 131/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1028\n",
      "Epoch 00131: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0285 - mean_absolute_error: 0.1029\n",
      "Epoch 132/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0956\n",
      "Epoch 00132: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0259 - mean_absolute_error: 0.0957\n",
      "Epoch 133/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.0975\n",
      "Epoch 00133: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0267 - mean_absolute_error: 0.0976\n",
      "Epoch 134/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1008\n",
      "Epoch 00134: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0277 - mean_absolute_error: 0.1008\n",
      "Epoch 135/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1034\n",
      "Epoch 00135: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0286 - mean_absolute_error: 0.1040\n",
      "Epoch 136/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1043\n",
      "Epoch 00136: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0287 - mean_absolute_error: 0.1042\n",
      "Epoch 137/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0268 - mean_absolute_error: 0.0969\n",
      "Epoch 00137: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0268 - mean_absolute_error: 0.0968\n",
      "Epoch 138/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.0922\n",
      "Epoch 00138: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 216us/step - loss: 0.0253 - mean_absolute_error: 0.0923\n",
      "Epoch 139/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0262 - mean_absolute_error: 0.0970\n",
      "Epoch 00139: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0262 - mean_absolute_error: 0.0970\n",
      "Epoch 140/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0256 - mean_absolute_error: 0.0963\n",
      "Epoch 00140: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0259 - mean_absolute_error: 0.0965\n",
      "Epoch 141/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1066\n",
      "Epoch 00141: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0297 - mean_absolute_error: 0.1066\n",
      "Epoch 142/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.0996\n",
      "Epoch 00142: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0269 - mean_absolute_error: 0.0996\n",
      "Epoch 143/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.0908\n",
      "Epoch 00143: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0243 - mean_absolute_error: 0.0908\n",
      "Epoch 144/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0246 - mean_absolute_error: 0.0931\n",
      "Epoch 00144: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0246 - mean_absolute_error: 0.0930\n",
      "Epoch 145/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.0983\n",
      "Epoch 00145: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0271 - mean_absolute_error: 0.0983\n",
      "Epoch 146/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.0966\n",
      "Epoch 00146: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0259 - mean_absolute_error: 0.0967\n",
      "Epoch 147/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0263 - mean_absolute_error: 0.0982\n",
      "Epoch 00147: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0263 - mean_absolute_error: 0.0983\n",
      "Epoch 148/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0977\n",
      "Epoch 00148: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0265 - mean_absolute_error: 0.0978\n",
      "Epoch 149/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.0919\n",
      "Epoch 00149: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0248 - mean_absolute_error: 0.0918\n",
      "Epoch 150/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0245 - mean_absolute_error: 0.0934\n",
      "Epoch 00150: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0245 - mean_absolute_error: 0.0934\n",
      "Epoch 151/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.0984\n",
      "Epoch 00151: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0264 - mean_absolute_error: 0.0983\n",
      "Epoch 152/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0262 - mean_absolute_error: 0.0966\n",
      "Epoch 00152: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0262 - mean_absolute_error: 0.0965\n",
      "Epoch 153/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0250 - mean_absolute_error: 0.0954\n",
      "Epoch 00153: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0250 - mean_absolute_error: 0.0954\n",
      "Epoch 154/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.0919\n",
      "Epoch 00154: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0244 - mean_absolute_error: 0.0920\n",
      "Epoch 155/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1037\n",
      "Epoch 00155: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0279 - mean_absolute_error: 0.1037\n",
      "Epoch 156/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0261 - mean_absolute_error: 0.0965\n",
      "Epoch 00156: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0261 - mean_absolute_error: 0.0965\n",
      "Epoch 157/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.0937\n",
      "Epoch 00157: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0250 - mean_absolute_error: 0.0936\n",
      "Epoch 158/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.0884\n",
      "Epoch 00158: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0235 - mean_absolute_error: 0.0884\n",
      "Epoch 159/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0256 - mean_absolute_error: 0.0957\n",
      "Epoch 00159: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0256 - mean_absolute_error: 0.0957\n",
      "Epoch 160/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0942\n",
      "Epoch 00160: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0247 - mean_absolute_error: 0.0941\n",
      "Epoch 161/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0229 - mean_absolute_error: 0.0884\n",
      "Epoch 00161: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0228 - mean_absolute_error: 0.0883\n",
      "Epoch 162/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.0964\n",
      "Epoch 00162: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0254 - mean_absolute_error: 0.0963\n",
      "Epoch 163/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.0989\n",
      "Epoch 00163: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0275 - mean_absolute_error: 0.0989\n",
      "Epoch 164/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.0910\n",
      "Epoch 00164: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0239 - mean_absolute_error: 0.0910\n",
      "Epoch 165/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0242 - mean_absolute_error: 0.0890\n",
      "Epoch 00165: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 215us/step - loss: 0.0242 - mean_absolute_error: 0.0890\n",
      "Epoch 166/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1014\n",
      "Epoch 00166: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0290 - mean_absolute_error: 0.1014\n",
      "Epoch 167/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.0937\n",
      "Epoch 00167: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0251 - mean_absolute_error: 0.0936\n",
      "Epoch 168/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0240 - mean_absolute_error: 0.0910\n",
      "Epoch 00168: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0240 - mean_absolute_error: 0.0909\n",
      "Epoch 169/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0236 - mean_absolute_error: 0.0902\n",
      "Epoch 00169: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0236 - mean_absolute_error: 0.0902\n",
      "Epoch 170/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.0941\n",
      "Epoch 00170: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0245 - mean_absolute_error: 0.0942\n",
      "Epoch 171/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0228 - mean_absolute_error: 0.0883\n",
      "Epoch 00171: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0228 - mean_absolute_error: 0.0883\n",
      "Epoch 172/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0954\n",
      "Epoch 00172: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 213us/step - loss: 0.0249 - mean_absolute_error: 0.0953\n",
      "Epoch 173/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.0942\n",
      "Epoch 00173: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0250 - mean_absolute_error: 0.0941\n",
      "Epoch 174/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.0947\n",
      "Epoch 00174: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0253 - mean_absolute_error: 0.0949\n",
      "Epoch 175/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.0947\n",
      "Epoch 00175: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0252 - mean_absolute_error: 0.0947\n",
      "Epoch 176/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0223 - mean_absolute_error: 0.0854\n",
      "Epoch 00176: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 214us/step - loss: 0.0223 - mean_absolute_error: 0.0854\n",
      "Epoch 177/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.0847\n",
      "Epoch 00177: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 212us/step - loss: 0.0217 - mean_absolute_error: 0.0847\n",
      "Epoch 178/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.0902\n",
      "Epoch 00178: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 218us/step - loss: 0.0239 - mean_absolute_error: 0.0902\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0272 - mean_absolute_error: 0.0988\n",
      "Epoch 00179: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 217us/step - loss: 0.0271 - mean_absolute_error: 0.0987\n",
      "Epoch 180/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0262 - mean_absolute_error: 0.0961\n",
      "Epoch 00180: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 230us/step - loss: 0.0262 - mean_absolute_error: 0.0961\n",
      "Epoch 181/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0236 - mean_absolute_error: 0.0878\n",
      "Epoch 00181: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 231us/step - loss: 0.0236 - mean_absolute_error: 0.0878\n",
      "Epoch 182/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0212 - mean_absolute_error: 0.0812\n",
      "Epoch 00182: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 249us/step - loss: 0.0212 - mean_absolute_error: 0.0813\n",
      "Epoch 183/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0209 - mean_absolute_error: 0.0828\n",
      "Epoch 00183: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 269us/step - loss: 0.0209 - mean_absolute_error: 0.0828\n",
      "Epoch 184/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0230 - mean_absolute_error: 0.0909\n",
      "Epoch 00184: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 235us/step - loss: 0.0230 - mean_absolute_error: 0.0909\n",
      "Epoch 185/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.0977\n",
      "Epoch 00185: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 226us/step - loss: 0.0259 - mean_absolute_error: 0.0976\n",
      "Epoch 186/200\n",
      "22304/22536 [============================>.] - ETA: 0s - loss: 0.0226 - mean_absolute_error: 0.0881\n",
      "Epoch 00186: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 235us/step - loss: 0.0226 - mean_absolute_error: 0.0881\n",
      "Epoch 187/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0224 - mean_absolute_error: 0.0851\n",
      "Epoch 00187: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 222us/step - loss: 0.0224 - mean_absolute_error: 0.0850\n",
      "Epoch 188/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.0913\n",
      "Epoch 00188: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 263us/step - loss: 0.0239 - mean_absolute_error: 0.0912\n",
      "Epoch 189/200\n",
      "22496/22536 [============================>.] - ETA: 0s - loss: 0.0207 - mean_absolute_error: 0.0808\n",
      "Epoch 00189: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 257us/step - loss: 0.0207 - mean_absolute_error: 0.0807\n",
      "Epoch 190/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0213 - mean_absolute_error: 0.0842\n",
      "Epoch 00190: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 230us/step - loss: 0.0213 - mean_absolute_error: 0.0842\n",
      "Epoch 191/200\n",
      "22400/22536 [============================>.] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.0919\n",
      "Epoch 00191: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 228us/step - loss: 0.0237 - mean_absolute_error: 0.0918\n",
      "Epoch 192/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.0953\n",
      "Epoch 00192: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 234us/step - loss: 0.0253 - mean_absolute_error: 0.0956\n",
      "Epoch 193/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.0988\n",
      "Epoch 00193: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 230us/step - loss: 0.0265 - mean_absolute_error: 0.0987\n",
      "Epoch 194/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.0856\n",
      "Epoch 00194: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 230us/step - loss: 0.0232 - mean_absolute_error: 0.0856\n",
      "Epoch 195/200\n",
      "22464/22536 [============================>.] - ETA: 0s - loss: 0.0222 - mean_absolute_error: 0.0866\n",
      "Epoch 00195: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 239us/step - loss: 0.0222 - mean_absolute_error: 0.0866\n",
      "Epoch 196/200\n",
      "22528/22536 [============================>.] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.0799\n",
      "Epoch 00196: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 251us/step - loss: 0.0200 - mean_absolute_error: 0.0798\n",
      "Epoch 197/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0223 - mean_absolute_error: 0.0884\n",
      "Epoch 00197: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 254us/step - loss: 0.0223 - mean_absolute_error: 0.0883\n",
      "Epoch 198/200\n",
      "22336/22536 [============================>.] - ETA: 0s - loss: 0.0245 - mean_absolute_error: 0.0945\n",
      "Epoch 00198: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 6s 252us/step - loss: 0.0245 - mean_absolute_error: 0.0944\n",
      "Epoch 199/200\n",
      "22432/22536 [============================>.] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.0851\n",
      "Epoch 00199: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 239us/step - loss: 0.0217 - mean_absolute_error: 0.0851\n",
      "Epoch 200/200\n",
      "22368/22536 [============================>.] - ETA: 0s - loss: 0.0205 - mean_absolute_error: 0.0819\n",
      "Epoch 00200: saving model to session/Experts_opt1_8_156_relu_1e-06_0.001_mse/7\n",
      "22536/22536 [==============================] - 5s 238us/step - loss: 0.0205 - mean_absolute_error: 0.0819\n"
     ]
    }
   ],
   "source": [
    "experts01.train_new_entities(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using gating network\n",
    "\n",
    "Here we want to train a gating network on a matrix $[S, b]$ where $S$ is the training samples and $b$ is the neural network that performed best on that sample. Then at prediction time, we ask to this gating network to assign to each neural network composing the crowd a probability that it should be selected. We then compute our final prediction :\n",
    "$$\\hat{y} = \\sum_{i=1}^k p_i \\hat{y}_i$$\n",
    "Where $\\hat{y}$ is the final prediction, $\\hat{y}_i$ is the prediction of network $i$ and $p_i$ is the probability that network $i$ should be selected to make the prediction according to the gating network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triggers the construction of the gating network (actual predictions will be computed in next cell for clarity)\n",
    "# Again output is removed because of the verbose of sklearn\n",
    "experts01.predict(X_test_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3791106590400615, 0.04025492235911599)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(experts01.predict(X_test_red), y_test), \\\n",
    "rmse(experts01.predict(X_train_red), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using k-means clustering\n",
    "\n",
    "The previous predictions being unsuccessful, we try another approach. We will cluster the data thanks to a k-mean algorithm (from the library sklearn) and then assign to each cluster the networks that have the smallest average RMSE over the cluster. At prediction time we assign the new sample to the closest cluster and use the related networks for prediction. This may work if data belonging to a given cluster are equally well predicted by a given set of networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts01.predict_kmeans(X_test_red, rmse, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3868712451569133, 0.09750435744976806)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(experts01.predict_kmeans(X_test_red, rmse, 8), y_test), \\\n",
    "rmse(experts01.predict_kmeans(X_train_red, rmse, 8), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion on mixture of experts\n",
    "\n",
    "None of the two algorithms described above were successful. We got good results, but nothing better than the prediction of the crowd. Hence we didn't push this idea any further. Moreover, this system is assumed to work well when the data can be categorized in subsets where some networks may perform better than others. It is not the case here.\n",
    "\n",
    "### Best results :\n",
    "- Using deep learning categorizer : $0.379$\n",
    "- Using clustering : $0.387$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative crowd\n",
    "\n",
    "Let's recall the wild idea we had when using the crowd of neural networks. The idea was to stack a neural network on top of the crowd and train it on the training data where we appended the predictions of the other networks of the crowd.\n",
    "\n",
    "We push this idea further and allow each network of the crowd to access the predictions of the other networks previously added. This will allow the newcomer to known what the others predicted, how wrong they were and to adjust its predictions based on this knownledge.\n",
    "\n",
    "The core code for this part is located in collaborative_crowd.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 16 entities from session/CollabCrowd_2_8_156_relu_1e-06_0.001_mse/16\n"
     ]
    }
   ],
   "source": [
    "cc1 = cc.CollaborativeCrowd(X_train_red, y_train, \"CollabCrowd_2\", nb_layers = 8, \\\n",
    "                      nb_neurons=156, regularization_factor=1e-6, validation_split = 0)\n",
    "cc1.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1.train_new_entities(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last entity RMSE : 0.3812139181354184\n",
      "Last 5 entities RMSE : 0.3586411031403149\n",
      "Average RMSE : 0.3489545411525422\n"
     ]
    }
   ],
   "source": [
    "last, avg, last5 = cc1.predict(X_test_red)\n",
    "print(\"Last entity RMSE : {}\".format(rmse(last, y_test)))\n",
    "print(\"Last 5 entities RMSE : {}\".format(rmse(last5, y_test)))\n",
    "print(\"Average RMSE : {}\".format(rmse(avg, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of collaborative crowd\n",
    "\n",
    "The collaborative crowd brought better results, we can observe that the newcomers indeed have an error way smaller than the first networks appended to the crowd.\n",
    "\n",
    "Above you can see that the last network performed with a RMSE of $0.38$ over the test set. The new average error has dropped by around $0.004$ compared to the standard crowd which represents $1\\%$ of the error, which is a quite tiny improvement.\n",
    "\n",
    "## Final structure :\n",
    "\n",
    "- Each network composing the crowd is an instance of the optimized version found in the first part and has been trained on both the training data and the predictions of the other networks composing the crowd.\n",
    "- 16 entities (more will bring better results but also increase the prediction time).\n",
    "- Collaborative crowd error : $0.349$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperCrowd\n",
    "\n",
    "The super crowd has been made with the idea that different estimators may be combined to offer even better estimations. The idea behind this is to vary the sources of biases. Two systems may have the same bias, however it will not be distributed the same way on all the samples. Consequently some biases may balance each others on some samples and reduce the error.\n",
    "\n",
    "If we combine two models with similar RMSE, the output of the supercrowd prediction will perform at least as well as them and there's high chances that it performs better.\n",
    "\n",
    "The class is following the Composite design pattern. Each element composing the SuperCrowd should have a predict(matix) method in order for the algorithm to work.\n",
    "\n",
    "The core code of this class is located in supercrowd.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 16 entities from session/CollabCrowd_2_8_156_relu_1e-06_0.001_mse/16\n",
      "Recovered 16 entities from session/Crowd_opt_2_8_156_relu_1e-06_0.001_mse/16\n"
     ]
    }
   ],
   "source": [
    "supercrowd = sc.SuperCrowd()\n",
    "\n",
    "cc1 = cc.CollaborativeCrowd(X_train_red, y_train, \"CollabCrowd_2\", nb_layers = 8, \\\n",
    "                      nb_neurons=156, regularization_factor=1e-6, validation_split = 0)\n",
    "cc1.restore()\n",
    "\n",
    "crowd_opt2 = crowd.Crowd(X_train_red, y_train, \"Crowd_opt_2\", nb_layers = 8, \\\n",
    "                      nb_neurons=156, regularization_factor=1e-6, validation_split = 0)\n",
    "crowd_opt2.restore()\n",
    "\n",
    "supercrowd.append_crowd(cc1)\n",
    "supercrowd.append_crowd(crowd_opt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3419144346517784"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(supercrowd.predict(X_test_red), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The accuracy of the prediction has been increased. However, note that the computation time is now the sum of all the computation times of all the crowds composing the supercrowd. However we remark that we reduced our RMSE of $0.008$ which is still a good amelioration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout & max-norm constraint\n",
    "\n",
    "Dropout layers combined with max-norm constraints are referenced in the litterature as a good way to avoid overfitting (N. Srebro and A. Shraibman _Rank, trace-norm and max-norm_). Since we remarked some overfit during the training of our neural network (a training error less that $0.1$ while the test error is around $0.4$ ) we wanted to see if those techniques were worth bringing in the equation. \n",
    "\n",
    "We hence execute a bunch of cross-validations on the input dropout percentage, the inter-layer dropout percentage and the max-norm value to see if we can have better results using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_dropout_maxnorm(df_in, df_hidden, max_norm):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dropout(df_in))\n",
    "    for i in range(8):\n",
    "        model.add(layers.Dense(156, activation='relu', \\\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(1e-6), \\\n",
    "                               kernel_constraint=MaxNorm(max_norm)))\n",
    "        model.add(layers.Dropout(df_hidden))\n",
    "    # Last layer represent the electromagnetic shielding, our prediction\n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                  loss='mse',\n",
    "                  # Note that the accuracy metric is useless but it doesn't compile when trying to use RMSE.\n",
    "                  metrics=['mae'])\n",
    "    EPOCHS = 200\n",
    "    BATCH_SIZE = 32\n",
    "    VALIDATION_SPLIT = 0.1\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = model.fit(X_train_red, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = VALIDATION_SPLIT, \\\n",
    "              callbacks=[early_stop])\n",
    "    plot_history(history)\n",
    "\n",
    "    result = model.predict(X_test_red, batch_size=32)\n",
    "    error = rmse(result, y_test)\n",
    "    print(\"Error : {}\".format(error))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20282/20282 [==============================] - 8s 391us/step - loss: 22.3194 - mean_absolute_error: 2.9690 - val_loss: 5.6041 - val_mean_absolute_error: 1.7566\n",
      "Epoch 2/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 4.8415 - mean_absolute_error: 1.6130 - val_loss: 3.1017 - val_mean_absolute_error: 1.2791\n",
      "Epoch 3/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 1.7316 - mean_absolute_error: 0.9382 - val_loss: 1.2099 - val_mean_absolute_error: 0.8174\n",
      "Epoch 4/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.5914 - mean_absolute_error: 0.5662 - val_loss: 0.7247 - val_mean_absolute_error: 0.5963\n",
      "Epoch 5/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.4205 - mean_absolute_error: 0.4795 - val_loss: 0.7767 - val_mean_absolute_error: 0.6629\n",
      "Epoch 6/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.3863 - mean_absolute_error: 0.4604 - val_loss: 0.6166 - val_mean_absolute_error: 0.5661\n",
      "Epoch 7/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.4219 - mean_absolute_error: 0.4842 - val_loss: 0.5453 - val_mean_absolute_error: 0.5326\n",
      "Epoch 8/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.4008 - mean_absolute_error: 0.4638 - val_loss: 0.4882 - val_mean_absolute_error: 0.4904\n",
      "Epoch 9/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.3584 - mean_absolute_error: 0.4413 - val_loss: 0.4728 - val_mean_absolute_error: 0.4865\n",
      "Epoch 10/200\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.3545 - mean_absolute_error: 0.4329 - val_loss: 0.6818 - val_mean_absolute_error: 0.6508\n",
      "Epoch 11/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.3274 - mean_absolute_error: 0.4134 - val_loss: 0.6202 - val_mean_absolute_error: 0.5993\n",
      "Epoch 12/200\n",
      "20282/20282 [==============================] - 6s 277us/step - loss: 0.3830 - mean_absolute_error: 0.4449 - val_loss: 0.6555 - val_mean_absolute_error: 0.5970\n",
      "Epoch 13/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.3880 - mean_absolute_error: 0.4556 - val_loss: 0.7467 - val_mean_absolute_error: 0.6630\n",
      "Epoch 14/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.3550 - mean_absolute_error: 0.4276 - val_loss: 0.5045 - val_mean_absolute_error: 0.5026\n",
      "Epoch 15/200\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.3349 - mean_absolute_error: 0.4140 - val_loss: 0.4870 - val_mean_absolute_error: 0.5025\n",
      "Epoch 16/200\n",
      "20282/20282 [==============================] - 6s 276us/step - loss: 0.3393 - mean_absolute_error: 0.4173 - val_loss: 0.5231 - val_mean_absolute_error: 0.5248\n",
      "Epoch 17/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2932 - mean_absolute_error: 0.3965 - val_loss: 0.4806 - val_mean_absolute_error: 0.4655\n",
      "Epoch 18/200\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.3108 - mean_absolute_error: 0.4024 - val_loss: 0.4478 - val_mean_absolute_error: 0.4852\n",
      "Epoch 19/200\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.2943 - mean_absolute_error: 0.3961 - val_loss: 0.4855 - val_mean_absolute_error: 0.4663\n",
      "Epoch 20/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.3049 - mean_absolute_error: 0.4023 - val_loss: 0.4311 - val_mean_absolute_error: 0.4647\n",
      "Epoch 21/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.2827 - mean_absolute_error: 0.3869 - val_loss: 0.4457 - val_mean_absolute_error: 0.4776\n",
      "Epoch 22/200\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.2903 - mean_absolute_error: 0.3920 - val_loss: 0.4429 - val_mean_absolute_error: 0.4628\n",
      "Epoch 23/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.2561 - mean_absolute_error: 0.3680 - val_loss: 0.3451 - val_mean_absolute_error: 0.4149\n",
      "Epoch 24/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2740 - mean_absolute_error: 0.3820 - val_loss: 0.4230 - val_mean_absolute_error: 0.4423\n",
      "Epoch 25/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.2895 - mean_absolute_error: 0.3928 - val_loss: 0.4481 - val_mean_absolute_error: 0.4585\n",
      "Epoch 26/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.2762 - mean_absolute_error: 0.3836 - val_loss: 0.4737 - val_mean_absolute_error: 0.5016\n",
      "Epoch 27/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.2837 - mean_absolute_error: 0.3900 - val_loss: 0.3833 - val_mean_absolute_error: 0.4325\n",
      "Epoch 28/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.2424 - mean_absolute_error: 0.3524 - val_loss: 0.4124 - val_mean_absolute_error: 0.4527\n",
      "Epoch 29/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.2724 - mean_absolute_error: 0.3718 - val_loss: 0.3792 - val_mean_absolute_error: 0.4325\n",
      "Epoch 30/200\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.2508 - mean_absolute_error: 0.3601 - val_loss: 0.3920 - val_mean_absolute_error: 0.4499\n",
      "Epoch 31/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2224 - mean_absolute_error: 0.3354 - val_loss: 0.3775 - val_mean_absolute_error: 0.4387\n",
      "Epoch 32/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2234 - mean_absolute_error: 0.3369 - val_loss: 0.4510 - val_mean_absolute_error: 0.4792\n",
      "Epoch 33/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2985 - mean_absolute_error: 0.3888 - val_loss: 0.4369 - val_mean_absolute_error: 0.4557\n",
      "Epoch 34/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.3298 - mean_absolute_error: 0.4159 - val_loss: 0.3842 - val_mean_absolute_error: 0.4381\n",
      "Epoch 35/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.2411 - mean_absolute_error: 0.3513 - val_loss: 0.3633 - val_mean_absolute_error: 0.4236\n",
      "Epoch 36/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2341 - mean_absolute_error: 0.3467 - val_loss: 0.5679 - val_mean_absolute_error: 0.5637\n",
      "Epoch 37/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2786 - mean_absolute_error: 0.3750 - val_loss: 0.4673 - val_mean_absolute_error: 0.4755\n",
      "Epoch 38/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2461 - mean_absolute_error: 0.3540 - val_loss: 0.3428 - val_mean_absolute_error: 0.4014\n",
      "Epoch 39/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.1823 - mean_absolute_error: 0.3061 - val_loss: 0.3114 - val_mean_absolute_error: 0.3728\n",
      "Epoch 40/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.1869 - mean_absolute_error: 0.3108 - val_loss: 0.3887 - val_mean_absolute_error: 0.4327\n",
      "Epoch 41/200\n",
      "20282/20282 [==============================] - 5s 242us/step - loss: 0.2630 - mean_absolute_error: 0.3643 - val_loss: 0.4292 - val_mean_absolute_error: 0.4470\n",
      "Epoch 42/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2597 - mean_absolute_error: 0.3658 - val_loss: 0.3807 - val_mean_absolute_error: 0.4302\n",
      "Epoch 43/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2085 - mean_absolute_error: 0.3270 - val_loss: 0.3862 - val_mean_absolute_error: 0.4244\n",
      "Epoch 44/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.2175 - mean_absolute_error: 0.3362 - val_loss: 0.3898 - val_mean_absolute_error: 0.4445\n",
      "Epoch 45/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.2030 - mean_absolute_error: 0.3211 - val_loss: 0.3551 - val_mean_absolute_error: 0.4045\n",
      "Epoch 46/200\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.2219 - mean_absolute_error: 0.3354 - val_loss: 0.4526 - val_mean_absolute_error: 0.4524\n",
      "Epoch 47/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.2788 - mean_absolute_error: 0.3797 - val_loss: 0.4744 - val_mean_absolute_error: 0.4744\n",
      "Epoch 48/200\n",
      "20282/20282 [==============================] - 6s 278us/step - loss: 0.3689 - mean_absolute_error: 0.4252 - val_loss: 0.4055 - val_mean_absolute_error: 0.4355\n",
      "Epoch 49/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.2259 - mean_absolute_error: 0.3343 - val_loss: 0.3582 - val_mean_absolute_error: 0.3903\n",
      "Epoch 50/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.1649 - mean_absolute_error: 0.2933 - val_loss: 0.3256 - val_mean_absolute_error: 0.3836\n",
      "Epoch 51/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.1882 - mean_absolute_error: 0.3114 - val_loss: 0.4093 - val_mean_absolute_error: 0.4464\n",
      "Epoch 52/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2405 - mean_absolute_error: 0.3490 - val_loss: 0.4126 - val_mean_absolute_error: 0.4765\n",
      "Epoch 53/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.2823 - mean_absolute_error: 0.3694 - val_loss: 0.4507 - val_mean_absolute_error: 0.4842\n",
      "Epoch 54/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.2271 - mean_absolute_error: 0.3429 - val_loss: 0.3469 - val_mean_absolute_error: 0.3932\n",
      "Epoch 55/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.1974 - mean_absolute_error: 0.3119 - val_loss: 0.3715 - val_mean_absolute_error: 0.4055\n",
      "Epoch 56/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.2190 - mean_absolute_error: 0.3364 - val_loss: 0.4039 - val_mean_absolute_error: 0.4357\n",
      "Epoch 57/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.2596 - mean_absolute_error: 0.3658 - val_loss: 0.4937 - val_mean_absolute_error: 0.4900\n",
      "Epoch 58/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.2866 - mean_absolute_error: 0.3810 - val_loss: 0.4002 - val_mean_absolute_error: 0.4391\n",
      "Epoch 59/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.1918 - mean_absolute_error: 0.3162 - val_loss: 0.3192 - val_mean_absolute_error: 0.3895\n",
      "Error : 0.5561591492086637\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20282/20282 [==============================] - 7s 360us/step - loss: 21.2156 - mean_absolute_error: 2.8867 - val_loss: 6.2006 - val_mean_absolute_error: 1.8325\n",
      "Epoch 2/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 4.6005 - mean_absolute_error: 1.5311 - val_loss: 2.9198 - val_mean_absolute_error: 1.2813\n",
      "Epoch 3/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 1.7531 - mean_absolute_error: 0.9348 - val_loss: 1.2497 - val_mean_absolute_error: 0.8227\n",
      "Epoch 4/200\n",
      "20282/20282 [==============================] - 6s 274us/step - loss: 0.6058 - mean_absolute_error: 0.5692 - val_loss: 0.6950 - val_mean_absolute_error: 0.5860\n",
      "Epoch 5/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.3780 - mean_absolute_error: 0.4536 - val_loss: 0.6637 - val_mean_absolute_error: 0.5718\n",
      "Epoch 6/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.3702 - mean_absolute_error: 0.4556 - val_loss: 0.6514 - val_mean_absolute_error: 0.5874\n",
      "Epoch 7/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.3800 - mean_absolute_error: 0.4490 - val_loss: 0.5123 - val_mean_absolute_error: 0.5073\n",
      "Epoch 8/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.3478 - mean_absolute_error: 0.4375 - val_loss: 0.5671 - val_mean_absolute_error: 0.5672\n",
      "Epoch 9/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.3701 - mean_absolute_error: 0.4510 - val_loss: 0.5039 - val_mean_absolute_error: 0.5082\n",
      "Epoch 10/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.3426 - mean_absolute_error: 0.4195 - val_loss: 0.6372 - val_mean_absolute_error: 0.6042\n",
      "Epoch 11/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.3711 - mean_absolute_error: 0.4533 - val_loss: 0.4921 - val_mean_absolute_error: 0.5072\n",
      "Epoch 12/200\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.3084 - mean_absolute_error: 0.3949 - val_loss: 0.4243 - val_mean_absolute_error: 0.4532\n",
      "Epoch 13/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.2936 - mean_absolute_error: 0.3948 - val_loss: 0.5776 - val_mean_absolute_error: 0.5866\n",
      "Epoch 14/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.2571 - mean_absolute_error: 0.3674 - val_loss: 0.4159 - val_mean_absolute_error: 0.4549\n",
      "Epoch 15/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.2424 - mean_absolute_error: 0.3517 - val_loss: 0.3931 - val_mean_absolute_error: 0.4336\n",
      "Epoch 16/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.2322 - mean_absolute_error: 0.3503 - val_loss: 0.4363 - val_mean_absolute_error: 0.4648\n",
      "Epoch 17/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.2741 - mean_absolute_error: 0.3805 - val_loss: 0.6293 - val_mean_absolute_error: 0.6236\n",
      "Epoch 18/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.2393 - mean_absolute_error: 0.3551 - val_loss: 0.5795 - val_mean_absolute_error: 0.5955\n",
      "Epoch 19/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.2456 - mean_absolute_error: 0.3620 - val_loss: 0.4118 - val_mean_absolute_error: 0.4665\n",
      "Epoch 20/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.2720 - mean_absolute_error: 0.3871 - val_loss: 0.5156 - val_mean_absolute_error: 0.5309\n",
      "Epoch 21/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.2569 - mean_absolute_error: 0.3678 - val_loss: 0.4457 - val_mean_absolute_error: 0.4829\n",
      "Epoch 22/200\n",
      "20282/20282 [==============================] - 6s 279us/step - loss: 0.2623 - mean_absolute_error: 0.3707 - val_loss: 0.5129 - val_mean_absolute_error: 0.5442\n",
      "Epoch 23/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2895 - mean_absolute_error: 0.3733 - val_loss: 0.3855 - val_mean_absolute_error: 0.4387\n",
      "Epoch 24/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2253 - mean_absolute_error: 0.3372 - val_loss: 0.4599 - val_mean_absolute_error: 0.5060\n",
      "Epoch 25/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2116 - mean_absolute_error: 0.3323 - val_loss: 0.3484 - val_mean_absolute_error: 0.4095\n",
      "Epoch 26/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.2291 - mean_absolute_error: 0.3283 - val_loss: 0.4151 - val_mean_absolute_error: 0.4862\n",
      "Epoch 27/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.2078 - mean_absolute_error: 0.3277 - val_loss: 0.3162 - val_mean_absolute_error: 0.3854\n",
      "Epoch 28/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.1967 - mean_absolute_error: 0.3146 - val_loss: 0.3746 - val_mean_absolute_error: 0.4222\n",
      "Epoch 29/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2257 - mean_absolute_error: 0.3395 - val_loss: 0.3765 - val_mean_absolute_error: 0.4414\n",
      "Epoch 30/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.2185 - mean_absolute_error: 0.3339 - val_loss: 0.3936 - val_mean_absolute_error: 0.4417\n",
      "Epoch 31/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.1933 - mean_absolute_error: 0.3217 - val_loss: 0.3406 - val_mean_absolute_error: 0.4054\n",
      "Epoch 32/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.1783 - mean_absolute_error: 0.3025 - val_loss: 0.3625 - val_mean_absolute_error: 0.4082\n",
      "Epoch 33/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.1760 - mean_absolute_error: 0.3032 - val_loss: 0.3224 - val_mean_absolute_error: 0.3957\n",
      "Epoch 34/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.1979 - mean_absolute_error: 0.3181 - val_loss: 0.3967 - val_mean_absolute_error: 0.4554\n",
      "Epoch 35/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.1991 - mean_absolute_error: 0.3245 - val_loss: 0.3179 - val_mean_absolute_error: 0.3862\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.1765 - mean_absolute_error: 0.3040 - val_loss: 0.3359 - val_mean_absolute_error: 0.4139\n",
      "Epoch 37/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.1621 - mean_absolute_error: 0.2900 - val_loss: 0.3868 - val_mean_absolute_error: 0.4524\n",
      "Epoch 38/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.1863 - mean_absolute_error: 0.3128 - val_loss: 0.3506 - val_mean_absolute_error: 0.4055\n",
      "Epoch 39/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.2018 - mean_absolute_error: 0.3279 - val_loss: 0.4240 - val_mean_absolute_error: 0.4825\n",
      "Epoch 40/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.1903 - mean_absolute_error: 0.3156 - val_loss: 0.3243 - val_mean_absolute_error: 0.4010\n",
      "Epoch 41/200\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.1736 - mean_absolute_error: 0.3020 - val_loss: 0.4404 - val_mean_absolute_error: 0.4316\n",
      "Epoch 42/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.1981 - mean_absolute_error: 0.3091 - val_loss: 0.3897 - val_mean_absolute_error: 0.4483\n",
      "Epoch 43/200\n",
      "20282/20282 [==============================] - 5s 242us/step - loss: 0.1916 - mean_absolute_error: 0.3045 - val_loss: 0.3041 - val_mean_absolute_error: 0.3685\n",
      "Epoch 44/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.1776 - mean_absolute_error: 0.2988 - val_loss: 0.2848 - val_mean_absolute_error: 0.3713\n",
      "Epoch 45/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.1442 - mean_absolute_error: 0.2734 - val_loss: 0.3467 - val_mean_absolute_error: 0.4339\n",
      "Epoch 46/200\n",
      "20282/20282 [==============================] - 5s 242us/step - loss: 0.1448 - mean_absolute_error: 0.2711 - val_loss: 0.3566 - val_mean_absolute_error: 0.4107\n",
      "Epoch 47/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.1826 - mean_absolute_error: 0.3071 - val_loss: 0.3486 - val_mean_absolute_error: 0.4099\n",
      "Epoch 48/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.2128 - mean_absolute_error: 0.3269 - val_loss: 0.4179 - val_mean_absolute_error: 0.4698\n",
      "Epoch 49/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.1863 - mean_absolute_error: 0.3036 - val_loss: 0.3329 - val_mean_absolute_error: 0.3993\n",
      "Epoch 50/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.1617 - mean_absolute_error: 0.2879 - val_loss: 0.3184 - val_mean_absolute_error: 0.4063\n",
      "Epoch 51/200\n",
      "20282/20282 [==============================] - 6s 283us/step - loss: 0.1695 - mean_absolute_error: 0.2912 - val_loss: 0.3514 - val_mean_absolute_error: 0.4233\n",
      "Epoch 52/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.1621 - mean_absolute_error: 0.2929 - val_loss: 0.2825 - val_mean_absolute_error: 0.3655\n",
      "Epoch 53/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.1374 - mean_absolute_error: 0.2673 - val_loss: 0.2936 - val_mean_absolute_error: 0.3687\n",
      "Epoch 54/200\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.2035 - mean_absolute_error: 0.3205 - val_loss: 0.3263 - val_mean_absolute_error: 0.3872\n",
      "Epoch 55/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.1616 - mean_absolute_error: 0.2864 - val_loss: 0.3018 - val_mean_absolute_error: 0.3663\n",
      "Epoch 56/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.1519 - mean_absolute_error: 0.2785 - val_loss: 0.3382 - val_mean_absolute_error: 0.4082\n",
      "Epoch 57/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.1883 - mean_absolute_error: 0.3105 - val_loss: 0.3465 - val_mean_absolute_error: 0.3941\n",
      "Epoch 58/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.1657 - mean_absolute_error: 0.2918 - val_loss: 0.3346 - val_mean_absolute_error: 0.4042\n",
      "Epoch 59/200\n",
      "20282/20282 [==============================] - 6s 297us/step - loss: 0.1641 - mean_absolute_error: 0.2877 - val_loss: 0.3169 - val_mean_absolute_error: 0.3766\n",
      "Epoch 60/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.1656 - mean_absolute_error: 0.2831 - val_loss: 0.3267 - val_mean_absolute_error: 0.3819\n",
      "Epoch 61/200\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.1548 - mean_absolute_error: 0.2795 - val_loss: 0.3381 - val_mean_absolute_error: 0.4035\n",
      "Epoch 62/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.1478 - mean_absolute_error: 0.2738 - val_loss: 0.3229 - val_mean_absolute_error: 0.3859\n",
      "Epoch 63/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.1735 - mean_absolute_error: 0.2906 - val_loss: 0.3588 - val_mean_absolute_error: 0.3998\n",
      "Epoch 64/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.1703 - mean_absolute_error: 0.2903 - val_loss: 0.3591 - val_mean_absolute_error: 0.4033\n",
      "Epoch 65/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.1972 - mean_absolute_error: 0.3139 - val_loss: 0.3743 - val_mean_absolute_error: 0.4097\n",
      "Epoch 66/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.1612 - mean_absolute_error: 0.2914 - val_loss: 0.3613 - val_mean_absolute_error: 0.4018\n",
      "Epoch 67/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.1435 - mean_absolute_error: 0.2697 - val_loss: 0.3304 - val_mean_absolute_error: 0.3829\n",
      "Epoch 68/200\n",
      "20282/20282 [==============================] - 5s 262us/step - loss: 0.1309 - mean_absolute_error: 0.2538 - val_loss: 0.3151 - val_mean_absolute_error: 0.3684\n",
      "Epoch 69/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.1369 - mean_absolute_error: 0.2608 - val_loss: 0.3170 - val_mean_absolute_error: 0.3836\n",
      "Epoch 70/200\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.1588 - mean_absolute_error: 0.2792 - val_loss: 0.3358 - val_mean_absolute_error: 0.3773\n",
      "Epoch 71/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.1602 - mean_absolute_error: 0.2786 - val_loss: 0.3414 - val_mean_absolute_error: 0.3980\n",
      "Epoch 72/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.2189 - mean_absolute_error: 0.3279 - val_loss: 0.3885 - val_mean_absolute_error: 0.4298\n",
      "Error : 0.622009010827703\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20282/20282 [==============================] - 8s 394us/step - loss: 28.9467 - mean_absolute_error: 3.2526 - val_loss: 6.1414 - val_mean_absolute_error: 1.8644\n",
      "Epoch 2/200\n",
      "20282/20282 [==============================] - 5s 269us/step - loss: 5.4745 - mean_absolute_error: 1.6915 - val_loss: 3.7226 - val_mean_absolute_error: 1.3193\n",
      "Epoch 3/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 2.0382 - mean_absolute_error: 1.0041 - val_loss: 1.2659 - val_mean_absolute_error: 0.8159\n",
      "Epoch 4/200\n",
      "20282/20282 [==============================] - 5s 270us/step - loss: 0.6013 - mean_absolute_error: 0.5725 - val_loss: 0.9081 - val_mean_absolute_error: 0.6986\n",
      "Epoch 5/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.4195 - mean_absolute_error: 0.4872 - val_loss: 0.8995 - val_mean_absolute_error: 0.7258\n",
      "Epoch 6/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.4230 - mean_absolute_error: 0.4886 - val_loss: 0.5964 - val_mean_absolute_error: 0.5440\n",
      "Epoch 7/200\n",
      "20282/20282 [==============================] - 6s 277us/step - loss: 0.3909 - mean_absolute_error: 0.4634 - val_loss: 0.6506 - val_mean_absolute_error: 0.5691\n",
      "Epoch 8/200\n",
      "20282/20282 [==============================] - 5s 269us/step - loss: 0.3742 - mean_absolute_error: 0.4470 - val_loss: 0.5451 - val_mean_absolute_error: 0.5256\n",
      "Epoch 9/200\n",
      "20282/20282 [==============================] - 6s 296us/step - loss: 0.4126 - mean_absolute_error: 0.4684 - val_loss: 0.5544 - val_mean_absolute_error: 0.5309\n",
      "Epoch 10/200\n",
      "20282/20282 [==============================] - 6s 292us/step - loss: 0.3757 - mean_absolute_error: 0.4446 - val_loss: 0.5352 - val_mean_absolute_error: 0.5180\n",
      "Epoch 11/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.3593 - mean_absolute_error: 0.4342 - val_loss: 0.4922 - val_mean_absolute_error: 0.5043\n",
      "Epoch 12/200\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.3248 - mean_absolute_error: 0.4131 - val_loss: 0.4664 - val_mean_absolute_error: 0.4775\n",
      "Epoch 13/200\n",
      "20282/20282 [==============================] - 7s 321us/step - loss: 0.3321 - mean_absolute_error: 0.4172 - val_loss: 0.5946 - val_mean_absolute_error: 0.5492\n",
      "Epoch 14/200\n",
      "20282/20282 [==============================] - 6s 293us/step - loss: 0.3348 - mean_absolute_error: 0.4229 - val_loss: 0.4988 - val_mean_absolute_error: 0.4918\n",
      "Epoch 15/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.3016 - mean_absolute_error: 0.3902 - val_loss: 0.4982 - val_mean_absolute_error: 0.5159\n",
      "Epoch 16/200\n",
      "20282/20282 [==============================] - 6s 281us/step - loss: 0.2424 - mean_absolute_error: 0.3545 - val_loss: 0.3572 - val_mean_absolute_error: 0.4112\n",
      "Epoch 17/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.2116 - mean_absolute_error: 0.3332 - val_loss: 0.3525 - val_mean_absolute_error: 0.4079\n",
      "Epoch 18/200\n",
      "20282/20282 [==============================] - 6s 320us/step - loss: 0.2508 - mean_absolute_error: 0.3678 - val_loss: 0.4130 - val_mean_absolute_error: 0.4652\n",
      "Epoch 19/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.2064 - mean_absolute_error: 0.3289 - val_loss: 0.3570 - val_mean_absolute_error: 0.4210\n",
      "Epoch 20/200\n",
      "20282/20282 [==============================] - 6s 295us/step - loss: 0.2174 - mean_absolute_error: 0.3450 - val_loss: 0.3591 - val_mean_absolute_error: 0.4249\n",
      "Epoch 21/200\n",
      "20282/20282 [==============================] - 6s 283us/step - loss: 0.2103 - mean_absolute_error: 0.3375 - val_loss: 0.3510 - val_mean_absolute_error: 0.4234\n",
      "Epoch 22/200\n",
      "20282/20282 [==============================] - 5s 269us/step - loss: 0.1806 - mean_absolute_error: 0.3116 - val_loss: 0.3187 - val_mean_absolute_error: 0.4027\n",
      "Epoch 23/200\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.1934 - mean_absolute_error: 0.3205 - val_loss: 0.3358 - val_mean_absolute_error: 0.4169\n",
      "Epoch 24/200\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.1946 - mean_absolute_error: 0.3247 - val_loss: 0.3410 - val_mean_absolute_error: 0.4257\n",
      "Epoch 25/200\n",
      "20282/20282 [==============================] - 5s 271us/step - loss: 0.1642 - mean_absolute_error: 0.2961 - val_loss: 0.3901 - val_mean_absolute_error: 0.4589\n",
      "Epoch 26/200\n",
      "20282/20282 [==============================] - 6s 275us/step - loss: 0.1883 - mean_absolute_error: 0.3163 - val_loss: 0.3091 - val_mean_absolute_error: 0.3900\n",
      "Epoch 27/200\n",
      "20282/20282 [==============================] - 6s 280us/step - loss: 0.1870 - mean_absolute_error: 0.3144 - val_loss: 0.3410 - val_mean_absolute_error: 0.4143\n",
      "Epoch 28/200\n",
      "20282/20282 [==============================] - 6s 278us/step - loss: 0.1796 - mean_absolute_error: 0.3074 - val_loss: 0.3888 - val_mean_absolute_error: 0.4757\n",
      "Epoch 29/200\n",
      "20282/20282 [==============================] - 6s 274us/step - loss: 0.1611 - mean_absolute_error: 0.2935 - val_loss: 0.3992 - val_mean_absolute_error: 0.4723\n",
      "Epoch 30/200\n",
      "20282/20282 [==============================] - 6s 278us/step - loss: 0.1808 - mean_absolute_error: 0.3060 - val_loss: 0.3064 - val_mean_absolute_error: 0.3885\n",
      "Epoch 31/200\n",
      "20282/20282 [==============================] - 6s 302us/step - loss: 0.1799 - mean_absolute_error: 0.3056 - val_loss: 0.2841 - val_mean_absolute_error: 0.3721\n",
      "Epoch 32/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.1382 - mean_absolute_error: 0.2687 - val_loss: 0.2640 - val_mean_absolute_error: 0.3592\n",
      "Epoch 33/200\n",
      "20282/20282 [==============================] - 6s 282us/step - loss: 0.1418 - mean_absolute_error: 0.2710 - val_loss: 0.2957 - val_mean_absolute_error: 0.3666\n",
      "Epoch 34/200\n",
      "20282/20282 [==============================] - 6s 301us/step - loss: 0.1660 - mean_absolute_error: 0.2939 - val_loss: 0.2697 - val_mean_absolute_error: 0.3688\n",
      "Epoch 35/200\n",
      "20282/20282 [==============================] - 5s 270us/step - loss: 0.1346 - mean_absolute_error: 0.2626 - val_loss: 0.2866 - val_mean_absolute_error: 0.3656\n",
      "Epoch 36/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.1496 - mean_absolute_error: 0.2792 - val_loss: 0.3001 - val_mean_absolute_error: 0.3903\n",
      "Epoch 37/200\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.1613 - mean_absolute_error: 0.2922 - val_loss: 0.2789 - val_mean_absolute_error: 0.3731\n",
      "Epoch 38/200\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.1536 - mean_absolute_error: 0.2851 - val_loss: 0.3140 - val_mean_absolute_error: 0.3992\n",
      "Epoch 39/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.1334 - mean_absolute_error: 0.2615 - val_loss: 0.2794 - val_mean_absolute_error: 0.3658\n",
      "Epoch 40/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.1609 - mean_absolute_error: 0.2798 - val_loss: 0.2799 - val_mean_absolute_error: 0.3677\n",
      "Epoch 41/200\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.1573 - mean_absolute_error: 0.2823 - val_loss: 0.2758 - val_mean_absolute_error: 0.3609\n",
      "Epoch 42/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.1309 - mean_absolute_error: 0.2619 - val_loss: 0.2827 - val_mean_absolute_error: 0.3529\n",
      "Epoch 43/200\n",
      "20282/20282 [==============================] - 5s 270us/step - loss: 0.1247 - mean_absolute_error: 0.2550 - val_loss: 0.2846 - val_mean_absolute_error: 0.3729\n",
      "Epoch 44/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.1291 - mean_absolute_error: 0.2607 - val_loss: 0.2633 - val_mean_absolute_error: 0.3509\n",
      "Epoch 45/200\n",
      "20282/20282 [==============================] - 6s 291us/step - loss: 0.1269 - mean_absolute_error: 0.2552 - val_loss: 0.2988 - val_mean_absolute_error: 0.3786\n",
      "Epoch 46/200\n",
      "20282/20282 [==============================] - 7s 331us/step - loss: 0.1364 - mean_absolute_error: 0.2655 - val_loss: 0.2812 - val_mean_absolute_error: 0.3657\n",
      "Epoch 47/200\n",
      "20282/20282 [==============================] - 6s 320us/step - loss: 0.1438 - mean_absolute_error: 0.2694 - val_loss: 0.2996 - val_mean_absolute_error: 0.3804\n",
      "Epoch 48/200\n",
      "20282/20282 [==============================] - 6s 289us/step - loss: 0.1402 - mean_absolute_error: 0.2687 - val_loss: 0.2946 - val_mean_absolute_error: 0.3762\n",
      "Epoch 49/200\n",
      "20282/20282 [==============================] - 6s 276us/step - loss: 0.1235 - mean_absolute_error: 0.2553 - val_loss: 0.3520 - val_mean_absolute_error: 0.4324\n",
      "Epoch 50/200\n",
      "20282/20282 [==============================] - 5s 262us/step - loss: 0.1353 - mean_absolute_error: 0.2647 - val_loss: 0.2853 - val_mean_absolute_error: 0.3672\n",
      "Epoch 51/200\n",
      "20282/20282 [==============================] - 6s 284us/step - loss: 0.1341 - mean_absolute_error: 0.2652 - val_loss: 0.2826 - val_mean_absolute_error: 0.3578\n",
      "Epoch 52/200\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.1255 - mean_absolute_error: 0.2573 - val_loss: 0.3049 - val_mean_absolute_error: 0.3792\n",
      "Epoch 53/200\n",
      "20282/20282 [==============================] - 6s 278us/step - loss: 0.1265 - mean_absolute_error: 0.2552 - val_loss: 0.2794 - val_mean_absolute_error: 0.3575\n",
      "Epoch 54/200\n",
      "20282/20282 [==============================] - 6s 280us/step - loss: 0.1292 - mean_absolute_error: 0.2574 - val_loss: 0.3114 - val_mean_absolute_error: 0.3666\n",
      "Epoch 55/200\n",
      "20282/20282 [==============================] - 5s 270us/step - loss: 0.1310 - mean_absolute_error: 0.2540 - val_loss: 0.2935 - val_mean_absolute_error: 0.3689\n",
      "Epoch 56/200\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.1366 - mean_absolute_error: 0.2642 - val_loss: 0.3205 - val_mean_absolute_error: 0.3867\n",
      "Epoch 57/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.1393 - mean_absolute_error: 0.2652 - val_loss: 0.2977 - val_mean_absolute_error: 0.3723\n",
      "Epoch 58/200\n",
      "20282/20282 [==============================] - 6s 319us/step - loss: 0.1188 - mean_absolute_error: 0.2480 - val_loss: 0.3001 - val_mean_absolute_error: 0.3584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "20282/20282 [==============================] - 6s 284us/step - loss: 0.1247 - mean_absolute_error: 0.2517 - val_loss: 0.2940 - val_mean_absolute_error: 0.3887\n",
      "Epoch 60/200\n",
      "20282/20282 [==============================] - 7s 330us/step - loss: 0.1095 - mean_absolute_error: 0.2395 - val_loss: 0.2755 - val_mean_absolute_error: 0.3795\n",
      "Epoch 61/200\n",
      "20282/20282 [==============================] - 6s 318us/step - loss: 0.1241 - mean_absolute_error: 0.2523 - val_loss: 0.3032 - val_mean_absolute_error: 0.3738\n",
      "Epoch 62/200\n",
      "20282/20282 [==============================] - 6s 319us/step - loss: 0.1418 - mean_absolute_error: 0.2721 - val_loss: 0.3010 - val_mean_absolute_error: 0.3760\n",
      "Epoch 63/200\n",
      "20282/20282 [==============================] - 6s 303us/step - loss: 0.1239 - mean_absolute_error: 0.2536 - val_loss: 0.2612 - val_mean_absolute_error: 0.3501\n",
      "Epoch 64/200\n",
      "20282/20282 [==============================] - 6s 294us/step - loss: 0.1098 - mean_absolute_error: 0.2368 - val_loss: 0.2388 - val_mean_absolute_error: 0.3339\n",
      "Epoch 65/200\n",
      "20282/20282 [==============================] - 6s 320us/step - loss: 0.1177 - mean_absolute_error: 0.2473 - val_loss: 0.2723 - val_mean_absolute_error: 0.3574\n",
      "Epoch 66/200\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.1161 - mean_absolute_error: 0.2411 - val_loss: 0.2446 - val_mean_absolute_error: 0.3428\n",
      "Epoch 67/200\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.1158 - mean_absolute_error: 0.2446 - val_loss: 0.2735 - val_mean_absolute_error: 0.3663\n",
      "Epoch 68/200\n",
      "20282/20282 [==============================] - 6s 289us/step - loss: 0.1361 - mean_absolute_error: 0.2676 - val_loss: 0.2773 - val_mean_absolute_error: 0.3591\n",
      "Epoch 69/200\n",
      "20282/20282 [==============================] - 6s 287us/step - loss: 0.1514 - mean_absolute_error: 0.2757 - val_loss: 0.3762 - val_mean_absolute_error: 0.4563\n",
      "Epoch 70/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.1181 - mean_absolute_error: 0.2437 - val_loss: 0.2467 - val_mean_absolute_error: 0.3416\n",
      "Epoch 71/200\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.1089 - mean_absolute_error: 0.2361 - val_loss: 0.2733 - val_mean_absolute_error: 0.3716\n",
      "Epoch 72/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.1076 - mean_absolute_error: 0.2328 - val_loss: 0.2602 - val_mean_absolute_error: 0.3498\n",
      "Epoch 73/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.1096 - mean_absolute_error: 0.2352 - val_loss: 0.2813 - val_mean_absolute_error: 0.3637\n",
      "Epoch 74/200\n",
      "20282/20282 [==============================] - 6s 302us/step - loss: 0.1468 - mean_absolute_error: 0.2630 - val_loss: 0.2836 - val_mean_absolute_error: 0.3668\n",
      "Epoch 75/200\n",
      "20282/20282 [==============================] - 6s 298us/step - loss: 0.1392 - mean_absolute_error: 0.2694 - val_loss: 0.3029 - val_mean_absolute_error: 0.3704\n",
      "Epoch 76/200\n",
      "20282/20282 [==============================] - 6s 271us/step - loss: 0.1253 - mean_absolute_error: 0.2532 - val_loss: 0.2877 - val_mean_absolute_error: 0.3618\n",
      "Epoch 77/200\n",
      "20282/20282 [==============================] - 6s 313us/step - loss: 0.1305 - mean_absolute_error: 0.2536 - val_loss: 0.3371 - val_mean_absolute_error: 0.3716\n",
      "Epoch 78/200\n",
      "20282/20282 [==============================] - 6s 309us/step - loss: 0.1426 - mean_absolute_error: 0.2590 - val_loss: 0.3194 - val_mean_absolute_error: 0.3855\n",
      "Epoch 79/200\n",
      "20282/20282 [==============================] - 6s 291us/step - loss: 0.1160 - mean_absolute_error: 0.2470 - val_loss: 0.2756 - val_mean_absolute_error: 0.3458\n",
      "Epoch 80/200\n",
      "20282/20282 [==============================] - 6s 274us/step - loss: 0.1026 - mean_absolute_error: 0.2275 - val_loss: 0.2656 - val_mean_absolute_error: 0.3405\n",
      "Epoch 81/200\n",
      "20282/20282 [==============================] - 6s 273us/step - loss: 0.0982 - mean_absolute_error: 0.2224 - val_loss: 0.2662 - val_mean_absolute_error: 0.3419\n",
      "Epoch 82/200\n",
      "20282/20282 [==============================] - 5s 270us/step - loss: 0.1231 - mean_absolute_error: 0.2490 - val_loss: 0.2976 - val_mean_absolute_error: 0.3658\n",
      "Epoch 83/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.1331 - mean_absolute_error: 0.2618 - val_loss: 0.3458 - val_mean_absolute_error: 0.4136\n",
      "Epoch 84/200\n",
      "20282/20282 [==============================] - 5s 269us/step - loss: 0.1429 - mean_absolute_error: 0.2664 - val_loss: 0.4082 - val_mean_absolute_error: 0.3858\n",
      "Error : 0.5491873492059124\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20282/20282 [==============================] - 8s 388us/step - loss: 24.8278 - mean_absolute_error: 3.0548 - val_loss: 7.8480 - val_mean_absolute_error: 2.1839\n",
      "Epoch 2/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 4.6968 - mean_absolute_error: 1.5780 - val_loss: 2.8040 - val_mean_absolute_error: 1.2321\n",
      "Epoch 3/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 1.4000 - mean_absolute_error: 0.8465 - val_loss: 0.8309 - val_mean_absolute_error: 0.6622\n",
      "Epoch 4/200\n",
      "20282/20282 [==============================] - 5s 245us/step - loss: 0.4865 - mean_absolute_error: 0.5132 - val_loss: 0.6386 - val_mean_absolute_error: 0.5603\n",
      "Epoch 5/200\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.4323 - mean_absolute_error: 0.4915 - val_loss: 1.0151 - val_mean_absolute_error: 0.7785\n",
      "Epoch 6/200\n",
      "20282/20282 [==============================] - 6s 298us/step - loss: 0.5203 - mean_absolute_error: 0.5410 - val_loss: 0.6613 - val_mean_absolute_error: 0.6094\n",
      "Epoch 7/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.3949 - mean_absolute_error: 0.4623 - val_loss: 0.4750 - val_mean_absolute_error: 0.4975\n",
      "Epoch 8/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.3446 - mean_absolute_error: 0.4389 - val_loss: 0.4725 - val_mean_absolute_error: 0.4901\n",
      "Epoch 9/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.3759 - mean_absolute_error: 0.4494 - val_loss: 0.4841 - val_mean_absolute_error: 0.5026\n",
      "Epoch 10/200\n",
      "20282/20282 [==============================] - 6s 275us/step - loss: 0.3748 - mean_absolute_error: 0.4469 - val_loss: 0.5805 - val_mean_absolute_error: 0.5563\n",
      "Epoch 11/200\n",
      "20282/20282 [==============================] - 6s 273us/step - loss: 0.3137 - mean_absolute_error: 0.3988 - val_loss: 0.6423 - val_mean_absolute_error: 0.6008\n",
      "Epoch 12/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.3720 - mean_absolute_error: 0.4453 - val_loss: 0.5093 - val_mean_absolute_error: 0.4755\n",
      "Epoch 13/200\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.3059 - mean_absolute_error: 0.4030 - val_loss: 0.4513 - val_mean_absolute_error: 0.4676\n",
      "Epoch 14/200\n",
      "20282/20282 [==============================] - 6s 276us/step - loss: 0.2749 - mean_absolute_error: 0.3735 - val_loss: 0.3787 - val_mean_absolute_error: 0.4297\n",
      "Epoch 15/200\n",
      "20282/20282 [==============================] - 6s 278us/step - loss: 0.2677 - mean_absolute_error: 0.3719 - val_loss: 0.4493 - val_mean_absolute_error: 0.4577\n",
      "Epoch 16/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.2475 - mean_absolute_error: 0.3572 - val_loss: 0.3750 - val_mean_absolute_error: 0.4304\n",
      "Epoch 17/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.2170 - mean_absolute_error: 0.3362 - val_loss: 0.4290 - val_mean_absolute_error: 0.4972\n",
      "Epoch 18/200\n",
      "20282/20282 [==============================] - 6s 277us/step - loss: 0.2310 - mean_absolute_error: 0.3531 - val_loss: 0.3356 - val_mean_absolute_error: 0.4043\n",
      "Epoch 19/200\n",
      "20282/20282 [==============================] - 6s 282us/step - loss: 0.1885 - mean_absolute_error: 0.3119 - val_loss: 0.3778 - val_mean_absolute_error: 0.4430\n",
      "Epoch 20/200\n",
      "20282/20282 [==============================] - 6s 293us/step - loss: 0.2066 - mean_absolute_error: 0.3295 - val_loss: 0.4933 - val_mean_absolute_error: 0.5385\n",
      "Epoch 21/200\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.2015 - mean_absolute_error: 0.3216 - val_loss: 0.4981 - val_mean_absolute_error: 0.5350\n",
      "Epoch 22/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.1787 - mean_absolute_error: 0.3111 - val_loss: 0.3071 - val_mean_absolute_error: 0.3819\n",
      "Epoch 23/200\n",
      "20282/20282 [==============================] - 6s 273us/step - loss: 0.1497 - mean_absolute_error: 0.2786 - val_loss: 0.3158 - val_mean_absolute_error: 0.3893\n",
      "Epoch 24/200\n",
      "20282/20282 [==============================] - 6s 277us/step - loss: 0.1780 - mean_absolute_error: 0.3062 - val_loss: 0.3242 - val_mean_absolute_error: 0.4043\n",
      "Epoch 25/200\n",
      "20282/20282 [==============================] - 6s 284us/step - loss: 0.1643 - mean_absolute_error: 0.2981 - val_loss: 0.3482 - val_mean_absolute_error: 0.4148\n",
      "Epoch 26/200\n",
      "20282/20282 [==============================] - 6s 302us/step - loss: 0.1422 - mean_absolute_error: 0.2691 - val_loss: 0.3276 - val_mean_absolute_error: 0.4128\n",
      "Epoch 27/200\n",
      "20282/20282 [==============================] - 6s 290us/step - loss: 0.1458 - mean_absolute_error: 0.2805 - val_loss: 0.3299 - val_mean_absolute_error: 0.4013\n",
      "Epoch 28/200\n",
      "20282/20282 [==============================] - 6s 299us/step - loss: 0.1553 - mean_absolute_error: 0.2877 - val_loss: 0.2990 - val_mean_absolute_error: 0.3801\n",
      "Epoch 29/200\n",
      "20282/20282 [==============================] - 6s 298us/step - loss: 0.1514 - mean_absolute_error: 0.2807 - val_loss: 0.2917 - val_mean_absolute_error: 0.3770\n",
      "Epoch 30/200\n",
      "20282/20282 [==============================] - 6s 272us/step - loss: 0.1392 - mean_absolute_error: 0.2757 - val_loss: 0.2686 - val_mean_absolute_error: 0.3599\n",
      "Epoch 31/200\n",
      "20282/20282 [==============================] - 6s 273us/step - loss: 0.1290 - mean_absolute_error: 0.2622 - val_loss: 0.2787 - val_mean_absolute_error: 0.3682\n",
      "Epoch 32/200\n",
      "20282/20282 [==============================] - 6s 307us/step - loss: 0.1263 - mean_absolute_error: 0.2579 - val_loss: 0.3031 - val_mean_absolute_error: 0.3977\n",
      "Epoch 33/200\n",
      "20282/20282 [==============================] - 6s 289us/step - loss: 0.1465 - mean_absolute_error: 0.2776 - val_loss: 0.6275 - val_mean_absolute_error: 0.6283\n",
      "Epoch 34/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.1591 - mean_absolute_error: 0.2909 - val_loss: 0.2647 - val_mean_absolute_error: 0.3572\n",
      "Epoch 35/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.1228 - mean_absolute_error: 0.2542 - val_loss: 0.2827 - val_mean_absolute_error: 0.3620\n",
      "Epoch 36/200\n",
      "20282/20282 [==============================] - 6s 302us/step - loss: 0.1311 - mean_absolute_error: 0.2596 - val_loss: 0.2624 - val_mean_absolute_error: 0.3547\n",
      "Epoch 37/200\n",
      "20282/20282 [==============================] - 6s 304us/step - loss: 0.1264 - mean_absolute_error: 0.2566 - val_loss: 0.2759 - val_mean_absolute_error: 0.3637\n",
      "Epoch 38/200\n",
      "20282/20282 [==============================] - 6s 308us/step - loss: 0.1254 - mean_absolute_error: 0.2570 - val_loss: 0.3048 - val_mean_absolute_error: 0.3871\n",
      "Epoch 39/200\n",
      "20282/20282 [==============================] - 6s 314us/step - loss: 0.1338 - mean_absolute_error: 0.2665 - val_loss: 0.2610 - val_mean_absolute_error: 0.3595\n",
      "Epoch 40/200\n",
      "20282/20282 [==============================] - 7s 325us/step - loss: 0.1123 - mean_absolute_error: 0.2466 - val_loss: 0.2474 - val_mean_absolute_error: 0.3382\n",
      "Epoch 41/200\n",
      "20282/20282 [==============================] - 6s 304us/step - loss: 0.1202 - mean_absolute_error: 0.2549 - val_loss: 0.2909 - val_mean_absolute_error: 0.3737\n",
      "Epoch 42/200\n",
      "20282/20282 [==============================] - 6s 300us/step - loss: 0.1192 - mean_absolute_error: 0.2525 - val_loss: 0.3572 - val_mean_absolute_error: 0.4601\n",
      "Epoch 43/200\n",
      "20282/20282 [==============================] - 6s 295us/step - loss: 0.1062 - mean_absolute_error: 0.2339 - val_loss: 0.2560 - val_mean_absolute_error: 0.3356\n",
      "Epoch 44/200\n",
      "20282/20282 [==============================] - 6s 306us/step - loss: 0.1050 - mean_absolute_error: 0.2335 - val_loss: 0.2705 - val_mean_absolute_error: 0.3526\n",
      "Epoch 45/200\n",
      "20282/20282 [==============================] - 6s 305us/step - loss: 0.1281 - mean_absolute_error: 0.2608 - val_loss: 0.2980 - val_mean_absolute_error: 0.3782\n",
      "Epoch 46/200\n",
      "20282/20282 [==============================] - 6s 293us/step - loss: 0.1147 - mean_absolute_error: 0.2439 - val_loss: 0.2788 - val_mean_absolute_error: 0.3550\n",
      "Epoch 47/200\n",
      "20282/20282 [==============================] - 5s 271us/step - loss: 0.0993 - mean_absolute_error: 0.2301 - val_loss: 0.2983 - val_mean_absolute_error: 0.3886\n",
      "Epoch 48/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.1073 - mean_absolute_error: 0.2378 - val_loss: 0.2718 - val_mean_absolute_error: 0.3564\n",
      "Epoch 49/200\n",
      "20282/20282 [==============================] - 5s 241us/step - loss: 0.1115 - mean_absolute_error: 0.2432 - val_loss: 0.2916 - val_mean_absolute_error: 0.3652\n",
      "Epoch 50/200\n",
      "20282/20282 [==============================] - 5s 244us/step - loss: 0.1131 - mean_absolute_error: 0.2424 - val_loss: 0.2687 - val_mean_absolute_error: 0.3613\n",
      "Epoch 51/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.0947 - mean_absolute_error: 0.2193 - val_loss: 0.2845 - val_mean_absolute_error: 0.3701\n",
      "Epoch 52/200\n",
      "20282/20282 [==============================] - 5s 243us/step - loss: 0.1322 - mean_absolute_error: 0.2577 - val_loss: 0.2621 - val_mean_absolute_error: 0.3526\n",
      "Epoch 53/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.1069 - mean_absolute_error: 0.2361 - val_loss: 0.3127 - val_mean_absolute_error: 0.4094\n",
      "Epoch 54/200\n",
      "20282/20282 [==============================] - 6s 294us/step - loss: 0.0936 - mean_absolute_error: 0.2229 - val_loss: 0.2840 - val_mean_absolute_error: 0.3704\n",
      "Epoch 55/200\n",
      "20282/20282 [==============================] - 6s 292us/step - loss: 0.0908 - mean_absolute_error: 0.2154 - val_loss: 0.2986 - val_mean_absolute_error: 0.3895\n",
      "Epoch 56/200\n",
      "20282/20282 [==============================] - 6s 293us/step - loss: 0.1040 - mean_absolute_error: 0.2310 - val_loss: 0.2929 - val_mean_absolute_error: 0.3596\n",
      "Epoch 57/200\n",
      "20282/20282 [==============================] - 6s 295us/step - loss: 0.1080 - mean_absolute_error: 0.2350 - val_loss: 0.2731 - val_mean_absolute_error: 0.3534\n",
      "Epoch 58/200\n",
      "20282/20282 [==============================] - 6s 290us/step - loss: 0.0981 - mean_absolute_error: 0.2288 - val_loss: 0.3057 - val_mean_absolute_error: 0.3998\n",
      "Epoch 59/200\n",
      "20282/20282 [==============================] - 6s 304us/step - loss: 0.0932 - mean_absolute_error: 0.2173 - val_loss: 0.2631 - val_mean_absolute_error: 0.3452\n",
      "Epoch 60/200\n",
      "20282/20282 [==============================] - 6s 298us/step - loss: 0.1035 - mean_absolute_error: 0.2289 - val_loss: 0.2812 - val_mean_absolute_error: 0.3750\n",
      "Error : 0.5096106165675329\n",
      "Train on 20282 samples, validate on 2254 samples\n",
      "Epoch 1/200\n",
      "20282/20282 [==============================] - 9s 447us/step - loss: 20.9933 - mean_absolute_error: 2.9156 - val_loss: 8.3980 - val_mean_absolute_error: 2.3110\n",
      "Epoch 2/200\n",
      "20282/20282 [==============================] - 6s 298us/step - loss: 4.4808 - mean_absolute_error: 1.5212 - val_loss: 2.2519 - val_mean_absolute_error: 1.0965\n",
      "Epoch 3/200\n",
      "20282/20282 [==============================] - 6s 300us/step - loss: 1.1068 - mean_absolute_error: 0.7538 - val_loss: 0.9002 - val_mean_absolute_error: 0.6761\n",
      "Epoch 4/200\n",
      "20282/20282 [==============================] - 6s 299us/step - loss: 0.4863 - mean_absolute_error: 0.5186 - val_loss: 0.6541 - val_mean_absolute_error: 0.5755\n",
      "Epoch 5/200\n",
      "20282/20282 [==============================] - 6s 298us/step - loss: 0.3806 - mean_absolute_error: 0.4567 - val_loss: 0.6242 - val_mean_absolute_error: 0.5529\n",
      "Epoch 6/200\n",
      "20282/20282 [==============================] - 6s 310us/step - loss: 0.3771 - mean_absolute_error: 0.4532 - val_loss: 0.5640 - val_mean_absolute_error: 0.5286\n",
      "Epoch 7/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.3804 - mean_absolute_error: 0.4586 - val_loss: 0.4777 - val_mean_absolute_error: 0.4880\n",
      "Epoch 8/200\n",
      "20282/20282 [==============================] - 7s 333us/step - loss: 0.3716 - mean_absolute_error: 0.4481 - val_loss: 0.7849 - val_mean_absolute_error: 0.6932\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20282/20282 [==============================] - 6s 279us/step - loss: 0.3921 - mean_absolute_error: 0.4623 - val_loss: 0.5527 - val_mean_absolute_error: 0.5196\n",
      "Epoch 10/200\n",
      "20282/20282 [==============================] - 6s 294us/step - loss: 0.3616 - mean_absolute_error: 0.4392 - val_loss: 0.4785 - val_mean_absolute_error: 0.4778\n",
      "Epoch 11/200\n",
      "20282/20282 [==============================] - 6s 284us/step - loss: 0.3458 - mean_absolute_error: 0.4244 - val_loss: 0.4921 - val_mean_absolute_error: 0.4993\n",
      "Epoch 12/200\n",
      "20282/20282 [==============================] - 6s 282us/step - loss: 0.2993 - mean_absolute_error: 0.3989 - val_loss: 0.5489 - val_mean_absolute_error: 0.5526\n",
      "Epoch 13/200\n",
      "20282/20282 [==============================] - 6s 284us/step - loss: 0.2975 - mean_absolute_error: 0.4002 - val_loss: 0.4619 - val_mean_absolute_error: 0.4985\n",
      "Epoch 14/200\n",
      "20282/20282 [==============================] - 6s 296us/step - loss: 0.2797 - mean_absolute_error: 0.3903 - val_loss: 0.3742 - val_mean_absolute_error: 0.4230\n",
      "Epoch 15/200\n",
      "20282/20282 [==============================] - 6s 296us/step - loss: 0.2391 - mean_absolute_error: 0.3540 - val_loss: 0.4076 - val_mean_absolute_error: 0.4704\n",
      "Epoch 16/200\n",
      "20282/20282 [==============================] - 6s 279us/step - loss: 0.2255 - mean_absolute_error: 0.3525 - val_loss: 0.3527 - val_mean_absolute_error: 0.4182\n",
      "Epoch 17/200\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.2031 - mean_absolute_error: 0.3322 - val_loss: 0.3369 - val_mean_absolute_error: 0.4099\n",
      "Epoch 18/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.1932 - mean_absolute_error: 0.3245 - val_loss: 0.3323 - val_mean_absolute_error: 0.4142\n",
      "Epoch 19/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.1832 - mean_absolute_error: 0.3180 - val_loss: 0.3308 - val_mean_absolute_error: 0.3991\n",
      "Epoch 20/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.1862 - mean_absolute_error: 0.3225 - val_loss: 0.3219 - val_mean_absolute_error: 0.3962\n",
      "Epoch 21/200\n",
      "20282/20282 [==============================] - 6s 280us/step - loss: 0.1416 - mean_absolute_error: 0.2775 - val_loss: 0.2963 - val_mean_absolute_error: 0.3729\n",
      "Epoch 22/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.1443 - mean_absolute_error: 0.2748 - val_loss: 0.4050 - val_mean_absolute_error: 0.4785\n",
      "Epoch 23/200\n",
      "20282/20282 [==============================] - 6s 277us/step - loss: 0.1940 - mean_absolute_error: 0.3209 - val_loss: 0.4102 - val_mean_absolute_error: 0.4721\n",
      "Epoch 24/200\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.1425 - mean_absolute_error: 0.2793 - val_loss: 0.2736 - val_mean_absolute_error: 0.3628\n",
      "Epoch 25/200\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.1308 - mean_absolute_error: 0.2679 - val_loss: 0.2936 - val_mean_absolute_error: 0.3731\n",
      "Epoch 26/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.1250 - mean_absolute_error: 0.2577 - val_loss: 0.2843 - val_mean_absolute_error: 0.3702\n",
      "Epoch 27/200\n",
      "20282/20282 [==============================] - 6s 271us/step - loss: 0.1231 - mean_absolute_error: 0.2581 - val_loss: 0.2703 - val_mean_absolute_error: 0.3514\n",
      "Epoch 28/200\n",
      "20282/20282 [==============================] - 6s 305us/step - loss: 0.1340 - mean_absolute_error: 0.2594 - val_loss: 0.3903 - val_mean_absolute_error: 0.4753\n",
      "Epoch 29/200\n",
      "20282/20282 [==============================] - 7s 335us/step - loss: 0.1243 - mean_absolute_error: 0.2553 - val_loss: 0.3061 - val_mean_absolute_error: 0.3988\n",
      "Epoch 30/200\n",
      "20282/20282 [==============================] - 7s 325us/step - loss: 0.1087 - mean_absolute_error: 0.2402 - val_loss: 0.2831 - val_mean_absolute_error: 0.3762\n",
      "Epoch 31/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.1109 - mean_absolute_error: 0.2423 - val_loss: 0.3007 - val_mean_absolute_error: 0.3895\n",
      "Epoch 32/200\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.1132 - mean_absolute_error: 0.2486 - val_loss: 0.3237 - val_mean_absolute_error: 0.4222\n",
      "Epoch 33/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.1193 - mean_absolute_error: 0.2524 - val_loss: 0.3454 - val_mean_absolute_error: 0.4351\n",
      "Epoch 34/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.1250 - mean_absolute_error: 0.2594 - val_loss: 0.2752 - val_mean_absolute_error: 0.3758\n",
      "Epoch 35/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.1186 - mean_absolute_error: 0.2530 - val_loss: 0.2820 - val_mean_absolute_error: 0.3630\n",
      "Epoch 36/200\n",
      "20282/20282 [==============================] - 5s 246us/step - loss: 0.1054 - mean_absolute_error: 0.2340 - val_loss: 0.2755 - val_mean_absolute_error: 0.3765\n",
      "Epoch 37/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.0972 - mean_absolute_error: 0.2212 - val_loss: 0.2481 - val_mean_absolute_error: 0.3343\n",
      "Epoch 38/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.1082 - mean_absolute_error: 0.2409 - val_loss: 0.2813 - val_mean_absolute_error: 0.3682\n",
      "Epoch 39/200\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.1012 - mean_absolute_error: 0.2337 - val_loss: 0.2520 - val_mean_absolute_error: 0.3415\n",
      "Epoch 40/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.1034 - mean_absolute_error: 0.2338 - val_loss: 0.2693 - val_mean_absolute_error: 0.3520\n",
      "Epoch 41/200\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.1048 - mean_absolute_error: 0.2342 - val_loss: 0.2562 - val_mean_absolute_error: 0.3435\n",
      "Epoch 42/200\n",
      "20282/20282 [==============================] - 6s 277us/step - loss: 0.1099 - mean_absolute_error: 0.2377 - val_loss: 0.2631 - val_mean_absolute_error: 0.3466\n",
      "Epoch 43/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.1035 - mean_absolute_error: 0.2313 - val_loss: 0.2635 - val_mean_absolute_error: 0.3608\n",
      "Epoch 44/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.1047 - mean_absolute_error: 0.2319 - val_loss: 0.2606 - val_mean_absolute_error: 0.3430\n",
      "Epoch 45/200\n",
      "20282/20282 [==============================] - 5s 251us/step - loss: 0.0894 - mean_absolute_error: 0.2153 - val_loss: 0.2811 - val_mean_absolute_error: 0.3683\n",
      "Epoch 46/200\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.0950 - mean_absolute_error: 0.2227 - val_loss: 0.2739 - val_mean_absolute_error: 0.3522\n",
      "Epoch 47/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.0995 - mean_absolute_error: 0.2289 - val_loss: 0.3076 - val_mean_absolute_error: 0.4002\n",
      "Epoch 48/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.0992 - mean_absolute_error: 0.2273 - val_loss: 0.2504 - val_mean_absolute_error: 0.3324\n",
      "Epoch 49/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.0858 - mean_absolute_error: 0.2113 - val_loss: 0.2651 - val_mean_absolute_error: 0.3458\n",
      "Epoch 50/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.0892 - mean_absolute_error: 0.2113 - val_loss: 0.2441 - val_mean_absolute_error: 0.3255\n",
      "Epoch 51/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.0852 - mean_absolute_error: 0.2102 - val_loss: 0.2702 - val_mean_absolute_error: 0.3492\n",
      "Epoch 52/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.1008 - mean_absolute_error: 0.2313 - val_loss: 0.2633 - val_mean_absolute_error: 0.3484\n",
      "Epoch 53/200\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.0932 - mean_absolute_error: 0.2203 - val_loss: 0.2428 - val_mean_absolute_error: 0.3276\n",
      "Epoch 54/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.0856 - mean_absolute_error: 0.2095 - val_loss: 0.2512 - val_mean_absolute_error: 0.3444\n",
      "Epoch 55/200\n",
      "20282/20282 [==============================] - 6s 281us/step - loss: 0.0835 - mean_absolute_error: 0.2078 - val_loss: 0.2661 - val_mean_absolute_error: 0.3534\n",
      "Epoch 56/200\n",
      "20282/20282 [==============================] - 6s 287us/step - loss: 0.0862 - mean_absolute_error: 0.2095 - val_loss: 0.2521 - val_mean_absolute_error: 0.3481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.1038 - mean_absolute_error: 0.2288 - val_loss: 0.2472 - val_mean_absolute_error: 0.3293\n",
      "Epoch 58/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.0894 - mean_absolute_error: 0.2146 - val_loss: 0.2435 - val_mean_absolute_error: 0.3374\n",
      "Epoch 59/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.0854 - mean_absolute_error: 0.2103 - val_loss: 0.2506 - val_mean_absolute_error: 0.3282\n",
      "Epoch 60/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.0871 - mean_absolute_error: 0.2098 - val_loss: 0.2385 - val_mean_absolute_error: 0.3276\n",
      "Epoch 61/200\n",
      "20282/20282 [==============================] - 6s 284us/step - loss: 0.0771 - mean_absolute_error: 0.1980 - val_loss: 0.2691 - val_mean_absolute_error: 0.3644\n",
      "Epoch 62/200\n",
      "20282/20282 [==============================] - 5s 269us/step - loss: 0.0816 - mean_absolute_error: 0.2044 - val_loss: 0.2371 - val_mean_absolute_error: 0.3261\n",
      "Epoch 63/200\n",
      "20282/20282 [==============================] - 5s 271us/step - loss: 0.0923 - mean_absolute_error: 0.2191 - val_loss: 0.2485 - val_mean_absolute_error: 0.3409\n",
      "Epoch 64/200\n",
      "20282/20282 [==============================] - 6s 291us/step - loss: 0.0931 - mean_absolute_error: 0.2200 - val_loss: 0.2650 - val_mean_absolute_error: 0.3631\n",
      "Epoch 65/200\n",
      "20282/20282 [==============================] - 6s 275us/step - loss: 0.0840 - mean_absolute_error: 0.2046 - val_loss: 0.2797 - val_mean_absolute_error: 0.3731\n",
      "Epoch 66/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.0935 - mean_absolute_error: 0.2189 - val_loss: 0.2564 - val_mean_absolute_error: 0.3364\n",
      "Epoch 67/200\n",
      "20282/20282 [==============================] - 6s 304us/step - loss: 0.0909 - mean_absolute_error: 0.2160 - val_loss: 0.2352 - val_mean_absolute_error: 0.3262\n",
      "Epoch 68/200\n",
      "20282/20282 [==============================] - 6s 286us/step - loss: 0.0778 - mean_absolute_error: 0.2019 - val_loss: 0.2478 - val_mean_absolute_error: 0.3377\n",
      "Epoch 69/200\n",
      "20282/20282 [==============================] - 5s 270us/step - loss: 0.0866 - mean_absolute_error: 0.2055 - val_loss: 0.2703 - val_mean_absolute_error: 0.3482\n",
      "Epoch 70/200\n",
      "20282/20282 [==============================] - 5s 253us/step - loss: 0.0845 - mean_absolute_error: 0.1989 - val_loss: 0.2303 - val_mean_absolute_error: 0.3205\n",
      "Epoch 71/200\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.0799 - mean_absolute_error: 0.2013 - val_loss: 0.2723 - val_mean_absolute_error: 0.3383\n",
      "Epoch 72/200\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.1173 - mean_absolute_error: 0.2376 - val_loss: 0.2985 - val_mean_absolute_error: 0.3870\n",
      "Epoch 73/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.0928 - mean_absolute_error: 0.2144 - val_loss: 0.2604 - val_mean_absolute_error: 0.3477\n",
      "Epoch 74/200\n",
      "20282/20282 [==============================] - 5s 264us/step - loss: 0.0655 - mean_absolute_error: 0.1812 - val_loss: 0.2687 - val_mean_absolute_error: 0.3521\n",
      "Epoch 75/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.0682 - mean_absolute_error: 0.1820 - val_loss: 0.2592 - val_mean_absolute_error: 0.3492\n",
      "Epoch 76/200\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.0820 - mean_absolute_error: 0.2043 - val_loss: 0.2520 - val_mean_absolute_error: 0.3363\n",
      "Epoch 77/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.0821 - mean_absolute_error: 0.2074 - val_loss: 0.2384 - val_mean_absolute_error: 0.3202\n",
      "Epoch 78/200\n",
      "20282/20282 [==============================] - 5s 265us/step - loss: 0.1056 - mean_absolute_error: 0.2286 - val_loss: 0.2939 - val_mean_absolute_error: 0.3758\n",
      "Epoch 79/200\n",
      "20282/20282 [==============================] - 5s 252us/step - loss: 0.0919 - mean_absolute_error: 0.2151 - val_loss: 0.2677 - val_mean_absolute_error: 0.3422\n",
      "Epoch 80/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.0842 - mean_absolute_error: 0.2015 - val_loss: 0.2352 - val_mean_absolute_error: 0.3142\n",
      "Epoch 81/200\n",
      "20282/20282 [==============================] - 5s 265us/step - loss: 0.0768 - mean_absolute_error: 0.1914 - val_loss: 0.2707 - val_mean_absolute_error: 0.3522\n",
      "Epoch 82/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.0828 - mean_absolute_error: 0.2008 - val_loss: 0.2513 - val_mean_absolute_error: 0.3334\n",
      "Epoch 83/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.0830 - mean_absolute_error: 0.2060 - val_loss: 0.2509 - val_mean_absolute_error: 0.3389\n",
      "Epoch 84/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.0803 - mean_absolute_error: 0.1994 - val_loss: 0.2332 - val_mean_absolute_error: 0.3194\n",
      "Epoch 85/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.0702 - mean_absolute_error: 0.1913 - val_loss: 0.2386 - val_mean_absolute_error: 0.3235\n",
      "Epoch 86/200\n",
      "20282/20282 [==============================] - 5s 259us/step - loss: 0.0796 - mean_absolute_error: 0.1997 - val_loss: 0.2460 - val_mean_absolute_error: 0.3346\n",
      "Epoch 87/200\n",
      "20282/20282 [==============================] - 5s 255us/step - loss: 0.0992 - mean_absolute_error: 0.2209 - val_loss: 0.2803 - val_mean_absolute_error: 0.3559\n",
      "Epoch 88/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.0849 - mean_absolute_error: 0.2103 - val_loss: 0.2526 - val_mean_absolute_error: 0.3266\n",
      "Epoch 89/200\n",
      "20282/20282 [==============================] - 5s 265us/step - loss: 0.0847 - mean_absolute_error: 0.2042 - val_loss: 0.2475 - val_mean_absolute_error: 0.3278\n",
      "Epoch 90/200\n",
      "20282/20282 [==============================] - 5s 258us/step - loss: 0.0766 - mean_absolute_error: 0.1957 - val_loss: 0.2262 - val_mean_absolute_error: 0.3168\n",
      "Epoch 91/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.0680 - mean_absolute_error: 0.1816 - val_loss: 0.2493 - val_mean_absolute_error: 0.3508\n",
      "Epoch 92/200\n",
      "20282/20282 [==============================] - 5s 261us/step - loss: 0.0808 - mean_absolute_error: 0.1986 - val_loss: 0.2475 - val_mean_absolute_error: 0.3318\n",
      "Epoch 93/200\n",
      "20282/20282 [==============================] - 5s 254us/step - loss: 0.0776 - mean_absolute_error: 0.1970 - val_loss: 0.2565 - val_mean_absolute_error: 0.3521\n",
      "Epoch 94/200\n",
      "20282/20282 [==============================] - 5s 262us/step - loss: 0.0813 - mean_absolute_error: 0.2015 - val_loss: 0.2930 - val_mean_absolute_error: 0.3917\n",
      "Epoch 95/200\n",
      "20282/20282 [==============================] - 5s 256us/step - loss: 0.0876 - mean_absolute_error: 0.2114 - val_loss: 0.2705 - val_mean_absolute_error: 0.3687\n",
      "Epoch 96/200\n",
      "20282/20282 [==============================] - 5s 248us/step - loss: 0.0971 - mean_absolute_error: 0.2209 - val_loss: 0.3194 - val_mean_absolute_error: 0.4107\n",
      "Epoch 97/200\n",
      "20282/20282 [==============================] - 6s 274us/step - loss: 0.0839 - mean_absolute_error: 0.2041 - val_loss: 0.2545 - val_mean_absolute_error: 0.3311\n",
      "Epoch 98/200\n",
      "20282/20282 [==============================] - 5s 266us/step - loss: 0.0707 - mean_absolute_error: 0.1837 - val_loss: 0.2376 - val_mean_absolute_error: 0.3242\n",
      "Epoch 99/200\n",
      "20282/20282 [==============================] - 5s 262us/step - loss: 0.0739 - mean_absolute_error: 0.1871 - val_loss: 0.2368 - val_mean_absolute_error: 0.3242\n",
      "Epoch 100/200\n",
      "20282/20282 [==============================] - 5s 250us/step - loss: 0.0735 - mean_absolute_error: 0.1883 - val_loss: 0.2371 - val_mean_absolute_error: 0.3264\n",
      "Epoch 101/200\n",
      "20282/20282 [==============================] - 5s 249us/step - loss: 0.0776 - mean_absolute_error: 0.1979 - val_loss: 0.2414 - val_mean_absolute_error: 0.3401\n",
      "Epoch 102/200\n",
      "20282/20282 [==============================] - 5s 247us/step - loss: 0.0866 - mean_absolute_error: 0.2075 - val_loss: 0.2439 - val_mean_absolute_error: 0.3313\n",
      "Epoch 103/200\n",
      "20282/20282 [==============================] - 5s 262us/step - loss: 0.0803 - mean_absolute_error: 0.1995 - val_loss: 0.2403 - val_mean_absolute_error: 0.3273\n",
      "Epoch 104/200\n",
      "20282/20282 [==============================] - 5s 260us/step - loss: 0.1162 - mean_absolute_error: 0.2369 - val_loss: 0.2527 - val_mean_absolute_error: 0.3463\n",
      "Epoch 105/200\n",
      "20282/20282 [==============================] - 5s 267us/step - loss: 0.0740 - mean_absolute_error: 0.1933 - val_loss: 0.2415 - val_mean_absolute_error: 0.3376\n",
      "Epoch 106/200\n",
      "20282/20282 [==============================] - 5s 263us/step - loss: 0.0605 - mean_absolute_error: 0.1727 - val_loss: 0.2377 - val_mean_absolute_error: 0.3260\n",
      "Epoch 107/200\n",
      "20282/20282 [==============================] - 5s 262us/step - loss: 0.0618 - mean_absolute_error: 0.1731 - val_loss: 0.2564 - val_mean_absolute_error: 0.3550\n",
      "Epoch 108/200\n",
      "20282/20282 [==============================] - 5s 257us/step - loss: 0.0931 - mean_absolute_error: 0.2146 - val_loss: 0.2675 - val_mean_absolute_error: 0.3513\n",
      "Epoch 109/200\n",
      "20282/20282 [==============================] - 5s 262us/step - loss: 0.0870 - mean_absolute_error: 0.2078 - val_loss: 0.2635 - val_mean_absolute_error: 0.3394\n",
      "Epoch 110/200\n",
      "20282/20282 [==============================] - 5s 268us/step - loss: 0.0782 - mean_absolute_error: 0.1935 - val_loss: 0.2701 - val_mean_absolute_error: 0.3462\n",
      "Error : 0.5015837798551004\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XmcnFW95/HPr6uqu7q7el+ydEJ2yAohhE02CXiviogIigFUEC5Xx+vGqMNVXzPq9bpwZy7KlRlkEAYUCQgiCEKuYmQXCCF7CCEhCd1Zekvva1Wd+eNUJ52kl+qkK93p+r5fr3ql1uc59aT6+5znnPOcx5xziIjI2Jcx0gUQEZFjQ4EvIpImFPgiImlCgS8ikiYU+CIiaUKBLyKSJoKpXLiZbQeagRgQdc4tTuX6RESkfykN/IQLnXO1x2A9IiIyADXpiIikCUvlmbZm9i6wD3DAL5xzd/XxnpuAmwByc3NPmz17dsrKIyIy1rzxxhu1zrmyZN6b6sCvcM5VmVk58CfgS8655/t7/+LFi93KlStTVh4RkbHGzN5Itn80pU06zrmqxL/VwGPAGalcn4iI9C9lgW9muWaW13Mf+DtgfarWJyIiA0vlKJ1xwGNm1rOe3zjnnknh+kREZAApC3zn3DbglFQtX0RGr+7ubiorK+no6BjpoowZ4XCYSZMmEQqFjngZx2IcvoikmcrKSvLy8pg6dSqJo3w5Cs456urqqKysZNq0aUe8HI3DF5Fh19HRQUlJicJ+mJgZJSUlR33EpMAXkZRQ2A+v4dieCnwRkTShwBeRMaeuro6FCxeycOFCxo8fT0VFxf7HXV1dSS3j+uuvZ/PmzUmv8+677+arX/3qkRb5mFCnrYiMOSUlJaxevRqA7373u0QiEb7+9a8f9B7nHM45MjL6rvfee++9KS/nsaYavoikjXfeeYe5c+dyzTXXMG/ePHbv3s1NN93E4sWLmTdvHt///vf3v/fcc89l9erVRKNRCgsLueWWWzjllFM4++yzqa6uTnqdv/71r1mwYAHz58/nW9/6FgDRaJRPf/rT+5+//fbbAbjtttuYO3cuJ598Mtdee+3wfnlUwxeRFPveHzawcVfTsC5z7sR8/sel847os2+99Rb3338/ixf76Wd+/OMfU1xcTDQa5cILL+TKK69k7ty5B32msbGRCy64gB//+MfcfPPN3HPPPdxyyy2DrquyspLvfOc7rFy5koKCAi6++GKefPJJysrKqK2tZd26dQA0NDQAcOutt7Jjxw4yMzP3PzecVMMXkbQyY8aM/WEP8OCDD7Jo0SIWLVrEpk2b2Lhx42Gfyc7O5kMf+hAAp512Gtu3b09qXa+++ipLliyhtLSUUCjE1VdfzfPPP8/MmTPZvHkzX/7yl1m+fDkFBQUAzJs3j2uvvZYHHnjgqE6w6o9q+CKSUkdaE0+V3Nzc/fe3bNnCz372M1577TUKCwu59tpr+xzrnpmZuf9+IBAgGo0eVRlKSkpYu3YtTz/9NHfccQePPvood911F8uXL+e5557jiSee4Ic//CFr164lEAgc1bp6Uw1fRNJWU1MTeXl55Ofns3v3bpYvXz6syz/zzDNZsWIFdXV1RKNRli1bxgUXXEBNTQ3OOT7xiU/w/e9/n1WrVhGLxaisrGTJkiXceuut1NbW0tbWNqzlUQ1fRNLWokWLmDt3LrNnz2bKlCmcc845R7W8X/7ylzzyyCP7H69cuZJ/+Zd/4f3vfz/OOS699FIuueQSVq1axQ033IBzDjPjJz/5CdFolKuvvprm5mbi8Thf//rXycvLO9qveJCUXgBlqHQBFJGxYdOmTcyZM2ekizHm9LVdR80FUEREZPRQ4IuIpAkFvohImlDgi4ikCQW+iEiaUOCLiKQJBb6IjDkXXnjhYSdR/fSnP+ULX/jCgJ+LRCJDev54o8AXkTFn6dKlLFu27KDnli1bxtKlS0eoRKODAl9Expwrr7ySp556av/FTrZv386uXbs477zzaGlp4aKLLmLRokUsWLCAxx9/POnlOuf4xje+wfz581mwYAEPPfQQALt37+b8889n4cKFzJ8/nxdeeIFYLMZ11123/7233XZbSr7rUGhqBRFJradvgT3rhneZ4xfAh37c78vFxcWcccYZPP3001x22WUsW7aMT37yk5gZ4XCYxx57jPz8fGpraznrrLP46Ec/mtQ1Y3/3u9+xevVq1qxZQ21tLaeffjrnn38+v/nNb/j7v/97vv3tbxOLxWhra2P16tVUVVWxfv16gJRMdzxUquGLyJjUu1mnd3OOc45vfetbnHzyyVx88cVUVVWxd+/epJb54osvsnTpUgKBAOPGjeOCCy7g9ddf5/TTT+fee+/lu9/9LuvWrSMvL4/p06ezbds2vvSlL/HMM8+Qn5+fsu+aLNXwRSS1BqiJp9Jll13G1772NVatWkVbWxunnXYaAA888AA1NTW88cYbhEIhpk6d2ueUyENx/vnn8/zzz/PUU09x3XXXcfPNN/OZz3yGNWvWsHz5cu68804efvhh7rnnnuH4akdMNXwRGZMikQgXXnghn/vc5w7qrG1sbKS8vJxQKMSKFSvYsWNH0ss877zzeOihh4jFYtTU1PD8889zxhlnsGPHDsaNG8c//MM/cOONN7Jq1Spqa2uJx+NcccUV/OAHP2DVqlWp+JpDohq+iIxZS5cu5fLLLz9oxM4111zDpZdeyoIFC1i8eDGzZ89OenmXX345r7zyCqeccgpmxq233sr48eO57777+Ld/+zdCoRCRSIT777+fqqoqrr/+euLxOAA/+tGPhv37DZWmRxaRYafpkVND0yOLiEhSFPgiImlCgS8iKTGamovHguHYngp8ERl24XCYuro6hf4wcc5RV1dHOBw+quVolI6IDLtJkyZRWVlJTU3NSBdlzAiHw0yaNOmolqHAF5FhFwqFmDZt2kgXQw6hJh0RkTSR8sA3s4CZvWlmT6Z6XSIi0r9jUcP/CrDpGKxHREQGkNLAN7NJwCXA3alcj4iIDC7VNfyfAt8E4v29wcxuMrOVZrZSPfoiIqmTssA3s48A1c65NwZ6n3PuLufcYufc4rKyslQVR0Qk7aWyhn8O8FEz2w4sA5aY2a9TuD4RERlAygLfOffPzrlJzrmpwKeAvzjnrk3V+kREZGAahy8ikiaOyZm2zrm/An89FusSEZG+qYYvIpImFPgiImlCgS8ikiYU+CIiaUKBLyKSJhT4IiJpQoEvIpImFPgiImlCgS8ikiYU+CIiaUKBLyKSJhT4IiJpQoEvIpImFPgiImlCgS8ikiYU+CIiaUKBLyKSJhT4IiJpQoEvIpImFPgiImlCgS8ikiYU+CIiaWLAwDezgJl97VgVRkREUmfAwHfOxYClx6gsIiKSQsEk3vOSmf0ceAho7XnSObcqZaUSEZFhl0zgL0z8+/1ezzlgyfAX58g8/Pp7zCiPcNqUopEuiojIqDVo4DvnLjwWBTka3/3DBq4+4wQFvojIAAYdpWNmBWb272a2MnH7X2ZWcCwKl6xIVpDWruhIF0NEZFRLZljmPUAz8MnErQm4N5WFGqpIOEhzhwJfRGQgybThz3DOXdHr8ffMbHWqCnQk8rKCtHQq8EVEBpJMDb/dzM7teWBm5wDtqSvS0EXCQVpUwxcRGVAyNfzPA/f3arffB3w2dUUautzMIHUtbSNdDBGRUW3AwDezDOAk59wpZpYP4JxrOiYlGwK14YuIDG6wM23jwDcT95tGY9iDb8PXKB0RkYEl04b/ZzP7uplNNrPinttgHzKzsJm9ZmZrzGyDmX1vGMrbp542fOdcqlYhInLcS6YN/6rEv1/s9ZwDpg/yuU5giXOuxcxCwItm9rRz7m9HUM4BRbJCROOOzmiccCgw3IsXERkTkmnDv9Y599JQF+x8dbsl8TCUuKWkCh7J8iHf3BFV4IuI9COZNvyfH+nCE9MrrwaqgT85517t4z039ZzFW1NTc0TriYT9fktj8UVE+pdMG/6zZnaFmdlQF+6ciznnFgKTgDPMbH4f77nLObfYObe4rKxsqKsAfJMOoLH4IiIDSCbw/xH4LdBpZk1m1mxmQxqt45xrAFYAHzyCMg4qkqUavojIYAYNfOdcnnMuwzmX6ZzLTzzOH+xzZlZmZoWJ+9nAB4C3jr7Ih8tTk46IyKD6DXwzu7bX/XMOee2fklj2BGCFma0FXse34T95pAUdyIEafncqFi8iMiYMVMO/udf9/zjktc8NtmDn3Frn3KnOuZOdc/Odc98f7DNHKrcn8NWGLyLSr4EC3/q539fjEdXTpNOsJh0RkX4NFPiun/t9PR5RWcEMghmmGr6IyAAGOvFqdqL93YAZifskHg92lu0xZWZEwkFaVcMXEenXQIE/55iVYhhEsoJq0hERGUC/ge+c23EsC3K0Ilm6CIqIyECSOfHquBDRZQ5FRAY0dgI/rMAXERnIkALfzIrM7ORUFeZoqElHRGRggwa+mf3VzPITFz1ZBfxfM/v31BdtaPJUwxcRGVAyNfyCxKUNPw7c75w7E7g4tcUaOrXhi4gMLJnAD5rZBOCTQErmwhkOuVlB2rpixOKj6pwwEZFRI5nA/z6wHNjqnHvdzKYDW1JbrKHTFMkiIgMb9Jq2zrnf4ufD73m8DbgilYU6Er2nSC7IDo1waURERp9kOm2nm9kfzKzGzKrN7PFELX9U0VWvREQGlkyTzm+Ah/Hz20/E1/YfTGWhjoSuaysiMrBkAj/HOfcr51w0cfs1EE51wYZKbfgiIgPrtw0/Me4e4GkzuwVYhp8W+Srgj8egbEMS0UVQREQGNFCn7Rv4gO+52Mk/9nrNAf+cqkIdiQNNOrrMoYhIXwaaLXNaf6+Z2agbBtNTw29WDV9EpE9Jz6Vj3kVm9kugMoVlOiI9gd/aGRvhkoiIjE7JDMs8y8xuB3YAjwPPA7NTXbChCmQYOZkBNemIiPSj38A3sx+a2RbgX4G1wKlAjXPuPufcvmNVwKHI1Xw6IiL9GqjT9kbgbeD/AH9wznWa2aieqCYvK6g2fBGRfgzUpDMB+AFwKbDVzH4FZJvZoNMxjBRdBEVEpH8DjdKJAc8Az5hZFvARIBuoMrNnnXNXH6MyJk0XQRER6V9So3Scc53OuUedc1cCs/A7glFHc+KLiPRvyM0ziYuh3J+Cshw1NemIiPRvzFzEHFTDFxEZyNgL/I4ozo3qwUQiIiMiqSYdM3sfMLX3+51zo65ZJxIOEo07OqNxwqHASBdHRGRUGTTwE8MxZwCrgZ55CxyjsB0/r9d8Ogp8EZGDJVPDXwzMdcdBO0nPjJmtnVHK8rJGuDQiIqNLMm3464HxqS7IcNh/mUN13IqIHCaZGn4psNHMXgM6e550zn00ZaU6QrlZvhlH0yuIiBwumcD/bqoLMVzyVMMXEenXoIHvnHvuSBZsZpPxHbvj8J28dznnfnYky0qWrnolItK/ZOfDf93MWsysy8xiZtaUxLKjwH91zs0FzgK+aGZzj7bAA9F1bUVE+pdMp+3PgaXAFvzkaTcCdwz2IefcbufcqsT9ZmATUHHkRR1c3v4avq56JSJyqGQnT3sHCDjnYs65e4EPDmUlZjYVfwGVV/t47SYzW2lmK2tqaoay2MNkBTMIZJiadERE+pBMp22bmWUCq83sVmA3Q7sWbgR4FPhqYuK1gzjn7gLuAli8ePFRjfU3M02RLCLSj2SC+9OJ9/0T0ApMBq5IZuFmFsKH/QPOud8daSGHIpIVpFmjdEREDpPMKJ0dZpYNTHDOfS/ZBZuZAb8ENjnn/v0oyjgkeWHV8EVE+pLMKJ1L8fPoPJN4vNDMnkhi2efgjw6WmNnqxO3DR1Xa/sSi0NkCaIpkEZH+JNOk813gDKABwDm3Gpg22Ieccy8658w5d7JzbmHi9sejKm1fYlH40SR48TbAj8VvVeCLiBwmmcDvds41HvLc6JlILRCEggqo2wJArtrwRUT6lMwonQ1mdjUQMLNZwJeBl1NbrCEqmQW1PvDzNEpHRKRPydTwvwTMw0+c9iDQBHw1lYUastJZULcV4jG14YuI9COZUTptwLcTt9Gp9ESIdULDTiLhIG1dMWJxRyDDRrpkIiKjRr+BP9hInFE1PXLpLP9v7RYiWTMBP2NmQXZoBAslIjK6DFTDPxt4D9+M8yoweqvLpSf6f+u2EMmaDfirXinwRUQOGCjwxwMfwE+cdjXwFPCgc27DsSjYkOQUQ3Yx1L5NZErPBGpqxxcR6a3fTtvERGnPOOc+i5/e+B3gr2b2T8esdENReiLUbqEwOxOAupauES6QiMjoMmCnrZllAZfga/lTgduBx1JfrCNQOgveXk5FUTYAuxraR7hAIiKjy0CdtvcD84E/At9zzq0/ZqU6EqWz4M1fMSHLX3a3cp8CX0Skt4Fq+NfiZ8f8CvBlPxca4DtvnXMuP8VlG5pEx224cRvleVlUNbSNcIFEREaXfgPfOZf0nPejQknP0My3qSiaohq+iMghjq9QH0jRFMgI+cAvzKZKbfgiIgcZO4EfCEHxdKjdwqSiHHY1tBOPj5453kRERtrYCXzwHbe1W6goyqY75qhu7hzpEomIjBpjL/DrtzG5wJ9hq45bEZEDxlbgl8yCeDdTM2oADc0UEeltbAV+YmjmhOh7gAJfRKS3MRb4fqbMrIZtFOdmaqSOiEgvYyvws4sgt2z/0EzV8EVEDhhbgQ/7J1GbVJRN1T512oqI9Bh7gV8yE+q27D/5yjmNxRcRgbEY+KUnQlsdM3I76eiOU9eqaZJFRGCsBj4wM2MXAFVqxxcRAcZi4JedBMCk6E5AQzNFRHqMvcAvmAyhXIrbtgE621ZEpMfYC/yMDCg7iaz6zeSFg6rhi4gkjL3AByifAzVvMakoR234IiIJYzPwy2ZDy15OzOvW2bYiIgljN/CBU8K7qdynsfgiIjBWA7/cB/6JVklLZ5Sm9ugIF0hEZOSNzcAvmAyZESZHdwDwnqZYEBEZo4FvBmUnUdL2LoDa8UVEGKuBD1A2h5zGLYDOthURgRQGvpndY2bVZrY+VesYUPlsMtpqmJDZprH4IiKktob//4APpnD5AyubA8DZkWqdbSsiQgoD3zn3PFCfquUPKjFSZ2F4j2r4IiKMgjZ8M7vJzFaa2cqamprhW3B+BWTmMTtQxbu1rcTiGosvIultxAPfOXeXc26xc25xWVnZ8C04MVJnanwnbV0x3q1tHb5li4gch0Y88FOqfDbFrX7WzA27Gke4MCIiI2tsB37ZHIIddYwPtrC+SoEvIuktlcMyHwReAU4ys0ozuyFV6+pXouP2opJ61lc1HfPVi4iMJsFULdg5tzRVy05aYmjmmZG9PFHViHMOMxvhQomIjIyx3aSTPxGy8pkT2EVzR5T36jU8U0TS19gOfDMom82ELj+J2np13IpIGhvbgQ8waTG51Ss5NbBNHbciktbGfuBf8E0sMp6fZ93Blsq9I10aEZERM/YDP7sIPn4XE+J7+EjVbbr6lYikrbEf+ABTz2H99Bu5zK2g4fVl/rl4DLa/BH+7E6JdI1s+EZFjIGXDMkeb7vO+yZvvrGD+n74Be16GzU9Da2LunkAQTr9xZAsoIpJi6VHDB+ZUFPPV7i/6SdTW/w6mngdX3gsTF8HL/+Fr/CIiY1ja1PBzMoNkls3gmwX3cftnzoVQ2L+QEYSHPw0bH4f5Hx/ZQoqIpFDa1PAB5lcU8OpeDoQ9wOxLoGQmvPRTUIeuiIxhaRX48ybms7epk+rmjgNPZgTgfV+G3Wtg219HrGwiIqmWVoE/v6IAgA27DplI7eSrIDIOXvrZCJRKROTYSKvAnzsxH4DnNh9yZa1QGM76AmxbAbtWQ/s+WPcIPP5FP2yzu6OPpYmIHF/SKvDzwyE+vqiC//fydu5+YdvBLy7+HGTlwwNXwq0z4NEbYMPj8Mx/g9tPhZX3QKz7wPvj8SMb2dO8Fx5cCn/5V43/F5FjKm1G6fS49YqT6eiO8YOnNpFhxufOneZfCBfA+/8Z1j0Mp10HJ37QD9nc/gL85V/gya/Bih9BMAs6mqCzyY/wKZ4GJbOgdCaUngRls6F0FoTzD1/53g3wm6ugeQ9s/qM/F+DyO2H8fP96LAqVr0MgBJMWH7NtIiLpwUbTVAOLFy92K1euTPl6umNxvvSbN3lmwx6+c8kc3n9SGdG4IxpzFOdmMrEw++APOAdb/gRrHvSBHy70O4hYJ9Rugbp3oH4bxHrV2AtOgFkXw5xL/Zj/bc/Bb6+DrAgsXQZNu+APX/HNR2fcBE2VsPWv0NkIGSG47kk44ayUbwsROb6Z2RvOuaRqiGkZ+OBD/4sPrOI/Nx4+odpJ4/JYMqeci+eUc8qkQoKBg1u+4nHHpj1NtHXFWDi5kFAgw9fOG3ZAzVv+tutNeOdZ6G7zO4fOZhg3D5Y+BAUVfkGtdfDUzbDx95A3AWZeDDMuhL/8ADpb4B+f83P69yfWDdEOyMobzk1z5Lra/PDWpioI5UIoGyLlcNr1kJkz0qUTGZMU+EnqisZZsbmarmicYIYRyDB21rfx7KZqXtteTyzuyApmMHtCPvMm5jOpKJs17zXw6rv1NLT59vxIVpBzZpZwwYnlzK/Ip6Iwm+LcTH9lre522LoC3nrSh9/F3/M1/EO11kJOiZ+/H6B6E9x9MZSdBNf98eDzBnpsfwl+/wVo3u2nhTj3ZoiUDe8GaqnxRzUbfw9Tz4Ul/91PQ9GXvRvgkc/5nV3eRL+j627zRz3Tzvc7OoW+HKlV9/sBFR/+Nz+UWvZT4A+DxvZuXthSw5r3Glhf1cT6XY00d0SZVJTN2dNLOHtGCTmZAZ57u5bn366hquHA1bSyQwEmF2dz2pRizppezNnTSyjPD+OcozMap6UzSlN7N42JWzTmOHtGCblZvcJ00x/goWth4TVw2R0Hdgbd7f4I4JU7oGgKnHA2rH0YgmE4+7/ApNOhqwW6Wv17LcP3CWQEIbcMJp8J2YUHf1nn/E6nqcrvQJp2wbvPwVt/hHi375eoeQumXwhX3gM5xQd/9vW7Yfm3/XIvvxNmLDnw+ppl8Njn/Q7j6ocgMzcF/1vHsabdvo+o4jQ/cECX4Dzcxsfh4c8CDpZ8B87/xkiXaFRR4KeAc47G9m4KczL7fG1bbStbq1uoamincl8722paWLl9H82dUQDysoK0dcf8XD59yMkMcOnJE7nqjMmcOrnQHyGs+CE89xMon+ubbULZsG+7v51+44Ejhtot/r0bfpfENzHfSXzC+3wfRPVbULMJOg65OEx2MZyyFBZ9xl8MftWvfMd1wSS46tf+/Vv+E95e7j8/82L42J19H2WseQh+/3mYcs6xD/32ff7oo+I0v/1GC+f80dMzt/hBADhY8Am49GfaKfb23mtw36Uw4RTfvLnxCbjuKZhy9kiX7Mh0tfm5u9Y86AdmzL3M/+0cxW9TgT9KxOKOjbuaeGVbLbsaOsjNCpCTGSSSFSQ/O0hBdoiC7BCd0Ti/f7OKJ9fupq0rxknj8vj02VO4fOEEcl/5n7B7rW8eiXaABeCCbxxci+5RtxXaG3xgZCba0F0c4lF/a9jpm4J2vOj/kIJhKJ/ja/BlJ/kwz5sI+RP8iWiHHjrvfNUfdbRW+8cZQX+EseBKOPUzkDHAKN+1v4XHboKiaTDtPP8HPOEUv+4jCTjnYM862LLcd6i3VPvlTTwVJpwMNW/D5qf893Ux39F+yqdg0Wdh3Nyhrw98bTxccHjTVDwGO1+BxkoonuFHbGUX+X6d+q1+h7PvXQhk+R10ZsQflW1Z7rffR3/um81W/Ksf6XXVr/xIr0O/777tsPNvvvlvytmD993E435AQdUbULXSVwwKT/AViPI5/hYZd+CowjnYs9aXbdtf/XfIn+hvkXF+G2YX+n8tw1cYYl2A+SPLvkamHY36bb5pM1wAN/zZH6n+4nzfd/X5Fw4+0uxoGvr6nYNop//+wazDX49F/WCKmrd9paZmsy/DmZ/3224o4nFY91t49nv+SHrKOb7ptr3e93ed9EG4/Bd++UOkwD9OtXRGeXLNLn71tx1s2NVEXjjIJ06bzKWnTGBBRcH+zuOuaJzlG/bwm1d30tjezWfOnsLliyrICg6hbTMe83+0Q21CaKyCN3/lQ2P6+4f2R/bWU/DqnX4ai95HFPkVfj6jwhP8cNfWWj91dXuDD5SeW0bQ76RCOf5xW63//MRToWCyX27DjgPLLZsNJ33Y7wg2PeGbyWJdkD/J7whjXT48MnMgpxRyS/y/kXG+szlvvG8a2/kK7HjF//EHMmHSGTD9Av9Hv3WFX27PTrBHTonvqI/1c65FMBsu/h9wxj8e2FFu+ys8coNvkiuZ5YO2oMI3zW1/ERrfO/B5C0DFIh+0nU2+Ga5pN7TV+SCOdvl/Xdy/PzPidyINO/17eoQL/XYqmel3CjVv+VFiU8/xYdhU5Zcb73UOSl8yQr6vZvaHfY21cMrBv61oF7z3qh/M0LPTKZ7uKyI7X4Gtz/rvH4/5bZdb5ndUnc1w45+hZIZfTtUq+OXfway/8+356x/1Q6n3rPPLnXY+TLvAV15q3/ZHsLWboa3eb8douz+RsqePqWf7ZBf5gRORcf75xkrfvNnzOvjXOpv96yd92PebTT69/20Si/ptuuVPfhh29UaYsBA++COY8j7/+vYXfJNV0y645uGBt3E/FPjHOeccq3Y2cN/L2/njut1E447czACnTytmSnEOT63bQ21LJ5OKsskPh9i4u4myvCyue99UCrJDbNjVxMbdTWyvbSUvHKQ0kkVpJItppTksmT2O06cWHTbyqPe627tjBDMyyAym6Lw853zw7F7j/xhrt/hbY6WvQeaWQW6pD6Nglg/ZQKavqXe3J/5Q8bXcmR+AvHEHlt1W72upBZMPhESP1jp/KL1nna9JBTL9v50tPgTbEjualmq/jh6Rcb4mPvlMHwLvPuePunB+5zPr72Dex3yI1W/z36V+q6+Zls/zO4aSGT7cOhP9KznF/jseqrEKXr4d9u3wO5jGKr9jnnqOH9475X2+jO8+72+71/jmt56aeE6x3ykGs/wRRfE035xVeuKBI7aWGh8+PSPKajatgXwdAAANxUlEQVT7cCyZCSd/EuZ+7ODaczwOHQ2+eayjwe+IwW+/YJb/Pu/82YdafeKExnAhjF8A4+b7I5PtL/gdWW+BLP/dou1+WZPP9NusZ4ePg8v+9+HNN6/cAcu/deBxxWn+d1C9Ad59wZexRyjHf/dI+YHKQijsa9WZOf4oOB6Hlj3+/Jjm3f49BZP9TqNgkj/6LT3Rb5O2enj1F/DaL/z2yIz4MocL/H3cwUfUHY1+5zz5DN88evKnBj4SPgIK/DGkrqWTV7bV8crWOv62rY53a1tZMruca86awgWzyjCDl7fWcedzW3lhi6/x5oeDzJtYwIzyXFo7Y9S2dFLT3Mm22la6onEKc0JceFI5uVkB9jT6yeSqmzpp6YzS2hXFOd+ncNGccXzk5AlccGIZzsGbO/fx2vZ6NuxqwoBQMIPMQAbhUICS3EyKczMpiWRyQnEOM8sj5IUPHJ52dMfYUddGXUsnGBh+VNTsCXnkh4d+GJtynS3QstcHUtHUw4+E2up9WE5YqNFHPZzzO48dL/md7u61vjkrbzzMvAhmXORDvanKN2dUb/RHWDMu9J36yTbtOec7ujNCfgfVe8cej/kdemuND+mCycMesID/faxdBnXbfKh3NPjaf0bAH4n2DJKYscQfCR86UGIYKfDHsGgs3m/tfHttK4EMY1JRtu/0PURrZ5Tn367hTxv3smJzNQ4Ynx+mPD9MeV4W+eEQuVkBcrOC7Kxv45n1e6hv7SI3M0BnNE407jCDGWURghlGd8w/19oZpb61i0P7oycUhKkozGZ3Ywe7Gtv7nH06NzPAJxZP5rr3TWVq6eF/8DvqWnlhSy2vvlvP5KJsPr5oEjPLDx7a2h2Ls6OulXeqW9lW28K7NX47lEQyKcnNojw/izOmFlOef/jw1sa2bva1ddEVi9PZ7Q/fZ42LEA5p6N+wcE4jj1JMgS/DIhqL8/LWOv5z4x7ywiHOmFbMaVOK+qyRx+N+FFNtSyfb69rYUt3Mlr0tVO1rZ2JhmGmlEaaV5VKe5zvH4okhqn9Ys4s/rNlFNO44d2YpeeEgXdE4ndE42+taea/eD3ctz8uitqWTuIOFkwv5wNxx7GpoZ31VI5v2NNMVPdDWWpZYR31r10GjomaPz+OCk8oYnx9mzXsNrH6vge11vZpuEjIDGSycXMjp04pYUFFASSSL4txMinMy6Y7H9w+pbe2MkZsVoCA7RH52COegcl87VQ3t7Gpop6Gtm7auKK2dMTq6Y2CQYUaGQV44yIyyiL+VR4jG4uxq6GBPUzvVTZ1E4w7nHM5BZjCDsrwsyvPClOVlkZMZIDNxdBUIGNGYoysa378NwpkZZIcCZIcC7Gvr3l+evU0d+3fS8bgjkhVkwaQC5k4oIDtzaDu43Y3tvL59Hyu317NlbwuzxkU49YRCTp1cxJSSnD4rHMmqbenkpXdqeX17PXsaO6lp7qC6uZOczAAfW1jBFadNOvxs+CGU+8UttdS0dNLQ1k19axcBM+ZO9OfazJmQf9DwaOccbV0xmjr8/7lhnFCcM+Tt1aO1M8q7ta3srG+jqb2bls4ozR1RAhnGly+aNfgC+qDAl+NKdVMHv351J0+v243DB25mMIPyvCzOmVnKubNKmV6aS01LJ4+/uYtHV1Xy1p5m8sJB5k8sYH6F/0OdWR5hWmnu/qaknp3Qe/vaePEdf77Eyu37iMYd5XlZLJxcyMITChmfHyYr6EM0GovzZuLkuvVVjf0Oo01GZiCDnKwAuZlBwiF/VOac39nVt3bR1BEdjs131AIZxqzyCLlZQdq6YrR3RemOOSoKs5lSksPU0lyyQwF/9FTbytbqVvY0+RlkczIDzCyPsLW6hdYuP5lgUU6I+RUF/jaxgLhzVO5rp3JfGzXNnUSyghTmZFKYEyIrmEF7d4z27hitnVHe3Nmwf/ryvKwgFUXZ+3d2VQ1t/G1bPWZw7sxSFk8ppjTPH8WVRjLJyQySnRkgJzNAIMP2Vxzau2K8vLWWP67bzaqdB9r3s4IZFOdm0hmNU9/qO9fN8GfOO3A4YnF32JEr+CPjKSU5zJtYwOKpRSyeUtTnEWR1cwd/3ljNnzftZeOupv3b7VAVhdm8dEsfI++SoMCXMc0lArMoJ5OMjKHVJFs6o7R0RBmXnzVoLbSnNlbf2rX/FgoY+YnhtJGsoD+JriNKY7sfxVJRGKaiMIeKomwiWf2clZz4DrUtXWytaWFbTSuZwQwmFISZUOCb2EIBwzDMfP9HbUsX1U0d1LR00tYVozsWpzvRzBYKZBAKHOhk7+iO0d7lQzQ/HKSiKIeKwmzGF4TJDGYQzDAyzKhv7WJdVSNrKxtYX9VIVyxOdihIblaAgJk/n6S2ldqWTsAflUwvizCjNJf5FQWcPrWYORPyCAYyiMUdW6qbWbWjwZ+suKuRzXuaifZKy6KcEGV5WbR1xWho87XbHpnBDHIyA5xYnsf5J5Zy3qwy5lcUEDjk/3dnXRuPrKrk929WsbP+8KOzgcydkM8lJ0/gA3PHMbnoQC3dOcfepk427Gpk464mWrqi+7d9wIy8cHD//3k07thR28q7da28W9vKxl1NdCaOrCoKsymNZJKfHSI/HGJPUwerdu7DOTihOIfFU4uYURZhemkuU0pyKcr1v6HczOCQf8e9KfBFZNg0d3TTGY1T0jNlSJI6ozG27G0hFMjocwfYFY0ndjKBw4I9GV2JmnltSyd1rV20d0X90UJXnGg8TlYwI9H0FWDexPw++4iOVlc0zoZdjbyxYx/rqhppaOumqaObpvZucrOCXDR7HH8/fxwnjcs7qmaugSjwRUTSxFACP60ugCIiks4U+CIiaUKBLyKSJhT4IiJpQoEvIpImUhr4ZvZBM9tsZu+Y2S2pXJeIiAwsZYFvZgHgDuBDwFxgqZkd4UTkIiJytFJZwz8DeMc5t8051wUsAy5L4fpERGQA/Z/7ffQqgF5XbKASOPPQN5nZTcBNiYctZrb5CNdXCtQe4WfThbbR4LSNkqPtNLhjtY2mJPvGVAZ+UpxzdwF3He1yzGxlsmebpStto8FpGyVH22lwo3EbpbJJpwqY3OvxpMRzIiIyAlIZ+K8Ds8xsmpllAp8Cnkjh+kREZAApa9JxzkXN7J+A5UAAuMc5tyFV62MYmoXSgLbR4LSNkqPtNLhRt41G1WyZIiKSOjrTVkQkTSjwRUTSxHEf+Jq+oW9mNtnMVpjZRjPbYGZfSTxfbGZ/MrMtiX+LRrqsI83MAmb2ppk9mXg8zcxeTfymHkoMOkhbZlZoZo+Y2VtmtsnMztbv6HBm9rXE39p6M3vQzMKj7bd0XAe+pm8YUBT4r865ucBZwBcT2+YW4Fnn3Czg2cTjdPcVYFOvxz8BbnPOzQT2ATeMSKlGj58BzzjnZgOn4LeVfke9mFkF8GVgsXNuPn6gyqcYZb+l4zrw0fQN/XLO7XbOrUrcb8b/kVbgt899ibfdB3xsZEo4OpjZJOAS4O7EYwOWAI8k3pLW28jMCoDzgV8COOe6nHMN6HfUlyCQbWZBIAfYzSj7LR3vgd/X9A0VI1SWUcvMpgKnAq8C45xzuxMv7QHGjVCxRoufAt8E4onHJUCDcy6aeJzuv6lpQA1wb6LZ624zy0W/o4M456qA/wnsxAd9I/AGo+y3dLwHvgzCzCLAo8BXnXNNvV9zfkxu2o7LNbOPANXOuTdGuiyjWBBYBPwf59ypQCuHNN+k++8IINGHcRl+BzkRyAU+OKKF6sPxHviavmEAZhbCh/0DzrnfJZ7ea2YTEq9PAKpHqnyjwDnAR81sO745cAm+vbowcVgO+k1VApXOuVcTjx/B7wD0OzrYxcC7zrka51w38Dv872tU/ZaO98DX9A39SLRF/xLY5Jz7914vPQF8NnH/s8Djx7pso4Vz7p+dc5Occ1Pxv52/OOeuAVYAVybelu7baA/wnpmdlHjqImAj+h0daidwlpnlJP72erbTqPotHfdn2prZh/HtsD3TN/zrCBdpVDCzc4EXgHUcaJ/+Fr4d/2HgBGAH8EnnXP2IFHIUMbP3A193zn3EzKbja/zFwJvAtc65zpEs30gys4X4Tu1MYBtwPb6yqN9RL2b2PeAq/Ai5N4Eb8W32o+a3dNwHvoiIJOd4b9IREZEkKfBFRNKEAl9EJE0o8EVE0oQCX0QkTSjwJa2YWczMVve6DdukX2Y21czWD9fyRIZbyi5xKDJKtTvnFo50IURGgmr4IoCZbTezW81snZm9ZmYzE89PNbO/mNlaM3vWzE5IPD/OzB4zszWJ2/sSiwqY2f9NzIv+n2aWPWJfSuQQCnxJN9mHNOlc1eu1RufcAuDn+LO3Af4DuM85dzLwAHB74vnbgeecc6fg55bZkHh+FnCHc24e0ABckeLvI5I0nWkracXMWpxzkT6e3w4scc5tS0w6t8c5V2JmtcAE51x34vndzrlSM6sBJvU+TT4xDfWfEhcFwcz+GxByzv0g9d9MZHCq4Ysc4Pq5PxS950mJoX4yGUUU+CIHXNXr31cS91/Gz6QJcA1+Qjrwl/X7Auy/Jm7BsSqkyJFS7UPSTbaZre71+BnnXM/QzCIzW4uvpS9NPPcl/NWevoG/8tP1iee/AtxlZjfga/JfwF/pSGTUUhu+CPvb8Bc752pHuiwiqaImHRGRNKEavohImlANX0QkTSjwRUTShAJfRCRNKPBFRNKEAl9EJE38fyT69qnA+ChRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XmcXFWd9/HPr6uqu6v3JZ19X8gOIYR9X1RQgUFQDIuKC46P4sKoD+g8M8D4OIrPiKKODqMwokhQZBOEKIsEkC0J2SCEhJCt0+k1va9VdZ4/TiXpLN1d3enqrb7v1+u+qurWrXt/p7r6d88999xzzTmHiIiMfGmDHYCIiAwMJXwRkRShhC8ikiKU8EVEUoQSvohIilDCFxFJEcFkrtzMtgENQBSIOOeWJHN7IiLStaQm/LhznXNVA7AdERHphpp0RERShCXzSlszew/YCzjgv5xzdx1hmeuB6wGys7NPmDNnTtLiEREZaVatWlXlnCtJZNlkJ/wJzrlSMxsN/BW4wTm3oqvllyxZ4lauXJm0eERERhozW5Xo+dGkNuk450rjjxXAw8BJydyeiIh0LWkJ38yyzSx333Pg/cCGZG1PRES6l8xeOmOAh81s33Z+55x7KonbExGRbiQt4TvntgLHJWv9IjJ0dXR0sGvXLlpbWwc7lBEjMzOTiRMnEgqF+ryOgeiHLyIpZteuXeTm5jJ16lTiR/lyFJxzVFdXs2vXLqZNm9bn9agfvoj0u9bWVoqLi5Xs+4mZUVxcfNRHTEr4IpIUSvb9qz++TyV8EZEUoYQvIiNOdXU1ixYtYtGiRYwdO5YJEybsf93e3p7QOq677jo2bdqU8DZ/+ctf8tWvfrWvIQ8InbQVkRGnuLiYNWvWAHDLLbeQk5PD17/+9YOWcc7hnCMt7cj13nvuuSfpcQ401fBFJGVs2bKFefPmcfXVVzN//nzKysq4/vrrWbJkCfPnz+e2227bv+wZZ5zBmjVriEQiFBQUcNNNN3Hcccdx6qmnUlFRkfA2f/vb37Jw4UIWLFjAt771LQAikQjXXnvt/vl33nknAHfccQfz5s3j2GOP5ZprrunfwqMavogk2a1/epO3dtf36zrnjc/jXy+e36fPvv3229x7770sWeKHn/ne975HUVERkUiEc889lyuuuIJ58+Yd9Jm6ujrOPvtsvve973HjjTdy9913c9NNN/W4rV27dvHP//zPrFy5kvz8fC644AIef/xxSkpKqKqqYv369QDU1tYCcPvtt7N9+3bS09P3z+tPquGLSEqZMWPG/mQPcP/997N48WIWL17Mxo0beeuttw77TDgc5qKLLgLghBNOYNu2bQlt69VXX+W8885j1KhRhEIhrrrqKlasWMHMmTPZtGkTX/7yl1m+fDn5+fkAzJ8/n2uuuYb77rvvqC6w6opq+CKSVH2tiSdLdnb2/uebN2/mxz/+Ma+99hoFBQVcc801R+zrnp6evv95IBAgEokcVQzFxcWsW7eOJ598kp/97Gf88Y9/5K677mL58uU8//zzPPbYY3z3u99l3bp1BAKBo9pWZ6rhi0jKqq+vJzc3l7y8PMrKyli+fHm/rv/kk0/mueeeo7q6mkgkwrJlyzj77LOprKzEOcdHP/pRbrvtNlavXk00GmXXrl2cd9553H777VRVVdHc3Nyv8aiGLyIpa/HixcybN485c+YwZcoUTj/99KNa369+9SsefPDB/a9XrlzJv/3bv3HOOefgnOPiiy/mQx/6EKtXr+Yzn/kMzjnMjO9///tEIhGuuuoqGhoaiMVifP3rXyc3N/doi3iQpN4Apbd0AxSRkWHjxo3MnTt3sMMYcY70vQ6ZG6CIiMjQoYQvIpIilPBFRFKEEr6ISIpQwhcRSRFK+CIiKUIJX0RGnHPPPfewi6h+9KMf8YUvfKHbz+Xk5PRq/nCjhC8iI87SpUtZtmzZQfOWLVvG0qVLBymioUEJX0RGnCuuuIInnnhi/81Otm3bxu7duznzzDNpbGzk/PPPZ/HixSxcuJBHH3004fU65/jGN77BggULWLhwIQ888AAAZWVlnHXWWSxatIgFCxbwwgsvEI1G+dSnPrV/2TvuuCMpZe0NDa0gIsn15E2wZ33/rnPsQrjoe12+XVRUxEknncSTTz7JpZdeyrJly/jYxz6GmZGZmcnDDz9MXl4eVVVVnHLKKVxyySUJ3TP2oYceYs2aNaxdu5aqqipOPPFEzjrrLH73u9/xgQ98gG9/+9tEo1Gam5tZs2YNpaWlbNiwASApwx33lmr4IjIidW7W6dyc45zjW9/6FsceeywXXHABpaWllJeXJ7TOF198kaVLlxIIBBgzZgxnn302r7/+OieeeCL33HMPt9xyC+vXryc3N5fp06ezdetWbrjhBp566iny8vKSVtZEqYYvIsnVTU08mS699FK+9rWvsXr1apqbmznhhBMAuO+++6isrGTVqlWEQiGmTp16xCGRe+Oss85ixYoVPPHEE3zqU5/ixhtv5BOf+ARr165l+fLl/OIXv+D3v/89d999d38Urc9UwxeRESknJ4dzzz2XT3/60wedrK2rq2P06NGEQiGee+45tm/fnvA6zzzzTB544AGi0SiVlZWsWLGCk046ie3btzNmzBg+97nP8dnPfpbVq1dTVVVFLBbj8ssv5zvf+Q6rV69ORjF7RTV8ERmxli5dymWXXXZQj52rr76aiy++mIULF7JkyRLmzJmT8Pouu+wyXn75ZY477jjMjNtvv52xY8fy61//mh/84AeEQiFycnK49957KS0t5brrriMWiwHw7//+7/1evt7S8Mgi0u80PHJyaHhkERFJiBK+iEiKUMIXkaQYSs3FI0F/fJ9K+CLS7zIzM6murlbS7yfOOaqrq8nMzDyq9aiXjoj0u4kTJ7Jr1y4qKysHO5QRIzMzk4kTJx7VOpTwRaTfhUIhpk2bNthhyCHUpCMikiKSnvDNLGBmb5jZ48neloiIdG0gavhfATYOwHZERKQbSU34ZjYR+BDwy2RuR0REepbsGv6PgG8Csa4WMLPrzWylma3UGX0RkeRJWsI3sw8DFc65Vd0t55y7yzm3xDm3pKSkJFnhiIikvGTW8E8HLjGzbcAy4Dwz+20StyciIt1IWsJ3zt3snJvonJsKfBx41jl3TbK2JyIi3VM/fBGRFDEgV9o65/4G/G0gtiUiIkemGr6ISIpQwhcRSRFK+CIiKUIJX0QkRSjhi4ikCCV8EZEUoYQvIpIilPBFRFKEEr6ISIpQwhcRSRFK+CIiKUIJX0QkRSjhi4ikCCV8EZEUoYQvIpIilPBFRFKEEr6ISIpQwhcRSRFK+CIiKUIJX0QkRSjhi4ikCCV8EZEU0W3CN7OAmX1toIIREZHk6TbhO+eiwNIBikVERJIomMAyL5nZT4EHgKZ9M51zq5MWlYiI9LtEEv6i+ONtneY54Lz+D0dERJKlx4TvnDt3IAIREZHk6rGXjpnlm9kPzWxlfPoPM8sfiOBERKT/JNIt826gAfhYfKoH7klmUCIi0v8SacOf4Zy7vNPrW81sTbICEhGR5Eikht9iZmfse2FmpwMtyQtJRESSIZEa/j8C93Zqt98LfDJ5IYmISDJ0m/DNLA2Y7Zw7zszyAJxz9QMSmYiI9KuerrSNAd+MP69XshcRGb4SacN/2sy+bmaTzKxo39TTh8ws08xeM7O1Zvammd3aD/EexjnH5T//O3e/+F4yVi8iMmIk0oZ/Zfzxi53mOWB6D59rA85zzjWaWQh40cyedM690oc4u2RmvFfVxLuVjf25WhGRESeRNvxrnHMv9XbFzjkH7MvCofjkeh1hAgqzQuxtbk/GqkVERoxE2vB/2teVx4dXXgNUAH91zr16hGWu33cVb2VlZZ+2U5ydQXWjEr6ISHcSacN/xswuNzPr7cqdc1Hn3CJgInCSmS04wjJ3OeeWOOeWlJSU9HYTABRmq4YvItKTRBL+54E/AG1mVm9mDWbWq946zrla4Dngwj7E2KOi7AxqmpTwRUS602PCd87lOufSnHPpzrm8+Ou8nj5nZiVmVhB/HgbeB7x99CEfrig7xN7mDmKxpJwiEBEZEbpM+GZ2Tafnpx/y3pcSWPc44DkzWwe8jm/Df7yvgXanKDuDaMxR39qRjNWLiIwI3dXwb+z0/CeHvPfpnlbsnFvnnDveOXesc26Bc+62nj7TV8XZ6QBUq1lHRKRL3SV86+L5kV4PqsJ4wt+rhC8i0qXuEr7r4vmRXg8q1fBFRHrW3YVXc+Lt7wbMiD8n/rqnq2wHlGr4IiI96y7hzx2wKI5SUZZq+CIiPeky4Tvntg9kIEcjnB4gHAqohi8i0o1ELrwaFoqy03XxlYhIN0ZMwi/OSadGwyuIiHSpVwnfzArN7NhkBXM0CrNUwxcR6U6PCd/M/mZmefGbnqwG/tvMfpj80HqnODtdI2aKiHQjkRp+fvzWhh8B7nXOnQxckNyweq8wO10jZoqIdCORhB80s3HAx4CkjIXTH4qy02luj9LaER3sUEREhqREEv5twHLgXefc62Y2Hdic3LB6ryh+8ZXa8UVEjqzHe9o65/6AHw9/3+utwOXJDKovOif88QXhQY5GRGToSeSk7XQz+5OZVZpZhZk9Gq/lDynFquGLiHQrkSad3wG/x49vPx5f278/mUH1RaESvohItxJJ+FnOud845yLx6bdAZrID6y3V8EVEutdlG3683z3Ak2Z2E7AMPyzylcCfByC2XsnLDBFIMyV8EZEudHfSdhU+we+72cnnO73ngJuTFVRfpKUZhVkhjZgpItKF7kbLnNbVe2YWSk44R6cwK10jZoqIdCHhsXTMO9/MfgXsSmJMfaYRM0VEupZIt8xTzOxOYDvwKLACmJPswPpCI2aKiHSty4RvZt81s83A/wXWAccDlc65Xzvn9g5UgL2hETNFRLrW3UnbzwLvAD8H/uScazOzIXXz8kMVZ6dT29xONOYIpFnPHxARSSHdNemMA74DXAy8a2a/AcJm1uNwDIOlMDudmIO6lo7BDkVEZMjprpdOFHgKeMrMMoAPA2Gg1Myecc5dNUAxJqzzeDr7nouIiJdQbd051wb8EfijmeUB/5DUqPpII2aKiHSt180z8Zuh3JuEWI7agYTfNsiRiIgMPSPmJuYAxdkZANQ0qQ1fRORQIyfhO0dhtr8AWDV8EZHDJdSkY2anAVM7L++cGxrNOrEY/GghHH8NGefeTE5GUDV8EZEj6DHhx7tjzgDWAPtuGOsYKu34aWlgBnu3AVCYHVINX0TkCBKp4S8B5jnnhu5FVwWToXYHAEXZGdQ0q4YvInKoRNrwNwBjkx3IUcmfBHU7ASjKUg1fRORIEqnhjwLeMrPXgP2Z1Dl3SdKi6q2CybD+9xDtoCg7g3fKGwc7IhGRISeRhH9LsoM4agWTwcWgvpTinHSqVcMXETlMjwnfOfd8X1ZsZpPwJ3bH4E/y3uWc+3Ff1tWjgsn+sXYHhVkTaO2I0dweISt9yA77IyIy4BIdD/91M2s0s3Yzi5pZfQLrjgD/5JybB5wCfNHM5h1twEfUKeHrZuYiIkeWyEnbnwJLgc34wdM+C/yspw8558qcc6vjzxuAjcCEvofajbwJYGm+hq+ELyJyRAldaeuc2wIEnHNR59w9wIW92YiZTcXfQOXVI7x3vZmtNLOVlZWVvVntAcF0yB0PtTs0gJqISBcSaeRuNrN0YI2Z3Q6U0bt74ebgR9r8anzgtYM45+4C7gJYsmRJ3/v6x/viK+GLiBxZIon72vhyXwKagEnA5Yms3MxC+GR/n3Puob4GmRAlfBGRbiXSS2e7mYWBcc65WxNdsZkZ8Ctgo3Puh0cRY2LiffHzQo5gminhi4gcIpFeOhfjx9F5Kv56kZk9lsC6T8cfHZxnZmvi0wePKtruFEwCF8MayijMTmdvsxK+iEhniV54dRLwNwDn3Bozm9bTh5xzLwIDdyfxQ7pmVjcq4YuIdJZIG36Hc67ukHlDbyC1gy6+SleTjojIIRJJ+G+a2VVAwMxmmdlPgL8nOa7ey5sImD9xm5NOjZp0REQOkkjCvwGYjx847X6gHvhqMoPqk2A65MX74quGLyJymER66TQD345PQ9u+rpkT06lr6SASjREMjJy7OIqIHI0uE35PPXGG1PDI+xRMhu0vUzQ7HeegtqWDUTkZgx2ViMiQ0F0N/1RgJ74Z51UGssdNXxVMhvUPUhz2tfq9Te1K+CIicd0l/LHA+/ADp10FPAHc75x7cyAC65OCyeCijLMaAKqb2pk1yCGJiAwVXTZwxwdKe8o590n88MZbgL+Z2ZcGLLreinfNHBUtBzS8gohIZ92etDWzDOBD+Fr+VOBO4OHkh9VH+ZMAKGzfA4xSwhcR6aS7k7b3AguAPwO3Ouc2DFhUfZXv++JntexGCV9E5GDd9Vm8BpgFfAX4u5nVx6eGBO94NfCCGZA7jmD9TnIzg0r4IiKddFnDd84Nzw7snYZJVsIXETlgeCb17hRMhtrtjMnLpKyuZbCjEREZMkZmwq8r5ZiSTDZXNOLc0BvnTURkMIzMhO+iLMxtpra5g2o164iIACM14QNzw3sB2FzeOJjRiIgMGSM24U9OqwJgS6USvogIjMSEnz/RP7TvIScjyJbyhkEOSERkaBh5CT/eF99qdzJjdI5q+CIicSMv4cP+rpmzRueoDV9EJG4EJ/wdzBydQ0VDG3UtHYMdkYjIoBu5Cb++lGNGZQKwpUK1fBGRkZvwYxGOyfaJ/l0lfBGREZzwgXGukoxgGpsr1FNHRGSEJvwpAATqdjK9JEdNOiIijNSEH++LT+0O31NHCV9EZIQm/HhffOp8T53S2haa2yODHZWIyKAamQkfoGg6VG5i1ugcnIOtlU2DHZGIyKAauQl//PGwZz0zizMAdc0UERnZCT/SytTYDoJppp46IpLyRm7Cn7AYgNCeN5hSnKUavoikvJGb8AunQbgQSlcxa3SueuqISMobuQnfDMYvht1vMHN0Dturm2mPxAY7KhGRQTNyEz74Zp2KjcwpDhCNObZVq6eOiKSupCV8M7vbzCrMbEOyttGj8YvBRZln2wDd7lBEUlsya/j/A1yYxPX3LH7idmLLRszUNVNEUlvSEr5zbgVQk6z1JyR3LORNIH3PGiYWhtU1U0RS2qC34ZvZ9Wa20sxWVlZW9v8Gxh8Pu1cza3SuavgiktIGPeE75+5yzi1xzi0pKSnp/w1MOAFqtrKwKMrWqiaiMdf/2xARGQYGPeEnXbwdf3FoG+2RGDtrmgc5IBGRwTHyE/64RQDM6tgMoAuwRCRlJbNb5v3Ay8BsM9tlZp9J1ra6FS6A4pmU1PveoWrHF5FUFUzWip1zS5O17l6bcAKhrc8zNu969dQRkZQ18pt0wF+A1biHE4tbdfGViKSs1Ej48RO3F+SXsmF3HeX1rYMckIjIwEuNhD92IaQFOStrO87Bn9buHuyIREQGXGok/FAYRs+jsHYDCyfk88ia0u6Xr9wED1wL9doxiMjIkRoJH3yzzu43uPS4sWworWdLdydvn/wmbHwMHvkCxDSksoiMDKmT8McvhtY6LpvSRprBI290UXvf8gxs/RtMOd0/vvqLgYxSRCRpUifhTzgBgOK6Nzl95igeXVuKc4cMsxCLwdP/CgVT4NqH4ZgL4elboPytgY9XRKSfpU7CL5kDwTCUrubSRRPYWdPC6h17D15m/R9gz3o4/18gmAGX/AQycuGhz0GkbXDiFhHpJ6mT8ANBGHccvPc8H5idT0Yw7eBmnY5WePbf/FAM8z/i5+WMhkt/CuUb4NnvDE7cIiL9JHUSPsAJn4SKt8h94AounZ3JE+vL6IjGT8q+/t9QtxPedyukdfpaZl8EJ1wHf/8JvPfC4MQtw0/tTmitG+woRA6SWgl/0VXw0f+B3W9wS/mXyW/ezgubK6FlL6z4fzDjfJh+zuGf+8D/haLp8PA/QvMA3NNFzUfDW0st/NeZ/vciMoSkVsIHmH8ZfOpxwrEmHsn4F9a/9CS8eIevjb3v1iN/Jj0bPvLf0FgO914CjUm4UUtTNbz6X/BfZ8H3JsOWp/t/GzIwXvlPX4nY9GeofnewoxHZL/USPsCkk7DPPkNbxii+sONG3Cu/gGOv9FfkdmXiCXDVMqjaAvdcBHW7jj6OaAQ2PQkPXAP/Mdv3/8egcCosuwa2//3otyEDq7kGXv5PmHomBNLVrVeGlNRM+ABF09h52aOsjM0mShqc9+1uF99T18rva2ez9/JlvqZ/90V9r721NfikcOciuP/jsOMVOPnz8I8vweefh08+DgWT4L6PQenqvm1jMOx4Fdb9Ad56DN5Z7q9j2PEKtKXQgHUv/RjaG+GDP4AFV8Ab9/kmHpEhwA7riz6IlixZ4lauXDlg24vFHGd9/xnmFMb4j0+eS344dND7zjlefrea37yynb+8VU405sgPh/jRWcY5r12PBUJw7SMwZl5iG6zf7ZttVt4DbXX+4q5T/hcc8wEIHLxt6krhngt9srzuzzB6bj+VOgliUd/D6cU7jvz+qNnwuWd8F9eRrLECfnwczPkQXP5LKFvrm+je/x047YbBjk5GKDNb5ZxbktCyqZzwAX789GbuePodACYUhJk7Lpe54/LIyQjyh1W72FLRSEFWiCuXTOLsY0r4f3/ZxOodtVw7o4Vbar9NINoKi6+FzHzILIg/5kNHM9SXQcNu/1i/G3a9Di4K8y6FU2/wzUTdqdnqjyRwcN2TUDwjuV/Gztdh2wo4+R/9eYtEtOyFP37Wn3NY8mk4+QsQbYNIO0RaYe978NgNMPcSf8LcLKlFGFRP3ex36F98DUbN9PPu+RDU7oAvv+G7Bov0MyX8XojFHCs2V/JWWT1vlzWwsax+/83Oj5uYz7WnTuXDx44jMxQAIBpz3PPSe/xg+SamB6v4Xf7PKWjaikVajryBQAbkjYPc8TB+kW+6KZyaeIAVb/tzBqEsX3MMF/gdS7gAwoUw8UTIHnV0X0LtDnj6VtjwoH89ej5c+ZuedzAVG+H+pf58xgd/AEuuO/JyL/7IX8H8gX+HU//X0cU6VNWVwp3Hw8KPwj/87MD8jY/DA1fDx+71O3qRfqaEf5RaO6JUN7UzoSDc5TJbKxv5339cx+vb9lKYFeL48WGOH53GwmKYU+AIhcNUMYqKSJiqpnaqGtpp6YgSCqQRChjBNCMYSGNMXiZnH1NCerDr0yltO1YTfejzhFv2YG31B79paTD5NJh7Mcz9MORPjBeiztfYd/zdt627KEw6CSadApNOhuxiaK33zTAv/8yv57Qb/MVpj33JDzPxkbtg9oWHB+QcvPUIPPJFyMiBj/0GJp/c9RfqnD8x/c5T/vzElFO7+/qHp8dvhNX3wg2roHDKgfmxqN8R5I2HTz81ePElItLmd/xbnoaP3wejZg12RJIAJfwBEos5Hl1byqtba1hfWsc75Q10RHv/fY7KyeDKEyfy8RMnM6koa//8t3bX88DrO3j4jVLqWyOkB9N4/5xRfGR+LmdMCJHeWukHe9v4J6jc6D80/njf+6d8A+DAAj6JW5pvU451+OWKZ0FrLTRVwrEfh/P/z4Gdxd7t8PtPQNkaOOubcM5NgMGu1+CtR/326nb68Ymu/K1PZj1prYO7zoH2Zvj8Csgd0+vvacjaux1+cgIs/gR8+IeHv//yf8Lym+Fzz+2/Gc+QU7UFHrwO9qyD9BzIyINPP9m7o1EZFEr4g6QtEuWdPY1s2F1HJBpjVE4Go3IzKM5OZ1RuBlmhAJGYoz0aIxJ1dERjvLW7nvte3cGzb5fjgLOPKeG0GcU8sa6MtbvqSA+mcdGCsbx/3lhee6+ax9eVUd3UTn44xAcXjuP8OaM5cVoR+U3b4e0/+W6ewUyYchpMPhUmLjnQHt/RArvf8D1ndr7qa97n3HTkJNTRCn/+J3jjt36k0frd0LjHdzWccT7MuwQWXO7HHErUng3wywv8juITjx65Tbu9yTcx7d0Otdv9jqWxEpoq/M6pqcpPAGlBf7I7LeCfhwshZwzkjj3wWDgNxsz3A+KlJaFTWrQDHv0SvPkwfGXNkXd+rfXww3kw54P+qGkocQ7W/A7+/A3/t/yH/4T8SfA/8ebD655MbIc+XNTu8Dvglr2+iXTmBZCe1fPneisWg9KV/jdYMLn/19+JEv4wtLu2hWWv72TZazuoaGhj9phcPn7SJC47fgIFWen7l+uIxnhxSxWPvFHKX94sp6UjihnMG5fHKdOLOXlaERMKwwTSfLNRmhmBNCM/HCI/HMJ6c9LUOVj9a3jhP/xRwrx/gFnvh8y8vhd07TJ4+PMw/VzIKvY1/7Z6/9hUBc1VBy8fyPDJO6cEsuNTVrE/Yol1+CaTWASi7b4PfGM5NOzxj5FOt7JMz4HR8+LJf5JfbyAdgun+MSMPiqb5K6pDXTflEe3wO81tL8C2l/zOs6MJTvkiXPjdrj/35E3w+i/hq+v9OZ2+ikagahPsXuOP2Co3+p3Z5FP8Dr5oeuInxptrfKLf8KC/buAjdx1I7rtW+YsM88b7pN/TeSLnfCeDsjX+HNO4Rb7Z8NBlqt/1TUZbnvYdG6adBTPO85WKoz2pHWn3FYAjlb9qs2++XPcAYL4psmUvhLLhmPf78yvjjoPqrf77rdwEVe9AczVMWAJTz4BpZ/acvOt3w5r7YPVvfIXFAv5iz9O/7Nd/JLU7feeGaWf1qdhK+MNYJBqjrK6ViYXhHpNza0eUNTtreWVrNa9srWb1jlraI13fsCU7PcDEwiwmFoaZUBhmSnE2s8fkMmdcLqNyDq+pt7RH2V7TRFVDO8dPLiA7o596mTx9q2/vzsw70KspM9/X0Asm+wRWMMW3hWeX9K1nj3O+yar6Xd+8Vf4WlL/pn7f20C8+b4JPnHkTfJ/6lr0HpuZqv3MBKJnrE8HUM2DOh7tPWDVb4c7FvkZZMtsnu44Wf0SDg4z8g7+LYIaPs7kamuPbbdzjT5Tv25GFsv269r7nYwP/fU062TftjVngd3D5Ew98h1Wb/bmUTU/Bjpf9vHNvhjNu9EdKnW17CX57ue9x9MnHfY0f/E6nbodvBtq9GnathNJV0HLIsCPIbFsNAAAOwUlEQVR5E32SG3esPzrb8jTs3ebfK57pu+nuXnOg/NPO9Mu31sW/6xq/zrYGn8iDYQhl+iPYQMgfObXUHPh+Ii1+x108w6+/aIZvknrnKd8UGcyEEz4Fp30JcsbC9hfhzUd8E+WhFY1wkf9uMwv80fC+shVM9ufMckb7+NNz/M7D0vx6Nv8FXMwn70VX+9/cynugvcEP23L6V3xz6rYX49MLfscQLoRvbO3TUagSfopq7YiyvrSOmqZ2ojG3f4rEHLXN7ZTWtrBrb3yqaaahLbL/s6Ny0pk9NpexeWF27W1mW3UT5fUHxvQJhwKcP3c0lxw3nrNnl5ARPJAcnHNUNraxraoZYP/RRH44RGYorXdHFcnmnD85GW33077nLXt9Uq7Z6ncSNe/6I4WMXP/PuG/KKvZNUlNO633vqIc+D+uW+R5X+6b0LMAOHOW0H3KRWjDTbzNc5Lc3Zn48iS7yiS0t4JsPqt6Bna/4I44dr/idwD4Z+f5akcYKXy7wPbFmX+hHhh27oOuYtzwNv/s4jDoG8if476Z2uz+qAh/76Ln+O5m4JH6jodoDRyBla6F6iz9qmnY2zDzf7/SKpvmPN9fAe8/Du8/Cu8/5JrxgGLKKfJmzCn0Sj3b4hB5p8zvKaIevMIQL48sV+R3lvjJWb/E1Z5z//Imf9de85JQcXsZYFLa/5P/2xbN8ou/8t43F/JHUthfhvRXxnVutj6eznLFw/NVw/DW+wrBPa51P+q/83O+09wkX+mtxpp7pKw1j5vepcqOELwmpamxj054G3t7TwNtl9Wwqb6C8vpWJhVlMLc5manEWU0dlk5sZ5OmN5fx5/R5qmtrJzQxywdwxRGKO96oaea+yiab26BG3kR5IozA7xKicDIpzMhiVk05JTgaTi7M4c2YJk4u7bj/d29TOO+UNZKUH/Q4kK0RuRpC0tCG0A+kt57r/p45GfPLvaPEJoa/ty631/migfEP8yOZNXxM95kJ/oV9v2pU3/sk3SYULfCIrnuFrz8Uz/FFET018bY3xGnoP53v27YxDmYnH1p2OVr9zyh13dM2QXYlGfM29rcH/vYpmdH+UF2mDDQ/5HcDU0/1Otx/OKynhS1J0RGO8tKWKx9bu5tm3K8jNDDJtVA7TR2UzbVQ2U4qzCKQZdS0dB017m9qpamynurGNqsZ2Khvb9jc9TSnO4sxZozhzVgkzSrJZs7OOldtqWLl9L1sqDh+SIc38EcSCCfmcMr2Yk6YVcezE/IOOOADaIzEqG9vY29ROQ2uE+tYO/9jSQcw58jJD5IWD5GaGyM0MkpMRJCs9SDg9QDgU6LabbCJiMX/Us7u2hT11reyua6WstoX8cIjz545h7rjcoXXkI8OWEr4Mac453qtqYsU7lbywuYqXt1bT3OkIIS8zyJKpRZwwpZAFE/Jpj8SobW7fvwOpamxj9fZaNpX7G9FnBNNYNKmAYMCobGijoqGN2uaOo4oxmGZkZwQZl5/pp4Iw4/MzGZsfJjs9QGZ6gMxggMxQGunBNEr3trC5opHN5Q28U97Iu5WNtB1yPiUzlEZbJIZzMLEwzPvmjeF988aweHIhbR0xmtojNLdHaW6P0BaJ7b9mIyOYRnogQDDgdxAu/h065yvFdS0d1DS3U9PURnVjO7XNHRRkhThmTC7HjMllTF7GEXcusXiPsVAgjUA/HDW1tEd5c3cdmaEAU4qzyM0M9fyhJKttbsfMDhs2ZSRRwpdhpT0SY/WOveyoaWbRpAJmluQk1GxT09TO69tqeHVrDau215CWZpTkZDA6L4PRuZmU5GZQmJVOXjjoa/Tx2nya2f4af0P8sbHNJ9uWjigt8cTb0BqhrK6VsroWyupaqWlq7zGmCQVhZo7OYdboHKaMymZ8fibj8sOMy8+kICtEVWM7z75dzl/eLOeFLVXdnmTvKzO/I9gnNzPIMWNyyckIUtvSQV2nnWfMHfhMKJBGKM3IyggybVQ2M0pymFGSzYzROUwtziYUsP07DgMiUcf60jpWbd/Lqu01vLm7nkjswIaLs9OZGj/ym1SYxYSCMOMLwowvyGR8QZiMYBpN7VHqWjqoj8fT0BqhuT1CU5vf8TW3R2nt8JWBNDPSDMyMUMCYXpLDgvH5TCo6uINDWV0Lyzfs4ckNe3h9Ww0xd2DYlDlj85g7Lo8Zo7MZlx8mLzPY6yMt5xxtkRhtHTHaIlFaO2K0R6NkBANkZwTJzggcdsSZTEr4IknQ0h6lvL7VJ6GIT0T7/unH5GUyK55UE9XUFuGFzZVsqWgknB4kOz1AVkaQrFCAjFAakahPLO3RGB2R2P67s5mBYWA+CeZlBinKTqcoO53i7AxyM4PUNPvzH5vLG/c/tkai5IdDFGSlUxAOUZAVIjMUoGPfdSEx/1jf0sF7VU1sqWxM6EgpM5TGcRMLOGFKIYsnFxKJxdhW3cy2qia2VTexraqZ8oZWDk01gTQjGus5/wTTDhzZxOJHNp3lZQaZPz6fY8bksHZXHWt2+l5Yx4zJ4cL5YwmnB9lYVs/be+p5t7LpoG1mpQfiR3FhRudmkBfvbJAXDpGXGSQUSKO0toWdNc3siE9lda09xp0eSCM7I0Bhdjqjc30FZHSur4w4BxXxI9GK+lYqG9oIBdJY/jV1yxSRQeKco6apnXcrm9hZ07w/yTl80k0z45ixucwbl9fjOY/2SIzy+lZKa1vYXeuPmJrbI/t7c+Vl+sfczBBZGQGy04NkZQTICgUIBg5e974a9jvlDWworefN3XVs2F3Ppj31zBydw0ULxnHhgrHMKMk5LI7WjihbKhrZVt1EWW3rQUdwlQ1t1Ld0HNR7bZ9ROelMKspicpE/UsnOCJIZCpARTCMzfs6nrSNKU1uEpvjRYWNbBzVN7VTUx5N7QyutHX6nHQ4F4keifmcwoTDMtz7YtxFxlfBFRPooGnM0xk/0t0WijMsP98s1KM45GtoiGJCT0fumpK70JuFrvFYRkU4CaUZ+lu8G3J/MjLxBPpGdune8EhFJMUr4IiIpQglfRCRFKOGLiKSIpCZ8M7vQzDaZ2RYzuymZ2xIRke4lLeGbWQD4GXARMA9YambzkrU9ERHpXjJr+CcBW5xzW51z7cAyQHdxFhEZJMnshz8B2Nnp9S7gsDtdm9n1wPXxl41mtqmP2xsFVPW41PAwksoCKs9QNpLKAiOrPImWZUqiKxz0C6+cc3cBR32jTzNbmejVZkPdSCoLqDxD2UgqC4ys8iSjLMls0ikFJnV6PTE+T0REBkEyE/7rwCwzm2Zm6cDHgceSuD0REelG0pp0nHMRM/sSsBwIAHc7595M1vboh2ahIWQklQVUnqFsJJUFRlZ5+r0sQ2q0TBERSR5daSsikiKU8EVEUsSwT/jDffgGM7vbzCrMbEOneUVm9lcz2xx/LBzMGBNlZpPM7Dkze8vM3jSzr8TnD9fyZJrZa2a2Nl6eW+Pzp5nZq/Hf3APxTgnDgpkFzOwNM3s8/no4l2Wbma03szVmtjI+b1j+1gDMrMDMHjSzt81so5md2t/lGdYJf4QM3/A/wIWHzLsJeMY5Nwt4Jv56OIgA/+ScmwecAnwx/vcYruVpA85zzh0HLAIuNLNTgO8DdzjnZgJ7gc8MYoy99RVgY6fXw7ksAOc65xZ16q8+XH9rAD8GnnLOzQGOw/+d+rc8zrlhOwGnAss7vb4ZuHmw4+pDOaYCGzq93gSMiz8fB2wa7Bj7WK5HgfeNhPIAWcBq/NXiVUAwPv+g3+BQnvDXwjwDnAc8DthwLUs83m3AqEPmDcvfGpAPvEe8I02yyjOsa/gcefiGCYMUS38a45wriz/fA4wZzGD6wsymAscDrzKMyxNvAlkDVAB/Bd4Fap1z++50PZx+cz8CvgnE4q+LGb5lAXDAX8xsVXyIFhi+v7VpQCVwT7zJ7Zdmlk0/l2e4J/wRz/ld+7DqO2tmOcAfga865+o7vzfcyuOcizrnFuFrxycBcwY5pD4xsw8DFc65VYMdSz86wzm3GN+k+0UzO6vzm8PstxYEFgM/d84dDzRxSPNNf5RnuCf8kTp8Q7mZjQOIP1YMcjwJM7MQPtnf55x7KD572JZnH+dcLfAcvtmjwMz2XbQ4XH5zpwOXmNk2/Mi15+HbjIdjWQBwzpXGHyuAh/E75OH6W9sF7HLOvRp//SB+B9Cv5RnuCX+kDt/wGPDJ+PNP4tvChzwzM+BXwEbn3A87vTVcy1NiZgXx52H8+YiN+MR/RXyxYVEe59zNzrmJzrmp+P+TZ51zVzMMywJgZtlmlrvvOfB+YAPD9LfmnNsD7DSz2fFZ5wNv0d/lGeyTFf1wsuODwDv4ttVvD3Y8fYj/fqAM6MDv5T+Db1t9BtgMPA0UDXacCZblDPwh5zpgTXz64DAuz7HAG/HybAD+JT5/OvAasAX4A5Ax2LH2slznAI8P57LE414bn97c978/XH9r8dgXASvjv7dHgML+Lo+GVhARSRHDvUlHREQSpIQvIpIilPBFRFKEEr6ISIpQwhcRSRFK+JJSzCwaH11x39Rvg2uZ2dTOo56KDDVJu8WhyBDV4vxQCSIpRzV8EfaPrX57fHz118xsZnz+VDN71szWmdkzZjY5Pn+MmT0cHyt/rZmdFl9VwMz+Oz5+/l/iV+iKDAlK+JJqwoc06VzZ6b0659xC4Kf4kSUBfgL82jl3LHAfcGd8/p3A886Plb8Yf7UnwCzgZ865+UAtcHmSyyOSMF1pKynFzBqdczlHmL8Nf7OTrfEB4PY454rNrAo/HnlHfH6Zc26UmVUCE51zbZ3WMRX4q/M3q8DM/jcQcs59J/klE+mZavgiB7gunvdGW6fnUXSeTIYQJXyRA67s9Phy/Pnf8aNLAlwNvBB//gzwBdh/k5T8gQpSpK9U+5BUE47fwWqfp5xz+7pmFprZOnwtfWl83g34uxB9A39Houvi878C3GVmn8HX5L+AH/VUZMhSG74I+9vwlzjnqgY7FpFkUZOOiEiKUA1fRCRFqIYvIpIilPBFRFKEEr6ISIpQwhcRSRFK+CIiKeL/A+bt6LLlbuAfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = []\n",
    "for i in np.linspace(2, 4, 5):\n",
    "    errors.append(cv_dropout_maxnorm(0.2, 0.5, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f81e3de7b70>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(2, 4, 5), errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Crowd on jittered matrix\n",
    "\n",
    "Another good way to increase performances of a neural network is to artificially add samples to the matrix we already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22761, 3004), (22761,), (7513, 3004), (7513,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_red = np.load(DATA_FOLDER + \"x_pca_train.npy\")\n",
    "y_train = np.load(DATA_FOLDER + \"y_pca_train.npy\")\n",
    "X_test_red = np.load(DATA_FOLDER + \"x_pca_test.npy\")\n",
    "y_test = np.load(DATA_FOLDER + \"y_pca_test.npy\")\n",
    "X_train_red.shape, y_train.shape, X_test_red.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No directory with name session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse\n"
     ]
    }
   ],
   "source": [
    "cc_jitt = cc.CollaborativeCrowd(X_train_red, y_train, \"CollabCrowd_jitter\", nb_layers = 8, \\\n",
    "                      nb_neurons=156, regularization_factor=1e-6, validation_split = 0)\n",
    "cc_jitt.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 23.9304 - mean_absolute_error: 3.1023\n",
      "Epoch 00001: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 7s 295us/step - loss: 23.8162 - mean_absolute_error: 3.0920\n",
      "Epoch 2/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 1.5192 - mean_absolute_error: 0.8994\n",
      "Epoch 00002: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 265us/step - loss: 1.5184 - mean_absolute_error: 0.8991\n",
      "Epoch 3/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.7851 - mean_absolute_error: 0.6541\n",
      "Epoch 00003: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 263us/step - loss: 0.7899 - mean_absolute_error: 0.6553\n",
      "Epoch 4/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.7636 - mean_absolute_error: 0.6364\n",
      "Epoch 00004: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 267us/step - loss: 0.7626 - mean_absolute_error: 0.6362\n",
      "Epoch 5/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.7973 - mean_absolute_error: 0.6559\n",
      "Epoch 00005: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 263us/step - loss: 0.8028 - mean_absolute_error: 0.6583\n",
      "Epoch 6/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.7279 - mean_absolute_error: 0.5989\n",
      "Epoch 00006: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 268us/step - loss: 0.7259 - mean_absolute_error: 0.5982\n",
      "Epoch 7/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.5645 - mean_absolute_error: 0.5317\n",
      "Epoch 00007: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 264us/step - loss: 0.5646 - mean_absolute_error: 0.5316\n",
      "Epoch 8/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.6156 - mean_absolute_error: 0.5647\n",
      "Epoch 00008: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 263us/step - loss: 0.6148 - mean_absolute_error: 0.5641\n",
      "Epoch 9/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.4919 - mean_absolute_error: 0.4931\n",
      "Epoch 00009: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 249us/step - loss: 0.4923 - mean_absolute_error: 0.4929\n",
      "Epoch 10/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.7391 - mean_absolute_error: 0.5897\n",
      "Epoch 00010: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 277us/step - loss: 0.7377 - mean_absolute_error: 0.5891\n",
      "Epoch 11/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.4461 - mean_absolute_error: 0.4549\n",
      "Epoch 00011: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 7s 289us/step - loss: 0.4474 - mean_absolute_error: 0.4550\n",
      "Epoch 12/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.4218 - mean_absolute_error: 0.4524\n",
      "Epoch 00012: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 7s 312us/step - loss: 0.4258 - mean_absolute_error: 0.4530\n",
      "Epoch 13/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.3755 - mean_absolute_error: 0.4249\n",
      "Epoch 00013: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 260us/step - loss: 0.3768 - mean_absolute_error: 0.4254\n",
      "Epoch 14/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.4608 - mean_absolute_error: 0.4693\n",
      "Epoch 00014: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 255us/step - loss: 0.4604 - mean_absolute_error: 0.4691\n",
      "Epoch 15/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.3519 - mean_absolute_error: 0.4130\n",
      "Epoch 00015: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 282us/step - loss: 0.3519 - mean_absolute_error: 0.4130\n",
      "Epoch 16/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.3631 - mean_absolute_error: 0.4192\n",
      "Epoch 00016: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 270us/step - loss: 0.3629 - mean_absolute_error: 0.4192\n",
      "Epoch 17/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.3198 - mean_absolute_error: 0.3954\n",
      "Epoch 00017: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 252us/step - loss: 0.3197 - mean_absolute_error: 0.3955\n",
      "Epoch 18/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.2969 - mean_absolute_error: 0.3758\n",
      "Epoch 00018: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.2969 - mean_absolute_error: 0.3758\n",
      "Epoch 19/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.2892 - mean_absolute_error: 0.3656\n",
      "Epoch 00019: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 245us/step - loss: 0.2900 - mean_absolute_error: 0.3661\n",
      "Epoch 20/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.2995 - mean_absolute_error: 0.3792\n",
      "Epoch 00020: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 246us/step - loss: 0.2993 - mean_absolute_error: 0.3791\n",
      "Epoch 21/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.2553 - mean_absolute_error: 0.3442\n",
      "Epoch 00021: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 246us/step - loss: 0.2547 - mean_absolute_error: 0.3439\n",
      "Epoch 22/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.2665 - mean_absolute_error: 0.3573\n",
      "Epoch 00022: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.2675 - mean_absolute_error: 0.3572\n",
      "Epoch 23/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.2213 - mean_absolute_error: 0.3183\n",
      "Epoch 00023: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.2211 - mean_absolute_error: 0.3182\n",
      "Epoch 24/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.2175 - mean_absolute_error: 0.3243\n",
      "Epoch 00024: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.2174 - mean_absolute_error: 0.3245\n",
      "Epoch 25/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.2147 - mean_absolute_error: 0.3097\n",
      "Epoch 00025: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.2147 - mean_absolute_error: 0.3096\n",
      "Epoch 26/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.1943 - mean_absolute_error: 0.3034\n",
      "Epoch 00026: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1941 - mean_absolute_error: 0.3033\n",
      "Epoch 27/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.1948 - mean_absolute_error: 0.3017\n",
      "Epoch 00027: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1948 - mean_absolute_error: 0.3018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.1802 - mean_absolute_error: 0.2897\n",
      "Epoch 00028: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.1801 - mean_absolute_error: 0.2896\n",
      "Epoch 29/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.1564 - mean_absolute_error: 0.2653\n",
      "Epoch 00029: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1566 - mean_absolute_error: 0.2655\n",
      "Epoch 30/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.1264 - mean_absolute_error: 0.2417\n",
      "Epoch 00030: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.1279 - mean_absolute_error: 0.2422\n",
      "Epoch 31/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.1548 - mean_absolute_error: 0.2746\n",
      "Epoch 00031: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1548 - mean_absolute_error: 0.2748\n",
      "Epoch 32/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.1631 - mean_absolute_error: 0.2681\n",
      "Epoch 00032: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1640 - mean_absolute_error: 0.2688\n",
      "Epoch 33/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.1726 - mean_absolute_error: 0.2844\n",
      "Epoch 00033: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.1725 - mean_absolute_error: 0.2843\n",
      "Epoch 34/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.1510 - mean_absolute_error: 0.2653\n",
      "Epoch 00034: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.1508 - mean_absolute_error: 0.2652\n",
      "Epoch 35/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.1305 - mean_absolute_error: 0.2396\n",
      "Epoch 00035: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.1301 - mean_absolute_error: 0.2393\n",
      "Epoch 36/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.2386\n",
      "Epoch 00036: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1247 - mean_absolute_error: 0.2385\n",
      "Epoch 37/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.1450 - mean_absolute_error: 0.2568\n",
      "Epoch 00037: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.1451 - mean_absolute_error: 0.2570\n",
      "Epoch 38/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.1172 - mean_absolute_error: 0.2387\n",
      "Epoch 00038: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1173 - mean_absolute_error: 0.2388\n",
      "Epoch 39/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2395\n",
      "Epoch 00039: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1183 - mean_absolute_error: 0.2399\n",
      "Epoch 40/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.2296\n",
      "Epoch 00040: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 5s 241us/step - loss: 0.1125 - mean_absolute_error: 0.2297\n",
      "Epoch 41/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.1359 - mean_absolute_error: 0.2376\n",
      "Epoch 00041: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1356 - mean_absolute_error: 0.2375\n",
      "Epoch 42/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0970 - mean_absolute_error: 0.2148\n",
      "Epoch 00042: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0969 - mean_absolute_error: 0.2148\n",
      "Epoch 43/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.1121 - mean_absolute_error: 0.2203\n",
      "Epoch 00043: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.1120 - mean_absolute_error: 0.2203\n",
      "Epoch 44/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.2098\n",
      "Epoch 00044: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0958 - mean_absolute_error: 0.2101\n",
      "Epoch 45/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0960 - mean_absolute_error: 0.2114\n",
      "Epoch 00045: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0959 - mean_absolute_error: 0.2114\n",
      "Epoch 46/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0848 - mean_absolute_error: 0.1982\n",
      "Epoch 00046: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0848 - mean_absolute_error: 0.1982\n",
      "Epoch 47/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0978 - mean_absolute_error: 0.2081\n",
      "Epoch 00047: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0980 - mean_absolute_error: 0.2083\n",
      "Epoch 48/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.1009 - mean_absolute_error: 0.2166\n",
      "Epoch 00048: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.1007 - mean_absolute_error: 0.2163\n",
      "Epoch 49/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0889 - mean_absolute_error: 0.2001\n",
      "Epoch 00049: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0888 - mean_absolute_error: 0.2001\n",
      "Epoch 50/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0889 - mean_absolute_error: 0.2041\n",
      "Epoch 00050: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0895 - mean_absolute_error: 0.2047\n",
      "Epoch 51/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0819 - mean_absolute_error: 0.1941\n",
      "Epoch 00051: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0821 - mean_absolute_error: 0.1946\n",
      "Epoch 52/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0792 - mean_absolute_error: 0.1882\n",
      "Epoch 00052: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0791 - mean_absolute_error: 0.1881\n",
      "Epoch 53/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0816 - mean_absolute_error: 0.1929\n",
      "Epoch 00053: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0816 - mean_absolute_error: 0.1928\n",
      "Epoch 54/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0867 - mean_absolute_error: 0.1950\n",
      "Epoch 00054: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0875 - mean_absolute_error: 0.1952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0860 - mean_absolute_error: 0.1930\n",
      "Epoch 00055: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0858 - mean_absolute_error: 0.1927\n",
      "Epoch 56/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0641 - mean_absolute_error: 0.1671\n",
      "Epoch 00056: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 5s 240us/step - loss: 0.0643 - mean_absolute_error: 0.1674\n",
      "Epoch 57/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0772 - mean_absolute_error: 0.1777\n",
      "Epoch 00057: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0771 - mean_absolute_error: 0.1777\n",
      "Epoch 58/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0660 - mean_absolute_error: 0.1647\n",
      "Epoch 00058: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0658 - mean_absolute_error: 0.1645\n",
      "Epoch 59/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0608 - mean_absolute_error: 0.1542\n",
      "Epoch 00059: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0607 - mean_absolute_error: 0.1542\n",
      "Epoch 60/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0622 - mean_absolute_error: 0.1604\n",
      "Epoch 00060: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.0623 - mean_absolute_error: 0.1605\n",
      "Epoch 61/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.1723\n",
      "Epoch 00061: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0670 - mean_absolute_error: 0.1725\n",
      "Epoch 62/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0733 - mean_absolute_error: 0.1768\n",
      "Epoch 00062: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0742 - mean_absolute_error: 0.1774\n",
      "Epoch 63/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0757 - mean_absolute_error: 0.1743\n",
      "Epoch 00063: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 245us/step - loss: 0.0757 - mean_absolute_error: 0.1743\n",
      "Epoch 64/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0908 - mean_absolute_error: 0.1896\n",
      "Epoch 00064: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0907 - mean_absolute_error: 0.1896\n",
      "Epoch 65/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0801 - mean_absolute_error: 0.1746\n",
      "Epoch 00065: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0799 - mean_absolute_error: 0.1744\n",
      "Epoch 66/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0594 - mean_absolute_error: 0.1384\n",
      "Epoch 00066: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0593 - mean_absolute_error: 0.1384\n",
      "Epoch 67/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0466 - mean_absolute_error: 0.1339\n",
      "Epoch 00067: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0466 - mean_absolute_error: 0.1338\n",
      "Epoch 68/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0640 - mean_absolute_error: 0.1600\n",
      "Epoch 00068: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0640 - mean_absolute_error: 0.1600\n",
      "Epoch 69/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0627 - mean_absolute_error: 0.1550\n",
      "Epoch 00069: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0629 - mean_absolute_error: 0.1551\n",
      "Epoch 70/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.1613\n",
      "Epoch 00070: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.0675 - mean_absolute_error: 0.1613\n",
      "Epoch 71/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.1611\n",
      "Epoch 00071: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 5s 241us/step - loss: 0.0671 - mean_absolute_error: 0.1611\n",
      "Epoch 72/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0553 - mean_absolute_error: 0.1436\n",
      "Epoch 00072: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0553 - mean_absolute_error: 0.1436\n",
      "Epoch 73/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0561 - mean_absolute_error: 0.1447\n",
      "Epoch 00073: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0561 - mean_absolute_error: 0.1446\n",
      "Epoch 74/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.1492\n",
      "Epoch 00074: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0681 - mean_absolute_error: 0.1493\n",
      "Epoch 75/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0695 - mean_absolute_error: 0.1576\n",
      "Epoch 00075: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0694 - mean_absolute_error: 0.1575\n",
      "Epoch 76/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0513 - mean_absolute_error: 0.1327\n",
      "Epoch 00076: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0516 - mean_absolute_error: 0.1328\n",
      "Epoch 77/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0531 - mean_absolute_error: 0.1331\n",
      "Epoch 00077: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0530 - mean_absolute_error: 0.1330\n",
      "Epoch 78/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0547 - mean_absolute_error: 0.1372\n",
      "Epoch 00078: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0547 - mean_absolute_error: 0.1371\n",
      "Epoch 79/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0705 - mean_absolute_error: 0.1659\n",
      "Epoch 00079: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0703 - mean_absolute_error: 0.1656\n",
      "Epoch 80/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0466 - mean_absolute_error: 0.1271\n",
      "Epoch 00080: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0466 - mean_absolute_error: 0.1271\n",
      "Epoch 81/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0499 - mean_absolute_error: 0.1316\n",
      "Epoch 00081: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0499 - mean_absolute_error: 0.1317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0550 - mean_absolute_error: 0.1468\n",
      "Epoch 00082: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0550 - mean_absolute_error: 0.1468\n",
      "Epoch 83/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.1667\n",
      "Epoch 00083: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0673 - mean_absolute_error: 0.1666\n",
      "Epoch 84/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0539 - mean_absolute_error: 0.1440\n",
      "Epoch 00084: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0538 - mean_absolute_error: 0.1439\n",
      "Epoch 85/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0575 - mean_absolute_error: 0.1490\n",
      "Epoch 00085: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0575 - mean_absolute_error: 0.1491\n",
      "Epoch 86/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0597 - mean_absolute_error: 0.1517\n",
      "Epoch 00086: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 5s 241us/step - loss: 0.0596 - mean_absolute_error: 0.1515\n",
      "Epoch 87/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0544 - mean_absolute_error: 0.1428\n",
      "Epoch 00087: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0543 - mean_absolute_error: 0.1427\n",
      "Epoch 88/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0613 - mean_absolute_error: 0.1468\n",
      "Epoch 00088: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0613 - mean_absolute_error: 0.1468\n",
      "Epoch 89/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0528 - mean_absolute_error: 0.1388\n",
      "Epoch 00089: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0528 - mean_absolute_error: 0.1388\n",
      "Epoch 90/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0565 - mean_absolute_error: 0.1388\n",
      "Epoch 00090: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0565 - mean_absolute_error: 0.1389\n",
      "Epoch 91/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0502 - mean_absolute_error: 0.1328\n",
      "Epoch 00091: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0510 - mean_absolute_error: 0.1329\n",
      "Epoch 92/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0482 - mean_absolute_error: 0.1287\n",
      "Epoch 00092: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0482 - mean_absolute_error: 0.1287\n",
      "Epoch 93/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0432 - mean_absolute_error: 0.1199\n",
      "Epoch 00093: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0432 - mean_absolute_error: 0.1199\n",
      "Epoch 94/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0440 - mean_absolute_error: 0.1234\n",
      "Epoch 00094: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0441 - mean_absolute_error: 0.1236\n",
      "Epoch 95/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0530 - mean_absolute_error: 0.1420\n",
      "Epoch 00095: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0533 - mean_absolute_error: 0.1426\n",
      "Epoch 96/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0639 - mean_absolute_error: 0.1590\n",
      "Epoch 00096: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0639 - mean_absolute_error: 0.1590\n",
      "Epoch 97/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0513 - mean_absolute_error: 0.1357\n",
      "Epoch 00097: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0511 - mean_absolute_error: 0.1354\n",
      "Epoch 98/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0539 - mean_absolute_error: 0.1421\n",
      "Epoch 00098: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0539 - mean_absolute_error: 0.1421\n",
      "Epoch 99/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.1228\n",
      "Epoch 00099: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0459 - mean_absolute_error: 0.1230\n",
      "Epoch 100/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0526 - mean_absolute_error: 0.1346\n",
      "Epoch 00100: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0526 - mean_absolute_error: 0.1345\n",
      "Epoch 101/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0522 - mean_absolute_error: 0.1360\n",
      "Epoch 00101: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0521 - mean_absolute_error: 0.1359\n",
      "Epoch 102/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0470 - mean_absolute_error: 0.1263\n",
      "Epoch 00102: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0471 - mean_absolute_error: 0.1263\n",
      "Epoch 103/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0543 - mean_absolute_error: 0.1365\n",
      "Epoch 00103: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 5s 242us/step - loss: 0.0542 - mean_absolute_error: 0.1364\n",
      "Epoch 104/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0579 - mean_absolute_error: 0.1404\n",
      "Epoch 00104: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0579 - mean_absolute_error: 0.1405\n",
      "Epoch 105/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0445 - mean_absolute_error: 0.1202\n",
      "Epoch 00105: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0445 - mean_absolute_error: 0.1201\n",
      "Epoch 106/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0456 - mean_absolute_error: 0.1170\n",
      "Epoch 00106: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0457 - mean_absolute_error: 0.1171\n",
      "Epoch 107/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0429 - mean_absolute_error: 0.1149\n",
      "Epoch 00107: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 5s 241us/step - loss: 0.0429 - mean_absolute_error: 0.1149\n",
      "Epoch 108/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0443 - mean_absolute_error: 0.1195\n",
      "Epoch 00108: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0444 - mean_absolute_error: 0.1196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0512 - mean_absolute_error: 0.1355\n",
      "Epoch 00109: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0513 - mean_absolute_error: 0.1354\n",
      "Epoch 110/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.1220\n",
      "Epoch 00110: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0465 - mean_absolute_error: 0.1222\n",
      "Epoch 111/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0435 - mean_absolute_error: 0.1182\n",
      "Epoch 00111: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0435 - mean_absolute_error: 0.1182\n",
      "Epoch 112/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0492 - mean_absolute_error: 0.1307\n",
      "Epoch 00112: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0492 - mean_absolute_error: 0.1307\n",
      "Epoch 113/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0498 - mean_absolute_error: 0.1309\n",
      "Epoch 00113: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0497 - mean_absolute_error: 0.1308\n",
      "Epoch 114/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0533 - mean_absolute_error: 0.1331\n",
      "Epoch 00114: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0532 - mean_absolute_error: 0.1331\n",
      "Epoch 115/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0551 - mean_absolute_error: 0.1394\n",
      "Epoch 00115: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0551 - mean_absolute_error: 0.1395\n",
      "Epoch 116/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0475 - mean_absolute_error: 0.1212\n",
      "Epoch 00116: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.0475 - mean_absolute_error: 0.1212\n",
      "Epoch 117/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0444 - mean_absolute_error: 0.1171\n",
      "Epoch 00117: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0447 - mean_absolute_error: 0.1173\n",
      "Epoch 118/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0454 - mean_absolute_error: 0.1181\n",
      "Epoch 00118: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0455 - mean_absolute_error: 0.1182\n",
      "Epoch 119/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0424 - mean_absolute_error: 0.1137\n",
      "Epoch 00119: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 251us/step - loss: 0.0423 - mean_absolute_error: 0.1136\n",
      "Epoch 120/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0457 - mean_absolute_error: 0.1154\n",
      "Epoch 00120: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 256us/step - loss: 0.0457 - mean_absolute_error: 0.1154\n",
      "Epoch 121/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0457 - mean_absolute_error: 0.1057\n",
      "Epoch 00121: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 249us/step - loss: 0.0460 - mean_absolute_error: 0.1064\n",
      "Epoch 122/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0535 - mean_absolute_error: 0.1133\n",
      "Epoch 00122: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 246us/step - loss: 0.0534 - mean_absolute_error: 0.1133\n",
      "Epoch 123/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0444 - mean_absolute_error: 0.0952\n",
      "Epoch 00123: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 274us/step - loss: 0.0444 - mean_absolute_error: 0.0951\n",
      "Epoch 124/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0437 - mean_absolute_error: 0.0955\n",
      "Epoch 00124: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 284us/step - loss: 0.0437 - mean_absolute_error: 0.0955\n",
      "Epoch 125/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0463 - mean_absolute_error: 0.1001\n",
      "Epoch 00125: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 264us/step - loss: 0.0462 - mean_absolute_error: 0.1001\n",
      "Epoch 126/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0547 - mean_absolute_error: 0.1252\n",
      "Epoch 00126: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 263us/step - loss: 0.0547 - mean_absolute_error: 0.1253\n",
      "Epoch 127/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0646 - mean_absolute_error: 0.1372\n",
      "Epoch 00127: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 270us/step - loss: 0.0645 - mean_absolute_error: 0.1371\n",
      "Epoch 128/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0537 - mean_absolute_error: 0.1150\n",
      "Epoch 00128: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 255us/step - loss: 0.0537 - mean_absolute_error: 0.1150\n",
      "Epoch 129/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0483 - mean_absolute_error: 0.1047\n",
      "Epoch 00129: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 253us/step - loss: 0.0483 - mean_absolute_error: 0.1048\n",
      "Epoch 130/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0454 - mean_absolute_error: 0.0967\n",
      "Epoch 00130: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 251us/step - loss: 0.0453 - mean_absolute_error: 0.0967\n",
      "Epoch 131/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0468 - mean_absolute_error: 0.1009\n",
      "Epoch 00131: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 258us/step - loss: 0.0467 - mean_absolute_error: 0.1009\n",
      "Epoch 132/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0495 - mean_absolute_error: 0.1097\n",
      "Epoch 00132: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 7s 292us/step - loss: 0.0495 - mean_absolute_error: 0.1097\n",
      "Epoch 133/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0556 - mean_absolute_error: 0.1199\n",
      "Epoch 00133: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 258us/step - loss: 0.0556 - mean_absolute_error: 0.1199\n",
      "Epoch 134/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0516 - mean_absolute_error: 0.1130\n",
      "Epoch 00134: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0515 - mean_absolute_error: 0.1129\n",
      "Epoch 135/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0504 - mean_absolute_error: 0.1142\n",
      "Epoch 00135: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 248us/step - loss: 0.0504 - mean_absolute_error: 0.1142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0526 - mean_absolute_error: 0.1236\n",
      "Epoch 00136: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0525 - mean_absolute_error: 0.1235\n",
      "Epoch 137/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0549 - mean_absolute_error: 0.1276\n",
      "Epoch 00137: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0548 - mean_absolute_error: 0.1275\n",
      "Epoch 138/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1050\n",
      "Epoch 00138: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0397 - mean_absolute_error: 0.1050\n",
      "Epoch 139/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0427 - mean_absolute_error: 0.1117\n",
      "Epoch 00139: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0426 - mean_absolute_error: 0.1117\n",
      "Epoch 140/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0467 - mean_absolute_error: 0.1244\n",
      "Epoch 00140: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 268us/step - loss: 0.0467 - mean_absolute_error: 0.1245\n",
      "Epoch 141/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0441 - mean_absolute_error: 0.1193\n",
      "Epoch 00141: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 7s 294us/step - loss: 0.0441 - mean_absolute_error: 0.1193\n",
      "Epoch 142/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0491 - mean_absolute_error: 0.1258\n",
      "Epoch 00142: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 272us/step - loss: 0.0492 - mean_absolute_error: 0.1261\n",
      "Epoch 143/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0524 - mean_absolute_error: 0.1341\n",
      "Epoch 00143: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 272us/step - loss: 0.0525 - mean_absolute_error: 0.1341\n",
      "Epoch 144/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0498 - mean_absolute_error: 0.1259\n",
      "Epoch 00144: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0498 - mean_absolute_error: 0.1259\n",
      "Epoch 145/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0422 - mean_absolute_error: 0.1108\n",
      "Epoch 00145: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 246us/step - loss: 0.0422 - mean_absolute_error: 0.1107\n",
      "Epoch 146/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1074\n",
      "Epoch 00146: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 262us/step - loss: 0.0401 - mean_absolute_error: 0.1075\n",
      "Epoch 147/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0413 - mean_absolute_error: 0.1121\n",
      "Epoch 00147: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 263us/step - loss: 0.0413 - mean_absolute_error: 0.1121\n",
      "Epoch 148/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0457 - mean_absolute_error: 0.1229\n",
      "Epoch 00148: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 7s 286us/step - loss: 0.0457 - mean_absolute_error: 0.1229\n",
      "Epoch 149/200\n",
      "22560/22761 [============================>.] - ETA: 0s - loss: 0.0462 - mean_absolute_error: 0.1234\n",
      "Epoch 00149: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 255us/step - loss: 0.0461 - mean_absolute_error: 0.1232\n",
      "Epoch 150/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1124\n",
      "Epoch 00150: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 254us/step - loss: 0.0421 - mean_absolute_error: 0.1123\n",
      "Epoch 151/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0461 - mean_absolute_error: 0.1206\n",
      "Epoch 00151: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 251us/step - loss: 0.0461 - mean_absolute_error: 0.1206\n",
      "Epoch 152/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0474 - mean_absolute_error: 0.1228\n",
      "Epoch 00152: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 255us/step - loss: 0.0474 - mean_absolute_error: 0.1228\n",
      "Epoch 153/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0420 - mean_absolute_error: 0.1145\n",
      "Epoch 00153: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 248us/step - loss: 0.0420 - mean_absolute_error: 0.1145\n",
      "Epoch 154/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0396 - mean_absolute_error: 0.1075\n",
      "Epoch 00154: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 282us/step - loss: 0.0396 - mean_absolute_error: 0.1074\n",
      "Epoch 155/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1125\n",
      "Epoch 00155: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 251us/step - loss: 0.0421 - mean_absolute_error: 0.1125\n",
      "Epoch 156/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0518 - mean_absolute_error: 0.1315\n",
      "Epoch 00156: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 245us/step - loss: 0.0518 - mean_absolute_error: 0.1315\n",
      "Epoch 157/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0533 - mean_absolute_error: 0.1292\n",
      "Epoch 00157: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0533 - mean_absolute_error: 0.1292\n",
      "Epoch 158/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.0961\n",
      "Epoch 00158: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 242us/step - loss: 0.0357 - mean_absolute_error: 0.0961\n",
      "Epoch 159/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.0850\n",
      "Epoch 00159: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 245us/step - loss: 0.0314 - mean_absolute_error: 0.0850\n",
      "Epoch 160/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.0937\n",
      "Epoch 00160: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 247us/step - loss: 0.0338 - mean_absolute_error: 0.0937\n",
      "Epoch 161/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0405 - mean_absolute_error: 0.1108\n",
      "Epoch 00161: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 246us/step - loss: 0.0405 - mean_absolute_error: 0.1108\n",
      "Epoch 162/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1099\n",
      "Epoch 00162: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.0400 - mean_absolute_error: 0.1099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0403 - mean_absolute_error: 0.1114\n",
      "Epoch 00163: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 244us/step - loss: 0.0403 - mean_absolute_error: 0.1113\n",
      "Epoch 164/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0435 - mean_absolute_error: 0.1136\n",
      "Epoch 00164: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 260us/step - loss: 0.0435 - mean_absolute_error: 0.1136\n",
      "Epoch 165/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.0970\n",
      "Epoch 00165: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 253us/step - loss: 0.0359 - mean_absolute_error: 0.0971\n",
      "Epoch 166/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0460 - mean_absolute_error: 0.1062\n",
      "Epoch 00166: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 250us/step - loss: 0.0459 - mean_absolute_error: 0.1062\n",
      "Epoch 167/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.0916\n",
      "Epoch 00167: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 267us/step - loss: 0.0342 - mean_absolute_error: 0.0916\n",
      "Epoch 168/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.0804\n",
      "Epoch 00168: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 268us/step - loss: 0.0306 - mean_absolute_error: 0.0804\n",
      "Epoch 169/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0386 - mean_absolute_error: 0.1067\n",
      "Epoch 00169: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 276us/step - loss: 0.0386 - mean_absolute_error: 0.1066\n",
      "Epoch 170/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0426 - mean_absolute_error: 0.1153\n",
      "Epoch 00170: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 248us/step - loss: 0.0427 - mean_absolute_error: 0.1153\n",
      "Epoch 171/200\n",
      "22624/22761 [============================>.] - ETA: 0s - loss: 0.0423 - mean_absolute_error: 0.1135\n",
      "Epoch 00171: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 245us/step - loss: 0.0423 - mean_absolute_error: 0.1133\n",
      "Epoch 172/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0430 - mean_absolute_error: 0.1110\n",
      "Epoch 00172: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 5s 242us/step - loss: 0.0432 - mean_absolute_error: 0.1115\n",
      "Epoch 173/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0481 - mean_absolute_error: 0.1166\n",
      "Epoch 00173: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 265us/step - loss: 0.0484 - mean_absolute_error: 0.1171\n",
      "Epoch 174/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0485 - mean_absolute_error: 0.1233\n",
      "Epoch 00174: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 268us/step - loss: 0.0485 - mean_absolute_error: 0.1233\n",
      "Epoch 175/200\n",
      "22656/22761 [============================>.] - ETA: 0s - loss: 0.0431 - mean_absolute_error: 0.1046\n",
      "Epoch 00175: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 261us/step - loss: 0.0432 - mean_absolute_error: 0.1049\n",
      "Epoch 176/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0610 - mean_absolute_error: 0.1365\n",
      "Epoch 00176: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 272us/step - loss: 0.0609 - mean_absolute_error: 0.1364\n",
      "Epoch 177/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0402 - mean_absolute_error: 0.1006\n",
      "Epoch 00177: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 249us/step - loss: 0.0402 - mean_absolute_error: 0.1006\n",
      "Epoch 178/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.0879\n",
      "Epoch 00178: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 270us/step - loss: 0.0347 - mean_absolute_error: 0.0881\n",
      "Epoch 179/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.0897\n",
      "Epoch 00179: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 256us/step - loss: 0.0345 - mean_absolute_error: 0.0897\n",
      "Epoch 180/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0351 - mean_absolute_error: 0.0903\n",
      "Epoch 00180: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 243us/step - loss: 0.0351 - mean_absolute_error: 0.0903\n",
      "Epoch 181/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0395 - mean_absolute_error: 0.1025\n",
      "Epoch 00181: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 245us/step - loss: 0.0395 - mean_absolute_error: 0.1025\n",
      "Epoch 182/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1055\n",
      "Epoch 00182: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 248us/step - loss: 0.0398 - mean_absolute_error: 0.1055\n",
      "Epoch 183/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1026\n",
      "Epoch 00183: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 252us/step - loss: 0.0406 - mean_absolute_error: 0.1026\n",
      "Epoch 184/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0377 - mean_absolute_error: 0.1005\n",
      "Epoch 00184: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 7s 289us/step - loss: 0.0377 - mean_absolute_error: 0.1005\n",
      "Epoch 185/200\n",
      "22688/22761 [============================>.] - ETA: 0s - loss: 0.0407 - mean_absolute_error: 0.1088\n",
      "Epoch 00185: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 246us/step - loss: 0.0408 - mean_absolute_error: 0.1088\n",
      "Epoch 186/200\n",
      "22720/22761 [============================>.] - ETA: 0s - loss: 0.0455 - mean_absolute_error: 0.1181\n",
      "Epoch 00186: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 246us/step - loss: 0.0455 - mean_absolute_error: 0.1180\n",
      "Epoch 187/200\n",
      "22752/22761 [============================>.] - ETA: 0s - loss: 0.0457 - mean_absolute_error: 0.1142\n",
      "Epoch 00187: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 253us/step - loss: 0.0457 - mean_absolute_error: 0.1143\n",
      "Epoch 188/200\n",
      "22592/22761 [============================>.] - ETA: 0s - loss: 0.0425 - mean_absolute_error: 0.1073\n",
      "Epoch 00188: saving model to session/CollabCrowd_jitter_8_156_relu_1e-06_0.001_mse/0\n",
      "22761/22761 [==============================] - 6s 245us/step - loss: 0.0425 - mean_absolute_error: 0.1072\n"
     ]
    }
   ],
   "source": [
    "cc_jitt.train_new_entities(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.117733862088689"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last, avg, last5 = cc_jitt.predict(X_test_red)\n",
    "rmse(avg, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
